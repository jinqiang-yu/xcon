2022-01-05 15:41:46 - INFO - saving to ./results/large/quantise/q4/other/fairml/compas/compas_test1/
2022-01-05 15:41:46 - DEBUG - run arguments: Namespace(config='./configs/config_large.json', data='../../paper_bench/complete/quantise/q4/other/fairml/compas/compas_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/large/quantise/q4/other/fairml/compas/compas_test1/', test='../../paper_bench/cv/test/quantise/q4/other/fairml/compas/compas_test1_data.csv', train='../../paper_bench/cv/train/quantise/q4/other/fairml/compas/compas_train1_data.csv')
2022-01-05 15:41:46 - INFO - creating model mlp_binary
2022-01-05 15:41:46 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [64, 32, 24, 2]}
2022-01-05 15:41:46 - INFO - number of parameters: 4762
2022-01-05 15:41:46 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-05 15:41:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:46 - INFO - TRAINING - Epoch: [0][0/78]	Time 0.157 (0.157)	Data 0.148 (0.148)	Loss 2.5705 (2.5705)	Prec@1 51.562 (51.562)	
2022-01-05 15:41:46 - INFO - TRAINING - Epoch: [0][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.7663 (2.0818)	Prec@1 59.375 (50.426)	
2022-01-05 15:41:46 - INFO - TRAINING - Epoch: [0][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.7349 (1.6875)	Prec@1 59.375 (51.711)	
2022-01-05 15:41:46 - INFO - TRAINING - Epoch: [0][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6657 (1.4560)	Prec@1 65.625 (53.327)	
2022-01-05 15:41:46 - INFO - TRAINING - Epoch: [0][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.2175 (1.4488)	Prec@1 62.500 (54.078)	
2022-01-05 15:41:46 - INFO - TRAINING - Epoch: [0][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8420 (1.4277)	Prec@1 45.312 (53.799)	
2022-01-05 15:41:46 - INFO - TRAINING - Epoch: [0][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1504 (1.3822)	Prec@1 64.062 (54.150)	
2022-01-05 15:41:46 - INFO - TRAINING - Epoch: [0][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7869 (1.3302)	Prec@1 60.938 (54.555)	
2022-01-05 15:41:46 - INFO - EVALUATING - Epoch: [0][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.2268 (0.2268)	Prec@1 100.000 (100.000)	
2022-01-05 15:41:46 - INFO - EVALUATING - Epoch: [0][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.5952 (1.4814)	Prec@1 81.250 (73.580)	
2022-01-05 15:41:46 - INFO - 
 Epoch: 1	Training Loss 1.2960 	Training Prec@1 55.033 	Validation Loss 1.7238 	Validation Prec@1 63.725 	
2022-01-05 15:41:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:47 - INFO - TRAINING - Epoch: [1][0/78]	Time 0.153 (0.153)	Data 0.146 (0.146)	Loss 2.1949 (2.1949)	Prec@1 54.688 (54.688)	
2022-01-05 15:41:47 - INFO - TRAINING - Epoch: [1][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.5947 (2.4792)	Prec@1 64.062 (52.273)	
2022-01-05 15:41:47 - INFO - TRAINING - Epoch: [1][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.5935 (1.9727)	Prec@1 70.312 (53.869)	
2022-01-05 15:41:47 - INFO - TRAINING - Epoch: [1][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.0847 (1.7040)	Prec@1 46.875 (54.788)	
2022-01-05 15:41:47 - INFO - TRAINING - Epoch: [1][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 2.5290 (1.7172)	Prec@1 56.250 (54.764)	
2022-01-05 15:41:47 - INFO - TRAINING - Epoch: [1][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.7372 (1.6436)	Prec@1 68.750 (55.392)	
2022-01-05 15:41:47 - INFO - TRAINING - Epoch: [1][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.5614 (1.5484)	Prec@1 50.000 (56.045)	
2022-01-05 15:41:47 - INFO - TRAINING - Epoch: [1][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.5001 (1.4972)	Prec@1 60.938 (56.536)	
2022-01-05 15:41:47 - INFO - EVALUATING - Epoch: [1][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.7749 (0.7749)	Prec@1 50.000 (50.000)	
2022-01-05 15:41:47 - INFO - EVALUATING - Epoch: [1][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.7801 (0.8496)	Prec@1 67.188 (77.841)	
2022-01-05 15:41:47 - INFO - 
 Epoch: 2	Training Loss 1.4639 	Training Prec@1 56.715 	Validation Loss 1.3040 	Validation Prec@1 66.559 	
2022-01-05 15:41:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:47 - INFO - TRAINING - Epoch: [2][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 1.1176 (1.1176)	Prec@1 64.062 (64.062)	
2022-01-05 15:41:47 - INFO - TRAINING - Epoch: [2][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.6722 (1.7665)	Prec@1 67.188 (53.551)	
2022-01-05 15:41:47 - INFO - TRAINING - Epoch: [2][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.2334 (1.5707)	Prec@1 32.812 (53.051)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [2][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.1384 (1.3845)	Prec@1 53.125 (54.990)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [2][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.9159 (1.4103)	Prec@1 45.312 (55.373)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [2][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 2.2174 (1.3817)	Prec@1 53.125 (56.495)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [2][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 2.3493 (1.4008)	Prec@1 64.062 (56.250)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [2][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 2.3007 (1.4871)	Prec@1 42.188 (56.008)	
2022-01-05 15:41:48 - INFO - EVALUATING - Epoch: [2][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.7168 (0.7168)	Prec@1 29.688 (29.688)	
2022-01-05 15:41:48 - INFO - EVALUATING - Epoch: [2][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.9718 (0.8480)	Prec@1 46.875 (55.540)	
2022-01-05 15:41:48 - INFO - 
 Epoch: 3	Training Loss 1.5045 	Training Prec@1 56.269 	Validation Loss 1.0669 	Validation Prec@1 56.923 	
2022-01-05 15:41:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [3][0/78]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 0.9452 (0.9452)	Prec@1 68.750 (68.750)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [3][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.7580 (1.7220)	Prec@1 60.938 (59.801)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [3][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.9825 (1.3916)	Prec@1 75.000 (60.193)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [3][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.8850 (1.4167)	Prec@1 54.688 (59.224)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [3][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.6269 (1.4567)	Prec@1 54.688 (57.355)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [3][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7736 (1.4126)	Prec@1 62.500 (56.863)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [3][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8227 (1.3877)	Prec@1 67.188 (57.172)	
2022-01-05 15:41:48 - INFO - TRAINING - Epoch: [3][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1511 (1.4046)	Prec@1 64.062 (56.690)	
2022-01-05 15:41:49 - INFO - EVALUATING - Epoch: [3][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.7320 (0.7320)	Prec@1 76.562 (76.562)	
2022-01-05 15:41:49 - INFO - EVALUATING - Epoch: [3][10/20]	Time 0.004 (0.017)	Data 0.002 (0.015)	Loss 2.7023 (1.3513)	Prec@1 17.188 (51.705)	
2022-01-05 15:41:49 - INFO - 
 Epoch: 4	Training Loss 1.3831 	Training Prec@1 56.593 	Validation Loss 1.5236 	Validation Prec@1 51.336 	
2022-01-05 15:41:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:49 - INFO - TRAINING - Epoch: [4][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 1.2653 (1.2653)	Prec@1 56.250 (56.250)	
2022-01-05 15:41:49 - INFO - TRAINING - Epoch: [4][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.6968 (2.1562)	Prec@1 53.125 (56.250)	
2022-01-05 15:41:49 - INFO - TRAINING - Epoch: [4][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 2.7465 (2.0278)	Prec@1 37.500 (54.018)	
2022-01-05 15:41:49 - INFO - TRAINING - Epoch: [4][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.1426 (1.8160)	Prec@1 53.125 (54.587)	
2022-01-05 15:41:49 - INFO - TRAINING - Epoch: [4][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.3488 (1.7034)	Prec@1 42.188 (54.345)	
2022-01-05 15:41:49 - INFO - TRAINING - Epoch: [4][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.2968 (1.6427)	Prec@1 43.750 (53.952)	
2022-01-05 15:41:49 - INFO - TRAINING - Epoch: [4][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0106 (1.5711)	Prec@1 48.438 (54.329)	
2022-01-05 15:41:49 - INFO - TRAINING - Epoch: [4][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7349 (1.5205)	Prec@1 60.938 (53.917)	
2022-01-05 15:41:49 - INFO - EVALUATING - Epoch: [4][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.9185 (0.9185)	Prec@1 45.312 (45.312)	
2022-01-05 15:41:49 - INFO - EVALUATING - Epoch: [4][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.4464 (0.8662)	Prec@1 85.938 (77.415)	
2022-01-05 15:41:50 - INFO - 
 Epoch: 5	Training Loss 1.4990 	Training Prec@1 54.365 	Validation Loss 1.3953 	Validation Prec@1 62.348 	
2022-01-05 15:41:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:50 - INFO - TRAINING - Epoch: [5][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 1.5443 (1.5443)	Prec@1 62.500 (62.500)	
2022-01-05 15:41:50 - INFO - TRAINING - Epoch: [5][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.2937 (2.3821)	Prec@1 68.750 (56.534)	
2022-01-05 15:41:50 - INFO - TRAINING - Epoch: [5][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.9742 (1.8245)	Prec@1 68.750 (55.357)	
2022-01-05 15:41:50 - INFO - TRAINING - Epoch: [5][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.2198 (1.6759)	Prec@1 65.625 (56.099)	
2022-01-05 15:41:50 - INFO - TRAINING - Epoch: [5][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 2.9880 (1.6111)	Prec@1 54.688 (55.793)	
2022-01-05 15:41:50 - INFO - TRAINING - Epoch: [5][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.2093 (1.6703)	Prec@1 60.938 (56.281)	
2022-01-05 15:41:50 - INFO - TRAINING - Epoch: [5][60/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 2.2507 (1.6282)	Prec@1 46.875 (56.045)	
2022-01-05 15:41:50 - INFO - TRAINING - Epoch: [5][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.8342 (1.6069)	Prec@1 62.500 (56.140)	
2022-01-05 15:41:50 - INFO - EVALUATING - Epoch: [5][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.7403 (0.7403)	Prec@1 81.250 (81.250)	
2022-01-05 15:41:50 - INFO - EVALUATING - Epoch: [5][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 2.7413 (2.1183)	Prec@1 45.312 (53.835)	
2022-01-05 15:41:50 - INFO - 
 Epoch: 6	Training Loss 1.6462 	Training Prec@1 56.066 	Validation Loss 2.3925 	Validation Prec@1 50.202 	
2022-01-05 15:41:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:50 - INFO - TRAINING - Epoch: [6][0/78]	Time 0.153 (0.153)	Data 0.147 (0.147)	Loss 2.6001 (2.6001)	Prec@1 45.312 (45.312)	
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [6][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.4420 (2.8804)	Prec@1 56.250 (56.818)	
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [6][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.5347 (2.3101)	Prec@1 31.250 (55.432)	
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [6][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.9735 (2.0160)	Prec@1 59.375 (55.746)	
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [6][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.9225 (1.7988)	Prec@1 50.000 (56.402)	
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [6][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.3879 (1.7522)	Prec@1 54.688 (56.403)	
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [6][60/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 1.0728 (1.6358)	Prec@1 67.188 (56.916)	
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [6][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.4642 (1.5502)	Prec@1 53.125 (57.350)	
2022-01-05 15:41:51 - INFO - EVALUATING - Epoch: [6][0/20]	Time 0.150 (0.150)	Data 0.147 (0.147)	Loss 11.0847 (11.0847)	Prec@1 23.438 (23.438)	
2022-01-05 15:41:51 - INFO - EVALUATING - Epoch: [6][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 4.9607 (3.8569)	Prec@1 46.875 (51.705)	
2022-01-05 15:41:51 - INFO - 
 Epoch: 7	Training Loss 1.5996 	Training Prec@1 57.180 	Validation Loss 4.0030 	Validation Prec@1 54.170 	
2022-01-05 15:41:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [7][0/78]	Time 0.155 (0.155)	Data 0.150 (0.150)	Loss 3.1246 (3.1246)	Prec@1 59.375 (59.375)	
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [7][10/78]	Time 0.005 (0.019)	Data 0.002 (0.016)	Loss 1.2275 (2.0819)	Prec@1 64.062 (55.682)	
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [7][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.4148 (1.7921)	Prec@1 50.000 (54.167)	
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [7][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.0155 (1.5661)	Prec@1 37.500 (54.435)	
2022-01-05 15:41:51 - INFO - TRAINING - Epoch: [7][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.0428 (1.4889)	Prec@1 54.688 (55.412)	
2022-01-05 15:41:52 - INFO - TRAINING - Epoch: [7][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.2712 (1.3913)	Prec@1 37.500 (56.342)	
2022-01-05 15:41:52 - INFO - TRAINING - Epoch: [7][60/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 1.1666 (1.3725)	Prec@1 62.500 (56.250)	
2022-01-05 15:41:52 - INFO - TRAINING - Epoch: [7][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0562 (1.3778)	Prec@1 51.562 (56.338)	
2022-01-05 15:41:52 - INFO - EVALUATING - Epoch: [7][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.5067 (0.5067)	Prec@1 50.000 (50.000)	
2022-01-05 15:41:52 - INFO - EVALUATING - Epoch: [7][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.8406 (0.7771)	Prec@1 67.188 (75.426)	
2022-01-05 15:41:52 - INFO - 
 Epoch: 8	Training Loss 1.4252 	Training Prec@1 56.107 	Validation Loss 1.1804 	Validation Prec@1 66.640 	
2022-01-05 15:41:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:52 - INFO - TRAINING - Epoch: [8][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.7222 (0.7222)	Prec@1 79.688 (79.688)	
2022-01-05 15:41:52 - INFO - TRAINING - Epoch: [8][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 0.9731 (1.6670)	Prec@1 64.062 (57.244)	
2022-01-05 15:41:52 - INFO - TRAINING - Epoch: [8][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0211 (1.3807)	Prec@1 64.062 (59.301)	
2022-01-05 15:41:52 - INFO - TRAINING - Epoch: [8][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.9021 (1.3562)	Prec@1 64.062 (58.468)	
2022-01-05 15:41:52 - INFO - TRAINING - Epoch: [8][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.7495 (1.3649)	Prec@1 46.875 (57.317)	
2022-01-05 15:41:52 - INFO - TRAINING - Epoch: [8][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 2.0100 (1.3263)	Prec@1 40.625 (57.108)	
2022-01-05 15:41:52 - INFO - TRAINING - Epoch: [8][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8512 (1.3370)	Prec@1 51.562 (56.865)	
2022-01-05 15:41:52 - INFO - TRAINING - Epoch: [8][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7901 (1.3054)	Prec@1 62.500 (56.932)	
2022-01-05 15:41:53 - INFO - EVALUATING - Epoch: [8][0/20]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 1.8723 (1.8723)	Prec@1 29.688 (29.688)	
2022-01-05 15:41:53 - INFO - EVALUATING - Epoch: [8][10/20]	Time 0.004 (0.017)	Data 0.002 (0.015)	Loss 0.9676 (0.8312)	Prec@1 50.000 (62.926)	
2022-01-05 15:41:53 - INFO - 
 Epoch: 9	Training Loss 1.2937 	Training Prec@1 57.201 	Validation Loss 0.9495 	Validation Prec@1 57.652 	
2022-01-05 15:41:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:53 - INFO - TRAINING - Epoch: [9][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.9747 (0.9747)	Prec@1 53.125 (53.125)	
2022-01-05 15:41:53 - INFO - TRAINING - Epoch: [9][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.7540 (1.9503)	Prec@1 56.250 (55.966)	
2022-01-05 15:41:53 - INFO - TRAINING - Epoch: [9][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 2.7107 (1.7098)	Prec@1 53.125 (57.292)	
2022-01-05 15:41:53 - INFO - TRAINING - Epoch: [9][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.8694 (1.5853)	Prec@1 62.500 (56.351)	
2022-01-05 15:41:53 - INFO - TRAINING - Epoch: [9][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.7876 (1.4811)	Prec@1 53.125 (56.479)	
2022-01-05 15:41:53 - INFO - TRAINING - Epoch: [9][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.1234 (1.4743)	Prec@1 57.812 (56.893)	
2022-01-05 15:41:53 - INFO - TRAINING - Epoch: [9][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6961 (1.4224)	Prec@1 62.500 (56.352)	
2022-01-05 15:41:53 - INFO - TRAINING - Epoch: [9][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.6167 (1.3490)	Prec@1 46.875 (56.492)	
2022-01-05 15:41:53 - INFO - EVALUATING - Epoch: [9][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.7989 (1.7989)	Prec@1 29.688 (29.688)	
2022-01-05 15:41:53 - INFO - EVALUATING - Epoch: [9][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.3022 (0.8266)	Prec@1 50.000 (69.886)	
2022-01-05 15:41:53 - INFO - 
 Epoch: 10	Training Loss 1.3623 	Training Prec@1 56.755 	Validation Loss 0.9677 	Validation Prec@1 62.591 	
2022-01-05 15:41:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:54 - INFO - TRAINING - Epoch: [10][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 1.2338 (1.2338)	Prec@1 51.562 (51.562)	
2022-01-05 15:41:54 - INFO - TRAINING - Epoch: [10][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.2860 (2.1834)	Prec@1 59.375 (58.239)	
2022-01-05 15:41:54 - INFO - TRAINING - Epoch: [10][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.9354 (1.8181)	Prec@1 67.188 (59.226)	
2022-01-05 15:41:54 - INFO - TRAINING - Epoch: [10][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.5472 (1.6336)	Prec@1 54.688 (57.913)	
2022-01-05 15:41:54 - INFO - TRAINING - Epoch: [10][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.0881 (1.5960)	Prec@1 53.125 (56.898)	
2022-01-05 15:41:54 - INFO - TRAINING - Epoch: [10][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9966 (1.5198)	Prec@1 39.062 (56.801)	
2022-01-05 15:41:54 - INFO - TRAINING - Epoch: [10][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.2787 (1.4626)	Prec@1 62.500 (56.685)	
2022-01-05 15:41:54 - INFO - TRAINING - Epoch: [10][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1085 (1.3808)	Prec@1 67.188 (56.580)	
2022-01-05 15:41:54 - INFO - EVALUATING - Epoch: [10][0/20]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.7933 (0.7933)	Prec@1 23.438 (23.438)	
2022-01-05 15:41:54 - INFO - EVALUATING - Epoch: [10][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.7167 (0.7157)	Prec@1 46.875 (51.705)	
2022-01-05 15:41:54 - INFO - 
 Epoch: 11	Training Loss 1.3522 	Training Prec@1 57.221 	Validation Loss 0.7006 	Validation Prec@1 54.170 	
2022-01-05 15:41:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:54 - INFO - TRAINING - Epoch: [11][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.6605 (0.6605)	Prec@1 64.062 (64.062)	
2022-01-05 15:41:54 - INFO - TRAINING - Epoch: [11][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.1764 (2.0197)	Prec@1 68.750 (58.381)	
2022-01-05 15:41:54 - INFO - TRAINING - Epoch: [11][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.9182 (1.9383)	Prec@1 73.438 (57.812)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [11][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6996 (1.6509)	Prec@1 51.562 (57.359)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [11][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.7118 (1.6213)	Prec@1 46.875 (57.203)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [11][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.1110 (1.4840)	Prec@1 54.688 (57.169)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [11][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.3741 (1.4611)	Prec@1 59.375 (57.223)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [11][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8776 (1.3946)	Prec@1 65.625 (57.702)	
2022-01-05 15:41:55 - INFO - EVALUATING - Epoch: [11][0/20]	Time 0.148 (0.148)	Data 0.146 (0.146)	Loss 1.2434 (1.2434)	Prec@1 23.438 (23.438)	
2022-01-05 15:41:55 - INFO - EVALUATING - Epoch: [11][10/20]	Time 0.004 (0.017)	Data 0.002 (0.015)	Loss 0.9357 (0.8723)	Prec@1 46.875 (51.705)	
2022-01-05 15:41:55 - INFO - 
 Epoch: 12	Training Loss 1.3691 	Training Prec@1 57.343 	Validation Loss 0.8400 	Validation Prec@1 54.170 	
2022-01-05 15:41:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [12][0/78]	Time 0.153 (0.153)	Data 0.146 (0.146)	Loss 0.7921 (0.7921)	Prec@1 57.812 (57.812)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [12][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 2.5527 (1.6199)	Prec@1 50.000 (58.097)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [12][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.2716 (1.4310)	Prec@1 65.625 (59.077)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [12][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7424 (1.3557)	Prec@1 59.375 (58.216)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [12][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.8685 (1.2816)	Prec@1 67.188 (58.270)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [12][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.4800 (1.3381)	Prec@1 42.188 (57.506)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [12][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1941 (1.3309)	Prec@1 51.562 (57.275)	
2022-01-05 15:41:55 - INFO - TRAINING - Epoch: [12][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6749 (1.3198)	Prec@1 65.625 (57.526)	
2022-01-05 15:41:56 - INFO - EVALUATING - Epoch: [12][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 2.9533 (2.9533)	Prec@1 23.438 (23.438)	
2022-01-05 15:41:56 - INFO - EVALUATING - Epoch: [12][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 2.6865 (1.8198)	Prec@1 46.875 (51.705)	
2022-01-05 15:41:56 - INFO - 
 Epoch: 13	Training Loss 1.3145 	Training Prec@1 57.869 	Validation Loss 1.7850 	Validation Prec@1 53.927 	
2022-01-05 15:41:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:56 - INFO - TRAINING - Epoch: [13][0/78]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 2.2686 (2.2686)	Prec@1 45.312 (45.312)	
2022-01-05 15:41:56 - INFO - TRAINING - Epoch: [13][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.4027 (2.4577)	Prec@1 62.500 (52.983)	
2022-01-05 15:41:56 - INFO - TRAINING - Epoch: [13][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.9398 (1.8833)	Prec@1 65.625 (53.497)	
2022-01-05 15:41:56 - INFO - TRAINING - Epoch: [13][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6691 (1.6097)	Prec@1 70.312 (54.335)	
2022-01-05 15:41:56 - INFO - TRAINING - Epoch: [13][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.0551 (1.4347)	Prec@1 62.500 (55.259)	
2022-01-05 15:41:56 - INFO - TRAINING - Epoch: [13][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.1129 (1.4021)	Prec@1 39.062 (54.994)	
2022-01-05 15:41:56 - INFO - TRAINING - Epoch: [13][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0600 (1.3597)	Prec@1 59.375 (55.379)	
2022-01-05 15:41:56 - INFO - TRAINING - Epoch: [13][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8110 (1.3540)	Prec@1 51.562 (56.008)	
2022-01-05 15:41:56 - INFO - EVALUATING - Epoch: [13][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 1.2567 (1.2567)	Prec@1 50.000 (50.000)	
2022-01-05 15:41:56 - INFO - EVALUATING - Epoch: [13][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 2.1032 (0.9030)	Prec@1 48.438 (71.165)	
2022-01-05 15:41:57 - INFO - 
 Epoch: 14	Training Loss 1.3441 	Training Prec@1 55.884 	Validation Loss 1.2311 	Validation Prec@1 62.834 	
2022-01-05 15:41:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:57 - INFO - TRAINING - Epoch: [14][0/78]	Time 0.153 (0.153)	Data 0.147 (0.147)	Loss 1.0820 (1.0820)	Prec@1 68.750 (68.750)	
2022-01-05 15:41:57 - INFO - TRAINING - Epoch: [14][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.0754 (1.8057)	Prec@1 62.500 (53.125)	
2022-01-05 15:41:57 - INFO - TRAINING - Epoch: [14][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.3601 (1.6265)	Prec@1 43.750 (54.390)	
2022-01-05 15:41:57 - INFO - TRAINING - Epoch: [14][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.7532 (1.6274)	Prec@1 53.125 (55.444)	
2022-01-05 15:41:57 - INFO - TRAINING - Epoch: [14][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.4472 (1.6117)	Prec@1 54.688 (54.383)	
2022-01-05 15:41:57 - INFO - TRAINING - Epoch: [14][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.5072 (1.6165)	Prec@1 57.812 (54.013)	
2022-01-05 15:41:57 - INFO - TRAINING - Epoch: [14][60/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 2.1213 (1.6162)	Prec@1 68.750 (54.022)	
2022-01-05 15:41:57 - INFO - TRAINING - Epoch: [14][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 2.2475 (1.6536)	Prec@1 45.312 (54.269)	
2022-01-05 15:41:57 - INFO - EVALUATING - Epoch: [14][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.1032 (0.1032)	Prec@1 100.000 (100.000)	
2022-01-05 15:41:57 - INFO - EVALUATING - Epoch: [14][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.7118 (1.0043)	Prec@1 71.875 (69.460)	
2022-01-05 15:41:57 - INFO - 
 Epoch: 15	Training Loss 1.6128 	Training Prec@1 54.385 	Validation Loss 1.1665 	Validation Prec@1 61.700 	
2022-01-05 15:41:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:57 - INFO - TRAINING - Epoch: [15][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.9255 (0.9255)	Prec@1 62.500 (62.500)	
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [15][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.8731 (1.9107)	Prec@1 50.000 (58.523)	
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [15][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0197 (1.8017)	Prec@1 67.188 (55.283)	
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [15][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8725 (1.5405)	Prec@1 40.625 (55.494)	
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [15][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.7073 (1.4300)	Prec@1 54.688 (56.784)	
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [15][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9361 (1.3397)	Prec@1 67.188 (57.200)	
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [15][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.9433 (1.3485)	Prec@1 60.938 (56.634)	
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [15][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1015 (1.3193)	Prec@1 42.188 (56.558)	
2022-01-05 15:41:58 - INFO - EVALUATING - Epoch: [15][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 1.3077 (1.3077)	Prec@1 26.562 (26.562)	
2022-01-05 15:41:58 - INFO - EVALUATING - Epoch: [15][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.2357 (1.4302)	Prec@1 85.938 (70.881)	
2022-01-05 15:41:58 - INFO - 
 Epoch: 16	Training Loss 1.2824 	Training Prec@1 56.654 	Validation Loss 2.1122 	Validation Prec@1 60.243 	
2022-01-05 15:41:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [16][0/78]	Time 0.154 (0.154)	Data 0.148 (0.148)	Loss 1.8813 (1.8813)	Prec@1 65.625 (65.625)	
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [16][10/78]	Time 0.005 (0.019)	Data 0.002 (0.016)	Loss 3.0599 (1.8006)	Prec@1 50.000 (55.540)	
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [16][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.6020 (1.5480)	Prec@1 60.938 (58.185)	
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [16][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.3439 (1.5094)	Prec@1 51.562 (57.006)	
2022-01-05 15:41:58 - INFO - TRAINING - Epoch: [16][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.2162 (1.4252)	Prec@1 42.188 (56.517)	
2022-01-05 15:41:59 - INFO - TRAINING - Epoch: [16][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7155 (1.3890)	Prec@1 64.062 (56.189)	
2022-01-05 15:41:59 - INFO - TRAINING - Epoch: [16][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.2491 (1.3430)	Prec@1 56.250 (56.096)	
2022-01-05 15:41:59 - INFO - TRAINING - Epoch: [16][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1234 (1.2902)	Prec@1 60.938 (56.580)	
2022-01-05 15:41:59 - INFO - EVALUATING - Epoch: [16][0/20]	Time 0.150 (0.150)	Data 0.147 (0.147)	Loss 1.0497 (1.0497)	Prec@1 50.000 (50.000)	
2022-01-05 15:41:59 - INFO - EVALUATING - Epoch: [16][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.5879 (1.0435)	Prec@1 35.938 (75.000)	
2022-01-05 15:41:59 - INFO - 
 Epoch: 17	Training Loss 1.3066 	Training Prec@1 56.735 	Validation Loss 1.2074 	Validation Prec@1 66.235 	
2022-01-05 15:41:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:59 - INFO - TRAINING - Epoch: [17][0/78]	Time 0.152 (0.152)	Data 0.145 (0.145)	Loss 1.5442 (1.5442)	Prec@1 59.375 (59.375)	
2022-01-05 15:41:59 - INFO - TRAINING - Epoch: [17][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.0478 (2.0157)	Prec@1 54.688 (52.699)	
2022-01-05 15:41:59 - INFO - TRAINING - Epoch: [17][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.3970 (1.6208)	Prec@1 50.000 (53.720)	
2022-01-05 15:41:59 - INFO - TRAINING - Epoch: [17][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.9621 (1.4802)	Prec@1 53.125 (55.696)	
2022-01-05 15:41:59 - INFO - TRAINING - Epoch: [17][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.0782 (1.4736)	Prec@1 57.812 (55.640)	
2022-01-05 15:41:59 - INFO - TRAINING - Epoch: [17][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.0382 (1.3543)	Prec@1 40.625 (55.576)	
2022-01-05 15:41:59 - INFO - TRAINING - Epoch: [17][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.2425 (1.3325)	Prec@1 53.125 (56.019)	
2022-01-05 15:41:59 - INFO - TRAINING - Epoch: [17][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9931 (1.3518)	Prec@1 51.562 (56.118)	
2022-01-05 15:42:00 - INFO - EVALUATING - Epoch: [17][0/20]	Time 0.151 (0.151)	Data 0.148 (0.148)	Loss 1.0990 (1.0990)	Prec@1 50.000 (50.000)	
2022-01-05 15:42:00 - INFO - EVALUATING - Epoch: [17][10/20]	Time 0.003 (0.017)	Data 0.002 (0.016)	Loss 1.1601 (0.8689)	Prec@1 75.000 (74.858)	
2022-01-05 15:42:00 - INFO - 
 Epoch: 18	Training Loss 1.3304 	Training Prec@1 55.925 	Validation Loss 0.9013 	Validation Prec@1 64.130 	
2022-01-05 15:42:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:00 - INFO - TRAINING - Epoch: [18][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.7227 (0.7227)	Prec@1 71.875 (71.875)	
2022-01-05 15:42:00 - INFO - TRAINING - Epoch: [18][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.7460 (2.8520)	Prec@1 70.312 (57.102)	
2022-01-05 15:42:00 - INFO - TRAINING - Epoch: [18][20/78]	Time 0.006 (0.012)	Data 0.002 (0.009)	Loss 1.8194 (2.3149)	Prec@1 70.312 (58.333)	
2022-01-05 15:42:00 - INFO - TRAINING - Epoch: [18][30/78]	Time 0.006 (0.010)	Data 0.002 (0.007)	Loss 0.9568 (2.0526)	Prec@1 62.500 (57.258)	
2022-01-05 15:42:00 - INFO - TRAINING - Epoch: [18][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.9666 (1.8317)	Prec@1 34.375 (57.279)	
2022-01-05 15:42:00 - INFO - TRAINING - Epoch: [18][50/78]	Time 0.006 (0.008)	Data 0.002 (0.005)	Loss 0.8151 (1.6592)	Prec@1 57.812 (56.924)	
2022-01-05 15:42:00 - INFO - TRAINING - Epoch: [18][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.3811 (1.6050)	Prec@1 70.312 (56.967)	
2022-01-05 15:42:00 - INFO - TRAINING - Epoch: [18][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.6038 (1.5551)	Prec@1 48.438 (56.668)	
2022-01-05 15:42:00 - INFO - EVALUATING - Epoch: [18][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 1.1133 (1.1133)	Prec@1 50.000 (50.000)	
2022-01-05 15:42:00 - INFO - EVALUATING - Epoch: [18][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.7590 (0.6162)	Prec@1 48.438 (70.455)	
2022-01-05 15:42:00 - INFO - 
 Epoch: 19	Training Loss 1.5219 	Training Prec@1 56.492 	Validation Loss 0.7256 	Validation Prec@1 62.024 	
2022-01-05 15:42:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:01 - INFO - TRAINING - Epoch: [19][0/78]	Time 0.156 (0.156)	Data 0.150 (0.150)	Loss 0.9601 (0.9601)	Prec@1 56.250 (56.250)	
2022-01-05 15:42:01 - INFO - TRAINING - Epoch: [19][10/78]	Time 0.005 (0.019)	Data 0.002 (0.016)	Loss 1.4580 (1.5310)	Prec@1 67.188 (54.972)	
2022-01-05 15:42:01 - INFO - TRAINING - Epoch: [19][20/78]	Time 0.005 (0.013)	Data 0.002 (0.009)	Loss 1.6497 (1.5633)	Prec@1 46.875 (54.464)	
2022-01-05 15:42:01 - INFO - TRAINING - Epoch: [19][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8280 (1.3841)	Prec@1 62.500 (55.343)	
2022-01-05 15:42:01 - INFO - TRAINING - Epoch: [19][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.1134 (1.2851)	Prec@1 48.438 (54.497)	
2022-01-05 15:42:01 - INFO - TRAINING - Epoch: [19][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.0462 (1.2612)	Prec@1 40.625 (55.147)	
2022-01-05 15:42:01 - INFO - TRAINING - Epoch: [19][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.0473 (1.2685)	Prec@1 68.750 (55.686)	
2022-01-05 15:42:01 - INFO - TRAINING - Epoch: [19][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7543 (1.2635)	Prec@1 56.250 (56.338)	
2022-01-05 15:42:01 - INFO - EVALUATING - Epoch: [19][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.5446 (0.5446)	Prec@1 76.562 (76.562)	
2022-01-05 15:42:01 - INFO - EVALUATING - Epoch: [19][10/20]	Time 0.004 (0.017)	Data 0.002 (0.015)	Loss 0.8273 (0.8856)	Prec@1 53.125 (48.295)	
2022-01-05 15:42:01 - INFO - 
 Epoch: 20	Training Loss 1.2451 	Training Prec@1 56.350 	Validation Loss 0.9154 	Validation Prec@1 45.830 	
2022-01-05 15:42:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:01 - INFO - TRAINING - Epoch: [20][0/78]	Time 0.153 (0.153)	Data 0.147 (0.147)	Loss 0.7580 (0.7580)	Prec@1 56.250 (56.250)	
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [20][10/78]	Time 0.005 (0.019)	Data 0.002 (0.016)	Loss 0.6521 (0.7900)	Prec@1 65.625 (64.347)	
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [20][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8671 (0.7533)	Prec@1 53.125 (59.449)	
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [20][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6591 (0.7979)	Prec@1 67.188 (59.677)	
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [20][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.7194 (0.7837)	Prec@1 40.625 (60.290)	
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [20][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8963 (0.7894)	Prec@1 40.625 (58.793)	
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [20][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6567 (0.7796)	Prec@1 73.438 (59.503)	
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [20][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7329 (0.7718)	Prec@1 64.062 (58.825)	
2022-01-05 15:42:02 - INFO - EVALUATING - Epoch: [20][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.4823 (0.4823)	Prec@1 100.000 (100.000)	
2022-01-05 15:42:02 - INFO - EVALUATING - Epoch: [20][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.6928 (0.5945)	Prec@1 53.125 (65.341)	
2022-01-05 15:42:02 - INFO - 
 Epoch: 21	Training Loss 0.7774 	Training Prec@1 59.165 	Validation Loss 0.6689 	Validation Prec@1 55.304 	
2022-01-05 15:42:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:02 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [21][0/78]	Time 0.153 (0.153)	Data 0.147 (0.147)	Loss 0.6396 (0.6396)	Prec@1 59.375 (59.375)	
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [21][10/78]	Time 0.005 (0.019)	Data 0.002 (0.016)	Loss 0.6982 (0.8368)	Prec@1 59.375 (59.943)	
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [21][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.1097 (0.8004)	Prec@1 53.125 (57.589)	
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [21][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6851 (0.8347)	Prec@1 60.938 (60.736)	
2022-01-05 15:42:02 - INFO - TRAINING - Epoch: [21][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.9638 (0.8208)	Prec@1 62.500 (59.718)	
2022-01-05 15:42:03 - INFO - TRAINING - Epoch: [21][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7023 (0.8222)	Prec@1 62.500 (59.620)	
2022-01-05 15:42:03 - INFO - TRAINING - Epoch: [21][60/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.8707 (0.8107)	Prec@1 62.500 (60.374)	
2022-01-05 15:42:03 - INFO - TRAINING - Epoch: [21][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7879 (0.8229)	Prec@1 48.438 (58.759)	
2022-01-05 15:42:03 - INFO - EVALUATING - Epoch: [21][0/20]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.4166 (0.4166)	Prec@1 100.000 (100.000)	
2022-01-05 15:42:03 - INFO - EVALUATING - Epoch: [21][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.1621 (0.5946)	Prec@1 53.125 (66.903)	
2022-01-05 15:42:03 - INFO - 
 Epoch: 22	Training Loss 0.8305 	Training Prec@1 58.760 	Validation Loss 0.7667 	Validation Prec@1 57.652 	
2022-01-05 15:42:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:03 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:03 - INFO - TRAINING - Epoch: [22][0/78]	Time 0.153 (0.153)	Data 0.146 (0.146)	Loss 0.6660 (0.6660)	Prec@1 59.375 (59.375)	
2022-01-05 15:42:03 - INFO - TRAINING - Epoch: [22][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.7994 (0.9856)	Prec@1 54.688 (56.250)	
2022-01-05 15:42:03 - INFO - TRAINING - Epoch: [22][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.6853 (0.8690)	Prec@1 59.375 (59.747)	
2022-01-05 15:42:03 - INFO - TRAINING - Epoch: [22][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6621 (0.8632)	Prec@1 65.625 (58.669)	
2022-01-05 15:42:03 - INFO - TRAINING - Epoch: [22][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.7137 (0.8314)	Prec@1 56.250 (58.346)	
2022-01-05 15:42:03 - INFO - TRAINING - Epoch: [22][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8858 (0.8740)	Prec@1 64.062 (58.548)	
2022-01-05 15:42:03 - INFO - TRAINING - Epoch: [22][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7329 (0.8545)	Prec@1 62.500 (58.197)	
2022-01-05 15:42:03 - INFO - TRAINING - Epoch: [22][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6883 (0.8288)	Prec@1 62.500 (58.165)	
2022-01-05 15:42:04 - INFO - EVALUATING - Epoch: [22][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.9578 (0.9578)	Prec@1 23.438 (23.438)	
2022-01-05 15:42:04 - INFO - EVALUATING - Epoch: [22][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.7838 (0.7479)	Prec@1 46.875 (51.705)	
2022-01-05 15:42:04 - INFO - 
 Epoch: 23	Training Loss 0.8284 	Training Prec@1 58.659 	Validation Loss 0.7296 	Validation Prec@1 54.170 	
2022-01-05 15:42:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:04 - INFO - TRAINING - Epoch: [23][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.7141 (0.7141)	Prec@1 56.250 (56.250)	
2022-01-05 15:42:04 - INFO - TRAINING - Epoch: [23][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 0.9445 (1.0459)	Prec@1 62.500 (59.233)	
2022-01-05 15:42:04 - INFO - TRAINING - Epoch: [23][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.7954 (0.9036)	Prec@1 57.812 (60.565)	
2022-01-05 15:42:04 - INFO - TRAINING - Epoch: [23][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8076 (0.8642)	Prec@1 59.375 (59.829)	
2022-01-05 15:42:04 - INFO - TRAINING - Epoch: [23][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.7143 (0.8233)	Prec@1 64.062 (60.480)	
2022-01-05 15:42:04 - INFO - TRAINING - Epoch: [23][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7102 (0.7939)	Prec@1 59.375 (61.029)	
2022-01-05 15:42:04 - INFO - TRAINING - Epoch: [23][60/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.6018 (0.7797)	Prec@1 70.312 (61.885)	
2022-01-05 15:42:04 - INFO - TRAINING - Epoch: [23][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.5935 (0.7841)	Prec@1 60.938 (61.532)	
2022-01-05 15:42:04 - INFO - EVALUATING - Epoch: [23][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.4068 (1.4068)	Prec@1 29.688 (29.688)	
2022-01-05 15:42:04 - INFO - EVALUATING - Epoch: [23][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.0835 (0.8594)	Prec@1 46.875 (61.648)	
2022-01-05 15:42:04 - INFO - 
 Epoch: 24	Training Loss 0.7919 	Training Prec@1 61.394 	Validation Loss 0.8472 	Validation Prec@1 60.729 	
2022-01-05 15:42:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:05 - INFO - TRAINING - Epoch: [24][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.8201 (0.8201)	Prec@1 62.500 (62.500)	
2022-01-05 15:42:05 - INFO - TRAINING - Epoch: [24][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 0.8468 (0.9913)	Prec@1 54.688 (58.665)	
2022-01-05 15:42:05 - INFO - TRAINING - Epoch: [24][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0796 (1.0101)	Prec@1 42.188 (60.119)	
2022-01-05 15:42:05 - INFO - TRAINING - Epoch: [24][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.9288 (0.9553)	Prec@1 40.625 (58.417)	
2022-01-05 15:42:05 - INFO - TRAINING - Epoch: [24][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.6486 (0.8941)	Prec@1 56.250 (58.346)	
2022-01-05 15:42:05 - INFO - TRAINING - Epoch: [24][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6319 (0.8632)	Prec@1 73.438 (59.099)	
2022-01-05 15:42:05 - INFO - TRAINING - Epoch: [24][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7617 (0.8427)	Prec@1 51.562 (58.811)	
2022-01-05 15:42:05 - INFO - TRAINING - Epoch: [24][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0742 (0.8836)	Prec@1 26.562 (57.768)	
2022-01-05 15:42:05 - INFO - EVALUATING - Epoch: [24][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.2544 (0.2544)	Prec@1 95.312 (95.312)	
2022-01-05 15:42:05 - INFO - EVALUATING - Epoch: [24][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.1460 (0.7633)	Prec@1 45.312 (65.767)	
2022-01-05 15:42:05 - INFO - 
 Epoch: 25	Training Loss 0.8819 	Training Prec@1 57.930 	Validation Loss 0.9844 	Validation Prec@1 58.138 	
2022-01-05 15:42:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:05 - INFO - TRAINING - Epoch: [25][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.7973 (0.7973)	Prec@1 68.750 (68.750)	
2022-01-05 15:42:05 - INFO - TRAINING - Epoch: [25][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.9373 (1.2356)	Prec@1 60.938 (59.375)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [25][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8114 (1.0260)	Prec@1 54.688 (58.110)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [25][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7157 (0.9665)	Prec@1 59.375 (59.879)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [25][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.6447 (0.8991)	Prec@1 62.500 (60.556)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [25][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7047 (0.8725)	Prec@1 56.250 (59.436)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [25][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0291 (0.8679)	Prec@1 42.188 (60.195)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [25][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9200 (0.8489)	Prec@1 46.875 (60.255)	
2022-01-05 15:42:06 - INFO - EVALUATING - Epoch: [25][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 2.5429 (2.5429)	Prec@1 29.688 (29.688)	
2022-01-05 15:42:06 - INFO - EVALUATING - Epoch: [25][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.9386 (1.1395)	Prec@1 78.125 (63.210)	
2022-01-05 15:42:06 - INFO - 
 Epoch: 26	Training Loss 0.8770 	Training Prec@1 60.219 	Validation Loss 1.2530 	Validation Prec@1 62.105 	
2022-01-05 15:42:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:06 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [26][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 1.2322 (1.2322)	Prec@1 64.062 (64.062)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [26][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.2467 (1.5014)	Prec@1 54.688 (51.136)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [26][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0229 (1.3537)	Prec@1 62.500 (53.348)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [26][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.0418 (1.2777)	Prec@1 57.812 (55.091)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [26][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.2252 (1.2288)	Prec@1 51.562 (54.497)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [26][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9675 (1.2339)	Prec@1 56.250 (55.270)	
2022-01-05 15:42:06 - INFO - TRAINING - Epoch: [26][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8044 (1.1637)	Prec@1 62.500 (56.378)	
2022-01-05 15:42:07 - INFO - TRAINING - Epoch: [26][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7211 (1.1095)	Prec@1 60.938 (56.008)	
2022-01-05 15:42:07 - INFO - EVALUATING - Epoch: [26][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.3521 (1.3521)	Prec@1 29.688 (29.688)	
2022-01-05 15:42:07 - INFO - EVALUATING - Epoch: [26][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.1083 (0.6502)	Prec@1 35.938 (72.727)	
2022-01-05 15:42:07 - INFO - 
 Epoch: 27	Training Loss 1.0873 	Training Prec@1 56.532 	Validation Loss 0.6935 	Validation Prec@1 67.368 	
2022-01-05 15:42:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:07 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:07 - INFO - TRAINING - Epoch: [27][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.8290 (0.8290)	Prec@1 53.125 (53.125)	
2022-01-05 15:42:07 - INFO - TRAINING - Epoch: [27][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 0.9295 (1.2224)	Prec@1 57.812 (52.699)	
2022-01-05 15:42:07 - INFO - TRAINING - Epoch: [27][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8517 (1.1126)	Prec@1 43.750 (53.571)	
2022-01-05 15:42:07 - INFO - TRAINING - Epoch: [27][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.5169 (1.0448)	Prec@1 51.562 (55.796)	
2022-01-05 15:42:07 - INFO - TRAINING - Epoch: [27][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.8701 (1.0079)	Prec@1 64.062 (56.936)	
2022-01-05 15:42:07 - INFO - TRAINING - Epoch: [27][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9648 (1.0432)	Prec@1 54.688 (55.086)	
2022-01-05 15:42:07 - INFO - TRAINING - Epoch: [27][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0036 (1.0366)	Prec@1 59.375 (54.969)	
2022-01-05 15:42:07 - INFO - TRAINING - Epoch: [27][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6722 (1.0034)	Prec@1 60.938 (55.304)	
2022-01-05 15:42:08 - INFO - EVALUATING - Epoch: [27][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.1070 (0.1070)	Prec@1 100.000 (100.000)	
2022-01-05 15:42:08 - INFO - EVALUATING - Epoch: [27][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.4602 (0.7981)	Prec@1 78.125 (74.716)	
2022-01-05 15:42:08 - INFO - 
 Epoch: 28	Training Loss 0.9754 	Training Prec@1 56.107 	Validation Loss 1.1107 	Validation Prec@1 63.320 	
2022-01-05 15:42:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:08 - INFO - TRAINING - Epoch: [28][0/78]	Time 0.158 (0.158)	Data 0.152 (0.152)	Loss 0.9342 (0.9342)	Prec@1 64.062 (64.062)	
2022-01-05 15:42:08 - INFO - TRAINING - Epoch: [28][10/78]	Time 0.005 (0.019)	Data 0.002 (0.016)	Loss 1.2234 (2.1301)	Prec@1 50.000 (57.812)	
2022-01-05 15:42:08 - INFO - TRAINING - Epoch: [28][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.9976 (1.8452)	Prec@1 54.688 (56.250)	
2022-01-05 15:42:08 - INFO - TRAINING - Epoch: [28][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.0478 (1.6175)	Prec@1 59.375 (58.317)	
2022-01-05 15:42:08 - INFO - TRAINING - Epoch: [28][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.9808 (1.4446)	Prec@1 67.188 (57.927)	
2022-01-05 15:42:08 - INFO - TRAINING - Epoch: [28][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.6289 (1.4342)	Prec@1 64.062 (56.893)	
2022-01-05 15:42:08 - INFO - TRAINING - Epoch: [28][60/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.7678 (1.3558)	Prec@1 57.812 (57.454)	
2022-01-05 15:42:08 - INFO - TRAINING - Epoch: [28][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7831 (1.2754)	Prec@1 62.500 (57.130)	
2022-01-05 15:42:08 - INFO - EVALUATING - Epoch: [28][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 1.0325 (1.0325)	Prec@1 50.000 (50.000)	
2022-01-05 15:42:08 - INFO - EVALUATING - Epoch: [28][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.6614 (0.6682)	Prec@1 78.125 (78.409)	
2022-01-05 15:42:08 - INFO - 
 Epoch: 29	Training Loss 1.2401 	Training Prec@1 57.869 	Validation Loss 0.8554 	Validation Prec@1 66.964 	
2022-01-05 15:42:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [29][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.9794 (0.9794)	Prec@1 68.750 (68.750)	
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [29][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.0782 (1.6367)	Prec@1 71.875 (57.102)	
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [29][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.2318 (1.3901)	Prec@1 65.625 (55.878)	
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [29][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6944 (1.2032)	Prec@1 71.875 (58.921)	
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [29][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.3319 (1.1023)	Prec@1 60.938 (58.613)	
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [29][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6904 (1.0841)	Prec@1 71.875 (58.670)	
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [29][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.6289 (1.0505)	Prec@1 48.438 (58.760)	
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [29][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9946 (1.0520)	Prec@1 35.938 (58.539)	
2022-01-05 15:42:09 - INFO - EVALUATING - Epoch: [29][0/20]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.9130 (0.9130)	Prec@1 23.438 (23.438)	
2022-01-05 15:42:09 - INFO - EVALUATING - Epoch: [29][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.7633 (0.7324)	Prec@1 46.875 (51.705)	
2022-01-05 15:42:09 - INFO - 
 Epoch: 30	Training Loss 1.0386 	Training Prec@1 59.247 	Validation Loss 0.7167 	Validation Prec@1 54.170 	
2022-01-05 15:42:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [30][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.7333 (0.7333)	Prec@1 51.562 (51.562)	
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [30][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 0.7114 (1.2862)	Prec@1 67.188 (58.097)	
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [30][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.7132 (1.0632)	Prec@1 65.625 (57.589)	
2022-01-05 15:42:09 - INFO - TRAINING - Epoch: [30][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6407 (0.9633)	Prec@1 73.438 (58.367)	
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [30][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.6796 (0.9081)	Prec@1 65.625 (59.299)	
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [30][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6455 (0.8696)	Prec@1 70.312 (58.640)	
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [30][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1505 (0.9186)	Prec@1 53.125 (58.453)	
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [30][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.3738 (0.9619)	Prec@1 59.375 (58.187)	
2022-01-05 15:42:10 - INFO - EVALUATING - Epoch: [30][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.4974 (0.4974)	Prec@1 76.562 (76.562)	
2022-01-05 15:42:10 - INFO - EVALUATING - Epoch: [30][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.7658 (0.6956)	Prec@1 53.125 (48.295)	
2022-01-05 15:42:10 - INFO - 
 Epoch: 31	Training Loss 0.9605 	Training Prec@1 58.801 	Validation Loss 0.8547 	Validation Prec@1 45.830 	
2022-01-05 15:42:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [31][0/78]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.8990 (0.8990)	Prec@1 39.062 (39.062)	
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [31][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.9532 (1.4954)	Prec@1 60.938 (55.966)	
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [31][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8147 (1.1979)	Prec@1 64.062 (58.482)	
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [31][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6024 (1.0574)	Prec@1 71.875 (59.627)	
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [31][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.2583 (1.0469)	Prec@1 40.625 (58.994)	
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [31][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.5788 (1.0222)	Prec@1 70.312 (57.904)	
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [31][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7275 (1.0010)	Prec@1 65.625 (56.557)	
2022-01-05 15:42:10 - INFO - TRAINING - Epoch: [31][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6818 (0.9756)	Prec@1 75.000 (57.482)	
2022-01-05 15:42:11 - INFO - EVALUATING - Epoch: [31][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.3234 (1.3234)	Prec@1 29.688 (29.688)	
2022-01-05 15:42:11 - INFO - EVALUATING - Epoch: [31][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.0507 (0.7815)	Prec@1 46.875 (66.477)	
2022-01-05 15:42:11 - INFO - 
 Epoch: 32	Training Loss 0.9691 	Training Prec@1 58.051 	Validation Loss 0.8139 	Validation Prec@1 62.348 	
2022-01-05 15:42:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:11 - INFO - TRAINING - Epoch: [32][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 1.2396 (1.2396)	Prec@1 37.500 (37.500)	
2022-01-05 15:42:11 - INFO - TRAINING - Epoch: [32][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.3683 (1.5619)	Prec@1 50.000 (56.250)	
2022-01-05 15:42:11 - INFO - TRAINING - Epoch: [32][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8600 (1.1966)	Prec@1 43.750 (60.417)	
2022-01-05 15:42:11 - INFO - TRAINING - Epoch: [32][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8452 (1.0852)	Prec@1 64.062 (58.821)	
2022-01-05 15:42:11 - INFO - TRAINING - Epoch: [32][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.3457 (1.0659)	Prec@1 56.250 (58.651)	
2022-01-05 15:42:11 - INFO - TRAINING - Epoch: [32][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.3555 (1.1213)	Prec@1 54.688 (57.935)	
2022-01-05 15:42:11 - INFO - TRAINING - Epoch: [32][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.3958 (1.1307)	Prec@1 64.062 (57.736)	
2022-01-05 15:42:11 - INFO - TRAINING - Epoch: [32][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9035 (1.1129)	Prec@1 48.438 (57.394)	
2022-01-05 15:42:11 - INFO - EVALUATING - Epoch: [32][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.2228 (0.2228)	Prec@1 100.000 (100.000)	
2022-01-05 15:42:11 - INFO - EVALUATING - Epoch: [32][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.0580 (0.7748)	Prec@1 48.438 (72.301)	
2022-01-05 15:42:11 - INFO - 
 Epoch: 33	Training Loss 1.0886 	Training Prec@1 57.586 	Validation Loss 1.0698 	Validation Prec@1 62.591 	
2022-01-05 15:42:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:12 - INFO - TRAINING - Epoch: [33][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.9567 (0.9567)	Prec@1 70.312 (70.312)	
2022-01-05 15:42:12 - INFO - TRAINING - Epoch: [33][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 2.3068 (2.9115)	Prec@1 53.125 (53.693)	
2022-01-05 15:42:12 - INFO - TRAINING - Epoch: [33][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.5745 (2.2732)	Prec@1 67.188 (56.324)	
2022-01-05 15:42:12 - INFO - TRAINING - Epoch: [33][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8602 (1.9744)	Prec@1 59.375 (56.754)	
2022-01-05 15:42:12 - INFO - TRAINING - Epoch: [33][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.7352 (1.6677)	Prec@1 43.750 (56.707)	
2022-01-05 15:42:12 - INFO - TRAINING - Epoch: [33][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.1025 (1.5057)	Prec@1 64.062 (56.556)	
2022-01-05 15:42:12 - INFO - TRAINING - Epoch: [33][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6456 (1.3929)	Prec@1 65.625 (57.018)	
2022-01-05 15:42:12 - INFO - TRAINING - Epoch: [33][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1257 (1.3374)	Prec@1 40.625 (56.910)	
2022-01-05 15:42:12 - INFO - EVALUATING - Epoch: [33][0/20]	Time 0.148 (0.148)	Data 0.144 (0.144)	Loss 0.9275 (0.9275)	Prec@1 50.000 (50.000)	
2022-01-05 15:42:12 - INFO - EVALUATING - Epoch: [33][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.3212 (0.7147)	Prec@1 46.875 (76.420)	
2022-01-05 15:42:12 - INFO - 
 Epoch: 34	Training Loss 1.2946 	Training Prec@1 57.424 	Validation Loss 0.8791 	Validation Prec@1 67.126 	
2022-01-05 15:42:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:12 - INFO - TRAINING - Epoch: [34][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.8905 (0.8905)	Prec@1 64.062 (64.062)	
2022-01-05 15:42:13 - INFO - TRAINING - Epoch: [34][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.2623 (1.7034)	Prec@1 54.688 (59.517)	
2022-01-05 15:42:13 - INFO - TRAINING - Epoch: [34][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.2995 (1.3178)	Prec@1 59.375 (59.970)	
2022-01-05 15:42:13 - INFO - TRAINING - Epoch: [34][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.0607 (1.3561)	Prec@1 50.000 (58.165)	
2022-01-05 15:42:13 - INFO - TRAINING - Epoch: [34][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.9234 (1.3432)	Prec@1 56.250 (58.384)	
2022-01-05 15:42:13 - INFO - TRAINING - Epoch: [34][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8580 (1.2569)	Prec@1 67.188 (58.487)	
2022-01-05 15:42:13 - INFO - TRAINING - Epoch: [34][60/78]	Time 0.006 (0.008)	Data 0.002 (0.005)	Loss 0.6761 (1.1885)	Prec@1 62.500 (58.991)	
2022-01-05 15:42:13 - INFO - TRAINING - Epoch: [34][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8302 (1.1639)	Prec@1 70.312 (58.165)	
2022-01-05 15:42:13 - INFO - EVALUATING - Epoch: [34][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.3251 (0.3251)	Prec@1 93.750 (93.750)	
2022-01-05 15:42:13 - INFO - EVALUATING - Epoch: [34][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.6272 (0.6867)	Prec@1 75.000 (67.330)	
2022-01-05 15:42:13 - INFO - 
 Epoch: 35	Training Loss 1.1589 	Training Prec@1 58.760 	Validation Loss 0.8015 	Validation Prec@1 58.623 	
2022-01-05 15:42:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:13 - INFO - TRAINING - Epoch: [35][0/78]	Time 0.157 (0.157)	Data 0.152 (0.152)	Loss 0.9007 (0.9007)	Prec@1 48.438 (48.438)	
2022-01-05 15:42:13 - INFO - TRAINING - Epoch: [35][10/78]	Time 0.005 (0.019)	Data 0.002 (0.016)	Loss 2.5048 (2.3692)	Prec@1 57.812 (56.392)	
2022-01-05 15:42:13 - INFO - TRAINING - Epoch: [35][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.6916 (1.8757)	Prec@1 59.375 (58.110)	
2022-01-05 15:42:13 - INFO - TRAINING - Epoch: [35][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6643 (1.6119)	Prec@1 68.750 (58.619)	
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [35][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.6949 (1.4028)	Prec@1 65.625 (58.651)	
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [35][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7777 (1.2694)	Prec@1 60.938 (58.425)	
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [35][60/78]	Time 0.006 (0.008)	Data 0.002 (0.005)	Loss 0.7373 (1.1722)	Prec@1 65.625 (59.734)	
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [35][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9696 (1.1146)	Prec@1 35.938 (59.397)	
2022-01-05 15:42:14 - INFO - EVALUATING - Epoch: [35][0/20]	Time 0.152 (0.152)	Data 0.149 (0.149)	Loss 0.6752 (0.6752)	Prec@1 76.562 (76.562)	
2022-01-05 15:42:14 - INFO - EVALUATING - Epoch: [35][10/20]	Time 0.003 (0.017)	Data 0.002 (0.016)	Loss 1.4232 (1.5702)	Prec@1 35.938 (33.523)	
2022-01-05 15:42:14 - INFO - 
 Epoch: 36	Training Loss 1.1251 	Training Prec@1 59.267 	Validation Loss 1.5017 	Validation Prec@1 39.109 	
2022-01-05 15:42:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:14 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [36][0/78]	Time 0.154 (0.154)	Data 0.149 (0.149)	Loss 1.3549 (1.3549)	Prec@1 37.500 (37.500)	
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [36][10/78]	Time 0.006 (0.019)	Data 0.002 (0.016)	Loss 0.7932 (2.0239)	Prec@1 64.062 (54.545)	
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [36][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.1387 (1.5286)	Prec@1 51.562 (58.333)	
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [36][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8022 (1.3713)	Prec@1 62.500 (57.611)	
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [36][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.8315 (1.2510)	Prec@1 60.938 (58.460)	
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [36][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8175 (1.1698)	Prec@1 60.938 (58.119)	
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [36][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6411 (1.1061)	Prec@1 73.438 (58.607)	
2022-01-05 15:42:14 - INFO - TRAINING - Epoch: [36][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6990 (1.0546)	Prec@1 62.500 (58.561)	
2022-01-05 15:42:15 - INFO - EVALUATING - Epoch: [36][0/20]	Time 0.150 (0.150)	Data 0.147 (0.147)	Loss 0.5273 (0.5273)	Prec@1 75.000 (75.000)	
2022-01-05 15:42:15 - INFO - EVALUATING - Epoch: [36][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.5534 (0.9213)	Prec@1 32.812 (40.341)	
2022-01-05 15:42:15 - INFO - 
 Epoch: 37	Training Loss 1.0331 	Training Prec@1 58.538 	Validation Loss 0.9689 	Validation Prec@1 44.777 	
2022-01-05 15:42:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:15 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:15 - INFO - TRAINING - Epoch: [37][0/78]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 1.0117 (1.0117)	Prec@1 39.062 (39.062)	
2022-01-05 15:42:15 - INFO - TRAINING - Epoch: [37][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.0104 (2.4163)	Prec@1 56.250 (57.812)	
2022-01-05 15:42:15 - INFO - TRAINING - Epoch: [37][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0489 (1.7488)	Prec@1 50.000 (56.324)	
2022-01-05 15:42:15 - INFO - TRAINING - Epoch: [37][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.3845 (1.5492)	Prec@1 57.812 (55.343)	
2022-01-05 15:42:15 - INFO - TRAINING - Epoch: [37][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.7321 (1.4344)	Prec@1 65.625 (55.945)	
2022-01-05 15:42:15 - INFO - TRAINING - Epoch: [37][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6771 (1.3433)	Prec@1 54.688 (55.729)	
2022-01-05 15:42:15 - INFO - TRAINING - Epoch: [37][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.5638 (1.2631)	Prec@1 71.875 (57.147)	
2022-01-05 15:42:15 - INFO - TRAINING - Epoch: [37][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1416 (1.1992)	Prec@1 54.688 (57.438)	
2022-01-05 15:42:15 - INFO - EVALUATING - Epoch: [37][0/20]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 3.8113 (3.8113)	Prec@1 50.000 (50.000)	
2022-01-05 15:42:15 - INFO - EVALUATING - Epoch: [37][10/20]	Time 0.004 (0.017)	Data 0.002 (0.015)	Loss 1.9873 (1.4567)	Prec@1 78.125 (77.699)	
2022-01-05 15:42:16 - INFO - 
 Epoch: 38	Training Loss 1.1865 	Training Prec@1 57.099 	Validation Loss 1.9982 	Validation Prec@1 65.506 	
2022-01-05 15:42:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:16 - INFO - TRAINING - Epoch: [38][0/78]	Time 0.153 (0.153)	Data 0.146 (0.146)	Loss 2.3463 (2.3463)	Prec@1 67.188 (67.188)	
2022-01-05 15:42:16 - INFO - TRAINING - Epoch: [38][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 5.5478 (2.7579)	Prec@1 40.625 (54.972)	
2022-01-05 15:42:16 - INFO - TRAINING - Epoch: [38][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.2215 (2.3336)	Prec@1 62.500 (53.795)	
2022-01-05 15:42:16 - INFO - TRAINING - Epoch: [38][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 3.1446 (2.2303)	Prec@1 43.750 (55.544)	
2022-01-05 15:42:16 - INFO - TRAINING - Epoch: [38][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 3.0904 (2.3296)	Prec@1 60.938 (55.602)	
2022-01-05 15:42:16 - INFO - TRAINING - Epoch: [38][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.9799 (2.2041)	Prec@1 46.875 (56.005)	
2022-01-05 15:42:16 - INFO - TRAINING - Epoch: [38][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0747 (2.0142)	Prec@1 54.688 (56.762)	
2022-01-05 15:42:16 - INFO - TRAINING - Epoch: [38][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7035 (1.8781)	Prec@1 65.625 (57.174)	
2022-01-05 15:42:16 - INFO - EVALUATING - Epoch: [38][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.7329 (0.7329)	Prec@1 75.000 (75.000)	
2022-01-05 15:42:16 - INFO - EVALUATING - Epoch: [38][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.6770 (0.6243)	Prec@1 56.250 (61.790)	
2022-01-05 15:42:16 - INFO - 
 Epoch: 39	Training Loss 1.7819 	Training Prec@1 58.051 	Validation Loss 0.6976 	Validation Prec@1 57.247 	
2022-01-05 15:42:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:16 - INFO - TRAINING - Epoch: [39][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.6902 (0.6902)	Prec@1 56.250 (56.250)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [39][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.3312 (1.9106)	Prec@1 59.375 (61.364)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [39][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.7118 (1.6158)	Prec@1 46.875 (55.878)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [39][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.5966 (1.4397)	Prec@1 67.188 (55.242)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [39][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.3378 (1.3418)	Prec@1 65.625 (56.441)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [39][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8808 (1.3460)	Prec@1 48.438 (56.985)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [39][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0067 (1.2886)	Prec@1 51.562 (57.018)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [39][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7450 (1.2123)	Prec@1 59.375 (58.033)	
2022-01-05 15:42:17 - INFO - EVALUATING - Epoch: [39][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.4904 (0.4904)	Prec@1 76.562 (76.562)	
2022-01-05 15:42:17 - INFO - EVALUATING - Epoch: [39][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 2.4305 (1.4208)	Prec@1 53.125 (48.295)	
2022-01-05 15:42:17 - INFO - 
 Epoch: 40	Training Loss 1.1727 	Training Prec@1 58.416 	Validation Loss 1.8551 	Validation Prec@1 46.154 	
2022-01-05 15:42:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [40][0/78]	Time 0.154 (0.154)	Data 0.147 (0.147)	Loss 1.7043 (1.7043)	Prec@1 45.312 (45.312)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [40][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.1206 (1.7505)	Prec@1 67.188 (57.244)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [40][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.6081 (1.4509)	Prec@1 37.500 (56.027)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [40][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7115 (1.2596)	Prec@1 62.500 (56.452)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [40][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.7195 (1.1164)	Prec@1 60.938 (58.841)	
2022-01-05 15:42:17 - INFO - TRAINING - Epoch: [40][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.0052 (1.0527)	Prec@1 43.750 (58.272)	
2022-01-05 15:42:18 - INFO - TRAINING - Epoch: [40][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6968 (1.0320)	Prec@1 70.312 (58.120)	
2022-01-05 15:42:18 - INFO - TRAINING - Epoch: [40][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7301 (1.0124)	Prec@1 51.562 (58.759)	
2022-01-05 15:42:18 - INFO - EVALUATING - Epoch: [40][0/20]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.8385 (0.8385)	Prec@1 29.688 (29.688)	
2022-01-05 15:42:18 - INFO - EVALUATING - Epoch: [40][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.5976 (0.5128)	Prec@1 89.062 (75.142)	
2022-01-05 15:42:18 - INFO - 
 Epoch: 41	Training Loss 1.0120 	Training Prec@1 58.112 	Validation Loss 0.9468 	Validation Prec@1 63.077 	
2022-01-05 15:42:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:18 - INFO - TRAINING - Epoch: [41][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.9954 (0.9954)	Prec@1 64.062 (64.062)	
2022-01-05 15:42:18 - INFO - TRAINING - Epoch: [41][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 2.7425 (2.6976)	Prec@1 57.812 (52.841)	
2022-01-05 15:42:18 - INFO - TRAINING - Epoch: [41][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.1439 (2.0940)	Prec@1 48.438 (54.762)	
2022-01-05 15:42:18 - INFO - TRAINING - Epoch: [41][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7924 (1.7020)	Prec@1 64.062 (57.712)	
2022-01-05 15:42:18 - INFO - TRAINING - Epoch: [41][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.7467 (1.4587)	Prec@1 64.062 (58.003)	
2022-01-05 15:42:18 - INFO - TRAINING - Epoch: [41][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8889 (1.3832)	Prec@1 68.750 (59.589)	
2022-01-05 15:42:18 - INFO - TRAINING - Epoch: [41][60/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.7559 (1.2790)	Prec@1 64.062 (59.785)	
2022-01-05 15:42:18 - INFO - TRAINING - Epoch: [41][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9277 (1.2443)	Prec@1 64.062 (59.947)	
2022-01-05 15:42:19 - INFO - EVALUATING - Epoch: [41][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.5482 (0.5482)	Prec@1 76.562 (76.562)	
2022-01-05 15:42:19 - INFO - EVALUATING - Epoch: [41][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 1.1216 (1.0048)	Prec@1 53.125 (48.722)	
2022-01-05 15:42:19 - INFO - 
 Epoch: 42	Training Loss 1.2632 	Training Prec@1 59.247 	Validation Loss 1.0874 	Validation Prec@1 46.235 	
2022-01-05 15:42:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:19 - INFO - TRAINING - Epoch: [42][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.9116 (0.9116)	Prec@1 54.688 (54.688)	
2022-01-05 15:42:19 - INFO - TRAINING - Epoch: [42][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.5876 (1.9790)	Prec@1 57.812 (55.256)	
2022-01-05 15:42:19 - INFO - TRAINING - Epoch: [42][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0460 (1.6047)	Prec@1 37.500 (56.920)	
2022-01-05 15:42:19 - INFO - TRAINING - Epoch: [42][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.2489 (1.3592)	Prec@1 54.688 (59.627)	
2022-01-05 15:42:19 - INFO - TRAINING - Epoch: [42][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.8084 (1.2231)	Prec@1 59.375 (59.870)	
2022-01-05 15:42:19 - INFO - TRAINING - Epoch: [42][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8653 (1.1306)	Prec@1 70.312 (58.977)	
2022-01-05 15:42:19 - INFO - TRAINING - Epoch: [42][60/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.8630 (1.1682)	Prec@1 71.875 (58.632)	
2022-01-05 15:42:19 - INFO - TRAINING - Epoch: [42][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6624 (1.1261)	Prec@1 62.500 (59.441)	
2022-01-05 15:42:19 - INFO - EVALUATING - Epoch: [42][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.3653 (0.3653)	Prec@1 100.000 (100.000)	
2022-01-05 15:42:19 - INFO - EVALUATING - Epoch: [42][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.9162 (0.6821)	Prec@1 48.438 (70.455)	
2022-01-05 15:42:19 - INFO - 
 Epoch: 43	Training Loss 1.1387 	Training Prec@1 59.247 	Validation Loss 0.8006 	Validation Prec@1 62.510 	
2022-01-05 15:42:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:20 - INFO - TRAINING - Epoch: [43][0/78]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.8792 (0.8792)	Prec@1 46.875 (46.875)	
2022-01-05 15:42:20 - INFO - TRAINING - Epoch: [43][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 0.7664 (1.9221)	Prec@1 45.312 (54.972)	
2022-01-05 15:42:20 - INFO - TRAINING - Epoch: [43][20/78]	Time 0.012 (0.012)	Data 0.009 (0.009)	Loss 0.6757 (1.4040)	Prec@1 64.062 (60.119)	
2022-01-05 15:42:20 - INFO - TRAINING - Epoch: [43][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8977 (1.2954)	Prec@1 62.500 (58.266)	
2022-01-05 15:42:20 - INFO - TRAINING - Epoch: [43][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.5131 (1.2100)	Prec@1 75.000 (58.651)	
2022-01-05 15:42:20 - INFO - TRAINING - Epoch: [43][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6955 (1.1017)	Prec@1 65.625 (60.294)	
2022-01-05 15:42:20 - INFO - TRAINING - Epoch: [43][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9777 (1.0409)	Prec@1 43.750 (60.476)	
2022-01-05 15:42:20 - INFO - TRAINING - Epoch: [43][70/78]	Time 0.006 (0.007)	Data 0.003 (0.004)	Loss 0.6581 (1.0010)	Prec@1 73.438 (60.299)	
2022-01-05 15:42:20 - INFO - EVALUATING - Epoch: [43][0/20]	Time 0.153 (0.153)	Data 0.150 (0.150)	Loss 2.0508 (2.0508)	Prec@1 23.438 (23.438)	
2022-01-05 15:42:20 - INFO - EVALUATING - Epoch: [43][10/20]	Time 0.003 (0.017)	Data 0.002 (0.016)	Loss 1.4453 (1.3205)	Prec@1 46.875 (51.705)	
2022-01-05 15:42:20 - INFO - 
 Epoch: 44	Training Loss 1.0029 	Training Prec@1 60.036 	Validation Loss 1.2568 	Validation Prec@1 54.170 	
2022-01-05 15:42:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:20 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:20 - INFO - TRAINING - Epoch: [44][0/78]	Time 0.155 (0.155)	Data 0.149 (0.149)	Loss 1.4049 (1.4049)	Prec@1 48.438 (48.438)	
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [44][10/78]	Time 0.005 (0.019)	Data 0.002 (0.016)	Loss 1.7435 (2.2775)	Prec@1 65.625 (50.994)	
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [44][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.2665 (1.8133)	Prec@1 60.938 (55.580)	
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [44][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.0731 (1.7803)	Prec@1 60.938 (52.722)	
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [44][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.6672 (1.5561)	Prec@1 65.625 (56.250)	
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [44][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7058 (1.4003)	Prec@1 65.625 (56.955)	
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [44][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6294 (1.2808)	Prec@1 67.188 (58.581)	
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [44][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6513 (1.2060)	Prec@1 60.938 (58.825)	
2022-01-05 15:42:21 - INFO - EVALUATING - Epoch: [44][0/20]	Time 0.150 (0.150)	Data 0.147 (0.147)	Loss 0.5198 (0.5198)	Prec@1 50.000 (50.000)	
2022-01-05 15:42:21 - INFO - EVALUATING - Epoch: [44][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.1342 (0.8966)	Prec@1 78.125 (77.841)	
2022-01-05 15:42:21 - INFO - 
 Epoch: 45	Training Loss 1.1753 	Training Prec@1 58.315 	Validation Loss 1.5048 	Validation Prec@1 66.397 	
2022-01-05 15:42:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:21 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [45][0/78]	Time 0.153 (0.153)	Data 0.147 (0.147)	Loss 1.5912 (1.5912)	Prec@1 59.375 (59.375)	
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [45][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.4697 (1.7920)	Prec@1 65.625 (56.392)	
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [45][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0016 (1.4942)	Prec@1 67.188 (57.217)	
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [45][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.5954 (1.2989)	Prec@1 65.625 (58.619)	
2022-01-05 15:42:21 - INFO - TRAINING - Epoch: [45][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 2.0031 (1.2506)	Prec@1 51.562 (56.631)	
2022-01-05 15:42:22 - INFO - TRAINING - Epoch: [45][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7661 (1.2569)	Prec@1 39.062 (56.679)	
2022-01-05 15:42:22 - INFO - TRAINING - Epoch: [45][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.0154 (1.2158)	Prec@1 60.938 (57.531)	
2022-01-05 15:42:22 - INFO - TRAINING - Epoch: [45][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6211 (1.1466)	Prec@1 64.062 (57.504)	
2022-01-05 15:42:22 - INFO - EVALUATING - Epoch: [45][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.7904 (0.7904)	Prec@1 23.438 (23.438)	
2022-01-05 15:42:22 - INFO - EVALUATING - Epoch: [45][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.8636 (0.6881)	Prec@1 46.875 (51.705)	
2022-01-05 15:42:22 - INFO - 
 Epoch: 46	Training Loss 1.1267 	Training Prec@1 57.322 	Validation Loss 0.7215 	Validation Prec@1 54.170 	
2022-01-05 15:42:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:22 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:22 - INFO - TRAINING - Epoch: [46][0/78]	Time 0.153 (0.153)	Data 0.147 (0.147)	Loss 0.7321 (0.7321)	Prec@1 60.938 (60.938)	
2022-01-05 15:42:22 - INFO - TRAINING - Epoch: [46][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.5618 (1.6275)	Prec@1 59.375 (55.682)	
2022-01-05 15:42:22 - INFO - TRAINING - Epoch: [46][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.2144 (1.5084)	Prec@1 56.250 (54.018)	
2022-01-05 15:42:22 - INFO - TRAINING - Epoch: [46][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.5491 (1.4043)	Prec@1 57.812 (56.956)	
2022-01-05 15:42:22 - INFO - TRAINING - Epoch: [46][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.1827 (1.3161)	Prec@1 51.562 (56.898)	
2022-01-05 15:42:22 - INFO - TRAINING - Epoch: [46][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8343 (1.2545)	Prec@1 43.750 (56.342)	
2022-01-05 15:42:22 - INFO - TRAINING - Epoch: [46][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7923 (1.1872)	Prec@1 60.938 (57.403)	
2022-01-05 15:42:22 - INFO - TRAINING - Epoch: [46][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7127 (1.1169)	Prec@1 67.188 (58.209)	
2022-01-05 15:42:23 - INFO - EVALUATING - Epoch: [46][0/20]	Time 0.150 (0.150)	Data 0.147 (0.147)	Loss 0.9818 (0.9818)	Prec@1 50.000 (50.000)	
2022-01-05 15:42:23 - INFO - EVALUATING - Epoch: [46][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.4987 (0.6680)	Prec@1 67.188 (77.983)	
2022-01-05 15:42:23 - INFO - 
 Epoch: 47	Training Loss 1.0999 	Training Prec@1 57.667 	Validation Loss 1.2411 	Validation Prec@1 66.640 	
2022-01-05 15:42:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:23 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:23 - INFO - TRAINING - Epoch: [47][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 1.0555 (1.0555)	Prec@1 73.438 (73.438)	
2022-01-05 15:42:23 - INFO - TRAINING - Epoch: [47][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.3629 (1.8844)	Prec@1 59.375 (57.670)	
2022-01-05 15:42:23 - INFO - TRAINING - Epoch: [47][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0017 (1.4312)	Prec@1 50.000 (55.878)	
2022-01-05 15:42:23 - INFO - TRAINING - Epoch: [47][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.0287 (1.2344)	Prec@1 51.562 (57.964)	
2022-01-05 15:42:23 - INFO - TRAINING - Epoch: [47][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.1817 (1.2529)	Prec@1 43.750 (56.784)	
2022-01-05 15:42:23 - INFO - TRAINING - Epoch: [47][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7044 (1.1847)	Prec@1 53.125 (56.832)	
2022-01-05 15:42:23 - INFO - TRAINING - Epoch: [47][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8239 (1.1169)	Prec@1 54.688 (57.095)	
2022-01-05 15:42:23 - INFO - TRAINING - Epoch: [47][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8454 (1.0594)	Prec@1 46.875 (57.526)	
2022-01-05 15:42:23 - INFO - EVALUATING - Epoch: [47][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 3.8021 (3.8021)	Prec@1 29.688 (29.688)	
2022-01-05 15:42:24 - INFO - EVALUATING - Epoch: [47][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.8408 (1.2835)	Prec@1 78.125 (72.017)	
2022-01-05 15:42:24 - INFO - 
 Epoch: 48	Training Loss 1.0640 	Training Prec@1 57.343 	Validation Loss 1.5265 	Validation Prec@1 64.211 	
2022-01-05 15:42:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:24 - INFO - TRAINING - Epoch: [48][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 1.5518 (1.5518)	Prec@1 62.500 (62.500)	
2022-01-05 15:42:24 - INFO - TRAINING - Epoch: [48][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.5800 (2.1932)	Prec@1 57.812 (55.398)	
2022-01-05 15:42:24 - INFO - TRAINING - Epoch: [48][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.3243 (1.8003)	Prec@1 51.562 (55.208)	
2022-01-05 15:42:24 - INFO - TRAINING - Epoch: [48][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.0198 (1.6192)	Prec@1 62.500 (55.897)	
2022-01-05 15:42:24 - INFO - TRAINING - Epoch: [48][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 3.0917 (1.5368)	Prec@1 37.500 (55.373)	
2022-01-05 15:42:24 - INFO - TRAINING - Epoch: [48][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7389 (1.4220)	Prec@1 56.250 (56.403)	
2022-01-05 15:42:24 - INFO - TRAINING - Epoch: [48][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6826 (1.3196)	Prec@1 56.250 (56.762)	
2022-01-05 15:42:24 - INFO - TRAINING - Epoch: [48][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6406 (1.2734)	Prec@1 71.875 (56.382)	
2022-01-05 15:42:24 - INFO - EVALUATING - Epoch: [48][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.8237 (0.8237)	Prec@1 29.688 (29.688)	
2022-01-05 15:42:24 - INFO - EVALUATING - Epoch: [48][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.6444 (0.5431)	Prec@1 67.188 (76.989)	
2022-01-05 15:42:24 - INFO - 
 Epoch: 49	Training Loss 1.2434 	Training Prec@1 56.654 	Validation Loss 0.7145 	Validation Prec@1 67.854 	
2022-01-05 15:42:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:25 - INFO - TRAINING - Epoch: [49][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.7879 (0.7879)	Prec@1 68.750 (68.750)	
2022-01-05 15:42:25 - INFO - TRAINING - Epoch: [49][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 0.6542 (1.9711)	Prec@1 70.312 (59.233)	
2022-01-05 15:42:25 - INFO - TRAINING - Epoch: [49][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.3757 (1.7622)	Prec@1 45.312 (56.176)	
2022-01-05 15:42:25 - INFO - TRAINING - Epoch: [49][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 2.5687 (1.6482)	Prec@1 40.625 (56.956)	
2022-01-05 15:42:25 - INFO - TRAINING - Epoch: [49][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.1760 (1.5529)	Prec@1 65.625 (58.194)	
2022-01-05 15:42:25 - INFO - TRAINING - Epoch: [49][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9696 (1.4703)	Prec@1 35.938 (56.219)	
2022-01-05 15:42:25 - INFO - TRAINING - Epoch: [49][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.4134 (1.5907)	Prec@1 42.188 (56.557)	
2022-01-05 15:42:25 - INFO - TRAINING - Epoch: [49][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0500 (1.5161)	Prec@1 67.188 (56.382)	
2022-01-05 15:42:25 - INFO - EVALUATING - Epoch: [49][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.8284 (0.8284)	Prec@1 29.688 (29.688)	
2022-01-05 15:42:25 - INFO - EVALUATING - Epoch: [49][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.6612 (0.6701)	Prec@1 57.812 (58.239)	
2022-01-05 15:42:25 - INFO - 
 Epoch: 50	Training Loss 1.4513 	Training Prec@1 56.775 	Validation Loss 0.6863 	Validation Prec@1 58.623 	
