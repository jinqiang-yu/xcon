2022-01-05 15:40:58 - INFO - saving to ./results/large/quantise/q5/other/fairml/compas/compas_test1/
2022-01-05 15:40:58 - DEBUG - run arguments: Namespace(config='./configs/config_large.json', data='../../paper_bench/complete/quantise/q5/other/fairml/compas/compas_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/large/quantise/q5/other/fairml/compas/compas_test1/', test='../../paper_bench/cv/test/quantise/q5/other/fairml/compas/compas_test1_data.csv', train='../../paper_bench/cv/train/quantise/q5/other/fairml/compas/compas_train1_data.csv')
2022-01-05 15:40:58 - INFO - creating model mlp_binary
2022-01-05 15:40:58 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [64, 32, 24, 2]}
2022-01-05 15:40:58 - INFO - number of parameters: 4826
2022-01-05 15:40:58 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-05 15:40:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:40:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:40:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:40:58 - INFO - TRAINING - Epoch: [0][0/78]	Time 0.157 (0.157)	Data 0.148 (0.148)	Loss 2.1737 (2.1737)	Prec@1 53.125 (53.125)	
2022-01-05 15:40:58 - INFO - TRAINING - Epoch: [0][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.5601 (1.8819)	Prec@1 34.375 (51.562)	
2022-01-05 15:40:58 - INFO - TRAINING - Epoch: [0][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.4262 (1.5367)	Prec@1 46.875 (54.613)	
2022-01-05 15:40:58 - INFO - TRAINING - Epoch: [0][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.9045 (1.4517)	Prec@1 42.188 (53.780)	
2022-01-05 15:40:58 - INFO - TRAINING - Epoch: [0][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.9883 (1.3528)	Prec@1 81.250 (54.802)	
2022-01-05 15:40:58 - INFO - TRAINING - Epoch: [0][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.2055 (1.4108)	Prec@1 56.250 (54.933)	
2022-01-05 15:40:59 - INFO - TRAINING - Epoch: [0][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.4575 (1.4002)	Prec@1 57.812 (54.688)	
2022-01-05 15:40:59 - INFO - TRAINING - Epoch: [0][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.2314 (1.3836)	Prec@1 67.188 (55.084)	
2022-01-05 15:40:59 - INFO - EVALUATING - Epoch: [0][0/20]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 1.2465 (1.2465)	Prec@1 50.000 (50.000)	
2022-01-05 15:40:59 - INFO - EVALUATING - Epoch: [0][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.1261 (0.7350)	Prec@1 57.812 (68.182)	
2022-01-05 15:40:59 - INFO - 
 Epoch: 1	Training Loss 1.3723 	Training Prec@1 54.932 	Validation Loss 0.9793 	Validation Prec@1 59.271 	
2022-01-05 15:40:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:40:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:40:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:40:59 - INFO - TRAINING - Epoch: [1][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 1.0357 (1.0357)	Prec@1 65.625 (65.625)	
2022-01-05 15:40:59 - INFO - TRAINING - Epoch: [1][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.9497 (1.5295)	Prec@1 62.500 (57.244)	
2022-01-05 15:40:59 - INFO - TRAINING - Epoch: [1][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0104 (1.3554)	Prec@1 75.000 (57.738)	
2022-01-05 15:40:59 - INFO - TRAINING - Epoch: [1][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7660 (1.2636)	Prec@1 62.500 (57.056)	
2022-01-05 15:40:59 - INFO - TRAINING - Epoch: [1][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.6641 (1.1712)	Prec@1 67.188 (57.774)	
2022-01-05 15:40:59 - INFO - TRAINING - Epoch: [1][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.0871 (1.1797)	Prec@1 54.688 (57.108)	
2022-01-05 15:40:59 - INFO - TRAINING - Epoch: [1][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9112 (1.1289)	Prec@1 51.562 (57.403)	
2022-01-05 15:40:59 - INFO - TRAINING - Epoch: [1][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.6263 (1.1001)	Prec@1 51.562 (57.152)	
2022-01-05 15:41:00 - INFO - EVALUATING - Epoch: [1][0/20]	Time 0.164 (0.164)	Data 0.161 (0.161)	Loss 4.3515 (4.3515)	Prec@1 23.438 (23.438)	
2022-01-05 15:41:00 - INFO - EVALUATING - Epoch: [1][10/20]	Time 0.003 (0.018)	Data 0.002 (0.017)	Loss 2.9760 (1.9804)	Prec@1 32.812 (41.051)	
2022-01-05 15:41:00 - INFO - 
 Epoch: 2	Training Loss 1.0968 	Training Prec@1 57.120 	Validation Loss 1.8142 	Validation Prec@1 46.721 	
2022-01-05 15:41:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:00 - INFO - TRAINING - Epoch: [2][0/78]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 1.7664 (1.7664)	Prec@1 53.125 (53.125)	
2022-01-05 15:41:00 - INFO - TRAINING - Epoch: [2][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 2.8545 (1.7556)	Prec@1 59.375 (55.256)	
2022-01-05 15:41:00 - INFO - TRAINING - Epoch: [2][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 2.0002 (1.6893)	Prec@1 53.125 (54.315)	
2022-01-05 15:41:00 - INFO - TRAINING - Epoch: [2][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7983 (1.4721)	Prec@1 64.062 (55.897)	
2022-01-05 15:41:00 - INFO - TRAINING - Epoch: [2][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.8762 (1.3899)	Prec@1 39.062 (55.945)	
2022-01-05 15:41:00 - INFO - TRAINING - Epoch: [2][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8787 (1.3241)	Prec@1 62.500 (57.230)	
2022-01-05 15:41:00 - INFO - TRAINING - Epoch: [2][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.6958 (1.2769)	Prec@1 50.000 (57.608)	
2022-01-05 15:41:00 - INFO - TRAINING - Epoch: [2][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1441 (1.2711)	Prec@1 54.688 (57.130)	
2022-01-05 15:41:00 - INFO - EVALUATING - Epoch: [2][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.7734 (0.7734)	Prec@1 79.688 (79.688)	
2022-01-05 15:41:00 - INFO - EVALUATING - Epoch: [2][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.1696 (1.5042)	Prec@1 40.625 (48.864)	
2022-01-05 15:41:00 - INFO - 
 Epoch: 3	Training Loss 1.2423 	Training Prec@1 56.856 	Validation Loss 1.8649 	Validation Prec@1 47.773 	
2022-01-05 15:41:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [3][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 2.4690 (2.4690)	Prec@1 42.188 (42.188)	
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [3][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.3202 (1.7441)	Prec@1 68.750 (57.244)	
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [3][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.7449 (1.3250)	Prec@1 68.750 (57.961)	
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [3][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.0373 (1.3042)	Prec@1 62.500 (57.308)	
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [3][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.2481 (1.1943)	Prec@1 64.062 (57.851)	
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [3][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9583 (1.1925)	Prec@1 50.000 (57.261)	
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [3][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.7113 (1.2044)	Prec@1 43.750 (57.480)	
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [3][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.2989 (1.2074)	Prec@1 60.938 (57.416)	
2022-01-05 15:41:01 - INFO - EVALUATING - Epoch: [3][0/20]	Time 0.150 (0.150)	Data 0.148 (0.148)	Loss 2.1493 (2.1493)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:01 - INFO - EVALUATING - Epoch: [3][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.1365 (1.0856)	Prec@1 59.375 (68.040)	
2022-01-05 15:41:01 - INFO - 
 Epoch: 4	Training Loss 1.2185 	Training Prec@1 57.586 	Validation Loss 1.3273 	Validation Prec@1 59.433 	
2022-01-05 15:41:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [4][0/78]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 1.0470 (1.0470)	Prec@1 67.188 (67.188)	
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [4][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.3829 (1.3311)	Prec@1 32.812 (53.267)	
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [4][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.3475 (1.3579)	Prec@1 56.250 (54.092)	
2022-01-05 15:41:01 - INFO - TRAINING - Epoch: [4][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 2.5120 (1.4071)	Prec@1 59.375 (55.343)	
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [4][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.8208 (1.3493)	Prec@1 62.500 (55.602)	
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [4][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.5341 (1.3504)	Prec@1 81.250 (55.423)	
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [4][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 2.0057 (1.3896)	Prec@1 51.562 (55.123)	
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [4][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7106 (1.3175)	Prec@1 62.500 (55.304)	
2022-01-05 15:41:02 - INFO - EVALUATING - Epoch: [4][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 2.1475 (2.1475)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:02 - INFO - EVALUATING - Epoch: [4][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.5848 (0.7251)	Prec@1 78.125 (72.727)	
2022-01-05 15:41:02 - INFO - 
 Epoch: 5	Training Loss 1.2804 	Training Prec@1 55.864 	Validation Loss 0.9763 	Validation Prec@1 63.239 	
2022-01-05 15:41:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [5][0/78]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.7946 (0.7946)	Prec@1 68.750 (68.750)	
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [5][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.9442 (1.4805)	Prec@1 67.188 (57.386)	
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [5][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 2.2088 (1.4172)	Prec@1 46.875 (56.920)	
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [5][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.1883 (1.4119)	Prec@1 48.438 (55.948)	
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [5][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.0532 (1.4441)	Prec@1 62.500 (55.983)	
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [5][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 2.0755 (1.3854)	Prec@1 53.125 (55.760)	
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [5][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.3528 (1.3824)	Prec@1 60.938 (56.660)	
2022-01-05 15:41:02 - INFO - TRAINING - Epoch: [5][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0912 (1.3803)	Prec@1 54.688 (56.580)	
2022-01-05 15:41:03 - INFO - EVALUATING - Epoch: [5][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8821 (0.8821)	Prec@1 20.312 (20.312)	
2022-01-05 15:41:03 - INFO - EVALUATING - Epoch: [5][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.6779 (0.7113)	Prec@1 59.375 (52.983)	
2022-01-05 15:41:03 - INFO - 
 Epoch: 6	Training Loss 1.3476 	Training Prec@1 56.492 	Validation Loss 0.7106 	Validation Prec@1 53.117 	
2022-01-05 15:41:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:03 - INFO - TRAINING - Epoch: [6][0/78]	Time 0.149 (0.149)	Data 0.143 (0.143)	Loss 0.6861 (0.6861)	Prec@1 57.812 (57.812)	
2022-01-05 15:41:03 - INFO - TRAINING - Epoch: [6][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.7955 (1.7803)	Prec@1 65.625 (59.801)	
2022-01-05 15:41:03 - INFO - TRAINING - Epoch: [6][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.9797 (1.6381)	Prec@1 64.062 (58.854)	
2022-01-05 15:41:03 - INFO - TRAINING - Epoch: [6][30/78]	Time 0.005 (0.009)	Data 0.002 (0.007)	Loss 1.9571 (1.5703)	Prec@1 53.125 (57.308)	
2022-01-05 15:41:03 - INFO - TRAINING - Epoch: [6][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 2.2333 (1.4551)	Prec@1 40.625 (57.012)	
2022-01-05 15:41:03 - INFO - TRAINING - Epoch: [6][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.2456 (1.4265)	Prec@1 59.375 (57.077)	
2022-01-05 15:41:03 - INFO - TRAINING - Epoch: [6][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7716 (1.3616)	Prec@1 60.938 (57.121)	
2022-01-05 15:41:03 - INFO - TRAINING - Epoch: [6][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.9133 (1.3094)	Prec@1 48.438 (56.998)	
2022-01-05 15:41:03 - INFO - EVALUATING - Epoch: [6][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.9335 (0.9335)	Prec@1 60.938 (60.938)	
2022-01-05 15:41:03 - INFO - EVALUATING - Epoch: [6][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.9552 (1.5487)	Prec@1 70.312 (43.182)	
2022-01-05 15:41:03 - INFO - 
 Epoch: 7	Training Loss 1.3035 	Training Prec@1 57.059 	Validation Loss 1.4476 	Validation Prec@1 45.830 	
2022-01-05 15:41:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:04 - INFO - TRAINING - Epoch: [7][0/78]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 1.5054 (1.5054)	Prec@1 48.438 (48.438)	
2022-01-05 15:41:04 - INFO - TRAINING - Epoch: [7][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.1834 (1.8058)	Prec@1 57.812 (58.097)	
2022-01-05 15:41:04 - INFO - TRAINING - Epoch: [7][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.8446 (1.5916)	Prec@1 54.688 (57.440)	
2022-01-05 15:41:04 - INFO - TRAINING - Epoch: [7][30/78]	Time 0.005 (0.009)	Data 0.002 (0.007)	Loss 0.7104 (1.5351)	Prec@1 53.125 (57.611)	
2022-01-05 15:41:04 - INFO - TRAINING - Epoch: [7][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.2544 (1.4195)	Prec@1 45.312 (56.593)	
2022-01-05 15:41:04 - INFO - TRAINING - Epoch: [7][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7445 (1.4194)	Prec@1 43.750 (56.771)	
2022-01-05 15:41:04 - INFO - TRAINING - Epoch: [7][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.9280 (1.4131)	Prec@1 57.812 (56.890)	
2022-01-05 15:41:04 - INFO - TRAINING - Epoch: [7][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8637 (1.3515)	Prec@1 59.375 (56.866)	
2022-01-05 15:41:04 - INFO - EVALUATING - Epoch: [7][0/20]	Time 0.146 (0.146)	Data 0.142 (0.142)	Loss 0.0477 (0.0477)	Prec@1 100.000 (100.000)	
2022-01-05 15:41:04 - INFO - EVALUATING - Epoch: [7][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.8641 (1.1094)	Prec@1 81.250 (71.023)	
2022-01-05 15:41:04 - INFO - 
 Epoch: 8	Training Loss 1.3317 	Training Prec@1 56.877 	Validation Loss 1.3752 	Validation Prec@1 60.081 	
2022-01-05 15:41:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:04 - INFO - TRAINING - Epoch: [8][0/78]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 1.7104 (1.7104)	Prec@1 53.125 (53.125)	
2022-01-05 15:41:04 - INFO - TRAINING - Epoch: [8][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 2.3887 (1.7078)	Prec@1 48.438 (54.972)	
2022-01-05 15:41:04 - INFO - TRAINING - Epoch: [8][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.7801 (1.6096)	Prec@1 57.812 (55.283)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [8][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 2.1925 (1.4760)	Prec@1 39.062 (55.998)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [8][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.8747 (1.5012)	Prec@1 45.312 (56.174)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [8][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.3317 (1.4833)	Prec@1 60.938 (55.974)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [8][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0674 (1.4785)	Prec@1 64.062 (55.994)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [8][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.2564 (1.5453)	Prec@1 56.250 (55.656)	
2022-01-05 15:41:05 - INFO - EVALUATING - Epoch: [8][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 1.0865 (1.0865)	Prec@1 68.750 (68.750)	
2022-01-05 15:41:05 - INFO - EVALUATING - Epoch: [8][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 2.0170 (2.3197)	Prec@1 51.562 (43.466)	
2022-01-05 15:41:05 - INFO - 
 Epoch: 9	Training Loss 1.5171 	Training Prec@1 56.228 	Validation Loss 2.2086 	Validation Prec@1 42.834 	
2022-01-05 15:41:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [9][0/78]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 2.3493 (2.3493)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [9][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.9537 (2.0302)	Prec@1 59.375 (57.244)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [9][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.4943 (1.9620)	Prec@1 62.500 (57.217)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [9][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.2541 (1.7058)	Prec@1 62.500 (55.242)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [9][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.6653 (1.5467)	Prec@1 57.812 (56.174)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [9][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9209 (1.4155)	Prec@1 64.062 (57.598)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [9][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7102 (1.3306)	Prec@1 57.812 (56.788)	
2022-01-05 15:41:05 - INFO - TRAINING - Epoch: [9][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7192 (1.2793)	Prec@1 56.250 (56.976)	
2022-01-05 15:41:06 - INFO - EVALUATING - Epoch: [9][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 4.6249 (4.6249)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:06 - INFO - EVALUATING - Epoch: [9][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.6271 (1.1140)	Prec@1 76.562 (68.466)	
2022-01-05 15:41:06 - INFO - 
 Epoch: 10	Training Loss 1.2489 	Training Prec@1 56.553 	Validation Loss 1.3599 	Validation Prec@1 60.000 	
2022-01-05 15:41:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:06 - INFO - TRAINING - Epoch: [10][0/78]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 1.0950 (1.0950)	Prec@1 60.938 (60.938)	
2022-01-05 15:41:06 - INFO - TRAINING - Epoch: [10][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 2.3369 (1.4762)	Prec@1 32.812 (56.392)	
2022-01-05 15:41:06 - INFO - TRAINING - Epoch: [10][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.1366 (1.4714)	Prec@1 59.375 (56.027)	
2022-01-05 15:41:06 - INFO - TRAINING - Epoch: [10][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.2439 (1.4561)	Prec@1 62.500 (56.502)	
2022-01-05 15:41:06 - INFO - TRAINING - Epoch: [10][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.9584 (1.3306)	Prec@1 57.812 (58.155)	
2022-01-05 15:41:06 - INFO - TRAINING - Epoch: [10][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 2.0005 (1.3458)	Prec@1 46.875 (57.567)	
2022-01-05 15:41:06 - INFO - TRAINING - Epoch: [10][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0513 (1.3243)	Prec@1 56.250 (57.147)	
2022-01-05 15:41:06 - INFO - TRAINING - Epoch: [10][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.2976 (1.2949)	Prec@1 65.625 (57.372)	
2022-01-05 15:41:06 - INFO - EVALUATING - Epoch: [10][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.9420 (0.9420)	Prec@1 79.688 (79.688)	
2022-01-05 15:41:06 - INFO - EVALUATING - Epoch: [10][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 3.7095 (2.5120)	Prec@1 40.625 (47.017)	
2022-01-05 15:41:06 - INFO - 
 Epoch: 11	Training Loss 1.2880 	Training Prec@1 57.120 	Validation Loss 2.4331 	Validation Prec@1 46.883 	
2022-01-05 15:41:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:07 - INFO - TRAINING - Epoch: [11][0/78]	Time 0.151 (0.151)	Data 0.144 (0.144)	Loss 2.3000 (2.3000)	Prec@1 46.875 (46.875)	
2022-01-05 15:41:07 - INFO - TRAINING - Epoch: [11][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.1891 (1.5194)	Prec@1 68.750 (55.682)	
2022-01-05 15:41:07 - INFO - TRAINING - Epoch: [11][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0362 (1.4376)	Prec@1 59.375 (56.399)	
2022-01-05 15:41:07 - INFO - TRAINING - Epoch: [11][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 2.2859 (1.3567)	Prec@1 43.750 (56.452)	
2022-01-05 15:41:07 - INFO - TRAINING - Epoch: [11][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.6857 (1.3594)	Prec@1 54.688 (55.678)	
2022-01-05 15:41:07 - INFO - TRAINING - Epoch: [11][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.2809 (1.3273)	Prec@1 32.812 (54.565)	
2022-01-05 15:41:07 - INFO - TRAINING - Epoch: [11][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.2774 (1.2764)	Prec@1 40.625 (55.994)	
2022-01-05 15:41:07 - INFO - TRAINING - Epoch: [11][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.4469 (1.3011)	Prec@1 53.125 (55.810)	
2022-01-05 15:41:07 - INFO - EVALUATING - Epoch: [11][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.5065 (0.5065)	Prec@1 79.688 (79.688)	
2022-01-05 15:41:07 - INFO - EVALUATING - Epoch: [11][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.9826 (0.9047)	Prec@1 40.625 (47.017)	
2022-01-05 15:41:07 - INFO - 
 Epoch: 12	Training Loss 1.3308 	Training Prec@1 56.026 	Validation Loss 0.9063 	Validation Prec@1 46.883 	
2022-01-05 15:41:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:07 - INFO - TRAINING - Epoch: [12][0/78]	Time 0.149 (0.149)	Data 0.143 (0.143)	Loss 0.8683 (0.8683)	Prec@1 50.000 (50.000)	
2022-01-05 15:41:07 - INFO - TRAINING - Epoch: [12][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 2.3335 (1.6683)	Prec@1 48.438 (55.824)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [12][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 2.5114 (1.7532)	Prec@1 31.250 (54.911)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [12][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 2.0212 (1.6287)	Prec@1 46.875 (56.754)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [12][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.3636 (1.6109)	Prec@1 50.000 (55.793)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [12][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.8493 (1.5686)	Prec@1 56.250 (56.403)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [12][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1214 (1.4960)	Prec@1 57.812 (56.019)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [12][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 2.4067 (1.4705)	Prec@1 50.000 (56.690)	
2022-01-05 15:41:08 - INFO - EVALUATING - Epoch: [12][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.6597 (0.6597)	Prec@1 79.688 (79.688)	
2022-01-05 15:41:08 - INFO - EVALUATING - Epoch: [12][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.8188 (0.5905)	Prec@1 57.812 (67.330)	
2022-01-05 15:41:08 - INFO - 
 Epoch: 13	Training Loss 1.4519 	Training Prec@1 56.836 	Validation Loss 0.7585 	Validation Prec@1 57.166 	
2022-01-05 15:41:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [13][0/78]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.9085 (0.9085)	Prec@1 48.438 (48.438)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [13][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.3572 (1.2988)	Prec@1 39.062 (55.824)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [13][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.1568 (1.3897)	Prec@1 62.500 (56.250)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [13][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.3847 (1.5432)	Prec@1 57.812 (54.385)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [13][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.8889 (1.5353)	Prec@1 65.625 (54.116)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [13][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9649 (1.4814)	Prec@1 59.375 (55.270)	
2022-01-05 15:41:08 - INFO - TRAINING - Epoch: [13][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6329 (1.3968)	Prec@1 67.188 (55.610)	
2022-01-05 15:41:09 - INFO - TRAINING - Epoch: [13][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1518 (1.3714)	Prec@1 57.812 (55.590)	
2022-01-05 15:41:09 - INFO - EVALUATING - Epoch: [13][0/20]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 4.0023 (4.0023)	Prec@1 50.000 (50.000)	
2022-01-05 15:41:09 - INFO - EVALUATING - Epoch: [13][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.8702 (1.1684)	Prec@1 75.000 (80.114)	
2022-01-05 15:41:09 - INFO - 
 Epoch: 14	Training Loss 1.3499 	Training Prec@1 54.892 	Validation Loss 1.4587 	Validation Prec@1 65.749 	
2022-01-05 15:41:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:09 - INFO - TRAINING - Epoch: [14][0/78]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 1.1280 (1.1280)	Prec@1 64.062 (64.062)	
2022-01-05 15:41:09 - INFO - TRAINING - Epoch: [14][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.4858 (1.3315)	Prec@1 48.438 (53.267)	
2022-01-05 15:41:09 - INFO - TRAINING - Epoch: [14][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8949 (1.4126)	Prec@1 62.500 (53.795)	
2022-01-05 15:41:09 - INFO - TRAINING - Epoch: [14][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.3109 (1.3457)	Prec@1 59.375 (54.587)	
2022-01-05 15:41:09 - INFO - TRAINING - Epoch: [14][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.1841 (1.3056)	Prec@1 64.062 (55.602)	
2022-01-05 15:41:09 - INFO - TRAINING - Epoch: [14][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9497 (1.3054)	Prec@1 65.625 (55.025)	
2022-01-05 15:41:09 - INFO - TRAINING - Epoch: [14][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1511 (1.2574)	Prec@1 60.938 (55.558)	
2022-01-05 15:41:09 - INFO - TRAINING - Epoch: [14][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0424 (1.2163)	Prec@1 71.875 (56.294)	
2022-01-05 15:41:09 - INFO - EVALUATING - Epoch: [14][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.0034 (1.0034)	Prec@1 20.312 (20.312)	
2022-01-05 15:41:10 - INFO - EVALUATING - Epoch: [14][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.6951 (0.8352)	Prec@1 59.375 (52.983)	
2022-01-05 15:41:10 - INFO - 
 Epoch: 15	Training Loss 1.2157 	Training Prec@1 56.512 	Validation Loss 0.9184 	Validation Prec@1 53.117 	
2022-01-05 15:41:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:10 - INFO - TRAINING - Epoch: [15][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 1.0146 (1.0146)	Prec@1 56.250 (56.250)	
2022-01-05 15:41:10 - INFO - TRAINING - Epoch: [15][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.1023 (1.4124)	Prec@1 54.688 (55.682)	
2022-01-05 15:41:10 - INFO - TRAINING - Epoch: [15][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 2.0385 (1.3120)	Prec@1 48.438 (55.134)	
2022-01-05 15:41:10 - INFO - TRAINING - Epoch: [15][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.6594 (1.4664)	Prec@1 50.000 (54.889)	
2022-01-05 15:41:10 - INFO - TRAINING - Epoch: [15][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.7997 (1.3401)	Prec@1 48.438 (55.907)	
2022-01-05 15:41:10 - INFO - TRAINING - Epoch: [15][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.2385 (1.3043)	Prec@1 51.562 (55.821)	
2022-01-05 15:41:10 - INFO - TRAINING - Epoch: [15][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0486 (1.2666)	Prec@1 56.250 (55.815)	
2022-01-05 15:41:10 - INFO - TRAINING - Epoch: [15][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.2471 (1.2162)	Prec@1 43.750 (56.052)	
2022-01-05 15:41:10 - INFO - EVALUATING - Epoch: [15][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.6173 (0.6173)	Prec@1 79.688 (79.688)	
2022-01-05 15:41:10 - INFO - EVALUATING - Epoch: [15][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.6243 (0.7987)	Prec@1 56.250 (41.761)	
2022-01-05 15:41:10 - INFO - 
 Epoch: 16	Training Loss 1.2137 	Training Prec@1 56.026 	Validation Loss 0.7726 	Validation Prec@1 44.291 	
2022-01-05 15:41:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:10 - INFO - TRAINING - Epoch: [16][0/78]	Time 0.151 (0.151)	Data 0.144 (0.144)	Loss 0.8056 (0.8056)	Prec@1 32.812 (32.812)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [16][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.2190 (1.4699)	Prec@1 50.000 (51.705)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [16][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8259 (1.2315)	Prec@1 46.875 (51.637)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [16][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.5484 (1.1510)	Prec@1 62.500 (53.125)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [16][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.3468 (1.2438)	Prec@1 46.875 (52.744)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [16][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8230 (1.2491)	Prec@1 43.750 (53.615)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [16][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.2890 (1.2178)	Prec@1 45.312 (54.380)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [16][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.4849 (1.2144)	Prec@1 45.312 (54.732)	
2022-01-05 15:41:11 - INFO - EVALUATING - Epoch: [16][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 2.3187 (2.3187)	Prec@1 20.312 (20.312)	
2022-01-05 15:41:11 - INFO - EVALUATING - Epoch: [16][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.2100 (1.3914)	Prec@1 59.375 (52.983)	
2022-01-05 15:41:11 - INFO - 
 Epoch: 17	Training Loss 1.2453 	Training Prec@1 54.649 	Validation Loss 1.3876 	Validation Prec@1 53.117 	
2022-01-05 15:41:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [17][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 1.2543 (1.2543)	Prec@1 57.812 (57.812)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [17][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.9877 (1.7227)	Prec@1 57.812 (54.545)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [17][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0968 (1.3851)	Prec@1 62.500 (57.440)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [17][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.1699 (1.4027)	Prec@1 51.562 (56.502)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [17][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.9726 (1.4495)	Prec@1 64.062 (55.030)	
2022-01-05 15:41:11 - INFO - TRAINING - Epoch: [17][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.0324 (1.4078)	Prec@1 48.438 (54.596)	
2022-01-05 15:41:12 - INFO - TRAINING - Epoch: [17][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8362 (1.3477)	Prec@1 59.375 (54.431)	
2022-01-05 15:41:12 - INFO - TRAINING - Epoch: [17][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7875 (1.3166)	Prec@1 48.438 (54.974)	
2022-01-05 15:41:12 - INFO - EVALUATING - Epoch: [17][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.3391 (0.3391)	Prec@1 79.688 (79.688)	
2022-01-05 15:41:12 - INFO - EVALUATING - Epoch: [17][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.9473 (0.9213)	Prec@1 40.625 (47.017)	
2022-01-05 15:41:12 - INFO - 
 Epoch: 18	Training Loss 1.2822 	Training Prec@1 55.601 	Validation Loss 0.8956 	Validation Prec@1 46.883 	
2022-01-05 15:41:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:12 - INFO - TRAINING - Epoch: [18][0/78]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.7766 (0.7766)	Prec@1 57.812 (57.812)	
2022-01-05 15:41:12 - INFO - TRAINING - Epoch: [18][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.6344 (2.4750)	Prec@1 50.000 (59.091)	
2022-01-05 15:41:12 - INFO - TRAINING - Epoch: [18][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.8668 (2.3553)	Prec@1 57.812 (54.911)	
2022-01-05 15:41:12 - INFO - TRAINING - Epoch: [18][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.1154 (2.0664)	Prec@1 56.250 (54.587)	
2022-01-05 15:41:12 - INFO - TRAINING - Epoch: [18][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.9410 (1.8011)	Prec@1 46.875 (55.335)	
2022-01-05 15:41:12 - INFO - TRAINING - Epoch: [18][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 2.0850 (1.6643)	Prec@1 32.812 (55.362)	
2022-01-05 15:41:12 - INFO - TRAINING - Epoch: [18][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1023 (1.5505)	Prec@1 60.938 (56.122)	
2022-01-05 15:41:12 - INFO - TRAINING - Epoch: [18][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.2651 (1.4925)	Prec@1 40.625 (55.876)	
2022-01-05 15:41:13 - INFO - EVALUATING - Epoch: [18][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.2118 (1.2118)	Prec@1 50.000 (50.000)	
2022-01-05 15:41:13 - INFO - EVALUATING - Epoch: [18][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.6729 (0.5992)	Prec@1 67.188 (79.403)	
2022-01-05 15:41:13 - INFO - 
 Epoch: 19	Training Loss 1.4630 	Training Prec@1 55.925 	Validation Loss 0.6958 	Validation Prec@1 66.316 	
2022-01-05 15:41:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:13 - INFO - TRAINING - Epoch: [19][0/78]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.7643 (0.7643)	Prec@1 65.625 (65.625)	
2022-01-05 15:41:13 - INFO - TRAINING - Epoch: [19][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.7303 (1.4519)	Prec@1 50.000 (59.233)	
2022-01-05 15:41:13 - INFO - TRAINING - Epoch: [19][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.4105 (1.3312)	Prec@1 51.562 (57.589)	
2022-01-05 15:41:13 - INFO - TRAINING - Epoch: [19][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7890 (1.3126)	Prec@1 48.438 (57.006)	
2022-01-05 15:41:13 - INFO - TRAINING - Epoch: [19][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.4317 (1.3775)	Prec@1 51.562 (56.669)	
2022-01-05 15:41:13 - INFO - TRAINING - Epoch: [19][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9262 (1.3890)	Prec@1 67.188 (56.495)	
2022-01-05 15:41:13 - INFO - TRAINING - Epoch: [19][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.3137 (1.4054)	Prec@1 64.062 (56.122)	
2022-01-05 15:41:13 - INFO - TRAINING - Epoch: [19][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.5122 (1.3522)	Prec@1 53.125 (56.184)	
2022-01-05 15:41:13 - INFO - EVALUATING - Epoch: [19][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.2725 (1.2725)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:13 - INFO - EVALUATING - Epoch: [19][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.6491 (0.7493)	Prec@1 82.812 (73.722)	
2022-01-05 15:41:13 - INFO - 
 Epoch: 20	Training Loss 1.3335 	Training Prec@1 55.844 	Validation Loss 1.3073 	Validation Prec@1 62.429 	
2022-01-05 15:41:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [20][0/78]	Time 0.152 (0.152)	Data 0.145 (0.145)	Loss 1.4072 (1.4072)	Prec@1 60.938 (60.938)	
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [20][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.7031 (0.8913)	Prec@1 54.688 (56.392)	
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [20][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.6332 (0.8306)	Prec@1 67.188 (56.250)	
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [20][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7598 (0.8072)	Prec@1 59.375 (59.123)	
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [20][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.6421 (0.8061)	Prec@1 65.625 (59.909)	
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [20][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7281 (0.7828)	Prec@1 40.625 (59.252)	
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [20][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.0094 (0.8076)	Prec@1 53.125 (59.247)	
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [20][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8521 (0.8376)	Prec@1 71.875 (58.935)	
2022-01-05 15:41:14 - INFO - EVALUATING - Epoch: [20][0/20]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.8414 (0.8414)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:14 - INFO - EVALUATING - Epoch: [20][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.4516 (0.6436)	Prec@1 78.125 (61.080)	
2022-01-05 15:41:14 - INFO - 
 Epoch: 21	Training Loss 0.8363 	Training Prec@1 58.659 	Validation Loss 0.7455 	Validation Prec@1 58.462 	
2022-01-05 15:41:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:14 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [21][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.7946 (0.7946)	Prec@1 59.375 (59.375)	
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [21][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.9146 (1.3334)	Prec@1 48.438 (57.386)	
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [21][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.6929 (1.0538)	Prec@1 60.938 (58.705)	
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [21][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.9228 (0.9510)	Prec@1 59.375 (60.736)	
2022-01-05 15:41:14 - INFO - TRAINING - Epoch: [21][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.7213 (0.8823)	Prec@1 62.500 (62.043)	
2022-01-05 15:41:15 - INFO - TRAINING - Epoch: [21][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.4748 (0.8449)	Prec@1 67.188 (60.723)	
2022-01-05 15:41:15 - INFO - TRAINING - Epoch: [21][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6891 (0.8336)	Prec@1 59.375 (60.886)	
2022-01-05 15:41:15 - INFO - TRAINING - Epoch: [21][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6382 (0.8085)	Prec@1 64.062 (61.400)	
2022-01-05 15:41:15 - INFO - EVALUATING - Epoch: [21][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8645 (0.8645)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:15 - INFO - EVALUATING - Epoch: [21][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.4623 (0.6490)	Prec@1 78.125 (61.506)	
2022-01-05 15:41:15 - INFO - 
 Epoch: 22	Training Loss 0.8060 	Training Prec@1 61.758 	Validation Loss 0.6947 	Validation Prec@1 58.462 	
2022-01-05 15:41:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:15 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:15 - INFO - TRAINING - Epoch: [22][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.6294 (0.6294)	Prec@1 68.750 (68.750)	
2022-01-05 15:41:15 - INFO - TRAINING - Epoch: [22][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.8593 (1.0086)	Prec@1 56.250 (59.801)	
2022-01-05 15:41:15 - INFO - TRAINING - Epoch: [22][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8232 (0.9618)	Prec@1 62.500 (60.938)	
2022-01-05 15:41:15 - INFO - TRAINING - Epoch: [22][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.9487 (0.9279)	Prec@1 62.500 (59.425)	
2022-01-05 15:41:15 - INFO - TRAINING - Epoch: [22][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.7191 (0.8979)	Prec@1 60.938 (59.756)	
2022-01-05 15:41:15 - INFO - TRAINING - Epoch: [22][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6748 (0.8654)	Prec@1 65.625 (59.099)	
2022-01-05 15:41:15 - INFO - TRAINING - Epoch: [22][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6083 (0.8476)	Prec@1 65.625 (59.657)	
2022-01-05 15:41:15 - INFO - TRAINING - Epoch: [22][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9247 (0.8436)	Prec@1 54.688 (59.331)	
2022-01-05 15:41:16 - INFO - EVALUATING - Epoch: [22][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.5048 (0.5048)	Prec@1 79.688 (79.688)	
2022-01-05 15:41:16 - INFO - EVALUATING - Epoch: [22][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.0235 (0.9386)	Prec@1 40.625 (47.017)	
2022-01-05 15:41:16 - INFO - 
 Epoch: 23	Training Loss 0.8473 	Training Prec@1 59.084 	Validation Loss 0.9404 	Validation Prec@1 46.883 	
2022-01-05 15:41:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:16 - INFO - TRAINING - Epoch: [23][0/78]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.9405 (0.9405)	Prec@1 46.875 (46.875)	
2022-01-05 15:41:16 - INFO - TRAINING - Epoch: [23][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 0.6959 (0.9487)	Prec@1 57.812 (59.233)	
2022-01-05 15:41:16 - INFO - TRAINING - Epoch: [23][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.7856 (0.8401)	Prec@1 65.625 (61.384)	
2022-01-05 15:41:16 - INFO - TRAINING - Epoch: [23][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6211 (0.7810)	Prec@1 64.062 (63.105)	
2022-01-05 15:41:16 - INFO - TRAINING - Epoch: [23][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.0209 (0.7872)	Prec@1 60.938 (61.966)	
2022-01-05 15:41:16 - INFO - TRAINING - Epoch: [23][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7738 (0.7890)	Prec@1 45.312 (61.305)	
2022-01-05 15:41:16 - INFO - TRAINING - Epoch: [23][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8703 (0.7865)	Prec@1 57.812 (61.219)	
2022-01-05 15:41:16 - INFO - TRAINING - Epoch: [23][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7301 (0.7802)	Prec@1 53.125 (60.233)	
2022-01-05 15:41:16 - INFO - EVALUATING - Epoch: [23][0/20]	Time 0.155 (0.155)	Data 0.152 (0.152)	Loss 0.5113 (0.5113)	Prec@1 84.375 (84.375)	
2022-01-05 15:41:16 - INFO - EVALUATING - Epoch: [23][10/20]	Time 0.003 (0.017)	Data 0.002 (0.016)	Loss 0.5071 (0.5442)	Prec@1 76.562 (72.869)	
2022-01-05 15:41:16 - INFO - 
 Epoch: 24	Training Loss 0.7869 	Training Prec@1 60.117 	Validation Loss 0.8157 	Validation Prec@1 63.239 	
2022-01-05 15:41:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:17 - INFO - TRAINING - Epoch: [24][0/78]	Time 0.153 (0.153)	Data 0.147 (0.147)	Loss 0.3675 (0.3675)	Prec@1 85.938 (85.938)	
2022-01-05 15:41:17 - INFO - TRAINING - Epoch: [24][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 0.6401 (0.8759)	Prec@1 73.438 (65.057)	
2022-01-05 15:41:17 - INFO - TRAINING - Epoch: [24][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.9598 (0.8151)	Prec@1 59.375 (64.137)	
2022-01-05 15:41:17 - INFO - TRAINING - Epoch: [24][30/78]	Time 0.006 (0.010)	Data 0.002 (0.007)	Loss 0.7435 (0.8082)	Prec@1 40.625 (61.240)	
2022-01-05 15:41:17 - INFO - TRAINING - Epoch: [24][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.6831 (0.7803)	Prec@1 53.125 (60.137)	
2022-01-05 15:41:17 - INFO - TRAINING - Epoch: [24][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6841 (0.7659)	Prec@1 59.375 (60.509)	
2022-01-05 15:41:17 - INFO - TRAINING - Epoch: [24][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7225 (0.7661)	Prec@1 57.812 (60.758)	
2022-01-05 15:41:17 - INFO - TRAINING - Epoch: [24][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.9742 (0.8021)	Prec@1 57.812 (59.749)	
2022-01-05 15:41:17 - INFO - EVALUATING - Epoch: [24][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.9202 (0.9202)	Prec@1 20.312 (20.312)	
2022-01-05 15:41:17 - INFO - EVALUATING - Epoch: [24][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.6584 (0.6992)	Prec@1 59.375 (52.983)	
2022-01-05 15:41:17 - INFO - 
 Epoch: 25	Training Loss 0.7962 	Training Prec@1 59.996 	Validation Loss 0.7978 	Validation Prec@1 53.117 	
2022-01-05 15:41:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:17 - INFO - TRAINING - Epoch: [25][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.9323 (0.9323)	Prec@1 46.875 (46.875)	
2022-01-05 15:41:17 - INFO - TRAINING - Epoch: [25][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.1742 (1.2170)	Prec@1 60.938 (52.273)	
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [25][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.6891 (1.1226)	Prec@1 65.625 (56.548)	
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [25][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7232 (1.0006)	Prec@1 60.938 (57.712)	
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [25][40/78]	Time 0.006 (0.009)	Data 0.003 (0.006)	Loss 0.5858 (0.9275)	Prec@1 68.750 (59.146)	
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [25][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7519 (0.8923)	Prec@1 37.500 (59.252)	
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [25][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7660 (0.8711)	Prec@1 59.375 (59.554)	
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [25][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9365 (0.8943)	Prec@1 51.562 (59.045)	
2022-01-05 15:41:18 - INFO - EVALUATING - Epoch: [25][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.3005 (0.3005)	Prec@1 79.688 (79.688)	
2022-01-05 15:41:18 - INFO - EVALUATING - Epoch: [25][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.0958 (0.8808)	Prec@1 40.625 (47.017)	
2022-01-05 15:41:18 - INFO - 
 Epoch: 26	Training Loss 0.9018 	Training Prec@1 58.943 	Validation Loss 0.9796 	Validation Prec@1 46.802 	
2022-01-05 15:41:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [26][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 1.2567 (1.2567)	Prec@1 32.812 (32.812)	
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [26][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 0.8250 (1.3305)	Prec@1 54.688 (52.841)	
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [26][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8194 (1.1350)	Prec@1 37.500 (55.580)	
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [26][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8692 (1.0281)	Prec@1 65.625 (57.157)	
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [26][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.8811 (0.9982)	Prec@1 65.625 (58.422)	
2022-01-05 15:41:18 - INFO - TRAINING - Epoch: [26][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9872 (0.9846)	Prec@1 32.812 (57.690)	
2022-01-05 15:41:19 - INFO - TRAINING - Epoch: [26][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.5041 (0.9955)	Prec@1 51.562 (57.812)	
2022-01-05 15:41:19 - INFO - TRAINING - Epoch: [26][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7886 (0.9581)	Prec@1 65.625 (57.614)	
2022-01-05 15:41:19 - INFO - EVALUATING - Epoch: [26][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.8482 (0.8482)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:19 - INFO - EVALUATING - Epoch: [26][10/20]	Time 0.004 (0.017)	Data 0.002 (0.015)	Loss 0.5776 (0.5374)	Prec@1 75.000 (77.557)	
2022-01-05 15:41:19 - INFO - 
 Epoch: 27	Training Loss 0.9487 	Training Prec@1 58.213 	Validation Loss 0.6534 	Validation Prec@1 66.478 	
2022-01-05 15:41:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:19 - INFO - TRAINING - Epoch: [27][0/78]	Time 0.154 (0.154)	Data 0.146 (0.146)	Loss 0.7785 (0.7785)	Prec@1 54.688 (54.688)	
2022-01-05 15:41:19 - INFO - TRAINING - Epoch: [27][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 0.7236 (1.1219)	Prec@1 68.750 (54.545)	
2022-01-05 15:41:19 - INFO - TRAINING - Epoch: [27][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.1045 (1.0902)	Prec@1 70.312 (58.333)	
2022-01-05 15:41:19 - INFO - TRAINING - Epoch: [27][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.5156 (1.0806)	Prec@1 50.000 (57.006)	
2022-01-05 15:41:19 - INFO - TRAINING - Epoch: [27][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.8134 (1.0707)	Prec@1 48.438 (56.136)	
2022-01-05 15:41:19 - INFO - TRAINING - Epoch: [27][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9111 (1.0264)	Prec@1 64.062 (56.219)	
2022-01-05 15:41:19 - INFO - TRAINING - Epoch: [27][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7410 (0.9867)	Prec@1 60.938 (56.762)	
2022-01-05 15:41:19 - INFO - TRAINING - Epoch: [27][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7079 (0.9502)	Prec@1 60.938 (57.923)	
2022-01-05 15:41:20 - INFO - EVALUATING - Epoch: [27][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 1.9470 (1.9470)	Prec@1 50.000 (50.000)	
2022-01-05 15:41:20 - INFO - EVALUATING - Epoch: [27][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.8274 (0.7678)	Prec@1 75.000 (79.261)	
2022-01-05 15:41:20 - INFO - 
 Epoch: 28	Training Loss 0.9333 	Training Prec@1 57.322 	Validation Loss 1.1142 	Validation Prec@1 66.883 	
2022-01-05 15:41:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:20 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:20 - INFO - TRAINING - Epoch: [28][0/78]	Time 0.158 (0.158)	Data 0.152 (0.152)	Loss 1.5035 (1.5035)	Prec@1 57.812 (57.812)	
2022-01-05 15:41:20 - INFO - TRAINING - Epoch: [28][10/78]	Time 0.005 (0.019)	Data 0.002 (0.016)	Loss 0.8986 (1.5456)	Prec@1 64.062 (54.972)	
2022-01-05 15:41:20 - INFO - TRAINING - Epoch: [28][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.9912 (1.2773)	Prec@1 56.250 (57.812)	
2022-01-05 15:41:20 - INFO - TRAINING - Epoch: [28][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6603 (1.1790)	Prec@1 67.188 (58.669)	
2022-01-05 15:41:20 - INFO - TRAINING - Epoch: [28][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.8726 (1.0739)	Prec@1 32.812 (59.108)	
2022-01-05 15:41:20 - INFO - TRAINING - Epoch: [28][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9390 (1.0246)	Prec@1 57.812 (58.395)	
2022-01-05 15:41:20 - INFO - TRAINING - Epoch: [28][60/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.5462 (0.9666)	Prec@1 76.562 (59.606)	
2022-01-05 15:41:20 - INFO - TRAINING - Epoch: [28][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.5626 (0.9200)	Prec@1 73.438 (60.497)	
2022-01-05 15:41:20 - INFO - EVALUATING - Epoch: [28][0/20]	Time 0.148 (0.148)	Data 0.146 (0.146)	Loss 1.0669 (1.0669)	Prec@1 50.000 (50.000)	
2022-01-05 15:41:20 - INFO - EVALUATING - Epoch: [28][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.5495 (0.5795)	Prec@1 76.562 (75.568)	
2022-01-05 15:41:20 - INFO - 
 Epoch: 29	Training Loss 0.8971 	Training Prec@1 61.353 	Validation Loss 0.7694 	Validation Prec@1 63.806 	
2022-01-05 15:41:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:20 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:21 - INFO - TRAINING - Epoch: [29][0/78]	Time 0.132 (0.132)	Data 0.127 (0.127)	Loss 0.6368 (0.6368)	Prec@1 70.312 (70.312)	
2022-01-05 15:41:21 - INFO - TRAINING - Epoch: [29][10/78]	Time 0.005 (0.017)	Data 0.002 (0.014)	Loss 0.8086 (1.1403)	Prec@1 64.062 (61.364)	
2022-01-05 15:41:21 - INFO - TRAINING - Epoch: [29][20/78]	Time 0.005 (0.011)	Data 0.002 (0.008)	Loss 0.7024 (0.9885)	Prec@1 68.750 (61.384)	
2022-01-05 15:41:21 - INFO - TRAINING - Epoch: [29][30/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.6218 (0.8827)	Prec@1 70.312 (63.407)	
2022-01-05 15:41:21 - INFO - TRAINING - Epoch: [29][40/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.0509 (0.8671)	Prec@1 67.188 (63.377)	
2022-01-05 15:41:21 - INFO - TRAINING - Epoch: [29][50/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.6778 (0.8440)	Prec@1 65.625 (64.154)	
2022-01-05 15:41:21 - INFO - TRAINING - Epoch: [29][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6641 (0.8177)	Prec@1 51.562 (63.012)	
2022-01-05 15:41:21 - INFO - TRAINING - Epoch: [29][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7028 (0.8206)	Prec@1 53.125 (61.664)	
2022-01-05 15:41:21 - INFO - EVALUATING - Epoch: [29][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.6890 (1.6890)	Prec@1 34.375 (34.375)	
2022-01-05 15:41:21 - INFO - EVALUATING - Epoch: [29][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.4644 (0.6805)	Prec@1 84.375 (75.000)	
2022-01-05 15:41:21 - INFO - 
 Epoch: 30	Training Loss 0.8159 	Training Prec@1 61.130 	Validation Loss 0.9363 	Validation Prec@1 63.563 	
2022-01-05 15:41:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:21 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:21 - INFO - TRAINING - Epoch: [30][0/78]	Time 0.158 (0.158)	Data 0.152 (0.152)	Loss 1.0314 (1.0314)	Prec@1 59.375 (59.375)	
2022-01-05 15:41:21 - INFO - TRAINING - Epoch: [30][10/78]	Time 0.005 (0.019)	Data 0.002 (0.016)	Loss 1.4929 (1.9068)	Prec@1 62.500 (55.540)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [30][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.1517 (1.6963)	Prec@1 67.188 (52.232)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [30][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.9947 (1.4459)	Prec@1 64.062 (54.940)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [30][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.0388 (1.3711)	Prec@1 73.438 (54.649)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [30][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8212 (1.3501)	Prec@1 56.250 (56.189)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [30][60/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 1.0542 (1.2563)	Prec@1 53.125 (56.532)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [30][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6284 (1.1925)	Prec@1 65.625 (57.130)	
2022-01-05 15:41:22 - INFO - EVALUATING - Epoch: [30][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8583 (0.8583)	Prec@1 34.375 (34.375)	
2022-01-05 15:41:22 - INFO - EVALUATING - Epoch: [30][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.4564 (0.6017)	Prec@1 84.375 (71.449)	
2022-01-05 15:41:22 - INFO - 
 Epoch: 31	Training Loss 1.1495 	Training Prec@1 57.606 	Validation Loss 0.7366 	Validation Prec@1 62.834 	
2022-01-05 15:41:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:22 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [31][0/78]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 0.7613 (0.7613)	Prec@1 62.500 (62.500)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [31][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.9799 (1.5020)	Prec@1 73.438 (60.227)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [31][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.6799 (1.2035)	Prec@1 64.062 (60.789)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [31][30/78]	Time 0.005 (0.009)	Data 0.002 (0.007)	Loss 0.8532 (1.0844)	Prec@1 54.688 (62.198)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [31][40/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7339 (0.9928)	Prec@1 54.688 (62.043)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [31][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9191 (0.9455)	Prec@1 48.438 (61.152)	
2022-01-05 15:41:22 - INFO - TRAINING - Epoch: [31][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8347 (0.9122)	Prec@1 48.438 (60.067)	
2022-01-05 15:41:23 - INFO - TRAINING - Epoch: [31][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7329 (0.8834)	Prec@1 51.562 (60.145)	
2022-01-05 15:41:23 - INFO - EVALUATING - Epoch: [31][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.6860 (1.6860)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:23 - INFO - EVALUATING - Epoch: [31][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.6711 (0.7192)	Prec@1 59.375 (59.801)	
2022-01-05 15:41:23 - INFO - 
 Epoch: 32	Training Loss 0.8717 	Training Prec@1 59.469 	Validation Loss 0.8067 	Validation Prec@1 57.328 	
2022-01-05 15:41:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:23 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:23 - INFO - TRAINING - Epoch: [32][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.7730 (0.7730)	Prec@1 57.812 (57.812)	
2022-01-05 15:41:23 - INFO - TRAINING - Epoch: [32][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 2.0879 (1.2523)	Prec@1 53.125 (55.540)	
2022-01-05 15:41:23 - INFO - TRAINING - Epoch: [32][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.0376 (1.1138)	Prec@1 57.812 (56.101)	
2022-01-05 15:41:23 - INFO - TRAINING - Epoch: [32][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6862 (0.9895)	Prec@1 57.812 (57.157)	
2022-01-05 15:41:23 - INFO - TRAINING - Epoch: [32][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.6972 (0.9168)	Prec@1 56.250 (58.765)	
2022-01-05 15:41:23 - INFO - TRAINING - Epoch: [32][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6722 (0.8719)	Prec@1 65.625 (59.344)	
2022-01-05 15:41:23 - INFO - TRAINING - Epoch: [32][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7029 (0.8506)	Prec@1 62.500 (60.220)	
2022-01-05 15:41:23 - INFO - TRAINING - Epoch: [32][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8945 (0.8512)	Prec@1 64.062 (59.441)	
2022-01-05 15:41:23 - INFO - EVALUATING - Epoch: [32][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8606 (0.8606)	Prec@1 34.375 (34.375)	
2022-01-05 15:41:24 - INFO - EVALUATING - Epoch: [32][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.6746 (0.6312)	Prec@1 76.562 (74.290)	
2022-01-05 15:41:24 - INFO - 
 Epoch: 33	Training Loss 0.8601 	Training Prec@1 59.105 	Validation Loss 0.8960 	Validation Prec@1 62.429 	
2022-01-05 15:41:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:24 - INFO - TRAINING - Epoch: [33][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.8736 (0.8736)	Prec@1 62.500 (62.500)	
2022-01-05 15:41:24 - INFO - TRAINING - Epoch: [33][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.2328 (1.2785)	Prec@1 67.188 (54.545)	
2022-01-05 15:41:24 - INFO - TRAINING - Epoch: [33][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.6857 (1.1536)	Prec@1 60.938 (56.101)	
2022-01-05 15:41:24 - INFO - TRAINING - Epoch: [33][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.9173 (1.0552)	Prec@1 71.875 (57.964)	
2022-01-05 15:41:24 - INFO - TRAINING - Epoch: [33][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.6744 (1.0296)	Prec@1 73.438 (57.203)	
2022-01-05 15:41:24 - INFO - TRAINING - Epoch: [33][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 2.1373 (1.0636)	Prec@1 50.000 (57.996)	
2022-01-05 15:41:24 - INFO - TRAINING - Epoch: [33][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.3215 (1.0409)	Prec@1 53.125 (57.992)	
2022-01-05 15:41:24 - INFO - TRAINING - Epoch: [33][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7335 (1.0158)	Prec@1 71.875 (57.790)	
2022-01-05 15:41:24 - INFO - EVALUATING - Epoch: [33][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.8552 (0.8552)	Prec@1 34.375 (34.375)	
2022-01-05 15:41:24 - INFO - EVALUATING - Epoch: [33][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.6791 (0.5769)	Prec@1 76.562 (74.290)	
2022-01-05 15:41:24 - INFO - 
 Epoch: 34	Training Loss 1.0006 	Training Prec@1 58.396 	Validation Loss 0.7844 	Validation Prec@1 62.753 	
2022-01-05 15:41:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [34][0/78]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 0.7734 (0.7734)	Prec@1 64.062 (64.062)	
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [34][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.9359 (1.6285)	Prec@1 35.938 (54.830)	
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [34][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8176 (1.2361)	Prec@1 46.875 (52.753)	
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [34][30/78]	Time 0.005 (0.009)	Data 0.002 (0.007)	Loss 1.1712 (1.1728)	Prec@1 51.562 (54.032)	
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [34][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.7521 (1.0809)	Prec@1 53.125 (55.640)	
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [34][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.5976 (1.0179)	Prec@1 73.438 (56.219)	
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [34][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6417 (1.0060)	Prec@1 65.625 (56.609)	
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [34][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7961 (0.9775)	Prec@1 39.062 (56.602)	
2022-01-05 15:41:25 - INFO - EVALUATING - Epoch: [34][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.9744 (1.9744)	Prec@1 50.000 (50.000)	
2022-01-05 15:41:25 - INFO - EVALUATING - Epoch: [34][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.6298 (0.6295)	Prec@1 76.562 (78.125)	
2022-01-05 15:41:25 - INFO - 
 Epoch: 35	Training Loss 0.9575 	Training Prec@1 57.484 	Validation Loss 0.8645 	Validation Prec@1 65.263 	
2022-01-05 15:41:25 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:25 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:25 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [35][0/78]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.7427 (0.7427)	Prec@1 60.938 (60.938)	
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [35][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.9400 (1.6614)	Prec@1 62.500 (57.670)	
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [35][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.5875 (1.2997)	Prec@1 73.438 (61.533)	
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [35][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.9872 (1.2612)	Prec@1 59.375 (58.720)	
2022-01-05 15:41:25 - INFO - TRAINING - Epoch: [35][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 2.0959 (1.2196)	Prec@1 42.188 (59.299)	
2022-01-05 15:41:26 - INFO - TRAINING - Epoch: [35][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.2535 (1.1542)	Prec@1 46.875 (58.640)	
2022-01-05 15:41:26 - INFO - TRAINING - Epoch: [35][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.8192 (1.1456)	Prec@1 57.812 (58.914)	
2022-01-05 15:41:26 - INFO - TRAINING - Epoch: [35][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8971 (1.1718)	Prec@1 51.562 (59.507)	
2022-01-05 15:41:26 - INFO - EVALUATING - Epoch: [35][0/20]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 2.5586 (2.5586)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:26 - INFO - EVALUATING - Epoch: [35][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.7590 (1.7746)	Prec@1 78.125 (61.080)	
2022-01-05 15:41:26 - INFO - 
 Epoch: 36	Training Loss 1.1511 	Training Prec@1 57.808 	Validation Loss 1.9129 	Validation Prec@1 58.381 	
2022-01-05 15:41:26 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:26 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:26 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:26 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:26 - INFO - TRAINING - Epoch: [36][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 1.7230 (1.7230)	Prec@1 59.375 (59.375)	
2022-01-05 15:41:26 - INFO - TRAINING - Epoch: [36][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.4693 (1.8072)	Prec@1 42.188 (55.398)	
2022-01-05 15:41:26 - INFO - TRAINING - Epoch: [36][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.7108 (1.4335)	Prec@1 56.250 (56.994)	
2022-01-05 15:41:26 - INFO - TRAINING - Epoch: [36][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8222 (1.2583)	Prec@1 65.625 (56.351)	
2022-01-05 15:41:26 - INFO - TRAINING - Epoch: [36][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.1636 (1.2067)	Prec@1 59.375 (55.640)	
2022-01-05 15:41:26 - INFO - TRAINING - Epoch: [36][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6728 (1.1193)	Prec@1 59.375 (57.904)	
2022-01-05 15:41:26 - INFO - TRAINING - Epoch: [36][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9174 (1.0700)	Prec@1 53.125 (57.044)	
2022-01-05 15:41:26 - INFO - TRAINING - Epoch: [36][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7104 (1.0232)	Prec@1 65.625 (58.033)	
2022-01-05 15:41:27 - INFO - EVALUATING - Epoch: [36][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6127 (0.6127)	Prec@1 79.688 (79.688)	
2022-01-05 15:41:27 - INFO - EVALUATING - Epoch: [36][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.7345 (0.7145)	Prec@1 40.625 (47.017)	
2022-01-05 15:41:27 - INFO - 
 Epoch: 37	Training Loss 0.9992 	Training Prec@1 58.173 	Validation Loss 0.7150 	Validation Prec@1 46.883 	
2022-01-05 15:41:27 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:27 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:27 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:27 - INFO - TRAINING - Epoch: [37][0/78]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.7393 (0.7393)	Prec@1 39.062 (39.062)	
2022-01-05 15:41:27 - INFO - TRAINING - Epoch: [37][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.4030 (1.5613)	Prec@1 48.438 (57.812)	
2022-01-05 15:41:27 - INFO - TRAINING - Epoch: [37][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.7988 (1.2675)	Prec@1 59.375 (57.217)	
2022-01-05 15:41:27 - INFO - TRAINING - Epoch: [37][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6591 (1.0982)	Prec@1 70.312 (57.863)	
2022-01-05 15:41:27 - INFO - TRAINING - Epoch: [37][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.5673 (1.0580)	Prec@1 75.000 (60.137)	
2022-01-05 15:41:27 - INFO - TRAINING - Epoch: [37][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6953 (0.9839)	Prec@1 57.812 (59.620)	
2022-01-05 15:41:27 - INFO - TRAINING - Epoch: [37][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7485 (0.9509)	Prec@1 59.375 (60.630)	
2022-01-05 15:41:27 - INFO - TRAINING - Epoch: [37][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.9159 (0.9673)	Prec@1 39.062 (59.661)	
2022-01-05 15:41:27 - INFO - EVALUATING - Epoch: [37][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8135 (0.8135)	Prec@1 84.375 (84.375)	
2022-01-05 15:41:27 - INFO - EVALUATING - Epoch: [37][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 1.3905 (1.1512)	Prec@1 40.625 (52.273)	
2022-01-05 15:41:27 - INFO - 
 Epoch: 38	Training Loss 1.0220 	Training Prec@1 59.712 	Validation Loss 1.0640 	Validation Prec@1 52.227 	
2022-01-05 15:41:27 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:27 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:27 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:28 - INFO - TRAINING - Epoch: [38][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 1.0402 (1.0402)	Prec@1 59.375 (59.375)	
2022-01-05 15:41:28 - INFO - TRAINING - Epoch: [38][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.7523 (1.2906)	Prec@1 60.938 (60.085)	
2022-01-05 15:41:28 - INFO - TRAINING - Epoch: [38][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.2280 (1.1717)	Prec@1 62.500 (57.812)	
2022-01-05 15:41:28 - INFO - TRAINING - Epoch: [38][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8435 (1.0467)	Prec@1 60.938 (59.980)	
2022-01-05 15:41:28 - INFO - TRAINING - Epoch: [38][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.6699 (1.0595)	Prec@1 67.188 (60.213)	
2022-01-05 15:41:28 - INFO - TRAINING - Epoch: [38][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.9031 (0.9916)	Prec@1 54.688 (60.815)	
2022-01-05 15:41:28 - INFO - TRAINING - Epoch: [38][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6634 (0.9586)	Prec@1 62.500 (59.144)	
2022-01-05 15:41:28 - INFO - TRAINING - Epoch: [38][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6816 (0.9795)	Prec@1 60.938 (59.221)	
2022-01-05 15:41:28 - INFO - EVALUATING - Epoch: [38][0/20]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.6111 (0.6111)	Prec@1 50.000 (50.000)	
2022-01-05 15:41:28 - INFO - EVALUATING - Epoch: [38][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.5518 (0.5179)	Prec@1 75.000 (79.261)	
2022-01-05 15:41:28 - INFO - 
 Epoch: 39	Training Loss 0.9578 	Training Prec@1 59.003 	Validation Loss 0.7382 	Validation Prec@1 66.073 	
2022-01-05 15:41:28 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:28 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:28 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:28 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:28 - INFO - TRAINING - Epoch: [39][0/78]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.7237 (0.7237)	Prec@1 70.312 (70.312)	
2022-01-05 15:41:28 - INFO - TRAINING - Epoch: [39][10/78]	Time 0.005 (0.019)	Data 0.002 (0.015)	Loss 1.4160 (1.6874)	Prec@1 46.875 (53.693)	
2022-01-05 15:41:28 - INFO - TRAINING - Epoch: [39][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.3586 (1.3760)	Prec@1 57.812 (57.812)	
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [39][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8793 (1.3034)	Prec@1 51.562 (56.804)	
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [39][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.9385 (1.2202)	Prec@1 59.375 (55.259)	
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [39][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7162 (1.1336)	Prec@1 48.438 (56.679)	
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [39][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9606 (1.0978)	Prec@1 46.875 (56.737)	
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [39][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7140 (1.0437)	Prec@1 64.062 (57.460)	
2022-01-05 15:41:29 - INFO - EVALUATING - Epoch: [39][0/20]	Time 0.152 (0.152)	Data 0.149 (0.149)	Loss 0.9279 (0.9279)	Prec@1 20.312 (20.312)	
2022-01-05 15:41:29 - INFO - EVALUATING - Epoch: [39][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.6828 (0.7229)	Prec@1 59.375 (52.983)	
2022-01-05 15:41:29 - INFO - 
 Epoch: 40	Training Loss 1.0187 	Training Prec@1 57.889 	Validation Loss 0.7220 	Validation Prec@1 53.117 	
2022-01-05 15:41:29 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:29 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:29 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:29 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [40][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.6631 (0.6631)	Prec@1 62.500 (62.500)	
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [40][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.0978 (1.6927)	Prec@1 53.125 (51.562)	
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [40][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.4849 (1.4109)	Prec@1 46.875 (54.390)	
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [40][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7631 (1.2999)	Prec@1 59.375 (55.292)	
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [40][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.0351 (1.2052)	Prec@1 59.375 (56.974)	
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [40][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7883 (1.1476)	Prec@1 62.500 (57.047)	
2022-01-05 15:41:29 - INFO - TRAINING - Epoch: [40][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.5390 (1.0948)	Prec@1 39.062 (56.839)	
2022-01-05 15:41:30 - INFO - TRAINING - Epoch: [40][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7318 (1.0558)	Prec@1 51.562 (57.152)	
2022-01-05 15:41:30 - INFO - EVALUATING - Epoch: [40][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8390 (0.8390)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:30 - INFO - EVALUATING - Epoch: [40][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.5271 (0.6535)	Prec@1 78.125 (61.506)	
2022-01-05 15:41:30 - INFO - 
 Epoch: 41	Training Loss 1.0216 	Training Prec@1 58.051 	Validation Loss 0.6912 	Validation Prec@1 58.300 	
2022-01-05 15:41:30 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:30 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:30 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:30 - INFO - TRAINING - Epoch: [41][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.7272 (0.7272)	Prec@1 57.812 (57.812)	
2022-01-05 15:41:30 - INFO - TRAINING - Epoch: [41][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.0733 (1.4714)	Prec@1 57.812 (60.511)	
2022-01-05 15:41:30 - INFO - TRAINING - Epoch: [41][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.7674 (1.1783)	Prec@1 62.500 (57.440)	
2022-01-05 15:41:30 - INFO - TRAINING - Epoch: [41][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.8960 (1.0781)	Prec@1 57.812 (57.712)	
2022-01-05 15:41:30 - INFO - TRAINING - Epoch: [41][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.7680 (1.0176)	Prec@1 53.125 (58.270)	
2022-01-05 15:41:30 - INFO - TRAINING - Epoch: [41][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.7555 (1.1061)	Prec@1 57.812 (57.567)	
2022-01-05 15:41:30 - INFO - TRAINING - Epoch: [41][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7471 (1.1108)	Prec@1 65.625 (58.094)	
2022-01-05 15:41:30 - INFO - TRAINING - Epoch: [41][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9488 (1.0671)	Prec@1 67.188 (58.891)	
2022-01-05 15:41:30 - INFO - EVALUATING - Epoch: [41][0/20]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.4565 (0.4565)	Prec@1 100.000 (100.000)	
2022-01-05 15:41:31 - INFO - EVALUATING - Epoch: [41][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.7438 (0.6407)	Prec@1 40.625 (56.960)	
2022-01-05 15:41:31 - INFO - 
 Epoch: 42	Training Loss 1.0471 	Training Prec@1 59.267 	Validation Loss 0.7090 	Validation Prec@1 53.279 	
2022-01-05 15:41:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:31 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:31 - INFO - TRAINING - Epoch: [42][0/78]	Time 0.153 (0.153)	Data 0.147 (0.147)	Loss 0.8879 (0.8879)	Prec@1 46.875 (46.875)	
2022-01-05 15:41:31 - INFO - TRAINING - Epoch: [42][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.7808 (2.6678)	Prec@1 59.375 (54.830)	
2022-01-05 15:41:31 - INFO - TRAINING - Epoch: [42][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.1961 (1.8537)	Prec@1 51.562 (52.083)	
2022-01-05 15:41:31 - INFO - TRAINING - Epoch: [42][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.2500 (1.5821)	Prec@1 31.250 (52.470)	
2022-01-05 15:41:31 - INFO - TRAINING - Epoch: [42][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.8427 (1.3956)	Prec@1 59.375 (54.078)	
2022-01-05 15:41:31 - INFO - TRAINING - Epoch: [42][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.5591 (1.2487)	Prec@1 71.875 (56.679)	
2022-01-05 15:41:31 - INFO - TRAINING - Epoch: [42][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7446 (1.1503)	Prec@1 64.062 (58.274)	
2022-01-05 15:41:31 - INFO - TRAINING - Epoch: [42][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6360 (1.0844)	Prec@1 68.750 (58.891)	
2022-01-05 15:41:31 - INFO - EVALUATING - Epoch: [42][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.5992 (0.5992)	Prec@1 79.688 (79.688)	
2022-01-05 15:41:31 - INFO - EVALUATING - Epoch: [42][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.7458 (0.7218)	Prec@1 40.625 (47.017)	
2022-01-05 15:41:31 - INFO - 
 Epoch: 43	Training Loss 1.0498 	Training Prec@1 59.368 	Validation Loss 0.7224 	Validation Prec@1 46.883 	
2022-01-05 15:41:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:31 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [43][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.7224 (0.7224)	Prec@1 46.875 (46.875)	
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [43][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.8189 (1.8521)	Prec@1 78.125 (58.239)	
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [43][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8144 (1.3618)	Prec@1 57.812 (58.631)	
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [43][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.9671 (1.1868)	Prec@1 34.375 (55.746)	
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [43][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 2.5266 (1.1957)	Prec@1 64.062 (55.412)	
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [43][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.3687 (1.1585)	Prec@1 51.562 (56.801)	
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [43][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.6672 (1.1040)	Prec@1 64.062 (58.555)	
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [43][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7714 (1.0540)	Prec@1 45.312 (57.482)	
2022-01-05 15:41:32 - INFO - EVALUATING - Epoch: [43][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.7392 (0.7392)	Prec@1 68.750 (68.750)	
2022-01-05 15:41:32 - INFO - EVALUATING - Epoch: [43][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.9659 (0.9316)	Prec@1 21.875 (30.540)	
2022-01-05 15:41:32 - INFO - 
 Epoch: 44	Training Loss 1.0401 	Training Prec@1 57.869 	Validation Loss 0.8654 	Validation Prec@1 38.866 	
2022-01-05 15:41:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:32 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [44][0/78]	Time 0.154 (0.154)	Data 0.148 (0.148)	Loss 0.9730 (0.9730)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [44][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.6552 (1.5945)	Prec@1 57.812 (56.392)	
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [44][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 3.2430 (1.4112)	Prec@1 39.062 (56.845)	
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [44][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7705 (1.2666)	Prec@1 45.312 (56.653)	
2022-01-05 15:41:32 - INFO - TRAINING - Epoch: [44][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.9031 (1.1374)	Prec@1 67.188 (58.460)	
2022-01-05 15:41:33 - INFO - TRAINING - Epoch: [44][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8583 (1.0690)	Prec@1 59.375 (58.425)	
2022-01-05 15:41:33 - INFO - TRAINING - Epoch: [44][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9000 (1.0579)	Prec@1 59.375 (58.069)	
2022-01-05 15:41:33 - INFO - TRAINING - Epoch: [44][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.8526 (1.0380)	Prec@1 46.875 (58.055)	
2022-01-05 15:41:33 - INFO - EVALUATING - Epoch: [44][0/20]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.7682 (0.7682)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:33 - INFO - EVALUATING - Epoch: [44][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.5270 (0.5575)	Prec@1 78.125 (73.580)	
2022-01-05 15:41:33 - INFO - 
 Epoch: 45	Training Loss 1.0147 	Training Prec@1 58.598 	Validation Loss 0.6744 	Validation Prec@1 63.401 	
2022-01-05 15:41:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:33 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:33 - INFO - TRAINING - Epoch: [45][0/78]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.6437 (0.6437)	Prec@1 68.750 (68.750)	
2022-01-05 15:41:33 - INFO - TRAINING - Epoch: [45][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.0175 (1.3671)	Prec@1 57.812 (60.085)	
2022-01-05 15:41:33 - INFO - TRAINING - Epoch: [45][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.6273 (1.4386)	Prec@1 64.062 (57.068)	
2022-01-05 15:41:33 - INFO - TRAINING - Epoch: [45][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7995 (1.2572)	Prec@1 37.500 (57.056)	
2022-01-05 15:41:33 - INFO - TRAINING - Epoch: [45][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.9174 (1.1888)	Prec@1 48.438 (57.546)	
2022-01-05 15:41:33 - INFO - TRAINING - Epoch: [45][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7442 (1.0916)	Prec@1 51.562 (58.487)	
2022-01-05 15:41:33 - INFO - TRAINING - Epoch: [45][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7401 (1.0209)	Prec@1 62.500 (59.477)	
2022-01-05 15:41:33 - INFO - TRAINING - Epoch: [45][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7412 (0.9880)	Prec@1 50.000 (59.287)	
2022-01-05 15:41:34 - INFO - EVALUATING - Epoch: [45][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.3319 (1.3319)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:34 - INFO - EVALUATING - Epoch: [45][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.5952 (0.5962)	Prec@1 75.000 (77.557)	
2022-01-05 15:41:34 - INFO - 
 Epoch: 46	Training Loss 0.9952 	Training Prec@1 58.821 	Validation Loss 0.7081 	Validation Prec@1 66.235 	
2022-01-05 15:41:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:34 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:34 - INFO - TRAINING - Epoch: [46][0/78]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.7018 (0.7018)	Prec@1 68.750 (68.750)	
2022-01-05 15:41:34 - INFO - TRAINING - Epoch: [46][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 0.7898 (1.6491)	Prec@1 64.062 (55.682)	
2022-01-05 15:41:34 - INFO - TRAINING - Epoch: [46][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.6042 (1.2525)	Prec@1 73.438 (60.119)	
2022-01-05 15:41:34 - INFO - TRAINING - Epoch: [46][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.7942 (1.1006)	Prec@1 50.000 (60.232)	
2022-01-05 15:41:34 - INFO - TRAINING - Epoch: [46][40/78]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.9586 (1.0470)	Prec@1 64.062 (58.498)	
2022-01-05 15:41:34 - INFO - TRAINING - Epoch: [46][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7711 (1.0311)	Prec@1 56.250 (58.578)	
2022-01-05 15:41:34 - INFO - TRAINING - Epoch: [46][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9990 (1.0220)	Prec@1 43.750 (58.325)	
2022-01-05 15:41:34 - INFO - TRAINING - Epoch: [46][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 2.0039 (1.0777)	Prec@1 45.312 (57.636)	
2022-01-05 15:41:34 - INFO - EVALUATING - Epoch: [46][0/20]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.1241 (1.1241)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:34 - INFO - EVALUATING - Epoch: [46][10/20]	Time 0.003 (0.017)	Data 0.002 (0.015)	Loss 0.8470 (0.5723)	Prec@1 75.000 (78.409)	
2022-01-05 15:41:34 - INFO - 
 Epoch: 47	Training Loss 1.0566 	Training Prec@1 57.586 	Validation Loss 0.7716 	Validation Prec@1 66.559 	
2022-01-05 15:41:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:34 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:35 - INFO - TRAINING - Epoch: [47][0/78]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.8657 (0.8657)	Prec@1 65.625 (65.625)	
2022-01-05 15:41:35 - INFO - TRAINING - Epoch: [47][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 2.2273 (1.6840)	Prec@1 54.688 (57.244)	
2022-01-05 15:41:35 - INFO - TRAINING - Epoch: [47][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.7882 (1.3411)	Prec@1 64.062 (57.217)	
2022-01-05 15:41:35 - INFO - TRAINING - Epoch: [47][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 2.9301 (1.3403)	Prec@1 37.500 (56.905)	
2022-01-05 15:41:35 - INFO - TRAINING - Epoch: [47][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 1.0147 (1.2337)	Prec@1 56.250 (57.927)	
2022-01-05 15:41:35 - INFO - TRAINING - Epoch: [47][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.8858 (1.1309)	Prec@1 48.438 (59.528)	
2022-01-05 15:41:35 - INFO - TRAINING - Epoch: [47][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7404 (1.0746)	Prec@1 59.375 (59.887)	
2022-01-05 15:41:35 - INFO - TRAINING - Epoch: [47][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.1198 (1.0603)	Prec@1 59.375 (59.045)	
2022-01-05 15:41:35 - INFO - EVALUATING - Epoch: [47][0/20]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.4163 (0.4163)	Prec@1 84.375 (84.375)	
2022-01-05 15:41:35 - INFO - EVALUATING - Epoch: [47][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.4609 (0.6616)	Prec@1 81.250 (58.949)	
2022-01-05 15:41:35 - INFO - 
 Epoch: 48	Training Loss 1.0575 	Training Prec@1 58.902 	Validation Loss 1.1125 	Validation Prec@1 52.794 	
2022-01-05 15:41:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:35 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:35 - INFO - TRAINING - Epoch: [48][0/78]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.7407 (0.7407)	Prec@1 59.375 (59.375)	
2022-01-05 15:41:35 - INFO - TRAINING - Epoch: [48][10/78]	Time 0.005 (0.018)	Data 0.002 (0.015)	Loss 1.0310 (1.3520)	Prec@1 42.188 (59.375)	
2022-01-05 15:41:35 - INFO - TRAINING - Epoch: [48][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 1.3822 (1.5176)	Prec@1 71.875 (59.226)	
2022-01-05 15:41:36 - INFO - TRAINING - Epoch: [48][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 0.6963 (1.3617)	Prec@1 65.625 (59.123)	
2022-01-05 15:41:36 - INFO - TRAINING - Epoch: [48][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.7304 (1.2346)	Prec@1 67.188 (60.938)	
2022-01-05 15:41:36 - INFO - TRAINING - Epoch: [48][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6440 (1.1335)	Prec@1 64.062 (61.029)	
2022-01-05 15:41:36 - INFO - TRAINING - Epoch: [48][60/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.7725 (1.0564)	Prec@1 57.812 (61.706)	
2022-01-05 15:41:36 - INFO - TRAINING - Epoch: [48][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 1.4035 (1.0400)	Prec@1 62.500 (60.761)	
2022-01-05 15:41:36 - INFO - EVALUATING - Epoch: [48][0/20]	Time 0.163 (0.163)	Data 0.161 (0.161)	Loss 0.7837 (0.7837)	Prec@1 31.250 (31.250)	
2022-01-05 15:41:36 - INFO - EVALUATING - Epoch: [48][10/20]	Time 0.003 (0.018)	Data 0.002 (0.017)	Loss 0.4594 (0.6311)	Prec@1 78.125 (60.227)	
2022-01-05 15:41:36 - INFO - 
 Epoch: 49	Training Loss 1.0305 	Training Prec@1 60.138 	Validation Loss 0.7549 	Validation Prec@1 58.300 	
2022-01-05 15:41:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:41:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:41:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:41:36 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:41:36 - INFO - TRAINING - Epoch: [49][0/78]	Time 0.161 (0.161)	Data 0.156 (0.156)	Loss 1.0890 (1.0890)	Prec@1 53.125 (53.125)	
2022-01-05 15:41:36 - INFO - TRAINING - Epoch: [49][10/78]	Time 0.005 (0.019)	Data 0.002 (0.016)	Loss 3.3221 (2.4737)	Prec@1 57.812 (55.398)	
2022-01-05 15:41:36 - INFO - TRAINING - Epoch: [49][20/78]	Time 0.005 (0.012)	Data 0.002 (0.009)	Loss 0.8509 (1.8644)	Prec@1 56.250 (58.259)	
2022-01-05 15:41:36 - INFO - TRAINING - Epoch: [49][30/78]	Time 0.005 (0.010)	Data 0.002 (0.007)	Loss 1.0761 (1.6047)	Prec@1 39.062 (57.661)	
2022-01-05 15:41:36 - INFO - TRAINING - Epoch: [49][40/78]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.7846 (1.4075)	Prec@1 54.688 (59.223)	
2022-01-05 15:41:36 - INFO - TRAINING - Epoch: [49][50/78]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.6051 (1.3031)	Prec@1 75.000 (58.701)	
2022-01-05 15:41:37 - INFO - TRAINING - Epoch: [49][60/78]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.6165 (1.1941)	Prec@1 70.312 (60.297)	
2022-01-05 15:41:37 - INFO - TRAINING - Epoch: [49][70/78]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.9635 (1.1354)	Prec@1 32.812 (59.507)	
2022-01-05 15:41:37 - INFO - EVALUATING - Epoch: [49][0/20]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.4163 (0.4163)	Prec@1 81.250 (81.250)	
2022-01-05 15:41:37 - INFO - EVALUATING - Epoch: [49][10/20]	Time 0.003 (0.016)	Data 0.002 (0.015)	Loss 0.6231 (0.6284)	Prec@1 76.562 (75.852)	
2022-01-05 15:41:37 - INFO - 
 Epoch: 50	Training Loss 1.1313 	Training Prec@1 59.631 	Validation Loss 0.8846 	Validation Prec@1 65.668 	
