2022-01-19 14:47:42 - INFO - saving to ./results/medium/quantise/q5/other/anchor/lending/lending_test1/
2022-01-19 14:47:42 - DEBUG - run arguments: Namespace(config='./configs/config_medium.json', data='../../paper_bench/complete/quantise/q5/other/anchor/lending/lending_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/medium/quantise/q5/other/anchor/lending/lending_test1/', test='../../paper_bench/cv/test/quantise/q5/other/anchor/lending/lending_test1_data.csv', train='../../paper_bench/cv/train/quantise/q5/other/anchor/lending/lending_train1_data.csv')
2022-01-19 14:47:42 - INFO - creating model mlp_binary
2022-01-19 14:47:42 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [32, 16, 8, 2]}
2022-01-19 14:47:42 - INFO - number of parameters: 1946
2022-01-19 14:47:42 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-19 14:47:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][0/128]	Time 0.209 (0.209)	Data 0.203 (0.203)	Loss 1.3608 (1.3608)	Prec@1 57.812 (57.812)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.7491 (1.0336)	Prec@1 67.188 (64.205)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6548 (0.8796)	Prec@1 73.438 (66.220)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.4398 (0.8166)	Prec@1 84.375 (67.843)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5419 (0.7520)	Prec@1 79.688 (71.113)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8436 (0.7391)	Prec@1 64.062 (71.017)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7201 (0.7348)	Prec@1 62.500 (71.363)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6206 (0.7144)	Prec@1 76.562 (72.073)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4660 (0.6858)	Prec@1 81.250 (73.283)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6971 (0.6759)	Prec@1 51.562 (73.369)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4392 (0.6755)	Prec@1 85.938 (73.793)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5738 (0.6734)	Prec@1 78.125 (73.691)	
2022-01-19 14:47:42 - INFO - TRAINING - Epoch: [0][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4509 (0.6705)	Prec@1 85.938 (73.722)	
2022-01-19 14:47:43 - INFO - EVALUATING - Epoch: [0][0/32]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.1986 (0.1986)	Prec@1 95.312 (95.312)	
2022-01-19 14:47:43 - INFO - EVALUATING - Epoch: [0][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.3064 (0.4844)	Prec@1 89.062 (87.074)	
2022-01-19 14:47:43 - INFO - EVALUATING - Epoch: [0][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3424 (0.5871)	Prec@1 90.625 (84.301)	
2022-01-19 14:47:43 - INFO - EVALUATING - Epoch: [0][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.0619 (0.7343)	Prec@1 78.125 (81.250)	
2022-01-19 14:47:43 - INFO - 
 Epoch: 1	Training Loss 0.6699 	Training Prec@1 73.809 	Validation Loss 0.7416 	Validation Prec@1 81.039 	
2022-01-19 14:47:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][0/128]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.6850 (0.6850)	Prec@1 82.812 (82.812)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][10/128]	Time 0.007 (0.023)	Data 0.002 (0.020)	Loss 1.1479 (0.8753)	Prec@1 73.438 (63.920)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.5640 (0.8690)	Prec@1 82.812 (66.146)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7019 (0.8361)	Prec@1 50.000 (68.296)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6294 (0.8333)	Prec@1 62.500 (68.064)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5766 (0.7941)	Prec@1 78.125 (69.730)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4826 (0.7731)	Prec@1 85.938 (70.876)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8621 (0.7567)	Prec@1 68.750 (70.973)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6726 (0.7381)	Prec@1 70.312 (71.431)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4585 (0.7520)	Prec@1 81.250 (71.549)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5115 (0.7435)	Prec@1 79.688 (71.705)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5858 (0.7366)	Prec@1 82.812 (71.931)	
2022-01-19 14:47:43 - INFO - TRAINING - Epoch: [1][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6828 (0.7339)	Prec@1 75.000 (71.978)	
2022-01-19 14:47:44 - INFO - EVALUATING - Epoch: [1][0/32]	Time 0.209 (0.209)	Data 0.207 (0.207)	Loss 0.1545 (0.1545)	Prec@1 98.438 (98.438)	
2022-01-19 14:47:44 - INFO - EVALUATING - Epoch: [1][10/32]	Time 0.003 (0.022)	Data 0.002 (0.021)	Loss 0.4093 (0.4280)	Prec@1 84.375 (88.636)	
2022-01-19 14:47:44 - INFO - EVALUATING - Epoch: [1][20/32]	Time 0.003 (0.013)	Data 0.002 (0.012)	Loss 0.2421 (0.5437)	Prec@1 93.750 (85.491)	
2022-01-19 14:47:44 - INFO - EVALUATING - Epoch: [1][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.0739 (0.6772)	Prec@1 71.875 (82.208)	
2022-01-19 14:47:44 - INFO - 
 Epoch: 2	Training Loss 0.7414 	Training Prec@1 71.714 	Validation Loss 0.6890 	Validation Prec@1 81.823 	
2022-01-19 14:47:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][0/128]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 0.6597 (0.6597)	Prec@1 81.250 (81.250)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7746 (0.6824)	Prec@1 70.312 (75.142)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5202 (0.7010)	Prec@1 79.688 (70.759)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8396 (0.7080)	Prec@1 75.000 (72.026)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7472 (0.7078)	Prec@1 50.000 (71.608)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5261 (0.7073)	Prec@1 78.125 (69.424)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6230 (0.6948)	Prec@1 81.250 (69.749)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7601 (0.6983)	Prec@1 79.688 (69.850)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4526 (0.6931)	Prec@1 81.250 (70.988)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7490 (0.7009)	Prec@1 78.125 (70.828)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7777 (0.6975)	Prec@1 53.125 (71.504)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.2889 (0.7122)	Prec@1 68.750 (70.664)	
2022-01-19 14:47:44 - INFO - TRAINING - Epoch: [2][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.8486 (0.7360)	Prec@1 70.312 (70.894)	
2022-01-19 14:47:45 - INFO - EVALUATING - Epoch: [2][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.7360 (0.7360)	Prec@1 43.750 (43.750)	
2022-01-19 14:47:45 - INFO - EVALUATING - Epoch: [2][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7905 (0.7564)	Prec@1 29.688 (38.494)	
2022-01-19 14:47:45 - INFO - EVALUATING - Epoch: [2][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.7360 (0.7366)	Prec@1 43.750 (43.601)	
2022-01-19 14:47:45 - INFO - EVALUATING - Epoch: [2][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6513 (0.7157)	Prec@1 65.625 (48.992)	
2022-01-19 14:47:45 - INFO - 
 Epoch: 3	Training Loss 0.7270 	Training Prec@1 71.310 	Validation Loss 0.7128 	Validation Prec@1 49.731 	
2022-01-19 14:47:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][0/128]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.6936 (0.6936)	Prec@1 54.688 (54.688)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.0306 (0.7925)	Prec@1 78.125 (74.574)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7150 (0.8112)	Prec@1 51.562 (74.628)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6665 (0.8245)	Prec@1 84.375 (71.925)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4109 (0.7802)	Prec@1 78.125 (72.370)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5965 (0.7441)	Prec@1 68.750 (71.078)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6065 (0.7352)	Prec@1 73.438 (71.132)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8814 (0.7261)	Prec@1 81.250 (71.765)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7194 (0.7459)	Prec@1 48.438 (71.547)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7876 (0.7428)	Prec@1 67.188 (71.772)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5851 (0.7315)	Prec@1 71.875 (72.416)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.0697 (0.7308)	Prec@1 76.562 (72.438)	
2022-01-19 14:47:45 - INFO - TRAINING - Epoch: [3][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4253 (0.7273)	Prec@1 81.250 (72.960)	
2022-01-19 14:47:46 - INFO - EVALUATING - Epoch: [3][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.3266 (0.3266)	Prec@1 92.188 (92.188)	
2022-01-19 14:47:46 - INFO - EVALUATING - Epoch: [3][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5211 (0.4552)	Prec@1 84.375 (85.938)	
2022-01-19 14:47:46 - INFO - EVALUATING - Epoch: [3][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4774 (0.4927)	Prec@1 85.938 (83.557)	
2022-01-19 14:47:46 - INFO - EVALUATING - Epoch: [3][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7219 (0.5419)	Prec@1 70.312 (80.645)	
2022-01-19 14:47:46 - INFO - 
 Epoch: 4	Training Loss 0.7257 	Training Prec@1 72.951 	Validation Loss 0.5420 	Validation Prec@1 80.549 	
2022-01-19 14:47:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][0/128]	Time 0.206 (0.206)	Data 0.202 (0.202)	Loss 0.4767 (0.4767)	Prec@1 84.375 (84.375)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][10/128]	Time 0.005 (0.023)	Data 0.002 (0.020)	Loss 1.6719 (0.9077)	Prec@1 45.312 (72.017)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.5676 (0.8521)	Prec@1 76.562 (73.512)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.5314 (0.7507)	Prec@1 81.250 (75.907)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6647 (0.7113)	Prec@1 75.000 (75.686)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7410 (0.6828)	Prec@1 81.250 (76.348)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4666 (0.7275)	Prec@1 81.250 (74.949)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.0301 (0.7218)	Prec@1 71.875 (74.736)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5586 (0.7374)	Prec@1 79.688 (74.614)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4231 (0.7296)	Prec@1 81.250 (74.468)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8967 (0.7235)	Prec@1 75.000 (73.778)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4605 (0.7230)	Prec@1 75.000 (73.508)	
2022-01-19 14:47:46 - INFO - TRAINING - Epoch: [4][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6562 (0.7144)	Prec@1 78.125 (73.773)	
2022-01-19 14:47:47 - INFO - EVALUATING - Epoch: [4][0/32]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.2045 (0.2045)	Prec@1 96.875 (96.875)	
2022-01-19 14:47:47 - INFO - EVALUATING - Epoch: [4][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6415 (0.5521)	Prec@1 84.375 (87.642)	
2022-01-19 14:47:47 - INFO - EVALUATING - Epoch: [4][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.7024 (0.6688)	Prec@1 81.250 (84.598)	
2022-01-19 14:47:47 - INFO - EVALUATING - Epoch: [4][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.2233 (0.8202)	Prec@1 70.312 (81.300)	
2022-01-19 14:47:47 - INFO - 
 Epoch: 5	Training Loss 0.7148 	Training Prec@1 73.453 	Validation Loss 0.8271 	Validation Prec@1 80.990 	
2022-01-19 14:47:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][0/128]	Time 0.194 (0.194)	Data 0.191 (0.191)	Loss 1.0733 (1.0733)	Prec@1 73.438 (73.438)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.7176 (0.6853)	Prec@1 78.125 (76.705)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.0733 (0.7265)	Prec@1 43.750 (71.354)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6504 (0.7393)	Prec@1 82.812 (71.169)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.3732 (0.7250)	Prec@1 87.500 (73.590)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.4641 (0.7392)	Prec@1 81.250 (72.151)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5002 (0.7235)	Prec@1 81.250 (72.823)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.1173 (0.7532)	Prec@1 50.000 (71.875)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7366 (0.7380)	Prec@1 73.438 (73.013)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7109 (0.7205)	Prec@1 78.125 (73.609)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8421 (0.7145)	Prec@1 68.750 (73.592)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.3804 (0.7108)	Prec@1 75.000 (73.452)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [5][120/128]	Time 0.004 (0.005)	Data 0.002 (0.003)	Loss 0.5172 (0.6954)	Prec@1 79.688 (73.825)	
2022-01-19 14:47:48 - INFO - EVALUATING - Epoch: [5][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.1055 (0.1055)	Prec@1 98.438 (98.438)	
2022-01-19 14:47:48 - INFO - EVALUATING - Epoch: [5][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6527 (0.5737)	Prec@1 84.375 (87.358)	
2022-01-19 14:47:48 - INFO - EVALUATING - Epoch: [5][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3008 (0.6801)	Prec@1 89.062 (84.970)	
2022-01-19 14:47:48 - INFO - EVALUATING - Epoch: [5][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.3385 (0.8217)	Prec@1 71.875 (81.956)	
2022-01-19 14:47:48 - INFO - 
 Epoch: 6	Training Loss 0.6942 	Training Prec@1 73.662 	Validation Loss 0.8318 	Validation Prec@1 81.774 	
2022-01-19 14:47:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][0/128]	Time 0.190 (0.190)	Data 0.186 (0.186)	Loss 0.7662 (0.7662)	Prec@1 84.375 (84.375)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 1.0725 (0.9486)	Prec@1 71.875 (67.614)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6862 (0.8607)	Prec@1 75.000 (68.824)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5401 (0.7611)	Prec@1 78.125 (69.859)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][40/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4364 (0.7393)	Prec@1 57.812 (70.160)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5079 (0.7277)	Prec@1 81.250 (72.243)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5297 (0.6972)	Prec@1 84.375 (73.386)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6465 (0.6707)	Prec@1 82.812 (74.758)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4213 (0.6644)	Prec@1 84.375 (75.540)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8001 (0.6574)	Prec@1 54.688 (75.395)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5365 (0.6616)	Prec@1 78.125 (75.371)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6889 (0.6614)	Prec@1 75.000 (75.113)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [6][120/128]	Time 0.004 (0.005)	Data 0.002 (0.003)	Loss 0.6324 (0.6647)	Prec@1 75.000 (74.742)	
2022-01-19 14:47:49 - INFO - EVALUATING - Epoch: [6][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.3691 (0.3691)	Prec@1 93.750 (93.750)	
2022-01-19 14:47:49 - INFO - EVALUATING - Epoch: [6][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5713 (0.5007)	Prec@1 78.125 (84.375)	
2022-01-19 14:47:49 - INFO - EVALUATING - Epoch: [6][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3970 (0.5286)	Prec@1 90.625 (81.845)	
2022-01-19 14:47:49 - INFO - EVALUATING - Epoch: [6][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6532 (0.5488)	Prec@1 64.062 (78.831)	
2022-01-19 14:47:49 - INFO - 
 Epoch: 7	Training Loss 0.6630 	Training Prec@1 74.666 	Validation Loss 0.5507 	Validation Prec@1 78.491 	
2022-01-19 14:47:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][0/128]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.6373 (0.6373)	Prec@1 75.000 (75.000)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4495 (0.6948)	Prec@1 81.250 (74.148)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6692 (0.6213)	Prec@1 67.188 (74.107)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5297 (0.5993)	Prec@1 78.125 (73.639)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4421 (0.5853)	Prec@1 84.375 (73.476)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4194 (0.5786)	Prec@1 85.938 (73.529)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.1375 (0.6167)	Prec@1 53.125 (73.617)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6787 (0.6187)	Prec@1 79.688 (73.636)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7238 (0.6349)	Prec@1 71.875 (74.498)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7007 (0.6495)	Prec@1 59.375 (73.678)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4280 (0.6619)	Prec@1 87.500 (73.654)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6432 (0.6883)	Prec@1 82.812 (73.353)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [7][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4503 (0.6871)	Prec@1 85.938 (73.024)	
2022-01-19 14:47:50 - INFO - EVALUATING - Epoch: [7][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.5302 (0.5302)	Prec@1 43.750 (43.750)	
2022-01-19 14:47:50 - INFO - EVALUATING - Epoch: [7][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7952 (0.6313)	Prec@1 29.688 (38.636)	
2022-01-19 14:47:50 - INFO - EVALUATING - Epoch: [7][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5478 (0.6004)	Prec@1 43.750 (43.899)	
2022-01-19 14:47:50 - INFO - EVALUATING - Epoch: [7][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6110 (0.5853)	Prec@1 65.625 (49.345)	
2022-01-19 14:47:50 - INFO - 
 Epoch: 8	Training Loss 0.6844 	Training Prec@1 73.270 	Validation Loss 0.5829 	Validation Prec@1 50.073 	
2022-01-19 14:47:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][0/128]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.5447 (0.5447)	Prec@1 70.312 (70.312)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6936 (0.7638)	Prec@1 53.125 (74.432)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.4952 (0.7709)	Prec@1 85.938 (75.149)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5400 (0.7165)	Prec@1 68.750 (74.093)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5407 (0.7545)	Prec@1 79.688 (74.466)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.3798 (0.7634)	Prec@1 73.438 (72.947)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6147 (0.7943)	Prec@1 54.688 (72.951)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7135 (0.7594)	Prec@1 76.562 (73.790)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4147 (0.7269)	Prec@1 85.938 (73.900)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6286 (0.7254)	Prec@1 75.000 (74.124)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3913 (0.7008)	Prec@1 84.375 (74.799)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5616 (0.6818)	Prec@1 82.812 (75.633)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [8][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7838 (0.6765)	Prec@1 59.375 (75.659)	
2022-01-19 14:47:51 - INFO - EVALUATING - Epoch: [8][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.5361 (0.5361)	Prec@1 43.750 (43.750)	
2022-01-19 14:47:51 - INFO - EVALUATING - Epoch: [8][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.9508 (0.6912)	Prec@1 29.688 (38.494)	
2022-01-19 14:47:51 - INFO - EVALUATING - Epoch: [8][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5525 (0.6589)	Prec@1 43.750 (43.601)	
2022-01-19 14:47:51 - INFO - EVALUATING - Epoch: [8][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7287 (0.6432)	Prec@1 65.625 (48.992)	
2022-01-19 14:47:51 - INFO - 
 Epoch: 9	Training Loss 0.6757 	Training Prec@1 75.622 	Validation Loss 0.6407 	Validation Prec@1 49.731 	
2022-01-19 14:47:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][0/128]	Time 0.203 (0.203)	Data 0.200 (0.200)	Loss 0.6300 (0.6300)	Prec@1 57.812 (57.812)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4671 (0.7574)	Prec@1 84.375 (74.858)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6626 (0.7455)	Prec@1 79.688 (76.042)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.9426 (0.7066)	Prec@1 48.438 (75.454)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6455 (0.6963)	Prec@1 75.000 (75.724)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4661 (0.6777)	Prec@1 82.812 (75.919)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6615 (0.6935)	Prec@1 60.938 (74.974)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8347 (0.6972)	Prec@1 71.875 (75.000)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6899 (0.6888)	Prec@1 68.750 (75.019)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5959 (0.6968)	Prec@1 84.375 (75.515)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4358 (0.7206)	Prec@1 81.250 (75.634)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6777 (0.7171)	Prec@1 76.562 (75.859)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [9][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5216 (0.7004)	Prec@1 81.250 (76.175)	
2022-01-19 14:47:52 - INFO - EVALUATING - Epoch: [9][0/32]	Time 0.199 (0.199)	Data 0.198 (0.198)	Loss 0.2942 (0.2942)	Prec@1 78.125 (78.125)	
2022-01-19 14:47:52 - INFO - EVALUATING - Epoch: [9][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6355 (0.4950)	Prec@1 60.938 (68.608)	
2022-01-19 14:47:52 - INFO - EVALUATING - Epoch: [9][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4605 (0.5188)	Prec@1 62.500 (68.824)	
2022-01-19 14:47:52 - INFO - EVALUATING - Epoch: [9][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7282 (0.5640)	Prec@1 68.750 (68.750)	
2022-01-19 14:47:52 - INFO - 
 Epoch: 10	Training Loss 0.6955 	Training Prec@1 76.001 	Validation Loss 0.5665 	Validation Prec@1 68.986 	
2022-01-19 14:47:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.5191 (0.5191)	Prec@1 67.188 (67.188)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 1.5898 (0.9409)	Prec@1 57.812 (72.017)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.8906 (0.8425)	Prec@1 67.188 (71.652)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8890 (0.8688)	Prec@1 71.875 (70.262)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6616 (0.8139)	Prec@1 81.250 (72.409)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7426 (0.8030)	Prec@1 75.000 (72.426)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4334 (0.7676)	Prec@1 79.688 (73.796)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.3271 (0.7334)	Prec@1 90.625 (74.274)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8674 (0.7131)	Prec@1 82.812 (74.923)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7736 (0.6994)	Prec@1 43.750 (75.034)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6056 (0.6926)	Prec@1 79.688 (75.294)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5033 (0.6891)	Prec@1 81.250 (74.620)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [10][120/128]	Time 0.004 (0.005)	Data 0.002 (0.003)	Loss 0.6375 (0.6726)	Prec@1 73.438 (75.155)	
2022-01-19 14:47:53 - INFO - EVALUATING - Epoch: [10][0/32]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.2899 (0.2899)	Prec@1 93.750 (93.750)	
2022-01-19 14:47:53 - INFO - EVALUATING - Epoch: [10][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.9698 (0.8672)	Prec@1 81.250 (81.392)	
2022-01-19 14:47:53 - INFO - EVALUATING - Epoch: [10][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.9585 (0.9368)	Prec@1 82.812 (79.836)	
2022-01-19 14:47:53 - INFO - EVALUATING - Epoch: [10][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.2526 (1.0363)	Prec@1 75.000 (77.873)	
2022-01-19 14:47:53 - INFO - 
 Epoch: 11	Training Loss 0.6817 	Training Prec@1 75.119 	Validation Loss 1.0380 	Validation Prec@1 77.805 	
2022-01-19 14:47:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][0/128]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 1.2422 (1.2422)	Prec@1 78.125 (78.125)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.3843 (0.9771)	Prec@1 82.812 (66.335)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.8677 (0.8186)	Prec@1 79.688 (69.271)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8682 (0.7453)	Prec@1 70.312 (72.782)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4318 (0.6991)	Prec@1 82.812 (73.552)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8982 (0.6829)	Prec@1 53.125 (73.100)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5698 (0.7108)	Prec@1 79.688 (72.669)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7388 (0.7707)	Prec@1 42.188 (71.875)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5144 (0.7546)	Prec@1 78.125 (72.608)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5530 (0.7449)	Prec@1 73.438 (72.339)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5477 (0.7182)	Prec@1 79.688 (73.128)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5404 (0.7165)	Prec@1 84.375 (73.170)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [11][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7376 (0.7127)	Prec@1 85.938 (72.998)	
2022-01-19 14:47:54 - INFO - EVALUATING - Epoch: [11][0/32]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.2582 (0.2582)	Prec@1 93.750 (93.750)	
2022-01-19 14:47:54 - INFO - EVALUATING - Epoch: [11][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5399 (0.4272)	Prec@1 79.688 (83.949)	
2022-01-19 14:47:54 - INFO - EVALUATING - Epoch: [11][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3487 (0.4435)	Prec@1 87.500 (81.994)	
2022-01-19 14:47:54 - INFO - EVALUATING - Epoch: [11][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7668 (0.4879)	Prec@1 59.375 (78.478)	
2022-01-19 14:47:54 - INFO - 
 Epoch: 12	Training Loss 0.7096 	Training Prec@1 72.927 	Validation Loss 0.4927 	Validation Prec@1 78.050 	
2022-01-19 14:47:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [12][0/128]	Time 0.247 (0.247)	Data 0.243 (0.243)	Loss 0.5379 (0.5379)	Prec@1 75.000 (75.000)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [12][10/128]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.5785 (0.6036)	Prec@1 75.000 (75.284)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [12][20/128]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 1.3692 (0.6224)	Prec@1 76.562 (77.009)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [12][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.8609 (0.6549)	Prec@1 68.750 (74.345)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [12][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.3052 (0.6375)	Prec@1 84.375 (74.543)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [12][50/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9055 (0.6400)	Prec@1 65.625 (73.805)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [12][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6611 (0.6439)	Prec@1 82.812 (74.283)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [12][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4419 (0.6647)	Prec@1 84.375 (73.966)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [12][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5956 (0.6647)	Prec@1 59.375 (73.611)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [12][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4538 (0.6735)	Prec@1 79.688 (73.352)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [12][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3776 (0.6632)	Prec@1 85.938 (73.963)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [12][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5433 (0.6629)	Prec@1 59.375 (73.663)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [12][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5035 (0.6487)	Prec@1 79.688 (74.174)	
2022-01-19 14:47:55 - INFO - EVALUATING - Epoch: [12][0/32]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.2919 (0.2919)	Prec@1 93.750 (93.750)	
2022-01-19 14:47:55 - INFO - EVALUATING - Epoch: [12][10/32]	Time 0.003 (0.021)	Data 0.002 (0.019)	Loss 0.5645 (0.4619)	Prec@1 82.812 (85.653)	
2022-01-19 14:47:55 - INFO - EVALUATING - Epoch: [12][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4440 (0.4883)	Prec@1 87.500 (83.780)	
2022-01-19 14:47:55 - INFO - EVALUATING - Epoch: [12][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6223 (0.5376)	Prec@1 75.000 (80.796)	
2022-01-19 14:47:55 - INFO - 
 Epoch: 13	Training Loss 0.6421 	Training Prec@1 74.446 	Validation Loss 0.5369 	Validation Prec@1 80.696 	
2022-01-19 14:47:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [13][0/128]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 0.2936 (0.2936)	Prec@1 90.625 (90.625)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [13][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4532 (0.6040)	Prec@1 84.375 (75.426)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [13][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.8393 (0.6472)	Prec@1 56.250 (73.884)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [13][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5674 (0.6584)	Prec@1 54.688 (72.480)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [13][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7339 (0.6602)	Prec@1 51.562 (72.713)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [13][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6225 (0.6702)	Prec@1 73.438 (71.967)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [13][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5131 (0.6656)	Prec@1 84.375 (72.669)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [13][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9369 (0.6653)	Prec@1 50.000 (73.239)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [13][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5340 (0.6731)	Prec@1 75.000 (73.187)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [13][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5486 (0.6721)	Prec@1 76.562 (72.837)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [13][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4269 (0.6568)	Prec@1 84.375 (73.484)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [13][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5328 (0.6578)	Prec@1 76.562 (73.156)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [13][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7236 (0.6556)	Prec@1 53.125 (72.960)	
2022-01-19 14:47:56 - INFO - EVALUATING - Epoch: [13][0/32]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.2073 (0.2073)	Prec@1 93.750 (93.750)	
2022-01-19 14:47:56 - INFO - EVALUATING - Epoch: [13][10/32]	Time 0.003 (0.021)	Data 0.002 (0.019)	Loss 0.6326 (0.4952)	Prec@1 79.688 (82.812)	
2022-01-19 14:47:56 - INFO - EVALUATING - Epoch: [13][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3763 (0.5303)	Prec@1 84.375 (82.515)	
2022-01-19 14:47:56 - INFO - EVALUATING - Epoch: [13][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.0740 (0.6219)	Prec@1 67.188 (79.536)	
2022-01-19 14:47:56 - INFO - 
 Epoch: 14	Training Loss 0.6689 	Training Prec@1 73.306 	Validation Loss 0.6332 	Validation Prec@1 79.422 	
2022-01-19 14:47:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [14][0/128]	Time 0.247 (0.247)	Data 0.243 (0.243)	Loss 0.6086 (0.6086)	Prec@1 78.125 (78.125)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [14][10/128]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.9499 (0.7241)	Prec@1 73.438 (73.295)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [14][20/128]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.5923 (0.6992)	Prec@1 84.375 (74.479)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [14][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.6476 (0.6436)	Prec@1 73.438 (76.915)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [14][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4565 (0.6243)	Prec@1 81.250 (77.058)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [14][50/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4569 (0.6110)	Prec@1 78.125 (76.471)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [14][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6812 (0.6055)	Prec@1 73.438 (76.358)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [14][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7100 (0.6158)	Prec@1 54.688 (76.034)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [14][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9053 (0.6238)	Prec@1 76.562 (76.640)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [14][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7261 (0.6256)	Prec@1 75.000 (76.442)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [14][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.0939 (0.6446)	Prec@1 70.312 (75.789)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [14][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5750 (0.6487)	Prec@1 67.188 (75.169)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [14][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5787 (0.6579)	Prec@1 79.688 (74.432)	
2022-01-19 14:47:57 - INFO - EVALUATING - Epoch: [14][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.1539 (0.1539)	Prec@1 95.312 (95.312)	
2022-01-19 14:47:57 - INFO - EVALUATING - Epoch: [14][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4294 (0.3494)	Prec@1 85.938 (87.926)	
2022-01-19 14:47:57 - INFO - EVALUATING - Epoch: [14][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2814 (0.3955)	Prec@1 89.062 (85.863)	
2022-01-19 14:47:57 - INFO - EVALUATING - Epoch: [14][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6654 (0.4767)	Prec@1 76.562 (82.157)	
2022-01-19 14:47:57 - INFO - 
 Epoch: 15	Training Loss 0.6530 	Training Prec@1 74.580 	Validation Loss 0.4813 	Validation Prec@1 82.019 	
2022-01-19 14:47:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [15][0/128]	Time 0.234 (0.234)	Data 0.230 (0.230)	Loss 0.6365 (0.6365)	Prec@1 78.125 (78.125)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [15][10/128]	Time 0.004 (0.025)	Data 0.002 (0.023)	Loss 0.6527 (0.8934)	Prec@1 48.438 (65.199)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [15][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.2977 (0.7288)	Prec@1 87.500 (72.396)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [15][30/128]	Time 0.004 (0.011)	Data 0.002 (0.009)	Loss 0.7806 (0.7158)	Prec@1 79.688 (73.185)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [15][40/128]	Time 0.004 (0.010)	Data 0.002 (0.007)	Loss 0.7114 (0.7479)	Prec@1 75.000 (72.180)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [15][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6918 (0.8406)	Prec@1 54.688 (70.956)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [15][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7731 (0.8165)	Prec@1 70.312 (70.850)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [15][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7996 (0.8026)	Prec@1 73.438 (71.765)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [15][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5043 (0.7826)	Prec@1 79.688 (71.547)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [15][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4243 (0.7592)	Prec@1 84.375 (72.287)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [15][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 2.0147 (0.7482)	Prec@1 40.625 (72.556)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [15][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7213 (0.7374)	Prec@1 51.562 (72.804)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [15][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5388 (0.7181)	Prec@1 75.000 (73.295)	
2022-01-19 14:47:58 - INFO - EVALUATING - Epoch: [15][0/32]	Time 0.195 (0.195)	Data 0.194 (0.194)	Loss 0.1127 (0.1127)	Prec@1 96.875 (96.875)	
2022-01-19 14:47:58 - INFO - EVALUATING - Epoch: [15][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.3834 (0.3658)	Prec@1 89.062 (86.790)	
2022-01-19 14:47:58 - INFO - EVALUATING - Epoch: [15][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3157 (0.4356)	Prec@1 82.812 (84.226)	
2022-01-19 14:47:58 - INFO - EVALUATING - Epoch: [15][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7402 (0.5212)	Prec@1 76.562 (81.099)	
2022-01-19 14:47:58 - INFO - 
 Epoch: 16	Training Loss 0.7091 	Training Prec@1 73.355 	Validation Loss 0.5319 	Validation Prec@1 80.941 	
2022-01-19 14:47:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [16][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.3818 (0.3818)	Prec@1 81.250 (81.250)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [16][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 1.0328 (0.6550)	Prec@1 65.625 (76.136)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [16][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5849 (0.6450)	Prec@1 76.562 (76.190)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [16][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7001 (0.6460)	Prec@1 82.812 (76.663)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [16][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.3741 (0.6313)	Prec@1 87.500 (75.686)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [16][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5359 (0.6211)	Prec@1 78.125 (76.164)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [16][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.1333 (0.6710)	Prec@1 54.688 (75.205)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [16][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.5588 (0.7552)	Prec@1 35.938 (74.670)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [16][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8352 (0.7532)	Prec@1 79.688 (74.788)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [16][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4069 (0.7506)	Prec@1 84.375 (74.845)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [16][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5465 (0.7484)	Prec@1 79.688 (74.319)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [16][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5264 (0.7325)	Prec@1 81.250 (74.550)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [16][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5011 (0.7170)	Prec@1 87.500 (74.509)	
2022-01-19 14:47:59 - INFO - EVALUATING - Epoch: [16][0/32]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.2227 (0.2227)	Prec@1 93.750 (93.750)	
2022-01-19 14:47:59 - INFO - EVALUATING - Epoch: [16][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5610 (0.4725)	Prec@1 79.688 (85.511)	
2022-01-19 14:47:59 - INFO - EVALUATING - Epoch: [16][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3226 (0.5417)	Prec@1 89.062 (84.301)	
2022-01-19 14:47:59 - INFO - EVALUATING - Epoch: [16][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8669 (0.6675)	Prec@1 78.125 (81.351)	
2022-01-19 14:47:59 - INFO - 
 Epoch: 17	Training Loss 0.7136 	Training Prec@1 74.715 	Validation Loss 0.6716 	Validation Prec@1 81.284 	
2022-01-19 14:47:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [17][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.6685 (0.6685)	Prec@1 79.688 (79.688)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [17][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.7080 (0.7628)	Prec@1 50.000 (70.170)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [17][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5864 (0.6710)	Prec@1 75.000 (73.214)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [17][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5438 (0.6829)	Prec@1 79.688 (73.589)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [17][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5525 (0.6456)	Prec@1 76.562 (74.238)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [17][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4646 (0.6242)	Prec@1 81.250 (74.939)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [17][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4207 (0.6272)	Prec@1 87.500 (74.821)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [17][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6017 (0.6313)	Prec@1 78.125 (75.154)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [17][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9077 (0.6332)	Prec@1 79.688 (75.116)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [17][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4542 (0.6244)	Prec@1 81.250 (75.549)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [17][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4655 (0.6313)	Prec@1 81.250 (75.480)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [17][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6531 (0.6345)	Prec@1 76.562 (75.324)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [17][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6442 (0.6272)	Prec@1 64.062 (75.529)	
2022-01-19 14:48:00 - INFO - EVALUATING - Epoch: [17][0/32]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.0844 (0.0844)	Prec@1 98.438 (98.438)	
2022-01-19 14:48:00 - INFO - EVALUATING - Epoch: [17][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6743 (0.4489)	Prec@1 79.688 (86.222)	
2022-01-19 14:48:00 - INFO - EVALUATING - Epoch: [17][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3726 (0.5303)	Prec@1 85.938 (83.705)	
2022-01-19 14:48:00 - INFO - EVALUATING - Epoch: [17][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.2172 (0.6524)	Prec@1 64.062 (80.040)	
2022-01-19 14:48:00 - INFO - 
 Epoch: 18	Training Loss 0.6293 	Training Prec@1 75.291 	Validation Loss 0.6707 	Validation Prec@1 79.569 	
2022-01-19 14:48:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [18][0/128]	Time 0.210 (0.210)	Data 0.206 (0.206)	Loss 0.7097 (0.7097)	Prec@1 81.250 (81.250)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [18][10/128]	Time 0.004 (0.023)	Data 0.002 (0.021)	Loss 0.6750 (0.9018)	Prec@1 78.125 (73.864)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [18][20/128]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 1.1310 (0.7813)	Prec@1 48.438 (72.098)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [18][30/128]	Time 0.004 (0.011)	Data 0.002 (0.009)	Loss 0.3550 (0.7225)	Prec@1 81.250 (73.538)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [18][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.0960 (0.7514)	Prec@1 75.000 (73.438)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [18][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.0760 (0.7430)	Prec@1 75.000 (73.376)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [18][60/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.4983 (0.7789)	Prec@1 81.250 (73.386)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [18][70/128]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 1.3979 (0.7729)	Prec@1 56.250 (73.107)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [18][80/128]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.3753 (0.7402)	Prec@1 85.938 (74.171)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [18][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7370 (0.7491)	Prec@1 70.312 (73.592)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [18][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4999 (0.7260)	Prec@1 73.438 (73.731)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [18][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7311 (0.7162)	Prec@1 76.562 (73.522)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [18][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9128 (0.7047)	Prec@1 62.500 (73.618)	
2022-01-19 14:48:01 - INFO - EVALUATING - Epoch: [18][0/32]	Time 0.192 (0.192)	Data 0.190 (0.190)	Loss 0.1565 (0.1565)	Prec@1 96.875 (96.875)	
2022-01-19 14:48:01 - INFO - EVALUATING - Epoch: [18][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4149 (0.3703)	Prec@1 79.688 (84.233)	
2022-01-19 14:48:01 - INFO - EVALUATING - Epoch: [18][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2610 (0.4036)	Prec@1 89.062 (82.143)	
2022-01-19 14:48:01 - INFO - EVALUATING - Epoch: [18][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6995 (0.4669)	Prec@1 62.500 (78.427)	
2022-01-19 14:48:01 - INFO - 
 Epoch: 19	Training Loss 0.6973 	Training Prec@1 73.576 	Validation Loss 0.4732 	Validation Prec@1 77.903 	
2022-01-19 14:48:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [19][0/128]	Time 0.204 (0.204)	Data 0.201 (0.201)	Loss 0.3865 (0.3865)	Prec@1 84.375 (84.375)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [19][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7443 (0.7171)	Prec@1 39.062 (75.568)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [19][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7857 (0.7143)	Prec@1 40.625 (72.470)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [19][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4356 (0.7116)	Prec@1 81.250 (72.278)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [19][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7184 (0.6791)	Prec@1 46.875 (72.142)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [19][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4975 (0.6500)	Prec@1 76.562 (73.438)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [19][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.0109 (0.6377)	Prec@1 73.438 (74.206)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [19][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6062 (0.6385)	Prec@1 75.000 (74.186)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [19][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5020 (0.6334)	Prec@1 82.812 (74.190)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [19][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6738 (0.6196)	Prec@1 68.750 (74.622)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [19][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4930 (0.6124)	Prec@1 81.250 (74.907)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [19][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4558 (0.6119)	Prec@1 85.938 (74.873)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [19][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5596 (0.6265)	Prec@1 84.375 (74.651)	
2022-01-19 14:48:02 - INFO - EVALUATING - Epoch: [19][0/32]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.1838 (0.1838)	Prec@1 87.500 (87.500)	
2022-01-19 14:48:02 - INFO - EVALUATING - Epoch: [19][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.9424 (0.5039)	Prec@1 56.250 (75.000)	
2022-01-19 14:48:02 - INFO - EVALUATING - Epoch: [19][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.6517 (0.5670)	Prec@1 68.750 (74.033)	
2022-01-19 14:48:02 - INFO - EVALUATING - Epoch: [19][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.9744 (0.6723)	Prec@1 68.750 (72.228)	
2022-01-19 14:48:02 - INFO - 
 Epoch: 20	Training Loss 0.6239 	Training Prec@1 74.874 	Validation Loss 0.6731 	Validation Prec@1 72.317 	
2022-01-19 14:48:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:02 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [20][0/128]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 0.4163 (0.4163)	Prec@1 84.375 (84.375)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [20][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4560 (0.5523)	Prec@1 85.938 (79.261)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [20][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.2663 (0.5715)	Prec@1 90.625 (75.818)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [20][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5054 (0.5673)	Prec@1 81.250 (77.268)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [20][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.3204 (0.5389)	Prec@1 87.500 (78.506)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [20][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4830 (0.5306)	Prec@1 78.125 (78.952)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [20][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3484 (0.5162)	Prec@1 82.812 (79.022)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [20][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4744 (0.5136)	Prec@1 71.875 (78.565)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [20][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6252 (0.5179)	Prec@1 78.125 (78.202)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [20][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4570 (0.5077)	Prec@1 82.812 (78.760)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [20][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.2948 (0.5024)	Prec@1 90.625 (79.115)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [20][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6156 (0.4999)	Prec@1 76.562 (79.434)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [20][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4563 (0.5037)	Prec@1 85.938 (79.429)	
2022-01-19 14:48:03 - INFO - EVALUATING - Epoch: [20][0/32]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.1974 (0.1974)	Prec@1 93.750 (93.750)	
2022-01-19 14:48:03 - INFO - EVALUATING - Epoch: [20][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6116 (0.4071)	Prec@1 76.562 (83.949)	
2022-01-19 14:48:03 - INFO - EVALUATING - Epoch: [20][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4512 (0.4268)	Prec@1 82.812 (82.738)	
2022-01-19 14:48:03 - INFO - EVALUATING - Epoch: [20][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5931 (0.4981)	Prec@1 76.562 (79.486)	
2022-01-19 14:48:03 - INFO - 
 Epoch: 21	Training Loss 0.5046 	Training Prec@1 79.395 	Validation Loss 0.4997 	Validation Prec@1 79.422 	
2022-01-19 14:48:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:03 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [21][0/128]	Time 0.191 (0.191)	Data 0.187 (0.187)	Loss 0.4180 (0.4180)	Prec@1 85.938 (85.938)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [21][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.5535 (0.5392)	Prec@1 78.125 (80.966)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [21][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.3024 (0.5543)	Prec@1 92.188 (80.060)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [21][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5091 (0.5343)	Prec@1 73.438 (78.427)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [21][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6733 (0.5176)	Prec@1 75.000 (78.887)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [21][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.7573 (0.5139)	Prec@1 60.938 (78.983)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [21][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4340 (0.5109)	Prec@1 87.500 (78.945)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [21][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5651 (0.5053)	Prec@1 78.125 (79.269)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [21][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.2612 (0.4973)	Prec@1 93.750 (79.572)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [21][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6029 (0.4956)	Prec@1 70.312 (79.602)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [21][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3246 (0.4947)	Prec@1 90.625 (79.657)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [21][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5431 (0.5025)	Prec@1 76.562 (79.026)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [21][120/128]	Time 0.004 (0.005)	Data 0.002 (0.003)	Loss 0.5226 (0.5139)	Prec@1 82.812 (79.274)	
2022-01-19 14:48:04 - INFO - EVALUATING - Epoch: [21][0/32]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.1780 (0.1780)	Prec@1 93.750 (93.750)	
2022-01-19 14:48:04 - INFO - EVALUATING - Epoch: [21][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6114 (0.4201)	Prec@1 73.438 (79.545)	
2022-01-19 14:48:04 - INFO - EVALUATING - Epoch: [21][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3696 (0.4264)	Prec@1 81.250 (79.762)	
2022-01-19 14:48:04 - INFO - EVALUATING - Epoch: [21][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5233 (0.4772)	Prec@1 78.125 (77.167)	
2022-01-19 14:48:04 - INFO - 
 Epoch: 22	Training Loss 0.5211 	Training Prec@1 78.868 	Validation Loss 0.4794 	Validation Prec@1 77.070 	
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [22][0/128]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.2318 (0.2318)	Prec@1 90.625 (90.625)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [22][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.3613 (0.5574)	Prec@1 89.062 (75.000)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6289 (0.5423)	Prec@1 75.000 (76.935)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7007 (0.5475)	Prec@1 81.250 (76.361)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.5743 (0.5598)	Prec@1 79.688 (77.401)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.9433 (0.5753)	Prec@1 71.875 (76.042)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5621 (0.5742)	Prec@1 73.438 (76.383)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7776 (0.5844)	Prec@1 65.625 (76.034)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4238 (0.5948)	Prec@1 79.688 (75.675)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4555 (0.5843)	Prec@1 76.562 (75.979)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5118 (0.5769)	Prec@1 73.438 (76.532)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6863 (0.5758)	Prec@1 73.438 (76.760)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][120/128]	Time 0.004 (0.005)	Data 0.002 (0.003)	Loss 0.7264 (0.5837)	Prec@1 82.812 (76.098)	
2022-01-19 14:48:05 - INFO - EVALUATING - Epoch: [22][0/32]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.5536 (0.5536)	Prec@1 79.688 (79.688)	
2022-01-19 14:48:05 - INFO - EVALUATING - Epoch: [22][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.8332 (0.6185)	Prec@1 56.250 (74.148)	
2022-01-19 14:48:05 - INFO - EVALUATING - Epoch: [22][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.6550 (0.5982)	Prec@1 70.312 (75.149)	
2022-01-19 14:48:05 - INFO - EVALUATING - Epoch: [22][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5593 (0.6073)	Prec@1 75.000 (73.286)	
2022-01-19 14:48:05 - INFO - 
 Epoch: 23	Training Loss 0.5817 	Training Prec@1 76.246 	Validation Loss 0.6052 	Validation Prec@1 73.346 	
2022-01-19 14:48:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [23][0/128]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.5352 (0.5352)	Prec@1 73.438 (73.438)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [23][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.5206 (0.6007)	Prec@1 82.812 (72.869)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][20/128]	Time 0.006 (0.014)	Data 0.003 (0.011)	Loss 0.6083 (0.6407)	Prec@1 67.188 (72.842)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.3704 (0.5915)	Prec@1 85.938 (73.942)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4930 (0.5677)	Prec@1 71.875 (74.619)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4265 (0.5539)	Prec@1 82.812 (74.816)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][60/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.4586 (0.5408)	Prec@1 79.688 (75.410)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3776 (0.5322)	Prec@1 82.812 (75.858)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5179 (0.5301)	Prec@1 78.125 (75.579)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6315 (0.5325)	Prec@1 76.562 (75.996)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6551 (0.5324)	Prec@1 81.250 (76.408)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.0396 (0.5576)	Prec@1 21.875 (74.972)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.2807 (0.5796)	Prec@1 90.625 (75.374)	
2022-01-19 14:48:06 - INFO - EVALUATING - Epoch: [23][0/32]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.3560 (0.3560)	Prec@1 96.875 (96.875)	
2022-01-19 14:48:06 - INFO - EVALUATING - Epoch: [23][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.4867 (0.4712)	Prec@1 85.938 (85.511)	
2022-01-19 14:48:06 - INFO - EVALUATING - Epoch: [23][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4010 (0.4814)	Prec@1 92.188 (83.631)	
2022-01-19 14:48:06 - INFO - EVALUATING - Epoch: [23][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5921 (0.4992)	Prec@1 68.750 (80.948)	
2022-01-19 14:48:06 - INFO - 
 Epoch: 24	Training Loss 0.5792 	Training Prec@1 75.597 	Validation Loss 0.5020 	Validation Prec@1 80.500 	
2022-01-19 14:48:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:06 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.4483 (0.4483)	Prec@1 85.938 (85.938)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.6723 (0.5897)	Prec@1 73.438 (74.290)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5095 (0.5585)	Prec@1 70.312 (75.744)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6204 (0.5556)	Prec@1 81.250 (74.798)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.3534 (0.5633)	Prec@1 87.500 (75.038)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][50/128]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.6979 (0.5674)	Prec@1 79.688 (75.980)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][60/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6734 (0.5485)	Prec@1 67.188 (77.100)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5711 (0.5438)	Prec@1 87.500 (77.905)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5418 (0.5422)	Prec@1 78.125 (78.106)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6588 (0.5382)	Prec@1 65.625 (78.211)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3576 (0.5351)	Prec@1 85.938 (78.017)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7014 (0.5478)	Prec@1 79.688 (77.182)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6025 (0.5610)	Prec@1 73.438 (77.286)	
2022-01-19 14:48:07 - INFO - EVALUATING - Epoch: [24][0/32]	Time 0.209 (0.209)	Data 0.206 (0.206)	Loss 0.2013 (0.2013)	Prec@1 93.750 (93.750)	
2022-01-19 14:48:07 - INFO - EVALUATING - Epoch: [24][10/32]	Time 0.003 (0.022)	Data 0.002 (0.021)	Loss 0.5276 (0.3850)	Prec@1 68.750 (80.824)	
2022-01-19 14:48:07 - INFO - EVALUATING - Epoch: [24][20/32]	Time 0.003 (0.013)	Data 0.002 (0.012)	Loss 0.4668 (0.4191)	Prec@1 67.188 (78.869)	
2022-01-19 14:48:07 - INFO - EVALUATING - Epoch: [24][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5664 (0.4589)	Prec@1 75.000 (76.865)	
2022-01-19 14:48:07 - INFO - 
 Epoch: 25	Training Loss 0.5662 	Training Prec@1 77.214 	Validation Loss 0.4604 	Validation Prec@1 76.874 	
2022-01-19 14:48:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:07 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][0/128]	Time 0.195 (0.195)	Data 0.191 (0.191)	Loss 0.3817 (0.3817)	Prec@1 87.500 (87.500)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.8139 (0.5468)	Prec@1 68.750 (77.273)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5171 (0.5141)	Prec@1 76.562 (79.613)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5009 (0.5073)	Prec@1 71.875 (78.478)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][40/128]	Time 0.005 (0.009)	Data 0.002 (0.007)	Loss 0.5760 (0.5099)	Prec@1 75.000 (78.125)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6789 (0.5459)	Prec@1 51.562 (75.613)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5010 (0.5424)	Prec@1 71.875 (75.461)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4181 (0.5517)	Prec@1 84.375 (76.078)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4715 (0.5423)	Prec@1 79.688 (76.601)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5102 (0.5355)	Prec@1 81.250 (76.923)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8332 (0.5382)	Prec@1 73.438 (76.980)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.1304 (0.5555)	Prec@1 29.688 (76.380)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4719 (0.5537)	Prec@1 85.938 (76.395)	
2022-01-19 14:48:08 - INFO - EVALUATING - Epoch: [25][0/32]	Time 0.206 (0.206)	Data 0.204 (0.204)	Loss 0.1706 (0.1706)	Prec@1 98.438 (98.438)	
2022-01-19 14:48:08 - INFO - EVALUATING - Epoch: [25][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.4391 (0.3561)	Prec@1 84.375 (88.210)	
2022-01-19 14:48:08 - INFO - EVALUATING - Epoch: [25][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2693 (0.3978)	Prec@1 92.188 (85.417)	
2022-01-19 14:48:08 - INFO - EVALUATING - Epoch: [25][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7246 (0.4605)	Prec@1 68.750 (81.552)	
2022-01-19 14:48:08 - INFO - 
 Epoch: 26	Training Loss 0.5511 	Training Prec@1 76.430 	Validation Loss 0.4669 	Validation Prec@1 81.235 	
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][0/128]	Time 0.206 (0.206)	Data 0.202 (0.202)	Loss 0.4619 (0.4619)	Prec@1 82.812 (82.812)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6043 (0.7209)	Prec@1 82.812 (75.568)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.8196 (0.6688)	Prec@1 78.125 (76.935)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.4697 (0.6527)	Prec@1 82.812 (77.268)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4589 (0.6133)	Prec@1 79.688 (77.896)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4455 (0.5789)	Prec@1 84.375 (78.186)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5254 (0.5598)	Prec@1 78.125 (78.637)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5267 (0.5631)	Prec@1 76.562 (77.861)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4570 (0.5547)	Prec@1 81.250 (77.855)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3769 (0.5493)	Prec@1 89.062 (78.159)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4968 (0.5452)	Prec@1 78.125 (78.311)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4715 (0.5377)	Prec@1 81.250 (78.463)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4996 (0.5387)	Prec@1 87.500 (78.357)	
2022-01-19 14:48:09 - INFO - EVALUATING - Epoch: [26][0/32]	Time 0.208 (0.208)	Data 0.206 (0.206)	Loss 0.3676 (0.3676)	Prec@1 70.312 (70.312)	
2022-01-19 14:48:09 - INFO - EVALUATING - Epoch: [26][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6019 (0.5042)	Prec@1 60.938 (64.631)	
2022-01-19 14:48:09 - INFO - EVALUATING - Epoch: [26][20/32]	Time 0.003 (0.013)	Data 0.002 (0.012)	Loss 0.5592 (0.5294)	Prec@1 53.125 (63.244)	
2022-01-19 14:48:09 - INFO - EVALUATING - Epoch: [26][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6366 (0.5488)	Prec@1 65.625 (64.315)	
2022-01-19 14:48:09 - INFO - 
 Epoch: 27	Training Loss 0.5504 	Training Prec@1 78.060 	Validation Loss 0.5490 	Validation Prec@1 64.478 	
2022-01-19 14:48:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][0/128]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 0.5931 (0.5931)	Prec@1 64.062 (64.062)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6499 (0.5842)	Prec@1 67.188 (75.568)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.5393 (0.5914)	Prec@1 81.250 (77.009)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.4833 (0.6387)	Prec@1 89.062 (76.260)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6902 (0.6300)	Prec@1 71.875 (76.334)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5056 (0.5960)	Prec@1 76.562 (76.808)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4075 (0.5678)	Prec@1 84.375 (77.536)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6131 (0.5611)	Prec@1 71.875 (77.487)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4942 (0.5529)	Prec@1 70.312 (77.334)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4953 (0.5710)	Prec@1 81.250 (76.940)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6424 (0.5648)	Prec@1 75.000 (77.073)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3769 (0.5562)	Prec@1 79.688 (77.126)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5035 (0.5511)	Prec@1 78.125 (77.027)	
2022-01-19 14:48:10 - INFO - EVALUATING - Epoch: [27][0/32]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.1471 (0.1471)	Prec@1 96.875 (96.875)	
2022-01-19 14:48:10 - INFO - EVALUATING - Epoch: [27][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5879 (0.3870)	Prec@1 82.812 (87.642)	
2022-01-19 14:48:10 - INFO - EVALUATING - Epoch: [27][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2711 (0.4646)	Prec@1 92.188 (85.045)	
2022-01-19 14:48:10 - INFO - EVALUATING - Epoch: [27][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8144 (0.5950)	Prec@1 65.625 (80.746)	
2022-01-19 14:48:11 - INFO - 
 Epoch: 28	Training Loss 0.5507 	Training Prec@1 77.165 	Validation Loss 0.6004 	Validation Prec@1 80.402 	
2022-01-19 14:48:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][0/128]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.8561 (0.8561)	Prec@1 75.000 (75.000)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.5277 (0.6876)	Prec@1 82.812 (74.290)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5151 (0.6149)	Prec@1 79.688 (75.446)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4023 (0.5942)	Prec@1 84.375 (76.865)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.4316 (0.5538)	Prec@1 79.688 (78.049)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.4867 (0.5341)	Prec@1 76.562 (77.145)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5021 (0.5351)	Prec@1 62.500 (76.895)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4845 (0.5443)	Prec@1 81.250 (76.430)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5036 (0.5600)	Prec@1 76.562 (76.775)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6309 (0.5612)	Prec@1 75.000 (76.872)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5499 (0.5603)	Prec@1 68.750 (77.104)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.3749 (0.5546)	Prec@1 81.250 (76.971)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5295 (0.5536)	Prec@1 76.562 (76.821)	
2022-01-19 14:48:11 - INFO - EVALUATING - Epoch: [28][0/32]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 0.2229 (0.2229)	Prec@1 93.750 (93.750)	
2022-01-19 14:48:11 - INFO - EVALUATING - Epoch: [28][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5052 (0.3823)	Prec@1 73.438 (83.381)	
2022-01-19 14:48:11 - INFO - EVALUATING - Epoch: [28][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3383 (0.4124)	Prec@1 82.812 (81.845)	
2022-01-19 14:48:12 - INFO - EVALUATING - Epoch: [28][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5543 (0.4738)	Prec@1 75.000 (78.780)	
2022-01-19 14:48:12 - INFO - 
 Epoch: 29	Training Loss 0.5553 	Training Prec@1 76.749 	Validation Loss 0.4740 	Validation Prec@1 78.736 	
2022-01-19 14:48:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][0/128]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.6111 (0.6111)	Prec@1 73.438 (73.438)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.5179 (0.7944)	Prec@1 85.938 (78.125)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4191 (0.7408)	Prec@1 82.812 (74.777)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5933 (0.7078)	Prec@1 75.000 (76.663)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.4743 (0.6769)	Prec@1 85.938 (77.363)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7148 (0.6530)	Prec@1 64.062 (76.930)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4172 (0.6278)	Prec@1 76.562 (77.382)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4172 (0.6228)	Prec@1 89.062 (77.047)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5043 (0.6047)	Prec@1 79.688 (77.218)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3919 (0.5869)	Prec@1 82.812 (77.490)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3730 (0.5713)	Prec@1 82.812 (77.676)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4132 (0.5684)	Prec@1 84.375 (77.759)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [29][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5942 (0.5662)	Prec@1 79.688 (77.918)	
2022-01-19 14:48:12 - INFO - EVALUATING - Epoch: [29][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.1532 (0.1532)	Prec@1 96.875 (96.875)	
2022-01-19 14:48:12 - INFO - EVALUATING - Epoch: [29][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6118 (0.3739)	Prec@1 82.812 (88.210)	
2022-01-19 14:48:13 - INFO - EVALUATING - Epoch: [29][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2447 (0.4033)	Prec@1 92.188 (85.491)	
2022-01-19 14:48:13 - INFO - EVALUATING - Epoch: [29][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6335 (0.4682)	Prec@1 71.875 (81.300)	
2022-01-19 14:48:13 - INFO - 
 Epoch: 30	Training Loss 0.5667 	Training Prec@1 78.023 	Validation Loss 0.4728 	Validation Prec@1 81.088 	
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][0/128]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.4814 (0.4814)	Prec@1 79.688 (79.688)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.5002 (0.6109)	Prec@1 68.750 (78.267)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 1.3752 (0.7460)	Prec@1 57.812 (74.405)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.3954 (0.6895)	Prec@1 82.812 (75.857)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4778 (0.6563)	Prec@1 79.688 (75.381)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4358 (0.6239)	Prec@1 82.812 (75.919)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5955 (0.6028)	Prec@1 75.000 (76.665)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4484 (0.5850)	Prec@1 82.812 (77.311)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.3367 (0.5791)	Prec@1 87.500 (77.083)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5409 (0.5646)	Prec@1 73.438 (77.352)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4201 (0.5544)	Prec@1 81.250 (77.754)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5884 (0.5538)	Prec@1 81.250 (77.900)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [30][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.3702 (0.5640)	Prec@1 89.062 (77.169)	
2022-01-19 14:48:14 - INFO - EVALUATING - Epoch: [30][0/32]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.4289 (0.4289)	Prec@1 96.875 (96.875)	
2022-01-19 14:48:14 - INFO - EVALUATING - Epoch: [30][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6745 (0.5490)	Prec@1 82.812 (87.784)	
2022-01-19 14:48:14 - INFO - EVALUATING - Epoch: [30][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5219 (0.5990)	Prec@1 92.188 (84.896)	
2022-01-19 14:48:14 - INFO - EVALUATING - Epoch: [30][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7387 (0.6620)	Prec@1 70.312 (80.948)	
2022-01-19 14:48:14 - INFO - 
 Epoch: 31	Training Loss 0.5691 	Training Prec@1 77.349 	Validation Loss 0.6565 	Validation Prec@1 80.745 	
2022-01-19 14:48:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:14 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.5035 (0.5035)	Prec@1 85.938 (85.938)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4057 (0.6585)	Prec@1 79.688 (81.818)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.3574 (0.5583)	Prec@1 85.938 (81.548)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5927 (0.5283)	Prec@1 76.562 (81.300)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9387 (0.5235)	Prec@1 65.625 (80.716)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5236 (0.5193)	Prec@1 81.250 (80.637)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6104 (0.5197)	Prec@1 78.125 (80.277)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][70/128]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.8453 (0.5227)	Prec@1 56.250 (79.621)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][80/128]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.5972 (0.5511)	Prec@1 76.562 (78.839)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][90/128]	Time 0.005 (0.006)	Data 0.002 (0.004)	Loss 0.8059 (0.5684)	Prec@1 60.938 (78.262)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6248 (0.5592)	Prec@1 73.438 (78.434)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4059 (0.5503)	Prec@1 79.688 (78.604)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [31][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4308 (0.5457)	Prec@1 81.250 (78.771)	
2022-01-19 14:48:15 - INFO - EVALUATING - Epoch: [31][0/32]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.2901 (0.2901)	Prec@1 78.125 (78.125)	
2022-01-19 14:48:15 - INFO - EVALUATING - Epoch: [31][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7393 (0.5226)	Prec@1 56.250 (66.193)	
2022-01-19 14:48:15 - INFO - EVALUATING - Epoch: [31][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3731 (0.5173)	Prec@1 68.750 (67.783)	
2022-01-19 14:48:15 - INFO - EVALUATING - Epoch: [31][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6366 (0.5589)	Prec@1 70.312 (67.440)	
2022-01-19 14:48:15 - INFO - 
 Epoch: 32	Training Loss 0.5487 	Training Prec@1 78.599 	Validation Loss 0.5567 	Validation Prec@1 67.712 	
2022-01-19 14:48:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:15 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][0/128]	Time 0.224 (0.224)	Data 0.219 (0.219)	Loss 0.5174 (0.5174)	Prec@1 65.625 (65.625)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][10/128]	Time 0.004 (0.025)	Data 0.002 (0.022)	Loss 0.4906 (0.6912)	Prec@1 82.812 (71.449)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][20/128]	Time 0.004 (0.015)	Data 0.002 (0.012)	Loss 0.7559 (0.7365)	Prec@1 76.562 (75.074)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][30/128]	Time 0.004 (0.012)	Data 0.002 (0.009)	Loss 1.0497 (0.6923)	Prec@1 71.875 (77.671)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][40/128]	Time 0.004 (0.010)	Data 0.002 (0.007)	Loss 0.4625 (0.6499)	Prec@1 76.562 (77.477)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.3550 (0.6134)	Prec@1 87.500 (78.248)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6042 (0.6027)	Prec@1 73.438 (77.818)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4552 (0.5812)	Prec@1 78.125 (78.059)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3401 (0.5603)	Prec@1 87.500 (78.723)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4709 (0.5483)	Prec@1 79.688 (78.880)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][100/128]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.5975 (0.5371)	Prec@1 79.688 (78.976)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5406 (0.5460)	Prec@1 73.438 (78.604)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [32][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5193 (0.5387)	Prec@1 75.000 (78.745)	
2022-01-19 14:48:16 - INFO - EVALUATING - Epoch: [32][0/32]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.1425 (0.1425)	Prec@1 98.438 (98.438)	
2022-01-19 14:48:16 - INFO - EVALUATING - Epoch: [32][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.3497 (0.3422)	Prec@1 82.812 (85.653)	
2022-01-19 14:48:16 - INFO - EVALUATING - Epoch: [32][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2436 (0.3939)	Prec@1 93.750 (83.482)	
2022-01-19 14:48:16 - INFO - EVALUATING - Epoch: [32][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7225 (0.4682)	Prec@1 62.500 (79.587)	
2022-01-19 14:48:16 - INFO - 
 Epoch: 33	Training Loss 0.5340 	Training Prec@1 78.905 	Validation Loss 0.4756 	Validation Prec@1 79.226 	
2022-01-19 14:48:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][0/128]	Time 0.247 (0.247)	Data 0.244 (0.244)	Loss 0.5511 (0.5511)	Prec@1 73.438 (73.438)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][10/128]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.3607 (0.8615)	Prec@1 87.500 (76.847)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][20/128]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.5118 (0.6808)	Prec@1 82.812 (78.943)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.5224 (0.6291)	Prec@1 73.438 (78.427)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.3878 (0.5827)	Prec@1 79.688 (78.887)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][50/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5543 (0.5644)	Prec@1 76.562 (79.320)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.1458 (0.5591)	Prec@1 53.125 (79.226)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][70/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5346 (0.5766)	Prec@1 76.562 (78.653)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4464 (0.5684)	Prec@1 81.250 (78.588)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][90/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4025 (0.5537)	Prec@1 82.812 (78.777)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][100/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.3965 (0.5482)	Prec@1 84.375 (78.899)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [33][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4984 (0.5423)	Prec@1 73.438 (78.927)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [33][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6018 (0.5435)	Prec@1 68.750 (78.435)	
2022-01-19 14:48:17 - INFO - EVALUATING - Epoch: [33][0/32]	Time 0.190 (0.190)	Data 0.187 (0.187)	Loss 0.2835 (0.2835)	Prec@1 95.312 (95.312)	
2022-01-19 14:48:17 - INFO - EVALUATING - Epoch: [33][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.8265 (0.5664)	Prec@1 81.250 (87.074)	
2022-01-19 14:48:17 - INFO - EVALUATING - Epoch: [33][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.6793 (0.6103)	Prec@1 82.812 (84.301)	
2022-01-19 14:48:17 - INFO - EVALUATING - Epoch: [33][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8242 (0.6680)	Prec@1 71.875 (80.796)	
2022-01-19 14:48:17 - INFO - 
 Epoch: 34	Training Loss 0.5399 	Training Prec@1 78.525 	Validation Loss 0.6670 	Validation Prec@1 80.696 	
2022-01-19 14:48:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [34][0/128]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.3480 (0.3480)	Prec@1 85.938 (85.938)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [34][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.5027 (0.6075)	Prec@1 81.250 (81.250)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [34][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7097 (0.7269)	Prec@1 54.688 (75.223)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [34][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5806 (0.6691)	Prec@1 73.438 (77.117)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [34][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4605 (0.6238)	Prec@1 79.688 (77.210)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [34][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5421 (0.5902)	Prec@1 75.000 (78.278)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [34][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4846 (0.5650)	Prec@1 81.250 (78.842)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [34][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4330 (0.5423)	Prec@1 81.250 (79.335)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [34][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.7554 (0.5502)	Prec@1 23.438 (78.627)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [34][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4475 (0.5442)	Prec@1 78.125 (78.486)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [34][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4834 (0.5396)	Prec@1 76.562 (78.465)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [34][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3905 (0.5317)	Prec@1 84.375 (78.463)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [34][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.8916 (0.5404)	Prec@1 76.562 (78.138)	
2022-01-19 14:48:18 - INFO - EVALUATING - Epoch: [34][0/32]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.2426 (0.2426)	Prec@1 95.312 (95.312)	
2022-01-19 14:48:18 - INFO - EVALUATING - Epoch: [34][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.3985 (0.3701)	Prec@1 87.500 (87.074)	
2022-01-19 14:48:18 - INFO - EVALUATING - Epoch: [34][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3359 (0.3952)	Prec@1 84.375 (84.375)	
2022-01-19 14:48:18 - INFO - EVALUATING - Epoch: [34][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5576 (0.4319)	Prec@1 75.000 (81.300)	
2022-01-19 14:48:18 - INFO - 
 Epoch: 35	Training Loss 0.5493 	Training Prec@1 77.937 	Validation Loss 0.4356 	Validation Prec@1 81.137 	
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [35][0/128]	Time 0.199 (0.199)	Data 0.196 (0.196)	Loss 0.4447 (0.4447)	Prec@1 82.812 (82.812)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [35][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.5971 (0.9726)	Prec@1 81.250 (73.438)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [35][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.9494 (0.8617)	Prec@1 51.562 (73.438)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [35][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4407 (0.7651)	Prec@1 85.938 (75.605)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [35][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4482 (0.6947)	Prec@1 79.688 (76.524)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [35][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4748 (0.6463)	Prec@1 70.312 (76.930)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [35][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4574 (0.6317)	Prec@1 79.688 (77.664)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [35][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8842 (0.6494)	Prec@1 56.250 (76.496)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [35][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5889 (0.6480)	Prec@1 84.375 (76.080)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [35][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4544 (0.6528)	Prec@1 85.938 (75.927)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [35][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4328 (0.6448)	Prec@1 84.375 (75.774)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [35][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6940 (0.6406)	Prec@1 73.438 (75.690)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [35][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4524 (0.6636)	Prec@1 73.438 (75.168)	
2022-01-19 14:48:19 - INFO - EVALUATING - Epoch: [35][0/32]	Time 0.240 (0.240)	Data 0.238 (0.238)	Loss 0.4041 (0.4041)	Prec@1 95.312 (95.312)	
2022-01-19 14:48:19 - INFO - EVALUATING - Epoch: [35][10/32]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.5356 (0.4988)	Prec@1 87.500 (87.500)	
2022-01-19 14:48:19 - INFO - EVALUATING - Epoch: [35][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.5317 (0.5127)	Prec@1 84.375 (84.598)	
2022-01-19 14:48:19 - INFO - EVALUATING - Epoch: [35][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.5838 (0.5304)	Prec@1 71.875 (81.300)	
2022-01-19 14:48:19 - INFO - 
 Epoch: 36	Training Loss 0.6565 	Training Prec@1 75.536 	Validation Loss 0.5292 	Validation Prec@1 81.137 	
2022-01-19 14:48:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [36][0/128]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.6269 (0.6269)	Prec@1 81.250 (81.250)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [36][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 1.5114 (1.5049)	Prec@1 82.812 (66.619)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [36][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.0167 (1.3281)	Prec@1 82.812 (71.577)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [36][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.9057 (1.1722)	Prec@1 76.562 (74.345)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [36][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5583 (1.0467)	Prec@1 75.000 (74.505)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [36][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7953 (0.9573)	Prec@1 65.625 (74.755)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [36][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6971 (0.8889)	Prec@1 71.875 (75.026)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [36][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7262 (0.8539)	Prec@1 76.562 (75.682)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [36][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4546 (0.8120)	Prec@1 78.125 (76.215)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [36][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5429 (0.8057)	Prec@1 79.688 (75.944)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [36][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5112 (0.7691)	Prec@1 75.000 (76.330)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [36][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6348 (0.7468)	Prec@1 73.438 (76.633)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [36][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7280 (0.7405)	Prec@1 57.812 (76.666)	
2022-01-19 14:48:20 - INFO - EVALUATING - Epoch: [36][0/32]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.1569 (0.1569)	Prec@1 95.312 (95.312)	
2022-01-19 14:48:20 - INFO - EVALUATING - Epoch: [36][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.4518 (0.3540)	Prec@1 87.500 (87.926)	
2022-01-19 14:48:20 - INFO - EVALUATING - Epoch: [36][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2715 (0.3887)	Prec@1 85.938 (85.491)	
2022-01-19 14:48:20 - INFO - EVALUATING - Epoch: [36][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6007 (0.4410)	Prec@1 76.562 (82.157)	
2022-01-19 14:48:20 - INFO - 
 Epoch: 37	Training Loss 0.7230 	Training Prec@1 76.945 	Validation Loss 0.4471 	Validation Prec@1 81.970 	
2022-01-19 14:48:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:20 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [37][0/128]	Time 0.210 (0.210)	Data 0.207 (0.207)	Loss 0.5607 (0.5607)	Prec@1 71.875 (71.875)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [37][10/128]	Time 0.004 (0.023)	Data 0.002 (0.021)	Loss 0.4115 (0.9815)	Prec@1 87.500 (76.989)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [37][20/128]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.4962 (0.9473)	Prec@1 81.250 (75.446)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [37][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6544 (0.8744)	Prec@1 79.688 (71.472)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [37][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7758 (0.9163)	Prec@1 82.812 (73.514)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [37][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8063 (0.8393)	Prec@1 62.500 (75.000)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [37][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6692 (0.8011)	Prec@1 79.688 (75.743)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [37][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5996 (0.7505)	Prec@1 64.062 (76.673)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [37][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.8124 (0.7302)	Prec@1 78.125 (76.987)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [37][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5774 (0.7129)	Prec@1 76.562 (77.198)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [37][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3966 (0.6888)	Prec@1 82.812 (77.692)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [37][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4006 (0.6670)	Prec@1 84.375 (78.181)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [37][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6599 (0.6525)	Prec@1 73.438 (77.880)	
2022-01-19 14:48:21 - INFO - EVALUATING - Epoch: [37][0/32]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.2082 (0.2082)	Prec@1 92.188 (92.188)	
2022-01-19 14:48:21 - INFO - EVALUATING - Epoch: [37][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5024 (0.3723)	Prec@1 78.125 (81.392)	
2022-01-19 14:48:21 - INFO - EVALUATING - Epoch: [37][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2381 (0.3958)	Prec@1 89.062 (79.911)	
2022-01-19 14:48:21 - INFO - EVALUATING - Epoch: [37][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6731 (0.4489)	Prec@1 59.375 (76.310)	
2022-01-19 14:48:21 - INFO - 
 Epoch: 38	Training Loss 0.6434 	Training Prec@1 77.937 	Validation Loss 0.4571 	Validation Prec@1 75.747 	
2022-01-19 14:48:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:21 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [38][0/128]	Time 0.209 (0.209)	Data 0.205 (0.205)	Loss 0.4057 (0.4057)	Prec@1 78.125 (78.125)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [38][10/128]	Time 0.004 (0.023)	Data 0.002 (0.021)	Loss 0.5997 (0.6991)	Prec@1 84.375 (72.017)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [38][20/128]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.8206 (0.7080)	Prec@1 71.875 (74.107)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [38][30/128]	Time 0.005 (0.011)	Data 0.002 (0.009)	Loss 0.5987 (0.6677)	Prec@1 73.438 (73.488)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [38][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.3671 (0.6218)	Prec@1 82.812 (75.724)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [38][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5187 (0.5904)	Prec@1 75.000 (76.348)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [38][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5030 (0.5689)	Prec@1 78.125 (76.383)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [38][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.2656 (0.5562)	Prec@1 85.938 (76.717)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [38][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4442 (0.5467)	Prec@1 89.062 (76.562)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [38][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5166 (0.5517)	Prec@1 76.562 (76.597)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [38][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5083 (0.5417)	Prec@1 70.312 (76.748)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [38][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7943 (0.5369)	Prec@1 79.688 (76.943)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [38][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5291 (0.5427)	Prec@1 71.875 (76.937)	
2022-01-19 14:48:22 - INFO - EVALUATING - Epoch: [38][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.2554 (0.2554)	Prec@1 90.625 (90.625)	
2022-01-19 14:48:22 - INFO - EVALUATING - Epoch: [38][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5611 (0.3863)	Prec@1 70.312 (84.091)	
2022-01-19 14:48:22 - INFO - EVALUATING - Epoch: [38][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3666 (0.4016)	Prec@1 81.250 (82.589)	
2022-01-19 14:48:22 - INFO - EVALUATING - Epoch: [38][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6150 (0.4375)	Prec@1 65.625 (79.536)	
2022-01-19 14:48:22 - INFO - 
 Epoch: 39	Training Loss 0.5414 	Training Prec@1 77.067 	Validation Loss 0.4398 	Validation Prec@1 79.471 	
2022-01-19 14:48:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:22 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [39][0/128]	Time 0.206 (0.206)	Data 0.203 (0.203)	Loss 0.4461 (0.4461)	Prec@1 76.562 (76.562)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [39][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 1.7305 (1.1983)	Prec@1 46.875 (69.034)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [39][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.4261 (0.9745)	Prec@1 85.938 (73.214)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [39][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.8023 (0.9670)	Prec@1 70.312 (74.798)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [39][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6999 (0.8664)	Prec@1 65.625 (75.419)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [39][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5618 (0.8278)	Prec@1 73.438 (75.674)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [39][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5353 (0.7657)	Prec@1 79.688 (76.332)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [39][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6154 (0.7638)	Prec@1 82.812 (75.418)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [39][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.4862 (0.7623)	Prec@1 78.125 (75.579)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [39][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4920 (0.7450)	Prec@1 82.812 (75.876)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [39][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4805 (0.7283)	Prec@1 73.438 (76.021)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [39][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5397 (0.7041)	Prec@1 84.375 (76.534)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [39][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.2490 (0.7166)	Prec@1 68.750 (76.614)	
2022-01-19 14:48:23 - INFO - EVALUATING - Epoch: [39][0/32]	Time 0.201 (0.201)	Data 0.200 (0.200)	Loss 0.4290 (0.4290)	Prec@1 90.625 (90.625)	
2022-01-19 14:48:23 - INFO - EVALUATING - Epoch: [39][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.8116 (0.5607)	Prec@1 76.562 (84.801)	
2022-01-19 14:48:23 - INFO - EVALUATING - Epoch: [39][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5437 (0.5476)	Prec@1 81.250 (83.259)	
2022-01-19 14:48:23 - INFO - EVALUATING - Epoch: [39][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6855 (0.5599)	Prec@1 64.062 (79.940)	
2022-01-19 14:48:23 - INFO - 
 Epoch: 40	Training Loss 0.7093 	Training Prec@1 76.687 	Validation Loss 0.5576 	Validation Prec@1 79.863 	
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [40][0/128]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.7713 (0.7713)	Prec@1 75.000 (75.000)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [40][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.9291 (1.1274)	Prec@1 79.688 (75.142)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [40][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.4630 (1.0009)	Prec@1 78.125 (73.214)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [40][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.2986 (0.9362)	Prec@1 70.312 (73.286)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [40][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5411 (0.8458)	Prec@1 78.125 (74.543)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [40][50/128]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.5015 (0.7818)	Prec@1 76.562 (75.061)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [40][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8987 (0.7516)	Prec@1 75.000 (75.999)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [40][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6741 (0.7372)	Prec@1 70.312 (75.308)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [40][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.0158 (0.7322)	Prec@1 67.188 (75.579)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [40][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.2883 (0.7212)	Prec@1 73.438 (75.755)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [40][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4983 (0.7079)	Prec@1 78.125 (76.083)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [40][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4996 (0.7176)	Prec@1 84.375 (76.520)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [40][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.8063 (0.7083)	Prec@1 76.562 (76.640)	
2022-01-19 14:48:24 - INFO - EVALUATING - Epoch: [40][0/32]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.5339 (0.5339)	Prec@1 85.938 (85.938)	
2022-01-19 14:48:24 - INFO - EVALUATING - Epoch: [40][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6600 (0.5775)	Prec@1 84.375 (85.227)	
2022-01-19 14:48:24 - INFO - EVALUATING - Epoch: [40][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5307 (0.5746)	Prec@1 85.938 (83.929)	
2022-01-19 14:48:24 - INFO - EVALUATING - Epoch: [40][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6927 (0.6091)	Prec@1 65.625 (80.645)	
2022-01-19 14:48:24 - INFO - 
 Epoch: 41	Training Loss 0.7231 	Training Prec@1 76.295 	Validation Loss 0.6045 	Validation Prec@1 80.549 	
2022-01-19 14:48:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [41][0/128]	Time 0.200 (0.200)	Data 0.197 (0.197)	Loss 0.3951 (0.3951)	Prec@1 87.500 (87.500)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7478 (0.8210)	Prec@1 81.250 (75.994)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5946 (0.7953)	Prec@1 78.125 (75.000)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6538 (0.7265)	Prec@1 81.250 (76.361)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5312 (0.6897)	Prec@1 75.000 (76.639)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5291 (0.7128)	Prec@1 81.250 (76.072)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4261 (0.6902)	Prec@1 85.938 (76.767)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5829 (0.6616)	Prec@1 76.562 (77.267)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][80/128]	Time 0.005 (0.006)	Data 0.002 (0.004)	Loss 0.5219 (0.6402)	Prec@1 78.125 (77.238)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][90/128]	Time 0.068 (0.008)	Data 0.007 (0.004)	Loss 0.4472 (0.6235)	Prec@1 81.250 (77.438)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][100/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.3707 (0.6024)	Prec@1 84.375 (78.001)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][110/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7018 (0.6026)	Prec@1 75.000 (78.012)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [41][120/128]	Time 0.004 (0.007)	Data 0.002 (0.003)	Loss 0.6736 (0.6191)	Prec@1 78.125 (77.944)	
2022-01-19 14:48:25 - INFO - EVALUATING - Epoch: [41][0/32]	Time 0.186 (0.186)	Data 0.184 (0.184)	Loss 0.3912 (0.3912)	Prec@1 96.875 (96.875)	
2022-01-19 14:48:25 - INFO - EVALUATING - Epoch: [41][10/32]	Time 0.003 (0.020)	Data 0.002 (0.018)	Loss 0.7404 (0.5287)	Prec@1 76.562 (82.955)	
2022-01-19 14:48:25 - INFO - EVALUATING - Epoch: [41][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4387 (0.5219)	Prec@1 89.062 (81.399)	
2022-01-19 14:48:25 - INFO - EVALUATING - Epoch: [41][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6643 (0.5365)	Prec@1 57.812 (77.722)	
2022-01-19 14:48:25 - INFO - 
 Epoch: 42	Training Loss 0.6147 	Training Prec@1 77.925 	Validation Loss 0.5357 	Validation Prec@1 77.364 	
2022-01-19 14:48:25 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:25 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:25 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][0/128]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.4601 (0.4601)	Prec@1 84.375 (84.375)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.7373 (0.8241)	Prec@1 79.688 (78.409)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.7627 (0.7220)	Prec@1 76.562 (76.265)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5672 (0.6739)	Prec@1 75.000 (75.605)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4899 (0.6624)	Prec@1 84.375 (75.877)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8372 (0.6499)	Prec@1 68.750 (76.164)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4545 (0.6189)	Prec@1 75.000 (76.358)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4467 (0.6005)	Prec@1 76.562 (76.518)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][80/128]	Time 0.005 (0.006)	Data 0.002 (0.004)	Loss 0.4131 (0.6007)	Prec@1 84.375 (77.025)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9470 (0.5922)	Prec@1 76.562 (77.404)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4669 (0.5845)	Prec@1 78.125 (77.769)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3193 (0.5760)	Prec@1 87.500 (77.956)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [42][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4906 (0.5684)	Prec@1 79.688 (78.125)	
2022-01-19 14:48:26 - INFO - EVALUATING - Epoch: [42][0/32]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.2227 (0.2227)	Prec@1 90.625 (90.625)	
2022-01-19 14:48:26 - INFO - EVALUATING - Epoch: [42][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4277 (0.3540)	Prec@1 78.125 (81.818)	
2022-01-19 14:48:26 - INFO - EVALUATING - Epoch: [42][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2667 (0.3852)	Prec@1 87.500 (80.208)	
2022-01-19 14:48:26 - INFO - EVALUATING - Epoch: [42][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7330 (0.4503)	Prec@1 59.375 (76.512)	
2022-01-19 14:48:27 - INFO - 
 Epoch: 43	Training Loss 0.5733 	Training Prec@1 77.815 	Validation Loss 0.4575 	Validation Prec@1 75.992 	
2022-01-19 14:48:27 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:27 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:27 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][0/128]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.4617 (0.4617)	Prec@1 75.000 (75.000)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.4361 (0.9647)	Prec@1 85.938 (74.858)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][20/128]	Time 0.005 (0.013)	Data 0.002 (0.011)	Loss 0.6156 (0.8031)	Prec@1 81.250 (77.158)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][30/128]	Time 0.005 (0.010)	Data 0.002 (0.008)	Loss 0.6544 (0.7746)	Prec@1 71.875 (77.772)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.0174 (0.7386)	Prec@1 76.562 (77.248)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4936 (0.7198)	Prec@1 82.812 (78.094)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3818 (0.6789)	Prec@1 84.375 (78.330)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3248 (0.6472)	Prec@1 81.250 (78.389)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4370 (0.6251)	Prec@1 78.125 (78.665)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3331 (0.6040)	Prec@1 87.500 (78.915)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][100/128]	Time 0.005 (0.006)	Data 0.002 (0.004)	Loss 0.8149 (0.6046)	Prec@1 76.562 (78.883)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7249 (0.6300)	Prec@1 78.125 (78.421)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [43][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.3936 (0.6323)	Prec@1 87.500 (78.383)	
2022-01-19 14:48:27 - INFO - EVALUATING - Epoch: [43][0/32]	Time 0.203 (0.203)	Data 0.201 (0.201)	Loss 0.1430 (0.1430)	Prec@1 96.875 (96.875)	
2022-01-19 14:48:28 - INFO - EVALUATING - Epoch: [43][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.8335 (0.6862)	Prec@1 79.688 (84.801)	
2022-01-19 14:48:28 - INFO - EVALUATING - Epoch: [43][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4817 (0.7559)	Prec@1 89.062 (83.185)	
2022-01-19 14:48:28 - INFO - EVALUATING - Epoch: [43][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.7265 (0.9371)	Prec@1 59.375 (79.133)	
2022-01-19 14:48:28 - INFO - 
 Epoch: 44	Training Loss 0.6349 	Training Prec@1 77.766 	Validation Loss 0.9521 	Validation Prec@1 78.834 	
2022-01-19 14:48:28 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:28 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:28 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:28 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 1.2359 (1.2359)	Prec@1 71.875 (71.875)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.5102 (1.0152)	Prec@1 79.688 (72.159)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.9465 (0.8685)	Prec@1 54.688 (71.577)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4233 (0.7756)	Prec@1 84.375 (73.841)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4856 (0.7218)	Prec@1 78.125 (75.267)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5500 (0.6672)	Prec@1 78.125 (76.991)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3981 (0.6317)	Prec@1 85.938 (77.843)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5992 (0.6228)	Prec@1 85.938 (77.597)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4778 (0.6152)	Prec@1 82.812 (78.029)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3314 (0.5995)	Prec@1 87.500 (78.194)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.5523 (0.6059)	Prec@1 53.125 (77.367)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4595 (0.6234)	Prec@1 85.938 (77.463)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [44][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5697 (0.6144)	Prec@1 81.250 (77.802)	
2022-01-19 14:48:29 - INFO - EVALUATING - Epoch: [44][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.1530 (0.1530)	Prec@1 96.875 (96.875)	
2022-01-19 14:48:29 - INFO - EVALUATING - Epoch: [44][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.4713 (0.3831)	Prec@1 82.812 (87.216)	
2022-01-19 14:48:29 - INFO - EVALUATING - Epoch: [44][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3044 (0.4362)	Prec@1 89.062 (84.747)	
2022-01-19 14:48:29 - INFO - EVALUATING - Epoch: [44][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8677 (0.5196)	Prec@1 67.188 (80.847)	
2022-01-19 14:48:29 - INFO - 
 Epoch: 45	Training Loss 0.6135 	Training Prec@1 77.937 	Validation Loss 0.5298 	Validation Prec@1 80.549 	
2022-01-19 14:48:29 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:29 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:29 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:29 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][0/128]	Time 0.206 (0.206)	Data 0.202 (0.202)	Loss 0.3794 (0.3794)	Prec@1 85.938 (85.938)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.2497 (1.1289)	Prec@1 71.875 (75.426)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.5449 (0.9552)	Prec@1 81.250 (74.702)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.4899 (0.8266)	Prec@1 84.375 (76.815)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5175 (0.7963)	Prec@1 73.438 (76.944)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7245 (0.7521)	Prec@1 81.250 (77.328)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6073 (0.7374)	Prec@1 78.125 (77.049)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5172 (0.7131)	Prec@1 78.125 (77.377)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8764 (0.7058)	Prec@1 78.125 (77.720)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][90/128]	Time 0.005 (0.007)	Data 0.002 (0.004)	Loss 0.5229 (0.7086)	Prec@1 73.438 (77.352)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][100/128]	Time 0.005 (0.006)	Data 0.002 (0.004)	Loss 0.2526 (0.6962)	Prec@1 87.500 (77.444)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5246 (0.6783)	Prec@1 78.125 (77.886)	
2022-01-19 14:48:29 - INFO - TRAINING - Epoch: [45][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4792 (0.6621)	Prec@1 76.562 (78.035)	
2022-01-19 14:48:30 - INFO - EVALUATING - Epoch: [45][0/32]	Time 0.218 (0.218)	Data 0.216 (0.216)	Loss 0.2933 (0.2933)	Prec@1 85.938 (85.938)	
2022-01-19 14:48:30 - INFO - EVALUATING - Epoch: [45][10/32]	Time 0.003 (0.023)	Data 0.002 (0.021)	Loss 0.7057 (0.4254)	Prec@1 70.312 (83.665)	
2022-01-19 14:48:30 - INFO - EVALUATING - Epoch: [45][20/32]	Time 0.003 (0.013)	Data 0.002 (0.012)	Loss 0.3807 (0.4397)	Prec@1 82.812 (82.738)	
2022-01-19 14:48:30 - INFO - EVALUATING - Epoch: [45][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.6398 (0.4847)	Prec@1 65.625 (79.536)	
2022-01-19 14:48:30 - INFO - 
 Epoch: 46	Training Loss 0.6474 	Training Prec@1 78.464 	Validation Loss 0.4837 	Validation Prec@1 79.520 	
2022-01-19 14:48:30 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:30 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:30 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][0/128]	Time 0.209 (0.209)	Data 0.205 (0.205)	Loss 0.4248 (0.4248)	Prec@1 79.688 (79.688)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.6816 (0.9200)	Prec@1 82.812 (75.568)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][20/128]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.4808 (0.7995)	Prec@1 79.688 (76.562)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.5595 (0.6913)	Prec@1 84.375 (77.470)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5680 (0.7908)	Prec@1 82.812 (76.829)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6442 (0.7459)	Prec@1 82.812 (77.237)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7892 (0.7305)	Prec@1 70.312 (76.588)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6332 (0.7169)	Prec@1 87.500 (76.959)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6042 (0.7038)	Prec@1 71.875 (77.141)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3811 (0.6858)	Prec@1 87.500 (77.661)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4125 (0.6707)	Prec@1 87.500 (77.645)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6529 (0.6663)	Prec@1 68.750 (77.393)	
2022-01-19 14:48:30 - INFO - TRAINING - Epoch: [46][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4967 (0.6492)	Prec@1 75.000 (77.583)	
2022-01-19 14:48:31 - INFO - EVALUATING - Epoch: [46][0/32]	Time 0.190 (0.190)	Data 0.189 (0.189)	Loss 0.2075 (0.2075)	Prec@1 96.875 (96.875)	
2022-01-19 14:48:31 - INFO - EVALUATING - Epoch: [46][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4807 (0.3937)	Prec@1 84.375 (87.074)	
2022-01-19 14:48:31 - INFO - EVALUATING - Epoch: [46][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2780 (0.4211)	Prec@1 92.188 (84.673)	
2022-01-19 14:48:31 - INFO - EVALUATING - Epoch: [46][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7505 (0.4839)	Prec@1 62.500 (80.494)	
2022-01-19 14:48:31 - INFO - 
 Epoch: 47	Training Loss 0.6384 	Training Prec@1 77.741 	Validation Loss 0.4865 	Validation Prec@1 80.206 	
2022-01-19 14:48:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:31 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][0/128]	Time 0.206 (0.206)	Data 0.202 (0.202)	Loss 0.4243 (0.4243)	Prec@1 82.812 (82.812)	
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.8878 (1.0568)	Prec@1 76.562 (75.000)	
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][20/128]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 1.1956 (0.9803)	Prec@1 81.250 (71.131)	
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.4437 (1.0550)	Prec@1 78.125 (73.992)	
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.4646 (1.0550)	Prec@1 51.562 (73.552)	
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5089 (0.9430)	Prec@1 75.000 (75.031)	
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4294 (0.8610)	Prec@1 85.938 (76.255)	
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.4574 (0.8520)	Prec@1 73.438 (76.100)	
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5909 (0.8310)	Prec@1 75.000 (76.408)	
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4249 (0.7964)	Prec@1 81.250 (76.477)	
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5051 (0.7645)	Prec@1 78.125 (76.856)	
2022-01-19 14:48:31 - INFO - TRAINING - Epoch: [47][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3880 (0.7395)	Prec@1 79.688 (77.126)	
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [47][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5259 (0.7308)	Prec@1 78.125 (77.389)	
2022-01-19 14:48:32 - INFO - EVALUATING - Epoch: [47][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.3999 (0.3999)	Prec@1 96.875 (96.875)	
2022-01-19 14:48:32 - INFO - EVALUATING - Epoch: [47][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5757 (0.5094)	Prec@1 84.375 (86.648)	
2022-01-19 14:48:32 - INFO - EVALUATING - Epoch: [47][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4624 (0.5074)	Prec@1 90.625 (84.449)	
2022-01-19 14:48:32 - INFO - EVALUATING - Epoch: [47][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6001 (0.5197)	Prec@1 62.500 (80.494)	
2022-01-19 14:48:32 - INFO - 
 Epoch: 48	Training Loss 0.7187 	Training Prec@1 77.557 	Validation Loss 0.5190 	Validation Prec@1 80.157 	
2022-01-19 14:48:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:32 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [48][0/128]	Time 0.186 (0.186)	Data 0.182 (0.182)	Loss 0.4795 (0.4795)	Prec@1 79.688 (79.688)	
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [48][10/128]	Time 0.004 (0.021)	Data 0.002 (0.018)	Loss 2.0458 (1.2645)	Prec@1 78.125 (71.307)	
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [48][20/128]	Time 0.005 (0.013)	Data 0.002 (0.010)	Loss 0.5098 (1.0432)	Prec@1 70.312 (73.289)	
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [48][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4358 (0.8855)	Prec@1 81.250 (74.798)	
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [48][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6064 (0.8083)	Prec@1 70.312 (74.924)	
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [48][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5894 (0.7587)	Prec@1 79.688 (75.551)	
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [48][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4820 (0.7182)	Prec@1 84.375 (76.153)	
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [48][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4808 (0.6941)	Prec@1 84.375 (77.135)	
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [48][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.2077 (0.6996)	Prec@1 73.438 (76.408)	
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [48][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.2926 (0.6827)	Prec@1 89.062 (77.112)	
2022-01-19 14:48:32 - INFO - TRAINING - Epoch: [48][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7689 (0.6839)	Prec@1 48.438 (76.996)	
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [48][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6019 (0.6766)	Prec@1 60.938 (76.830)	
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [48][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4918 (0.6786)	Prec@1 79.688 (76.278)	
2022-01-19 14:48:33 - INFO - EVALUATING - Epoch: [48][0/32]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.1800 (0.1800)	Prec@1 98.438 (98.438)	
2022-01-19 14:48:33 - INFO - EVALUATING - Epoch: [48][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4752 (0.3756)	Prec@1 84.375 (88.210)	
2022-01-19 14:48:33 - INFO - EVALUATING - Epoch: [48][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3291 (0.4108)	Prec@1 90.625 (85.565)	
2022-01-19 14:48:33 - INFO - EVALUATING - Epoch: [48][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7349 (0.4677)	Prec@1 64.062 (81.855)	
2022-01-19 14:48:33 - INFO - 
 Epoch: 49	Training Loss 0.6743 	Training Prec@1 76.381 	Validation Loss 0.4709 	Validation Prec@1 81.529 	
2022-01-19 14:48:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:33 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [49][0/128]	Time 0.195 (0.195)	Data 0.191 (0.191)	Loss 0.4692 (0.4692)	Prec@1 81.250 (81.250)	
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [49][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.4537 (0.9725)	Prec@1 85.938 (71.165)	
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [49][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6892 (0.8793)	Prec@1 73.438 (72.470)	
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [49][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5655 (0.8365)	Prec@1 84.375 (71.069)	
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [49][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.7474 (0.8159)	Prec@1 60.938 (72.104)	
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [49][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.3966 (0.7986)	Prec@1 81.250 (73.560)	
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [49][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5710 (0.7623)	Prec@1 79.688 (74.360)	
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [49][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4881 (0.7560)	Prec@1 78.125 (74.692)	
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [49][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7123 (0.7530)	Prec@1 54.688 (74.306)	
2022-01-19 14:48:33 - INFO - TRAINING - Epoch: [49][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5745 (0.7359)	Prec@1 75.000 (74.845)	
2022-01-19 14:48:34 - INFO - TRAINING - Epoch: [49][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5790 (0.7379)	Prec@1 75.000 (74.118)	
2022-01-19 14:48:34 - INFO - TRAINING - Epoch: [49][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5819 (0.7342)	Prec@1 79.688 (74.268)	
2022-01-19 14:48:34 - INFO - TRAINING - Epoch: [49][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7957 (0.7312)	Prec@1 79.688 (73.954)	
2022-01-19 14:48:34 - INFO - EVALUATING - Epoch: [49][0/32]	Time 0.197 (0.197)	Data 0.194 (0.194)	Loss 0.1493 (0.1493)	Prec@1 96.875 (96.875)	
2022-01-19 14:48:34 - INFO - EVALUATING - Epoch: [49][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7554 (0.5480)	Prec@1 79.688 (84.659)	
2022-01-19 14:48:34 - INFO - EVALUATING - Epoch: [49][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3957 (0.6043)	Prec@1 89.062 (82.887)	
2022-01-19 14:48:34 - INFO - EVALUATING - Epoch: [49][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.2431 (0.7230)	Prec@1 60.938 (79.083)	
2022-01-19 14:48:34 - INFO - 
 Epoch: 50	Training Loss 0.7189 	Training Prec@1 74.458 	Validation Loss 0.7380 	Validation Prec@1 78.687 	
