2022-01-19 14:47:47 - INFO - saving to ./results/medium/quantise/q5/other/anchor/recidivism/recidivism_test1/
2022-01-19 14:47:47 - DEBUG - run arguments: Namespace(config='./configs/config_medium.json', data='../../paper_bench/complete/quantise/q5/other/anchor/recidivism/recidivism_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/medium/quantise/q5/other/anchor/recidivism/recidivism_test1/', test='../../paper_bench/cv/test/quantise/q5/other/anchor/recidivism/recidivism_test1_data.csv', train='../../paper_bench/cv/train/quantise/q5/other/anchor/recidivism/recidivism_train1_data.csv')
2022-01-19 14:47:47 - INFO - creating model mlp_binary
2022-01-19 14:47:47 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [32, 16, 8, 2]}
2022-01-19 14:47:47 - INFO - number of parameters: 2074
2022-01-19 14:47:47 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-19 14:47:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [0][0/80]	Time 0.246 (0.246)	Data 0.239 (0.239)	Loss 1.2696 (1.2696)	Prec@1 62.500 (62.500)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [0][10/80]	Time 0.004 (0.026)	Data 0.002 (0.023)	Loss 0.6980 (1.1621)	Prec@1 46.875 (52.557)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [0][20/80]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.6969 (1.0042)	Prec@1 48.438 (53.274)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [0][30/80]	Time 0.004 (0.012)	Data 0.002 (0.009)	Loss 0.6930 (0.9251)	Prec@1 53.125 (52.722)	
2022-01-19 14:47:47 - INFO - TRAINING - Epoch: [0][40/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6878 (0.8881)	Prec@1 56.250 (52.668)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [0][50/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6919 (0.8593)	Prec@1 53.125 (52.267)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [0][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6720 (0.8393)	Prec@1 64.062 (52.152)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [0][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6912 (0.8408)	Prec@1 53.125 (52.179)	
2022-01-19 14:47:48 - INFO - EVALUATING - Epoch: [0][0/20]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.6817 (0.6817)	Prec@1 57.812 (57.812)	
2022-01-19 14:47:48 - INFO - EVALUATING - Epoch: [0][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7218 (0.6943)	Prec@1 40.625 (52.415)	
2022-01-19 14:47:48 - INFO - 
 Epoch: 1	Training Loss 0.8486 	Training Prec@1 52.495 	Validation Loss 0.6997 	Validation Prec@1 50.079 	
2022-01-19 14:47:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [1][0/80]	Time 0.192 (0.192)	Data 0.188 (0.188)	Loss 0.7145 (0.7145)	Prec@1 43.750 (43.750)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [1][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.6931 (0.8548)	Prec@1 51.562 (51.278)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [1][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6956 (0.8285)	Prec@1 45.312 (53.274)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [1][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6929 (0.8129)	Prec@1 53.125 (53.327)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [1][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.7319 (0.8057)	Prec@1 59.375 (53.163)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [1][50/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6978 (0.8354)	Prec@1 48.438 (53.125)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [1][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.2331 (0.8705)	Prec@1 51.562 (52.843)	
2022-01-19 14:47:48 - INFO - TRAINING - Epoch: [1][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.2422 (0.9012)	Prec@1 62.500 (52.993)	
2022-01-19 14:47:49 - INFO - EVALUATING - Epoch: [1][0/20]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.9015 (0.9015)	Prec@1 42.188 (42.188)	
2022-01-19 14:47:49 - INFO - EVALUATING - Epoch: [1][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7356 (0.7916)	Prec@1 57.812 (52.983)	
2022-01-19 14:47:49 - INFO - 
 Epoch: 2	Training Loss 0.9279 	Training Prec@1 52.652 	Validation Loss 0.7860 	Validation Prec@1 53.391 	
2022-01-19 14:47:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [2][0/80]	Time 0.195 (0.195)	Data 0.191 (0.191)	Loss 0.7527 (0.7527)	Prec@1 56.250 (56.250)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [2][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 2.1356 (1.1648)	Prec@1 46.875 (52.699)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [2][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6874 (1.0180)	Prec@1 59.375 (54.539)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [2][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.0776 (0.9620)	Prec@1 54.688 (53.831)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [2][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.8888 (0.9590)	Prec@1 62.500 (53.887)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [2][50/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.7930 (0.9272)	Prec@1 51.562 (53.554)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [2][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6916 (0.9009)	Prec@1 57.812 (53.919)	
2022-01-19 14:47:49 - INFO - TRAINING - Epoch: [2][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.0466 (0.8808)	Prec@1 60.938 (54.049)	
2022-01-19 14:47:49 - INFO - EVALUATING - Epoch: [2][0/20]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.7041 (0.7041)	Prec@1 42.188 (42.188)	
2022-01-19 14:47:49 - INFO - EVALUATING - Epoch: [2][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6838 (0.6978)	Prec@1 59.375 (47.585)	
2022-01-19 14:47:49 - INFO - 
 Epoch: 3	Training Loss 0.8793 	Training Prec@1 54.348 	Validation Loss 0.6950 	Validation Prec@1 49.921 	
2022-01-19 14:47:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [3][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.6949 (0.6949)	Prec@1 50.000 (50.000)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [3][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7068 (1.0493)	Prec@1 37.500 (45.739)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [3][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6892 (1.0287)	Prec@1 54.688 (50.372)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [3][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6659 (0.9638)	Prec@1 54.688 (51.260)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [3][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8179 (0.9494)	Prec@1 67.188 (50.953)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [3][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.9527 (0.9467)	Prec@1 67.188 (51.532)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [3][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9311 (0.9429)	Prec@1 62.500 (52.280)	
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [3][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8171 (0.9324)	Prec@1 43.750 (52.179)	
2022-01-19 14:47:50 - INFO - EVALUATING - Epoch: [3][0/20]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.7598 (0.7598)	Prec@1 67.188 (67.188)	
2022-01-19 14:47:50 - INFO - EVALUATING - Epoch: [3][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7298 (0.8704)	Prec@1 70.312 (62.216)	
2022-01-19 14:47:50 - INFO - 
 Epoch: 4	Training Loss 0.9170 	Training Prec@1 52.218 	Validation Loss 0.8888 	Validation Prec@1 61.514 	
2022-01-19 14:47:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:50 - INFO - TRAINING - Epoch: [4][0/80]	Time 0.245 (0.245)	Data 0.241 (0.241)	Loss 0.9049 (0.9049)	Prec@1 60.938 (60.938)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [4][10/80]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.8661 (0.8498)	Prec@1 53.125 (50.426)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [4][20/80]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.8602 (0.8264)	Prec@1 43.750 (51.265)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [4][30/80]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.6691 (0.8233)	Prec@1 60.938 (50.655)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [4][40/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7023 (0.7952)	Prec@1 51.562 (50.724)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [4][50/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 1.7371 (0.8439)	Prec@1 59.375 (52.145)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [4][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.2760 (0.8990)	Prec@1 48.438 (52.024)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [4][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7517 (0.8905)	Prec@1 57.812 (52.531)	
2022-01-19 14:47:51 - INFO - EVALUATING - Epoch: [4][0/20]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.7107 (0.7107)	Prec@1 70.312 (70.312)	
2022-01-19 14:47:51 - INFO - EVALUATING - Epoch: [4][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7887 (0.8001)	Prec@1 67.188 (65.483)	
2022-01-19 14:47:51 - INFO - 
 Epoch: 5	Training Loss 0.8916 	Training Prec@1 52.790 	Validation Loss 0.8526 	Validation Prec@1 63.170 	
2022-01-19 14:47:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [5][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.7846 (0.7846)	Prec@1 65.625 (65.625)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [5][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.0531 (0.8444)	Prec@1 53.125 (56.534)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [5][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.7242 (0.8385)	Prec@1 35.938 (55.655)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [5][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8113 (0.8174)	Prec@1 51.562 (55.393)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [5][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6981 (0.7959)	Prec@1 48.438 (54.992)	
2022-01-19 14:47:51 - INFO - TRAINING - Epoch: [5][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6994 (0.7763)	Prec@1 46.875 (54.810)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [5][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6912 (0.8012)	Prec@1 53.125 (54.226)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [5][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6928 (0.8046)	Prec@1 51.562 (54.137)	
2022-01-19 14:47:52 - INFO - EVALUATING - Epoch: [5][0/20]	Time 0.205 (0.205)	Data 0.203 (0.203)	Loss 1.1731 (1.1731)	Prec@1 46.875 (46.875)	
2022-01-19 14:47:52 - INFO - EVALUATING - Epoch: [5][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.9139 (0.9775)	Prec@1 60.938 (56.818)	
2022-01-19 14:47:52 - INFO - 
 Epoch: 6	Training Loss 0.7939 	Training Prec@1 53.658 	Validation Loss 0.9741 	Validation Prec@1 57.177 	
2022-01-19 14:47:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [6][0/80]	Time 0.246 (0.246)	Data 0.242 (0.242)	Loss 0.8971 (0.8971)	Prec@1 60.938 (60.938)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [6][10/80]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.7026 (1.0682)	Prec@1 40.625 (49.574)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [6][20/80]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.8509 (1.1720)	Prec@1 46.875 (49.554)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [6][30/80]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.6901 (1.0502)	Prec@1 54.688 (50.907)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [6][40/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6912 (1.0042)	Prec@1 53.125 (51.867)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [6][50/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7273 (1.0663)	Prec@1 57.812 (52.482)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [6][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6973 (1.0113)	Prec@1 48.438 (52.664)	
2022-01-19 14:47:52 - INFO - TRAINING - Epoch: [6][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6761 (0.9765)	Prec@1 60.938 (53.191)	
2022-01-19 14:47:53 - INFO - EVALUATING - Epoch: [6][0/20]	Time 0.242 (0.242)	Data 0.240 (0.240)	Loss 0.7322 (0.7322)	Prec@1 57.812 (57.812)	
2022-01-19 14:47:53 - INFO - EVALUATING - Epoch: [6][10/20]	Time 0.003 (0.025)	Data 0.002 (0.023)	Loss 0.8191 (0.8084)	Prec@1 40.625 (52.415)	
2022-01-19 14:47:53 - INFO - 
 Epoch: 7	Training Loss 0.9570 	Training Prec@1 52.692 	Validation Loss 0.8240 	Validation Prec@1 50.079 	
2022-01-19 14:47:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [7][0/80]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 1.0394 (1.0394)	Prec@1 40.625 (40.625)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [7][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 1.0007 (1.0350)	Prec@1 53.125 (47.301)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [7][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.7170 (0.8890)	Prec@1 45.312 (47.991)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [7][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6355 (0.8643)	Prec@1 56.250 (50.706)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [7][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 1.1545 (0.8875)	Prec@1 45.312 (50.534)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [7][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6433 (0.8681)	Prec@1 70.312 (51.654)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [7][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6869 (0.8800)	Prec@1 65.625 (52.690)	
2022-01-19 14:47:53 - INFO - TRAINING - Epoch: [7][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7216 (0.8734)	Prec@1 43.750 (52.509)	
2022-01-19 14:47:53 - INFO - EVALUATING - Epoch: [7][0/20]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.6809 (0.6809)	Prec@1 57.812 (57.812)	
2022-01-19 14:47:54 - INFO - EVALUATING - Epoch: [7][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7355 (0.6980)	Prec@1 40.625 (52.415)	
2022-01-19 14:47:54 - INFO - 
 Epoch: 8	Training Loss 0.8563 	Training Prec@1 52.810 	Validation Loss 0.7055 	Validation Prec@1 50.079 	
2022-01-19 14:47:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [8][0/80]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 0.7008 (0.7008)	Prec@1 51.562 (51.562)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [8][10/80]	Time 0.005 (0.022)	Data 0.002 (0.020)	Loss 0.8683 (0.8308)	Prec@1 60.938 (50.994)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [8][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.7250 (0.9521)	Prec@1 48.438 (54.167)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [8][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7113 (0.8921)	Prec@1 45.312 (53.881)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [8][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8644 (0.8639)	Prec@1 62.500 (53.544)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [8][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.1056 (0.8729)	Prec@1 46.875 (53.768)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [8][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6973 (0.8686)	Prec@1 48.438 (54.252)	
2022-01-19 14:47:54 - INFO - TRAINING - Epoch: [8][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8931 (0.8525)	Prec@1 60.938 (53.873)	
2022-01-19 14:47:54 - INFO - EVALUATING - Epoch: [8][0/20]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 1.0114 (1.0114)	Prec@1 57.812 (57.812)	
2022-01-19 14:47:54 - INFO - EVALUATING - Epoch: [8][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 1.3778 (1.1265)	Prec@1 40.625 (52.415)	
2022-01-19 14:47:54 - INFO - 
 Epoch: 9	Training Loss 0.8410 	Training Prec@1 53.244 	Validation Loss 1.1763 	Validation Prec@1 50.079 	
2022-01-19 14:47:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [9][0/80]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 1.0447 (1.0447)	Prec@1 56.250 (56.250)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [9][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.7792 (0.9798)	Prec@1 53.125 (50.710)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [9][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.7452 (0.9209)	Prec@1 56.250 (51.265)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [9][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6927 (0.8637)	Prec@1 51.562 (52.319)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [9][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6957 (0.8333)	Prec@1 45.312 (51.639)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [9][50/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.8444 (0.8630)	Prec@1 64.062 (52.788)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [9][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6974 (0.8544)	Prec@1 39.062 (52.408)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [9][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.0389 (0.8473)	Prec@1 54.688 (52.245)	
2022-01-19 14:47:55 - INFO - EVALUATING - Epoch: [9][0/20]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.9213 (0.9213)	Prec@1 57.812 (57.812)	
2022-01-19 14:47:55 - INFO - EVALUATING - Epoch: [9][10/20]	Time 0.003 (0.021)	Data 0.002 (0.019)	Loss 1.2362 (1.0202)	Prec@1 40.625 (52.415)	
2022-01-19 14:47:55 - INFO - 
 Epoch: 10	Training Loss 0.8529 	Training Prec@1 52.179 	Validation Loss 1.0630 	Validation Prec@1 50.079 	
2022-01-19 14:47:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [10][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 1.1503 (1.1503)	Prec@1 45.312 (45.312)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [10][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7384 (0.8244)	Prec@1 70.312 (55.824)	
2022-01-19 14:47:55 - INFO - TRAINING - Epoch: [10][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7437 (0.8045)	Prec@1 68.750 (56.994)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [10][30/80]	Time 0.005 (0.011)	Data 0.002 (0.008)	Loss 0.7729 (0.8246)	Prec@1 67.188 (56.502)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [10][40/80]	Time 0.005 (0.009)	Data 0.002 (0.007)	Loss 0.6920 (0.8107)	Prec@1 53.125 (56.059)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [10][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6922 (0.8251)	Prec@1 62.500 (55.178)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [10][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.1405 (0.8119)	Prec@1 59.375 (55.302)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [10][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7013 (0.8252)	Prec@1 46.875 (54.864)	
2022-01-19 14:47:56 - INFO - EVALUATING - Epoch: [10][0/20]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.7021 (0.7021)	Prec@1 42.188 (42.188)	
2022-01-19 14:47:56 - INFO - EVALUATING - Epoch: [10][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6851 (0.6983)	Prec@1 59.375 (47.869)	
2022-01-19 14:47:56 - INFO - 
 Epoch: 11	Training Loss 0.8213 	Training Prec@1 54.605 	Validation Loss 0.6971 	Validation Prec@1 50.394 	
2022-01-19 14:47:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [11][0/80]	Time 0.193 (0.193)	Data 0.189 (0.189)	Loss 0.6877 (0.6877)	Prec@1 46.875 (46.875)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [11][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.6923 (0.9727)	Prec@1 65.625 (54.403)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [11][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.0959 (1.0480)	Prec@1 50.000 (51.190)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [11][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.1747 (1.0634)	Prec@1 53.125 (52.067)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [11][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.7129 (1.0282)	Prec@1 45.312 (50.877)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [11][50/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.7059 (1.0394)	Prec@1 48.438 (51.808)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [11][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.1041 (1.0443)	Prec@1 46.875 (51.665)	
2022-01-19 14:47:56 - INFO - TRAINING - Epoch: [11][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.0174 (1.0393)	Prec@1 68.750 (51.937)	
2022-01-19 14:47:57 - INFO - EVALUATING - Epoch: [11][0/20]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.9836 (0.9836)	Prec@1 42.188 (42.188)	
2022-01-19 14:47:57 - INFO - EVALUATING - Epoch: [11][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.9914 (1.0667)	Prec@1 59.375 (47.585)	
2022-01-19 14:47:57 - INFO - 
 Epoch: 12	Training Loss 1.0332 	Training Prec@1 52.475 	Validation Loss 1.0301 	Validation Prec@1 49.921 	
2022-01-19 14:47:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [12][0/80]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 1.2360 (1.2360)	Prec@1 48.438 (48.438)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [12][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.6932 (0.9491)	Prec@1 50.000 (52.983)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [12][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.1272 (0.8955)	Prec@1 62.500 (54.539)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [12][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.2366 (0.9087)	Prec@1 46.875 (53.024)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [12][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.9221 (0.9025)	Prec@1 59.375 (53.163)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [12][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6815 (0.9365)	Prec@1 57.812 (54.228)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [12][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9956 (0.9450)	Prec@1 50.000 (54.175)	
2022-01-19 14:47:57 - INFO - TRAINING - Epoch: [12][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6692 (0.9422)	Prec@1 60.938 (54.071)	
2022-01-19 14:47:58 - INFO - EVALUATING - Epoch: [12][0/20]	Time 0.242 (0.242)	Data 0.240 (0.240)	Loss 0.8374 (0.8374)	Prec@1 57.812 (57.812)	
2022-01-19 14:47:58 - INFO - EVALUATING - Epoch: [12][10/20]	Time 0.003 (0.025)	Data 0.002 (0.024)	Loss 1.0974 (0.9190)	Prec@1 40.625 (52.415)	
2022-01-19 14:47:58 - INFO - 
 Epoch: 13	Training Loss 0.9470 	Training Prec@1 54.190 	Validation Loss 0.9544 	Validation Prec@1 50.079 	
2022-01-19 14:47:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [13][0/80]	Time 0.190 (0.190)	Data 0.186 (0.186)	Loss 1.0028 (1.0028)	Prec@1 46.875 (46.875)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [13][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 1.2594 (1.3690)	Prec@1 51.562 (53.977)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [13][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6601 (1.2699)	Prec@1 65.625 (55.878)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [13][30/80]	Time 0.005 (0.010)	Data 0.003 (0.008)	Loss 1.0647 (1.1603)	Prec@1 62.500 (54.990)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [13][40/80]	Time 0.005 (0.009)	Data 0.003 (0.007)	Loss 0.6913 (1.0692)	Prec@1 53.125 (55.755)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [13][50/80]	Time 0.006 (0.008)	Data 0.003 (0.006)	Loss 0.7036 (1.0291)	Prec@1 43.750 (55.821)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [13][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6850 (0.9763)	Prec@1 57.812 (55.405)	
2022-01-19 14:47:58 - INFO - TRAINING - Epoch: [13][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7809 (0.9796)	Prec@1 53.125 (55.040)	
2022-01-19 14:47:58 - INFO - EVALUATING - Epoch: [13][0/20]	Time 0.237 (0.237)	Data 0.235 (0.235)	Loss 1.0349 (1.0349)	Prec@1 54.688 (54.688)	
2022-01-19 14:47:58 - INFO - EVALUATING - Epoch: [13][10/20]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.8628 (0.8473)	Prec@1 62.500 (63.636)	
2022-01-19 14:47:58 - INFO - 
 Epoch: 14	Training Loss 0.9575 	Training Prec@1 55.295 	Validation Loss 0.9283 	Validation Prec@1 59.385 	
2022-01-19 14:47:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [14][0/80]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.8678 (0.8678)	Prec@1 62.500 (62.500)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [14][10/80]	Time 0.005 (0.022)	Data 0.002 (0.020)	Loss 1.0637 (0.8960)	Prec@1 53.125 (53.551)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [14][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7018 (0.8500)	Prec@1 43.750 (54.762)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [14][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8616 (0.8178)	Prec@1 64.062 (54.587)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [14][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7033 (0.8170)	Prec@1 42.188 (54.535)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [14][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6965 (0.7927)	Prec@1 42.188 (53.830)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [14][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6995 (0.8323)	Prec@1 43.750 (53.765)	
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [14][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8498 (0.8444)	Prec@1 59.375 (54.555)	
2022-01-19 14:47:59 - INFO - EVALUATING - Epoch: [14][0/20]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.6851 (0.6851)	Prec@1 57.812 (57.812)	
2022-01-19 14:47:59 - INFO - EVALUATING - Epoch: [14][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7075 (0.6921)	Prec@1 40.625 (52.415)	
2022-01-19 14:47:59 - INFO - 
 Epoch: 15	Training Loss 0.8345 	Training Prec@1 54.447 	Validation Loss 0.6952 	Validation Prec@1 50.079 	
2022-01-19 14:47:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:47:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:47:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:47:59 - INFO - TRAINING - Epoch: [15][0/80]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.6871 (0.6871)	Prec@1 56.250 (56.250)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [15][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.8538 (0.9576)	Prec@1 62.500 (53.125)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [15][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 1.1726 (1.0161)	Prec@1 45.312 (53.348)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [15][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 1.3784 (1.0411)	Prec@1 57.812 (51.562)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [15][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6951 (1.0609)	Prec@1 51.562 (53.544)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [15][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7111 (1.0072)	Prec@1 45.312 (53.309)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [15][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6942 (0.9682)	Prec@1 53.125 (54.022)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [15][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6947 (0.9415)	Prec@1 53.125 (54.181)	
2022-01-19 14:48:00 - INFO - EVALUATING - Epoch: [15][0/20]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 0.7910 (0.7910)	Prec@1 46.875 (46.875)	
2022-01-19 14:48:00 - INFO - EVALUATING - Epoch: [15][10/20]	Time 0.003 (0.025)	Data 0.002 (0.023)	Loss 0.6590 (0.6972)	Prec@1 65.625 (58.949)	
2022-01-19 14:48:00 - INFO - 
 Epoch: 16	Training Loss 0.9375 	Training Prec@1 54.033 	Validation Loss 0.7054 	Validation Prec@1 58.833 	
2022-01-19 14:48:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [16][0/80]	Time 0.242 (0.242)	Data 0.238 (0.238)	Loss 0.7053 (0.7053)	Prec@1 59.375 (59.375)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [16][10/80]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 1.2593 (1.0907)	Prec@1 42.188 (49.432)	
2022-01-19 14:48:00 - INFO - TRAINING - Epoch: [16][20/80]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 1.3956 (1.1172)	Prec@1 51.562 (52.307)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [16][30/80]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.7159 (1.0208)	Prec@1 40.625 (52.016)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [16][40/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7215 (0.9571)	Prec@1 35.938 (52.439)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [16][50/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7874 (0.9182)	Prec@1 59.375 (52.175)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [16][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6913 (0.8902)	Prec@1 53.125 (52.228)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [16][70/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.7959 (0.8866)	Prec@1 50.000 (51.474)	
2022-01-19 14:48:01 - INFO - EVALUATING - Epoch: [16][0/20]	Time 0.236 (0.236)	Data 0.233 (0.233)	Loss 0.6833 (0.6833)	Prec@1 57.812 (57.812)	
2022-01-19 14:48:01 - INFO - EVALUATING - Epoch: [16][10/20]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.7136 (0.6928)	Prec@1 40.625 (52.415)	
2022-01-19 14:48:01 - INFO - 
 Epoch: 17	Training Loss 0.8917 	Training Prec@1 52.199 	Validation Loss 0.6969 	Validation Prec@1 50.079 	
2022-01-19 14:48:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [17][0/80]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.7053 (0.7053)	Prec@1 45.312 (45.312)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [17][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.7045 (1.0089)	Prec@1 43.750 (51.847)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [17][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.3162 (1.0027)	Prec@1 42.188 (50.818)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [17][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.9052 (0.9841)	Prec@1 40.625 (50.605)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [17][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.9557 (1.0017)	Prec@1 40.625 (49.924)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [17][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8821 (0.9839)	Prec@1 62.500 (50.919)	
2022-01-19 14:48:01 - INFO - TRAINING - Epoch: [17][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6925 (0.9475)	Prec@1 54.688 (51.255)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [17][70/80]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.6921 (0.9150)	Prec@1 71.875 (52.223)	
2022-01-19 14:48:02 - INFO - EVALUATING - Epoch: [17][0/20]	Time 0.186 (0.186)	Data 0.184 (0.184)	Loss 0.6938 (0.6938)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:02 - INFO - EVALUATING - Epoch: [17][10/20]	Time 0.003 (0.020)	Data 0.002 (0.018)	Loss 0.6924 (0.6933)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:02 - INFO - 
 Epoch: 18	Training Loss 0.9157 	Training Prec@1 52.337 	Validation Loss 0.6932 	Validation Prec@1 49.921 	
2022-01-19 14:48:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [18][0/80]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.6924 (0.6924)	Prec@1 59.375 (59.375)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [18][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.8519 (0.9021)	Prec@1 64.062 (52.841)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [18][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.7449 (0.8980)	Prec@1 70.312 (52.381)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [18][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7018 (0.9012)	Prec@1 46.875 (53.427)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [18][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6991 (0.8573)	Prec@1 45.312 (54.192)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [18][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.0968 (0.8435)	Prec@1 51.562 (53.922)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [18][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9150 (0.8621)	Prec@1 60.938 (54.124)	
2022-01-19 14:48:02 - INFO - TRAINING - Epoch: [18][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7831 (0.8493)	Prec@1 67.188 (53.741)	
2022-01-19 14:48:03 - INFO - EVALUATING - Epoch: [18][0/20]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.9319 (0.9319)	Prec@1 59.375 (59.375)	
2022-01-19 14:48:03 - INFO - EVALUATING - Epoch: [18][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7813 (0.8674)	Prec@1 67.188 (62.784)	
2022-01-19 14:48:03 - INFO - 
 Epoch: 19	Training Loss 0.8415 	Training Prec@1 53.974 	Validation Loss 0.8984 	Validation Prec@1 61.278 	
2022-01-19 14:48:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [19][0/80]	Time 0.208 (0.208)	Data 0.204 (0.204)	Loss 0.9028 (0.9028)	Prec@1 60.938 (60.938)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [19][10/80]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 1.1766 (1.0396)	Prec@1 50.000 (55.966)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [19][20/80]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.9005 (0.8946)	Prec@1 60.938 (54.688)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [19][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6896 (0.8717)	Prec@1 57.812 (54.083)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [19][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9176 (0.8509)	Prec@1 60.938 (54.040)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [19][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6773 (0.8515)	Prec@1 64.062 (54.442)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [19][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6784 (0.8312)	Prec@1 62.500 (54.995)	
2022-01-19 14:48:03 - INFO - TRAINING - Epoch: [19][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.1948 (0.8459)	Prec@1 53.125 (54.533)	
2022-01-19 14:48:03 - INFO - EVALUATING - Epoch: [19][0/20]	Time 0.237 (0.237)	Data 0.235 (0.235)	Loss 0.8910 (0.8910)	Prec@1 50.000 (50.000)	
2022-01-19 14:48:03 - INFO - EVALUATING - Epoch: [19][10/20]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.9121 (1.0543)	Prec@1 62.500 (53.977)	
2022-01-19 14:48:03 - INFO - 
 Epoch: 20	Training Loss 0.8380 	Training Prec@1 54.605 	Validation Loss 1.0410 	Validation Prec@1 55.442 	
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [20][0/80]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 1.1678 (1.1678)	Prec@1 53.125 (53.125)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [20][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.7111 (0.8599)	Prec@1 45.312 (52.841)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [20][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.9481 (0.8142)	Prec@1 57.812 (52.679)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [20][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6525 (0.7919)	Prec@1 65.625 (56.250)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [20][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7163 (0.7673)	Prec@1 40.625 (56.098)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [20][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6759 (0.7534)	Prec@1 51.562 (55.055)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [20][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9245 (0.7563)	Prec@1 53.125 (54.841)	
2022-01-19 14:48:04 - INFO - TRAINING - Epoch: [20][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8947 (0.7636)	Prec@1 50.000 (55.348)	
2022-01-19 14:48:04 - INFO - EVALUATING - Epoch: [20][0/20]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.7136 (0.7136)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:04 - INFO - EVALUATING - Epoch: [20][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6794 (0.7029)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:04 - INFO - 
 Epoch: 21	Training Loss 0.7644 	Training Prec@1 55.295 	Validation Loss 0.6982 	Validation Prec@1 49.921 	
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [21][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.6857 (0.6857)	Prec@1 56.250 (56.250)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [21][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7001 (0.6979)	Prec@1 62.500 (57.528)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [21][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6874 (0.6924)	Prec@1 60.938 (57.664)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [21][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6563 (0.6788)	Prec@1 53.125 (59.224)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [21][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7025 (0.6809)	Prec@1 46.875 (59.032)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [21][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6917 (0.6847)	Prec@1 60.938 (59.406)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [21][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7753 (0.6887)	Prec@1 56.250 (59.247)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [21][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7027 (0.6944)	Prec@1 45.312 (58.781)	
2022-01-19 14:48:05 - INFO - EVALUATING - Epoch: [21][0/20]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.9029 (0.9029)	Prec@1 57.812 (57.812)	
2022-01-19 14:48:05 - INFO - EVALUATING - Epoch: [21][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6209 (0.8285)	Prec@1 71.875 (59.091)	
2022-01-19 14:48:05 - INFO - 
 Epoch: 22	Training Loss 0.6938 	Training Prec@1 58.667 	Validation Loss 0.8313 	Validation Prec@1 60.174 	
2022-01-19 14:48:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][0/80]	Time 0.202 (0.202)	Data 0.198 (0.198)	Loss 0.9325 (0.9325)	Prec@1 56.250 (56.250)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6567 (0.7212)	Prec@1 75.000 (60.369)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.7939 (0.7245)	Prec@1 51.562 (56.920)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7011 (0.7291)	Prec@1 43.750 (55.897)	
2022-01-19 14:48:05 - INFO - TRAINING - Epoch: [22][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8956 (0.7475)	Prec@1 39.062 (54.878)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [22][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7860 (0.7446)	Prec@1 53.125 (54.381)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [22][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8917 (0.7417)	Prec@1 51.562 (54.534)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [22][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7373 (0.7368)	Prec@1 57.812 (55.920)	
2022-01-19 14:48:06 - INFO - EVALUATING - Epoch: [22][0/20]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.6701 (0.6701)	Prec@1 64.062 (64.062)	
2022-01-19 14:48:06 - INFO - EVALUATING - Epoch: [22][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6931 (0.6704)	Prec@1 60.938 (63.920)	
2022-01-19 14:48:06 - INFO - 
 Epoch: 23	Training Loss 0.7321 	Training Prec@1 55.413 	Validation Loss 0.7031 	Validation Prec@1 60.489 	
2022-01-19 14:48:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:06 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.7721 (0.7721)	Prec@1 53.125 (53.125)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7724 (0.7341)	Prec@1 53.125 (54.545)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6874 (0.7253)	Prec@1 60.938 (56.101)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.9850 (0.7335)	Prec@1 57.812 (57.510)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8028 (0.7437)	Prec@1 50.000 (57.241)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][50/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.7480 (0.7385)	Prec@1 57.812 (55.944)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6222 (0.7533)	Prec@1 68.750 (56.224)	
2022-01-19 14:48:06 - INFO - TRAINING - Epoch: [23][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6927 (0.7455)	Prec@1 51.562 (55.986)	
2022-01-19 14:48:07 - INFO - EVALUATING - Epoch: [23][0/20]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 0.7398 (0.7398)	Prec@1 70.312 (70.312)	
2022-01-19 14:48:07 - INFO - EVALUATING - Epoch: [23][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7431 (0.9333)	Prec@1 73.438 (64.205)	
2022-01-19 14:48:07 - INFO - 
 Epoch: 24	Training Loss 0.7535 	Training Prec@1 56.261 	Validation Loss 0.9788 	Validation Prec@1 62.382 	
2022-01-19 14:48:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:07 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][0/80]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.8093 (0.8093)	Prec@1 67.188 (67.188)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.7423 (0.8385)	Prec@1 56.250 (58.239)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6978 (0.7938)	Prec@1 60.938 (58.557)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7192 (0.7590)	Prec@1 59.375 (60.181)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7255 (0.7453)	Prec@1 59.375 (58.194)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6972 (0.7338)	Prec@1 45.312 (58.732)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6989 (0.7294)	Prec@1 43.750 (58.376)	
2022-01-19 14:48:07 - INFO - TRAINING - Epoch: [24][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7495 (0.7267)	Prec@1 56.250 (57.548)	
2022-01-19 14:48:07 - INFO - EVALUATING - Epoch: [24][0/20]	Time 0.185 (0.185)	Data 0.184 (0.184)	Loss 0.7012 (0.7012)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:08 - INFO - EVALUATING - Epoch: [24][10/20]	Time 0.003 (0.019)	Data 0.002 (0.018)	Loss 0.6857 (0.6963)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:08 - INFO - 
 Epoch: 25	Training Loss 0.7243 	Training Prec@1 57.287 	Validation Loss 0.6942 	Validation Prec@1 49.921 	
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][0/80]	Time 0.233 (0.233)	Data 0.229 (0.229)	Loss 0.6857 (0.6857)	Prec@1 59.375 (59.375)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][10/80]	Time 0.004 (0.025)	Data 0.002 (0.023)	Loss 0.6941 (0.9631)	Prec@1 50.000 (55.824)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][20/80]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.6954 (0.8419)	Prec@1 60.938 (56.920)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][30/80]	Time 0.004 (0.011)	Data 0.002 (0.009)	Loss 0.7033 (0.7937)	Prec@1 40.625 (56.099)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][40/80]	Time 0.004 (0.010)	Data 0.002 (0.007)	Loss 0.7393 (0.7750)	Prec@1 56.250 (55.488)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][50/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6993 (0.7632)	Prec@1 45.312 (54.105)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6922 (0.7539)	Prec@1 62.500 (54.662)	
2022-01-19 14:48:08 - INFO - TRAINING - Epoch: [25][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7342 (0.7395)	Prec@1 57.812 (56.228)	
2022-01-19 14:48:08 - INFO - EVALUATING - Epoch: [25][0/20]	Time 0.192 (0.192)	Data 0.190 (0.190)	Loss 0.7021 (0.7021)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:08 - INFO - EVALUATING - Epoch: [25][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6851 (0.6967)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:08 - INFO - 
 Epoch: 26	Training Loss 0.7347 	Training Prec@1 55.729 	Validation Loss 0.6944 	Validation Prec@1 49.921 	
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][0/80]	Time 0.245 (0.245)	Data 0.241 (0.241)	Loss 0.7021 (0.7021)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][10/80]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.6860 (0.8196)	Prec@1 57.812 (50.852)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][20/80]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.9426 (0.8089)	Prec@1 60.938 (52.902)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][30/80]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.7031 (0.7715)	Prec@1 40.625 (52.369)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][40/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6953 (0.7524)	Prec@1 48.438 (52.134)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][50/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6927 (0.7409)	Prec@1 51.562 (51.654)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6901 (0.7368)	Prec@1 54.688 (52.510)	
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [26][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6547 (0.7302)	Prec@1 65.625 (52.861)	
2022-01-19 14:48:09 - INFO - EVALUATING - Epoch: [26][0/20]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.7006 (0.7006)	Prec@1 62.500 (62.500)	
2022-01-19 14:48:09 - INFO - EVALUATING - Epoch: [26][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6120 (0.7179)	Prec@1 70.312 (60.369)	
2022-01-19 14:48:09 - INFO - 
 Epoch: 27	Training Loss 0.7255 	Training Prec@1 53.993 	Validation Loss 0.7117 	Validation Prec@1 60.726 	
2022-01-19 14:48:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:09 - INFO - TRAINING - Epoch: [27][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.7254 (0.7254)	Prec@1 59.375 (59.375)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7725 (0.9582)	Prec@1 54.688 (51.136)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6928 (0.8319)	Prec@1 51.562 (54.464)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7130 (0.8355)	Prec@1 59.375 (55.645)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.2570 (0.8410)	Prec@1 50.000 (55.335)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][50/80]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.6860 (0.8491)	Prec@1 57.812 (55.944)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6930 (0.8234)	Prec@1 51.562 (55.302)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [27][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8632 (0.8182)	Prec@1 64.062 (55.194)	
2022-01-19 14:48:10 - INFO - EVALUATING - Epoch: [27][0/20]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.6499 (0.6499)	Prec@1 65.625 (65.625)	
2022-01-19 14:48:10 - INFO - EVALUATING - Epoch: [27][10/20]	Time 0.003 (0.021)	Data 0.002 (0.019)	Loss 0.6702 (0.6867)	Prec@1 62.500 (61.932)	
2022-01-19 14:48:10 - INFO - 
 Epoch: 28	Training Loss 0.8114 	Training Prec@1 55.512 	Validation Loss 0.7104 	Validation Prec@1 59.385 	
2022-01-19 14:48:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [28][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.6764 (0.6764)	Prec@1 62.500 (62.500)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [28][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6843 (0.7603)	Prec@1 62.500 (53.977)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [28][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6940 (0.7433)	Prec@1 50.000 (57.366)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [28][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.0350 (0.7471)	Prec@1 53.125 (55.192)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [28][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9131 (0.7461)	Prec@1 60.938 (55.183)	
2022-01-19 14:48:10 - INFO - TRAINING - Epoch: [28][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6856 (0.7587)	Prec@1 60.938 (55.178)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6938 (0.7483)	Prec@1 50.000 (54.098)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [28][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6927 (0.7408)	Prec@1 51.562 (53.191)	
2022-01-19 14:48:11 - INFO - EVALUATING - Epoch: [28][0/20]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 0.8540 (0.8540)	Prec@1 64.062 (64.062)	
2022-01-19 14:48:11 - INFO - EVALUATING - Epoch: [28][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7560 (0.9810)	Prec@1 68.750 (57.670)	
2022-01-19 14:48:11 - INFO - 
 Epoch: 29	Training Loss 0.7490 	Training Prec@1 53.461 	Validation Loss 0.9618 	Validation Prec@1 58.596 	
2022-01-19 14:48:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [29][0/80]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.8818 (0.8818)	Prec@1 62.500 (62.500)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [29][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.6977 (0.8169)	Prec@1 39.062 (47.727)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [29][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6934 (0.8110)	Prec@1 50.000 (52.381)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [29][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6965 (0.7729)	Prec@1 45.312 (51.915)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [29][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6974 (0.7581)	Prec@1 45.312 (53.316)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [29][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7013 (0.7617)	Prec@1 40.625 (53.585)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [29][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6939 (0.7704)	Prec@1 50.000 (53.945)	
2022-01-19 14:48:11 - INFO - TRAINING - Epoch: [29][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.9823 (0.7685)	Prec@1 57.812 (54.159)	
2022-01-19 14:48:12 - INFO - EVALUATING - Epoch: [29][0/20]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 0.6998 (0.6998)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:12 - INFO - EVALUATING - Epoch: [29][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6867 (0.6957)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:12 - INFO - 
 Epoch: 30	Training Loss 0.7651 	Training Prec@1 53.993 	Validation Loss 0.6939 	Validation Prec@1 49.921 	
2022-01-19 14:48:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [30][0/80]	Time 0.198 (0.198)	Data 0.195 (0.195)	Loss 0.6927 (0.6927)	Prec@1 51.562 (51.562)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [30][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.6941 (0.7408)	Prec@1 48.438 (52.273)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [30][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6917 (0.7180)	Prec@1 54.688 (51.488)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [30][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6943 (0.7098)	Prec@1 46.875 (51.815)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [30][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6938 (0.7058)	Prec@1 48.438 (51.410)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [30][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6966 (0.7032)	Prec@1 40.625 (51.379)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [30][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8530 (0.7301)	Prec@1 46.875 (51.742)	
2022-01-19 14:48:12 - INFO - TRAINING - Epoch: [30][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6947 (0.7469)	Prec@1 45.312 (51.122)	
2022-01-19 14:48:12 - INFO - EVALUATING - Epoch: [30][0/20]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.5888 (0.5888)	Prec@1 70.312 (70.312)	
2022-01-19 14:48:12 - INFO - EVALUATING - Epoch: [30][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.4993 (0.7716)	Prec@1 76.562 (62.500)	
2022-01-19 14:48:13 - INFO - 
 Epoch: 31	Training Loss 0.7552 	Training Prec@1 51.075 	Validation Loss 0.8003 	Validation Prec@1 61.593 	
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [31][0/80]	Time 0.194 (0.194)	Data 0.191 (0.191)	Loss 0.8871 (0.8871)	Prec@1 56.250 (56.250)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [31][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.6226 (0.7594)	Prec@1 68.750 (55.540)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [31][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.9970 (0.7615)	Prec@1 56.250 (55.134)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [31][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6972 (0.7463)	Prec@1 43.750 (55.292)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [31][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6953 (0.7686)	Prec@1 45.312 (54.688)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [31][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6913 (0.7881)	Prec@1 54.688 (54.228)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [31][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7643 (0.7708)	Prec@1 54.688 (55.635)	
2022-01-19 14:48:13 - INFO - TRAINING - Epoch: [31][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8699 (0.7644)	Prec@1 68.750 (55.458)	
2022-01-19 14:48:13 - INFO - EVALUATING - Epoch: [31][0/20]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.6465 (0.6465)	Prec@1 67.188 (67.188)	
2022-01-19 14:48:13 - INFO - EVALUATING - Epoch: [31][10/20]	Time 0.003 (0.021)	Data 0.002 (0.019)	Loss 0.5445 (0.7092)	Prec@1 76.562 (60.795)	
2022-01-19 14:48:13 - INFO - 
 Epoch: 32	Training Loss 0.7627 	Training Prec@1 56.222 	Validation Loss 0.7032 	Validation Prec@1 61.199 	
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [32][0/80]	Time 0.195 (0.195)	Data 0.191 (0.191)	Loss 0.6790 (0.6790)	Prec@1 64.062 (64.062)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [32][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.6916 (0.7659)	Prec@1 53.125 (52.699)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [32][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6916 (0.7315)	Prec@1 53.125 (51.488)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [32][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6880 (0.7192)	Prec@1 59.375 (51.058)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [32][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6919 (0.7131)	Prec@1 53.125 (50.648)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [32][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6927 (0.7089)	Prec@1 51.562 (51.072)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [32][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8426 (0.7090)	Prec@1 57.812 (51.639)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [32][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7292 (0.7198)	Prec@1 59.375 (52.179)	
2022-01-19 14:48:14 - INFO - EVALUATING - Epoch: [32][0/20]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.6966 (0.6966)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:14 - INFO - EVALUATING - Epoch: [32][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6894 (0.6944)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:14 - INFO - 
 Epoch: 33	Training Loss 0.7201 	Training Prec@1 52.613 	Validation Loss 0.6934 	Validation Prec@1 49.921 	
2022-01-19 14:48:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:14 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [33][0/80]	Time 0.242 (0.242)	Data 0.238 (0.238)	Loss 0.6901 (0.6901)	Prec@1 57.812 (57.812)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [33][10/80]	Time 0.004 (0.026)	Data 0.002 (0.023)	Loss 0.8105 (0.9389)	Prec@1 65.625 (53.693)	
2022-01-19 14:48:14 - INFO - TRAINING - Epoch: [33][20/80]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.7258 (0.8479)	Prec@1 59.375 (58.185)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [33][30/80]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.6947 (0.7989)	Prec@1 46.875 (55.897)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [33][40/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6706 (0.7716)	Prec@1 64.062 (57.241)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [33][50/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6945 (0.7535)	Prec@1 46.875 (57.230)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [33][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6576 (0.7437)	Prec@1 65.625 (56.583)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [33][70/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6933 (0.7414)	Prec@1 50.000 (57.130)	
2022-01-19 14:48:15 - INFO - EVALUATING - Epoch: [33][0/20]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.6967 (0.6967)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:15 - INFO - EVALUATING - Epoch: [33][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6894 (0.6944)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:15 - INFO - 
 Epoch: 34	Training Loss 0.7422 	Training Prec@1 57.010 	Validation Loss 0.6934 	Validation Prec@1 49.921 	
2022-01-19 14:48:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:15 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [34][0/80]	Time 0.245 (0.245)	Data 0.242 (0.242)	Loss 0.6907 (0.6907)	Prec@1 56.250 (56.250)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [34][10/80]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 1.0300 (0.9284)	Prec@1 54.688 (53.125)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [34][20/80]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.6948 (0.8876)	Prec@1 46.875 (55.060)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [34][30/80]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.7650 (0.8274)	Prec@1 62.500 (55.746)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [34][40/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7074 (0.7971)	Prec@1 60.938 (58.117)	
2022-01-19 14:48:15 - INFO - TRAINING - Epoch: [34][50/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6663 (0.7757)	Prec@1 64.062 (57.690)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [34][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6911 (0.7653)	Prec@1 54.688 (57.684)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [34][70/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6308 (0.7545)	Prec@1 68.750 (57.042)	
2022-01-19 14:48:16 - INFO - EVALUATING - Epoch: [34][0/20]	Time 0.239 (0.239)	Data 0.237 (0.237)	Loss 0.6960 (0.6960)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:16 - INFO - EVALUATING - Epoch: [34][10/20]	Time 0.003 (0.025)	Data 0.002 (0.023)	Loss 0.6901 (0.6941)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:16 - INFO - 
 Epoch: 35	Training Loss 0.7506 	Training Prec@1 57.208 	Validation Loss 0.6933 	Validation Prec@1 49.921 	
2022-01-19 14:48:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [35][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.6944 (0.6944)	Prec@1 46.875 (46.875)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [35][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6718 (0.8118)	Prec@1 64.062 (58.381)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [35][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6938 (0.7625)	Prec@1 45.312 (55.060)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [35][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7036 (0.7436)	Prec@1 60.938 (56.956)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [35][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6932 (0.7313)	Prec@1 50.000 (55.221)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [35][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6922 (0.7238)	Prec@1 62.500 (54.350)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [35][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6569 (0.7204)	Prec@1 65.625 (53.868)	
2022-01-19 14:48:16 - INFO - TRAINING - Epoch: [35][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6931 (0.7162)	Prec@1 50.000 (54.886)	
2022-01-19 14:48:17 - INFO - EVALUATING - Epoch: [35][0/20]	Time 0.203 (0.203)	Data 0.201 (0.201)	Loss 0.7677 (0.7677)	Prec@1 54.688 (54.688)	
2022-01-19 14:48:17 - INFO - EVALUATING - Epoch: [35][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5946 (0.7175)	Prec@1 71.875 (59.659)	
2022-01-19 14:48:17 - INFO - 
 Epoch: 36	Training Loss 0.7150 	Training Prec@1 54.565 	Validation Loss 0.7137 	Validation Prec@1 60.016 	
2022-01-19 14:48:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [36][0/80]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.6889 (0.6889)	Prec@1 62.500 (62.500)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [36][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.8795 (0.9866)	Prec@1 62.500 (51.989)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [36][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6924 (0.9048)	Prec@1 59.375 (52.381)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [36][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7820 (0.8738)	Prec@1 67.188 (54.183)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [36][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6968 (0.8301)	Prec@1 39.062 (52.134)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [36][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6954 (0.8286)	Prec@1 45.312 (52.359)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [36][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6920 (0.8065)	Prec@1 53.125 (51.819)	
2022-01-19 14:48:17 - INFO - TRAINING - Epoch: [36][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6941 (0.7907)	Prec@1 48.438 (51.430)	
2022-01-19 14:48:18 - INFO - EVALUATING - Epoch: [36][0/20]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.6902 (0.6902)	Prec@1 57.812 (57.812)	
2022-01-19 14:48:18 - INFO - EVALUATING - Epoch: [36][10/20]	Time 0.003 (0.021)	Data 0.002 (0.019)	Loss 0.6972 (0.6924)	Prec@1 40.625 (52.415)	
2022-01-19 14:48:18 - INFO - 
 Epoch: 37	Training Loss 0.7805 	Training Prec@1 51.331 	Validation Loss 0.6933 	Validation Prec@1 50.079 	
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [37][0/80]	Time 0.206 (0.206)	Data 0.203 (0.203)	Loss 0.6959 (0.6959)	Prec@1 43.750 (43.750)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [37][10/80]	Time 0.005 (0.023)	Data 0.002 (0.020)	Loss 0.6934 (0.7995)	Prec@1 50.000 (50.000)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [37][20/80]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.9520 (0.7933)	Prec@1 43.750 (50.967)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [37][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.9813 (0.8549)	Prec@1 57.812 (52.268)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [37][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7177 (0.8177)	Prec@1 59.375 (52.172)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [37][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6029 (0.7875)	Prec@1 70.312 (54.626)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [37][60/80]	Time 0.006 (0.008)	Data 0.003 (0.005)	Loss 0.6970 (0.7736)	Prec@1 43.750 (54.150)	
2022-01-19 14:48:18 - INFO - TRAINING - Epoch: [37][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6437 (0.7605)	Prec@1 67.188 (54.621)	
2022-01-19 14:48:18 - INFO - EVALUATING - Epoch: [37][0/20]	Time 0.192 (0.192)	Data 0.190 (0.190)	Loss 1.2720 (1.2720)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:18 - INFO - EVALUATING - Epoch: [37][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.9324 (1.1654)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:18 - INFO - 
 Epoch: 38	Training Loss 0.7524 	Training Prec@1 55.196 	Validation Loss 1.1192 	Validation Prec@1 49.921 	
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [38][0/80]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 1.0868 (1.0868)	Prec@1 51.562 (51.562)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [38][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.6929 (0.8075)	Prec@1 51.562 (51.847)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [38][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7027 (0.7576)	Prec@1 60.938 (53.125)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [38][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7675 (0.7389)	Prec@1 54.688 (52.873)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [38][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6918 (0.7265)	Prec@1 60.938 (54.802)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [38][50/80]	Time 0.005 (0.008)	Data 0.003 (0.006)	Loss 0.6407 (0.7179)	Prec@1 67.188 (55.086)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [38][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6925 (0.7137)	Prec@1 56.250 (55.225)	
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [38][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5943 (0.7133)	Prec@1 54.688 (54.974)	
2022-01-19 14:48:19 - INFO - EVALUATING - Epoch: [38][0/20]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.6919 (0.6919)	Prec@1 57.812 (57.812)	
2022-01-19 14:48:19 - INFO - EVALUATING - Epoch: [38][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6947 (0.6928)	Prec@1 40.625 (52.415)	
2022-01-19 14:48:19 - INFO - 
 Epoch: 39	Training Loss 0.7158 	Training Prec@1 55.176 	Validation Loss 0.6932 	Validation Prec@1 50.079 	
2022-01-19 14:48:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:19 - INFO - TRAINING - Epoch: [39][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.6945 (0.6945)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [39][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6700 (0.8828)	Prec@1 64.062 (55.682)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [39][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5821 (0.7718)	Prec@1 73.438 (60.789)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [39][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6933 (0.7435)	Prec@1 50.000 (58.569)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [39][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8035 (0.7525)	Prec@1 59.375 (57.050)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [39][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5876 (0.7482)	Prec@1 62.500 (56.801)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [39][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7895 (0.7412)	Prec@1 54.688 (56.737)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [39][70/80]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.6944 (0.7338)	Prec@1 46.875 (56.162)	
2022-01-19 14:48:20 - INFO - EVALUATING - Epoch: [39][0/20]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 1.2709 (1.2709)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:20 - INFO - EVALUATING - Epoch: [39][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.9318 (1.1644)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:20 - INFO - 
 Epoch: 40	Training Loss 0.7410 	Training Prec@1 55.748 	Validation Loss 1.1183 	Validation Prec@1 49.921 	
2022-01-19 14:48:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:20 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [40][0/80]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.9626 (0.9626)	Prec@1 57.812 (57.812)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [40][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.6921 (0.7931)	Prec@1 53.125 (55.540)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [40][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6445 (0.8036)	Prec@1 67.188 (56.473)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [40][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6118 (0.7658)	Prec@1 70.312 (55.696)	
2022-01-19 14:48:20 - INFO - TRAINING - Epoch: [40][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6948 (0.7667)	Prec@1 45.312 (56.250)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [40][50/80]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.6940 (0.7525)	Prec@1 46.875 (54.442)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [40][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6415 (0.7419)	Prec@1 67.188 (54.226)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [40][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6932 (0.7588)	Prec@1 50.000 (54.467)	
2022-01-19 14:48:21 - INFO - EVALUATING - Epoch: [40][0/20]	Time 0.234 (0.234)	Data 0.232 (0.232)	Loss 0.8131 (0.8131)	Prec@1 65.625 (65.625)	
2022-01-19 14:48:21 - INFO - EVALUATING - Epoch: [40][10/20]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.6276 (0.8304)	Prec@1 75.000 (64.773)	
2022-01-19 14:48:21 - INFO - 
 Epoch: 41	Training Loss 0.7528 	Training Prec@1 54.329 	Validation Loss 0.8772 	Validation Prec@1 62.461 	
2022-01-19 14:48:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:21 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [41][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.8786 (0.8786)	Prec@1 62.500 (62.500)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [41][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6862 (0.8200)	Prec@1 62.500 (54.972)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [41][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.8045 (0.7755)	Prec@1 51.562 (52.083)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [41][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.0218 (0.7892)	Prec@1 57.812 (54.284)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [41][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7099 (0.7857)	Prec@1 65.625 (55.335)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [41][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6923 (0.7701)	Prec@1 60.938 (55.484)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [41][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8223 (0.7737)	Prec@1 57.812 (55.994)	
2022-01-19 14:48:21 - INFO - TRAINING - Epoch: [41][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5954 (0.7669)	Prec@1 71.875 (56.338)	
2022-01-19 14:48:22 - INFO - EVALUATING - Epoch: [41][0/20]	Time 0.201 (0.201)	Data 0.200 (0.200)	Loss 0.8259 (0.8259)	Prec@1 59.375 (59.375)	
2022-01-19 14:48:22 - INFO - EVALUATING - Epoch: [41][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.8474 (0.7864)	Prec@1 70.312 (64.773)	
2022-01-19 14:48:22 - INFO - 
 Epoch: 42	Training Loss 0.7683 	Training Prec@1 56.340 	Validation Loss 0.8484 	Validation Prec@1 61.199 	
2022-01-19 14:48:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:22 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [42][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.7898 (0.7898)	Prec@1 68.750 (68.750)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [42][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.5905 (0.8914)	Prec@1 71.875 (59.375)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [42][20/80]	Time 0.005 (0.014)	Data 0.002 (0.011)	Loss 0.7186 (0.8508)	Prec@1 59.375 (56.920)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [42][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.9935 (0.8089)	Prec@1 53.125 (56.401)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [42][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8167 (0.7928)	Prec@1 50.000 (56.059)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [42][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.0303 (0.7912)	Prec@1 28.125 (56.066)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [42][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.7544 (0.7756)	Prec@1 56.250 (57.864)	
2022-01-19 14:48:22 - INFO - TRAINING - Epoch: [42][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6147 (0.7892)	Prec@1 70.312 (57.482)	
2022-01-19 14:48:23 - INFO - EVALUATING - Epoch: [42][0/20]	Time 0.194 (0.194)	Data 0.193 (0.193)	Loss 0.6984 (0.6984)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:23 - INFO - EVALUATING - Epoch: [42][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6879 (0.6951)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:23 - INFO - 
 Epoch: 43	Training Loss 0.7780 	Training Prec@1 57.503 	Validation Loss 0.6937 	Validation Prec@1 49.921 	
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [43][0/80]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.6898 (0.6898)	Prec@1 56.250 (56.250)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [43][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 1.1020 (0.9762)	Prec@1 57.812 (60.653)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [43][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6509 (0.9726)	Prec@1 65.625 (55.952)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [43][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6067 (0.9070)	Prec@1 70.312 (57.308)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [43][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6966 (0.8519)	Prec@1 42.188 (58.232)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [43][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7128 (0.8200)	Prec@1 59.375 (57.874)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [43][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6945 (0.7962)	Prec@1 48.438 (58.607)	
2022-01-19 14:48:23 - INFO - TRAINING - Epoch: [43][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7377 (0.7826)	Prec@1 57.812 (57.592)	
2022-01-19 14:48:23 - INFO - EVALUATING - Epoch: [43][0/20]	Time 0.192 (0.192)	Data 0.190 (0.190)	Loss 0.6981 (0.6981)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:23 - INFO - EVALUATING - Epoch: [43][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6882 (0.6950)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:23 - INFO - 
 Epoch: 44	Training Loss 0.7737 	Training Prec@1 57.780 	Validation Loss 0.6936 	Validation Prec@1 49.921 	
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:23 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [44][0/80]	Time 0.206 (0.206)	Data 0.202 (0.202)	Loss 0.6936 (0.6936)	Prec@1 50.000 (50.000)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [44][10/80]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.6948 (0.8694)	Prec@1 46.875 (49.574)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [44][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7029 (0.8335)	Prec@1 60.938 (54.167)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [44][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6406 (0.7731)	Prec@1 67.188 (58.216)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [44][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6932 (0.7703)	Prec@1 50.000 (57.660)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [44][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5946 (0.7515)	Prec@1 71.875 (58.395)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [44][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6932 (0.7416)	Prec@1 48.438 (58.299)	
2022-01-19 14:48:24 - INFO - TRAINING - Epoch: [44][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6929 (0.7461)	Prec@1 53.125 (57.592)	
2022-01-19 14:48:24 - INFO - EVALUATING - Epoch: [44][0/20]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.7343 (0.7343)	Prec@1 57.812 (57.812)	
2022-01-19 14:48:24 - INFO - EVALUATING - Epoch: [44][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.9053 (0.7880)	Prec@1 40.625 (52.415)	
2022-01-19 14:48:24 - INFO - 
 Epoch: 45	Training Loss 0.7512 	Training Prec@1 57.365 	Validation Loss 0.8113 	Validation Prec@1 50.079 	
2022-01-19 14:48:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [45][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.7810 (0.7810)	Prec@1 53.125 (53.125)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [45][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6930 (0.9125)	Prec@1 54.688 (55.256)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [45][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7047 (0.8431)	Prec@1 60.938 (55.134)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [45][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.5945 (0.8125)	Prec@1 71.875 (56.048)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [45][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8444 (0.7875)	Prec@1 64.062 (55.793)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [45][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6934 (0.7941)	Prec@1 46.875 (55.729)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [45][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6934 (0.7775)	Prec@1 40.625 (55.149)	
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [45][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6929 (0.7786)	Prec@1 53.125 (55.524)	
2022-01-19 14:48:25 - INFO - EVALUATING - Epoch: [45][0/20]	Time 0.245 (0.245)	Data 0.242 (0.242)	Loss 0.6940 (0.6940)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:25 - INFO - EVALUATING - Epoch: [45][10/20]	Time 0.003 (0.025)	Data 0.002 (0.024)	Loss 0.6922 (0.6934)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:25 - INFO - 
 Epoch: 46	Training Loss 0.7789 	Training Prec@1 56.360 	Validation Loss 0.6932 	Validation Prec@1 49.921 	
2022-01-19 14:48:25 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:25 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:25 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:25 - INFO - TRAINING - Epoch: [46][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.6924 (0.6924)	Prec@1 57.812 (57.812)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [46][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.4410 (0.9724)	Prec@1 34.375 (54.119)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [46][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6577 (0.8288)	Prec@1 65.625 (57.515)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [46][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6933 (0.7810)	Prec@1 48.438 (57.863)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [46][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.0037 (0.7732)	Prec@1 56.250 (56.631)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [46][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.2401 (0.8087)	Prec@1 67.188 (56.679)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [46][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8296 (0.8042)	Prec@1 48.438 (56.301)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [46][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7037 (0.7973)	Prec@1 60.938 (56.602)	
2022-01-19 14:48:26 - INFO - EVALUATING - Epoch: [46][0/20]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.6939 (0.6939)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:26 - INFO - EVALUATING - Epoch: [46][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6923 (0.6934)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:26 - INFO - 
 Epoch: 47	Training Loss 0.7986 	Training Prec@1 56.675 	Validation Loss 0.6932 	Validation Prec@1 49.921 	
2022-01-19 14:48:26 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:26 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:26 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:26 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [47][0/80]	Time 0.195 (0.195)	Data 0.191 (0.191)	Loss 0.6932 (0.6932)	Prec@1 50.000 (50.000)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [47][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 1.0984 (1.0475)	Prec@1 51.562 (58.949)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [47][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6946 (0.9301)	Prec@1 32.812 (57.068)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [47][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6938 (0.8723)	Prec@1 42.188 (55.746)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [47][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9559 (0.8608)	Prec@1 48.438 (54.878)	
2022-01-19 14:48:26 - INFO - TRAINING - Epoch: [47][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.0612 (0.8715)	Prec@1 40.625 (54.994)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [47][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.1842 (0.8624)	Prec@1 46.875 (55.200)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [47][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6594 (0.8516)	Prec@1 65.625 (55.678)	
2022-01-19 14:48:27 - INFO - EVALUATING - Epoch: [47][0/20]	Time 0.205 (0.205)	Data 0.203 (0.203)	Loss 0.7822 (0.7822)	Prec@1 67.188 (67.188)	
2022-01-19 14:48:27 - INFO - EVALUATING - Epoch: [47][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6269 (0.8479)	Prec@1 75.000 (63.920)	
2022-01-19 14:48:27 - INFO - 
 Epoch: 48	Training Loss 0.8358 	Training Prec@1 56.340 	Validation Loss 0.8836 	Validation Prec@1 62.145 	
2022-01-19 14:48:27 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:27 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:27 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [48][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.7832 (0.7832)	Prec@1 67.188 (67.188)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [48][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7036 (0.7998)	Prec@1 60.938 (57.955)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [48][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6571 (0.7760)	Prec@1 65.625 (57.887)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [48][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6400 (0.7759)	Prec@1 67.188 (58.669)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [48][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9760 (0.7701)	Prec@1 57.812 (59.947)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [48][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6253 (0.7512)	Prec@1 68.750 (60.202)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [48][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6903 (0.7416)	Prec@1 62.500 (60.067)	
2022-01-19 14:48:27 - INFO - TRAINING - Epoch: [48][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7482 (0.7306)	Prec@1 56.250 (59.705)	
2022-01-19 14:48:28 - INFO - EVALUATING - Epoch: [48][0/20]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.6971 (0.6971)	Prec@1 42.188 (42.188)	
2022-01-19 14:48:28 - INFO - EVALUATING - Epoch: [48][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6890 (0.6946)	Prec@1 59.375 (47.585)	
2022-01-19 14:48:28 - INFO - 
 Epoch: 49	Training Loss 0.7279 	Training Prec@1 59.692 	Validation Loss 0.6935 	Validation Prec@1 49.921 	
2022-01-19 14:48:28 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:48:28 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:48:28 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:48:28 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [49][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.6875 (0.6875)	Prec@1 62.500 (62.500)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [49][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7023 (1.0614)	Prec@1 60.938 (53.977)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [49][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6235 (0.8601)	Prec@1 68.750 (60.268)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [49][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6631 (0.8019)	Prec@1 64.062 (58.871)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [49][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6935 (0.8375)	Prec@1 50.000 (58.803)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [49][50/80]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.6809 (0.8064)	Prec@1 62.500 (59.191)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [49][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6782 (0.7986)	Prec@1 62.500 (59.375)	
2022-01-19 14:48:28 - INFO - TRAINING - Epoch: [49][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6869 (0.7834)	Prec@1 59.375 (58.781)	
2022-01-19 14:48:28 - INFO - EVALUATING - Epoch: [49][0/20]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.7016 (0.7016)	Prec@1 60.938 (60.938)	
2022-01-19 14:48:28 - INFO - EVALUATING - Epoch: [49][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6889 (0.6677)	Prec@1 60.938 (64.062)	
2022-01-19 14:48:29 - INFO - 
 Epoch: 50	Training Loss 0.7881 	Training Prec@1 58.746 	Validation Loss 0.6988 	Validation Prec@1 60.804 	
