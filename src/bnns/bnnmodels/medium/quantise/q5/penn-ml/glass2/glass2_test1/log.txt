2022-01-19 14:53:13 - INFO - saving to ./results/medium/quantise/q5/penn-ml/glass2/glass2_test1/
2022-01-19 14:53:13 - DEBUG - run arguments: Namespace(config='./configs/config_medium.json', data='../../paper_bench/complete/quantise/q5/penn-ml/glass2/glass2_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/medium/quantise/q5/penn-ml/glass2/glass2_test1/', test='../../paper_bench/cv/test/quantise/q5/penn-ml/glass2/glass2_test1_data.csv', train='../../paper_bench/cv/train/quantise/q5/penn-ml/glass2/glass2_train1_data.csv')
2022-01-19 14:53:13 - INFO - creating model mlp_binary
2022-01-19 14:53:13 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [32, 16, 8, 2]}
2022-01-19 14:53:13 - INFO - number of parameters: 2170
2022-01-19 14:53:13 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-19 14:53:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:14 - INFO - TRAINING - Epoch: [0][0/3]	Time 0.198 (0.198)	Data 0.192 (0.192)	Loss 1.2488 (1.2488)	Prec@1 54.688 (54.688)	
2022-01-19 14:53:14 - INFO - EVALUATING - Epoch: [0][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 1.0591 (1.0591)	Prec@1 24.242 (24.242)	
2022-01-19 14:53:14 - INFO - 
 Epoch: 1	Training Loss 1.0508 	Training Prec@1 53.846 	Validation Loss 1.0591 	Validation Prec@1 24.242 	
2022-01-19 14:53:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:14 - INFO - TRAINING - Epoch: [1][0/3]	Time 0.203 (0.203)	Data 0.200 (0.200)	Loss 0.8260 (0.8260)	Prec@1 51.562 (51.562)	
2022-01-19 14:53:14 - INFO - EVALUATING - Epoch: [1][0/1]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.5915 (0.5915)	Prec@1 75.758 (75.758)	
2022-01-19 14:53:14 - INFO - 
 Epoch: 2	Training Loss 0.7167 	Training Prec@1 59.231 	Validation Loss 0.5915 	Validation Prec@1 75.758 	
2022-01-19 14:53:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:15 - INFO - TRAINING - Epoch: [2][0/3]	Time 0.246 (0.246)	Data 0.242 (0.242)	Loss 0.9112 (0.9112)	Prec@1 68.750 (68.750)	
2022-01-19 14:53:15 - INFO - EVALUATING - Epoch: [2][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.7210 (0.7210)	Prec@1 78.788 (78.788)	
2022-01-19 14:53:15 - INFO - 
 Epoch: 3	Training Loss 0.9881 	Training Prec@1 65.385 	Validation Loss 0.7210 	Validation Prec@1 78.788 	
2022-01-19 14:53:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:15 - INFO - TRAINING - Epoch: [3][0/3]	Time 0.198 (0.198)	Data 0.195 (0.195)	Loss 0.6265 (0.6265)	Prec@1 65.625 (65.625)	
2022-01-19 14:53:15 - INFO - EVALUATING - Epoch: [3][0/1]	Time 0.184 (0.184)	Data 0.182 (0.182)	Loss 0.6418 (0.6418)	Prec@1 75.758 (75.758)	
2022-01-19 14:53:15 - INFO - 
 Epoch: 4	Training Loss 0.8120 	Training Prec@1 67.692 	Validation Loss 0.6418 	Validation Prec@1 75.758 	
2022-01-19 14:53:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:15 - INFO - TRAINING - Epoch: [4][0/3]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.6118 (0.6118)	Prec@1 78.125 (78.125)	
2022-01-19 14:53:16 - INFO - EVALUATING - Epoch: [4][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 1.4887 (1.4887)	Prec@1 66.667 (66.667)	
2022-01-19 14:53:16 - INFO - 
 Epoch: 5	Training Loss 0.6605 	Training Prec@1 75.385 	Validation Loss 1.4887 	Validation Prec@1 66.667 	
2022-01-19 14:53:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:16 - INFO - TRAINING - Epoch: [5][0/3]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.9085 (0.9085)	Prec@1 73.438 (73.438)	
2022-01-19 14:53:16 - INFO - EVALUATING - Epoch: [5][0/1]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 0.6718 (0.6718)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:16 - INFO - 
 Epoch: 6	Training Loss 0.7129 	Training Prec@1 73.077 	Validation Loss 0.6718 	Validation Prec@1 69.697 	
2022-01-19 14:53:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:16 - INFO - TRAINING - Epoch: [6][0/3]	Time 0.207 (0.207)	Data 0.204 (0.204)	Loss 0.7040 (0.7040)	Prec@1 42.188 (42.188)	
2022-01-19 14:53:16 - INFO - EVALUATING - Epoch: [6][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.5544 (0.5544)	Prec@1 81.818 (81.818)	
2022-01-19 14:53:16 - INFO - 
 Epoch: 7	Training Loss 0.6667 	Training Prec@1 58.462 	Validation Loss 0.5544 	Validation Prec@1 81.818 	
2022-01-19 14:53:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:17 - INFO - TRAINING - Epoch: [7][0/3]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 1.0732 (1.0732)	Prec@1 71.875 (71.875)	
2022-01-19 14:53:17 - INFO - EVALUATING - Epoch: [7][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 1.4827 (1.4827)	Prec@1 30.303 (30.303)	
2022-01-19 14:53:17 - INFO - 
 Epoch: 8	Training Loss 0.8890 	Training Prec@1 74.615 	Validation Loss 1.4827 	Validation Prec@1 30.303 	
2022-01-19 14:53:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:17 - INFO - TRAINING - Epoch: [8][0/3]	Time 0.219 (0.219)	Data 0.215 (0.215)	Loss 1.7676 (1.7676)	Prec@1 18.750 (18.750)	
2022-01-19 14:53:17 - INFO - EVALUATING - Epoch: [8][0/1]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 1.9003 (1.9003)	Prec@1 54.545 (54.545)	
2022-01-19 14:53:17 - INFO - 
 Epoch: 9	Training Loss 1.2236 	Training Prec@1 46.923 	Validation Loss 1.9003 	Validation Prec@1 54.545 	
2022-01-19 14:53:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:18 - INFO - TRAINING - Epoch: [9][0/3]	Time 0.203 (0.203)	Data 0.200 (0.200)	Loss 1.1129 (1.1129)	Prec@1 78.125 (78.125)	
2022-01-19 14:53:18 - INFO - EVALUATING - Epoch: [9][0/1]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 0.6682 (0.6682)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:18 - INFO - 
 Epoch: 10	Training Loss 0.7819 	Training Prec@1 80.769 	Validation Loss 0.6682 	Validation Prec@1 69.697 	
2022-01-19 14:53:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:18 - INFO - TRAINING - Epoch: [10][0/3]	Time 0.246 (0.246)	Data 0.242 (0.242)	Loss 0.6977 (0.6977)	Prec@1 48.438 (48.438)	
2022-01-19 14:53:18 - INFO - EVALUATING - Epoch: [10][0/1]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 1.0152 (1.0152)	Prec@1 72.727 (72.727)	
2022-01-19 14:53:18 - INFO - 
 Epoch: 11	Training Loss 0.9297 	Training Prec@1 50.000 	Validation Loss 1.0152 	Validation Prec@1 72.727 	
2022-01-19 14:53:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:18 - INFO - TRAINING - Epoch: [11][0/3]	Time 0.202 (0.202)	Data 0.190 (0.190)	Loss 0.5752 (0.5752)	Prec@1 73.438 (73.438)	
2022-01-19 14:53:19 - INFO - EVALUATING - Epoch: [11][0/1]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 1.8023 (1.8023)	Prec@1 60.606 (60.606)	
2022-01-19 14:53:19 - INFO - 
 Epoch: 12	Training Loss 0.5404 	Training Prec@1 76.923 	Validation Loss 1.8023 	Validation Prec@1 60.606 	
2022-01-19 14:53:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:19 - INFO - TRAINING - Epoch: [12][0/3]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.5390 (0.5390)	Prec@1 87.500 (87.500)	
2022-01-19 14:53:19 - INFO - EVALUATING - Epoch: [12][0/1]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 0.7335 (0.7335)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:19 - INFO - 
 Epoch: 13	Training Loss 0.6274 	Training Prec@1 64.615 	Validation Loss 0.7335 	Validation Prec@1 69.697 	
2022-01-19 14:53:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:19 - INFO - TRAINING - Epoch: [13][0/3]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.6275 (0.6275)	Prec@1 75.000 (75.000)	
2022-01-19 14:53:20 - INFO - EVALUATING - Epoch: [13][0/1]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 0.6835 (0.6835)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:20 - INFO - 
 Epoch: 14	Training Loss 0.9462 	Training Prec@1 68.462 	Validation Loss 0.6835 	Validation Prec@1 69.697 	
2022-01-19 14:53:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:20 - INFO - TRAINING - Epoch: [14][0/3]	Time 0.208 (0.208)	Data 0.204 (0.204)	Loss 0.6974 (0.6974)	Prec@1 42.188 (42.188)	
2022-01-19 14:53:20 - INFO - EVALUATING - Epoch: [14][0/1]	Time 0.199 (0.199)	Data 0.197 (0.197)	Loss 1.2166 (1.2166)	Prec@1 66.667 (66.667)	
2022-01-19 14:53:20 - INFO - 
 Epoch: 15	Training Loss 0.6714 	Training Prec@1 63.846 	Validation Loss 1.2166 	Validation Prec@1 66.667 	
2022-01-19 14:53:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:20 - INFO - TRAINING - Epoch: [15][0/3]	Time 0.206 (0.206)	Data 0.202 (0.202)	Loss 0.3476 (0.3476)	Prec@1 87.500 (87.500)	
2022-01-19 14:53:20 - INFO - EVALUATING - Epoch: [15][0/1]	Time 0.208 (0.208)	Data 0.206 (0.206)	Loss 0.5539 (0.5539)	Prec@1 78.788 (78.788)	
2022-01-19 14:53:20 - INFO - 
 Epoch: 16	Training Loss 0.4295 	Training Prec@1 83.077 	Validation Loss 0.5539 	Validation Prec@1 78.788 	
2022-01-19 14:53:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:21 - INFO - TRAINING - Epoch: [16][0/3]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.6616 (0.6616)	Prec@1 73.438 (73.438)	
2022-01-19 14:53:21 - INFO - EVALUATING - Epoch: [16][0/1]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 1.1848 (1.1848)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:21 - INFO - 
 Epoch: 17	Training Loss 0.6976 	Training Prec@1 61.538 	Validation Loss 1.1848 	Validation Prec@1 69.697 	
2022-01-19 14:53:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:21 - INFO - TRAINING - Epoch: [17][0/3]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.5764 (0.5764)	Prec@1 81.250 (81.250)	
2022-01-19 14:53:21 - INFO - EVALUATING - Epoch: [17][0/1]	Time 0.179 (0.179)	Data 0.178 (0.178)	Loss 1.1967 (1.1967)	Prec@1 45.455 (45.455)	
2022-01-19 14:53:21 - INFO - 
 Epoch: 18	Training Loss 0.6640 	Training Prec@1 61.538 	Validation Loss 1.1967 	Validation Prec@1 45.455 	
2022-01-19 14:53:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:22 - INFO - TRAINING - Epoch: [18][0/3]	Time 0.214 (0.214)	Data 0.210 (0.210)	Loss 0.9659 (0.9659)	Prec@1 57.812 (57.812)	
2022-01-19 14:53:22 - INFO - EVALUATING - Epoch: [18][0/1]	Time 0.208 (0.208)	Data 0.205 (0.205)	Loss 0.8286 (0.8286)	Prec@1 78.788 (78.788)	
2022-01-19 14:53:22 - INFO - 
 Epoch: 19	Training Loss 0.7587 	Training Prec@1 70.000 	Validation Loss 0.8286 	Validation Prec@1 78.788 	
2022-01-19 14:53:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:22 - INFO - TRAINING - Epoch: [19][0/3]	Time 0.202 (0.202)	Data 0.198 (0.198)	Loss 0.3017 (0.3017)	Prec@1 85.938 (85.938)	
2022-01-19 14:53:22 - INFO - EVALUATING - Epoch: [19][0/1]	Time 0.245 (0.245)	Data 0.243 (0.243)	Loss 0.8538 (0.8538)	Prec@1 63.636 (63.636)	
2022-01-19 14:53:22 - INFO - 
 Epoch: 20	Training Loss 0.3414 	Training Prec@1 86.154 	Validation Loss 0.8538 	Validation Prec@1 63.636 	
2022-01-19 14:53:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:22 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:23 - INFO - TRAINING - Epoch: [20][0/3]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.4395 (0.4395)	Prec@1 84.375 (84.375)	
2022-01-19 14:53:23 - INFO - EVALUATING - Epoch: [20][0/1]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.6725 (0.6725)	Prec@1 72.727 (72.727)	
2022-01-19 14:53:23 - INFO - 
 Epoch: 21	Training Loss 0.4502 	Training Prec@1 83.846 	Validation Loss 0.6725 	Validation Prec@1 72.727 	
2022-01-19 14:53:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:23 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:23 - INFO - TRAINING - Epoch: [21][0/3]	Time 0.209 (0.209)	Data 0.205 (0.205)	Loss 0.3770 (0.3770)	Prec@1 87.500 (87.500)	
2022-01-19 14:53:23 - INFO - EVALUATING - Epoch: [21][0/1]	Time 0.199 (0.199)	Data 0.197 (0.197)	Loss 0.8863 (0.8863)	Prec@1 75.758 (75.758)	
2022-01-19 14:53:23 - INFO - 
 Epoch: 22	Training Loss 0.4488 	Training Prec@1 83.846 	Validation Loss 0.8863 	Validation Prec@1 75.758 	
2022-01-19 14:53:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:23 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:24 - INFO - TRAINING - Epoch: [22][0/3]	Time 0.246 (0.246)	Data 0.242 (0.242)	Loss 0.3113 (0.3113)	Prec@1 87.500 (87.500)	
2022-01-19 14:53:24 - INFO - EVALUATING - Epoch: [22][0/1]	Time 0.208 (0.208)	Data 0.206 (0.206)	Loss 0.8680 (0.8680)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:24 - INFO - 
 Epoch: 23	Training Loss 0.2788 	Training Prec@1 88.462 	Validation Loss 0.8680 	Validation Prec@1 69.697 	
2022-01-19 14:53:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:24 - INFO - TRAINING - Epoch: [23][0/3]	Time 0.240 (0.240)	Data 0.236 (0.236)	Loss 0.1960 (0.1960)	Prec@1 90.625 (90.625)	
2022-01-19 14:53:24 - INFO - EVALUATING - Epoch: [23][0/1]	Time 0.130 (0.130)	Data 0.128 (0.128)	Loss 0.6163 (0.6163)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:24 - INFO - 
 Epoch: 24	Training Loss 0.3675 	Training Prec@1 85.385 	Validation Loss 0.6163 	Validation Prec@1 69.697 	
2022-01-19 14:53:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:24 - INFO - TRAINING - Epoch: [24][0/3]	Time 0.242 (0.242)	Data 0.238 (0.238)	Loss 0.5164 (0.5164)	Prec@1 79.688 (79.688)	
2022-01-19 14:53:25 - INFO - EVALUATING - Epoch: [24][0/1]	Time 0.188 (0.188)	Data 0.187 (0.187)	Loss 0.7874 (0.7874)	Prec@1 75.758 (75.758)	
2022-01-19 14:53:25 - INFO - 
 Epoch: 25	Training Loss 0.3310 	Training Prec@1 83.077 	Validation Loss 0.7874 	Validation Prec@1 75.758 	
2022-01-19 14:53:25 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:25 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:25 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:25 - INFO - TRAINING - Epoch: [25][0/3]	Time 0.200 (0.200)	Data 0.197 (0.197)	Loss 0.2063 (0.2063)	Prec@1 93.750 (93.750)	
2022-01-19 14:53:25 - INFO - EVALUATING - Epoch: [25][0/1]	Time 0.204 (0.204)	Data 0.203 (0.203)	Loss 0.8073 (0.8073)	Prec@1 72.727 (72.727)	
2022-01-19 14:53:25 - INFO - 
 Epoch: 26	Training Loss 0.1998 	Training Prec@1 93.077 	Validation Loss 0.8073 	Validation Prec@1 72.727 	
2022-01-19 14:53:25 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:25 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:25 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:25 - INFO - TRAINING - Epoch: [26][0/3]	Time 0.244 (0.244)	Data 0.239 (0.239)	Loss 0.2591 (0.2591)	Prec@1 89.062 (89.062)	
2022-01-19 14:53:26 - INFO - EVALUATING - Epoch: [26][0/1]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.7151 (0.7151)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:26 - INFO - 
 Epoch: 27	Training Loss 0.2695 	Training Prec@1 90.000 	Validation Loss 0.7151 	Validation Prec@1 69.697 	
2022-01-19 14:53:26 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:26 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:26 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:26 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:26 - INFO - TRAINING - Epoch: [27][0/3]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 0.2071 (0.2071)	Prec@1 93.750 (93.750)	
2022-01-19 14:53:26 - INFO - EVALUATING - Epoch: [27][0/1]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.7277 (0.7277)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:26 - INFO - 
 Epoch: 28	Training Loss 0.2639 	Training Prec@1 91.538 	Validation Loss 0.7277 	Validation Prec@1 69.697 	
2022-01-19 14:53:26 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:26 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:26 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:26 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:26 - INFO - TRAINING - Epoch: [28][0/3]	Time 0.247 (0.247)	Data 0.243 (0.243)	Loss 0.3133 (0.3133)	Prec@1 90.625 (90.625)	
2022-01-19 14:53:27 - INFO - EVALUATING - Epoch: [28][0/1]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.7208 (0.7208)	Prec@1 72.727 (72.727)	
2022-01-19 14:53:27 - INFO - 
 Epoch: 29	Training Loss 0.2917 	Training Prec@1 90.769 	Validation Loss 0.7208 	Validation Prec@1 72.727 	
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:27 - INFO - TRAINING - Epoch: [29][0/3]	Time 0.203 (0.203)	Data 0.198 (0.198)	Loss 0.3730 (0.3730)	Prec@1 85.938 (85.938)	
2022-01-19 14:53:27 - INFO - EVALUATING - Epoch: [29][0/1]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.7511 (0.7511)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:27 - INFO - 
 Epoch: 30	Training Loss 0.3265 	Training Prec@1 88.462 	Validation Loss 0.7511 	Validation Prec@1 69.697 	
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:27 - INFO - TRAINING - Epoch: [30][0/3]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.2707 (0.2707)	Prec@1 89.062 (89.062)	
2022-01-19 14:53:27 - INFO - EVALUATING - Epoch: [30][0/1]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.8333 (0.8333)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:27 - INFO - 
 Epoch: 31	Training Loss 0.3008 	Training Prec@1 87.692 	Validation Loss 0.8333 	Validation Prec@1 69.697 	
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:27 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:28 - INFO - TRAINING - Epoch: [31][0/3]	Time 0.248 (0.248)	Data 0.244 (0.244)	Loss 0.0970 (0.0970)	Prec@1 96.875 (96.875)	
2022-01-19 14:53:28 - INFO - EVALUATING - Epoch: [31][0/1]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.7668 (0.7668)	Prec@1 72.727 (72.727)	
2022-01-19 14:53:28 - INFO - 
 Epoch: 32	Training Loss 0.2601 	Training Prec@1 94.615 	Validation Loss 0.7668 	Validation Prec@1 72.727 	
2022-01-19 14:53:28 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:28 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:28 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:28 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:28 - INFO - TRAINING - Epoch: [32][0/3]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 0.2486 (0.2486)	Prec@1 93.750 (93.750)	
2022-01-19 14:53:28 - INFO - EVALUATING - Epoch: [32][0/1]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.8133 (0.8133)	Prec@1 75.758 (75.758)	
2022-01-19 14:53:28 - INFO - 
 Epoch: 33	Training Loss 0.2294 	Training Prec@1 92.308 	Validation Loss 0.8133 	Validation Prec@1 75.758 	
2022-01-19 14:53:28 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:28 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:28 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:28 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:29 - INFO - TRAINING - Epoch: [33][0/3]	Time 0.241 (0.241)	Data 0.237 (0.237)	Loss 0.1800 (0.1800)	Prec@1 90.625 (90.625)	
2022-01-19 14:53:29 - INFO - EVALUATING - Epoch: [33][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.8940 (0.8940)	Prec@1 66.667 (66.667)	
2022-01-19 14:53:29 - INFO - 
 Epoch: 34	Training Loss 0.2337 	Training Prec@1 90.769 	Validation Loss 0.8940 	Validation Prec@1 66.667 	
2022-01-19 14:53:29 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:29 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:29 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:29 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:29 - INFO - TRAINING - Epoch: [34][0/3]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.2798 (0.2798)	Prec@1 92.188 (92.188)	
2022-01-19 14:53:29 - INFO - EVALUATING - Epoch: [34][0/1]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.8118 (0.8118)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:29 - INFO - 
 Epoch: 35	Training Loss 0.2413 	Training Prec@1 93.846 	Validation Loss 0.8118 	Validation Prec@1 69.697 	
2022-01-19 14:53:29 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:29 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:29 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:29 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:30 - INFO - TRAINING - Epoch: [35][0/3]	Time 0.193 (0.193)	Data 0.190 (0.190)	Loss 0.0824 (0.0824)	Prec@1 100.000 (100.000)	
2022-01-19 14:53:30 - INFO - EVALUATING - Epoch: [35][0/1]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.8230 (0.8230)	Prec@1 75.758 (75.758)	
2022-01-19 14:53:30 - INFO - 
 Epoch: 36	Training Loss 0.2137 	Training Prec@1 93.846 	Validation Loss 0.8230 	Validation Prec@1 75.758 	
2022-01-19 14:53:30 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:30 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:30 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:30 - INFO - TRAINING - Epoch: [36][0/3]	Time 0.241 (0.241)	Data 0.237 (0.237)	Loss 0.2776 (0.2776)	Prec@1 93.750 (93.750)	
2022-01-19 14:53:30 - INFO - EVALUATING - Epoch: [36][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.5461 (0.5461)	Prec@1 81.818 (81.818)	
2022-01-19 14:53:30 - INFO - 
 Epoch: 37	Training Loss 0.1714 	Training Prec@1 95.385 	Validation Loss 0.5461 	Validation Prec@1 81.818 	
2022-01-19 14:53:30 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:30 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:30 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:30 - INFO - TRAINING - Epoch: [37][0/3]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.1158 (0.1158)	Prec@1 98.438 (98.438)	
2022-01-19 14:53:31 - INFO - EVALUATING - Epoch: [37][0/1]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.7415 (0.7415)	Prec@1 72.727 (72.727)	
2022-01-19 14:53:31 - INFO - 
 Epoch: 38	Training Loss 0.1476 	Training Prec@1 95.385 	Validation Loss 0.7415 	Validation Prec@1 72.727 	
2022-01-19 14:53:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:31 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:31 - INFO - TRAINING - Epoch: [38][0/3]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.3302 (0.3302)	Prec@1 90.625 (90.625)	
2022-01-19 14:53:31 - INFO - EVALUATING - Epoch: [38][0/1]	Time 0.183 (0.183)	Data 0.182 (0.182)	Loss 0.7311 (0.7311)	Prec@1 75.758 (75.758)	
2022-01-19 14:53:31 - INFO - 
 Epoch: 39	Training Loss 0.2724 	Training Prec@1 92.308 	Validation Loss 0.7311 	Validation Prec@1 75.758 	
2022-01-19 14:53:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:31 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:31 - INFO - TRAINING - Epoch: [39][0/3]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.2421 (0.2421)	Prec@1 92.188 (92.188)	
2022-01-19 14:53:32 - INFO - EVALUATING - Epoch: [39][0/1]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.6237 (0.6237)	Prec@1 81.818 (81.818)	
2022-01-19 14:53:32 - INFO - 
 Epoch: 40	Training Loss 0.1978 	Training Prec@1 95.385 	Validation Loss 0.6237 	Validation Prec@1 81.818 	
2022-01-19 14:53:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:32 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:32 - INFO - TRAINING - Epoch: [40][0/3]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.2860 (0.2860)	Prec@1 85.938 (85.938)	
2022-01-19 14:53:32 - INFO - EVALUATING - Epoch: [40][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 1.2239 (1.2239)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:32 - INFO - 
 Epoch: 41	Training Loss 0.2879 	Training Prec@1 86.923 	Validation Loss 1.2239 	Validation Prec@1 69.697 	
2022-01-19 14:53:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:32 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:32 - INFO - TRAINING - Epoch: [41][0/3]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.2848 (0.2848)	Prec@1 92.188 (92.188)	
2022-01-19 14:53:33 - INFO - EVALUATING - Epoch: [41][0/1]	Time 0.234 (0.234)	Data 0.232 (0.232)	Loss 1.0035 (1.0035)	Prec@1 66.667 (66.667)	
2022-01-19 14:53:33 - INFO - 
 Epoch: 42	Training Loss 0.2881 	Training Prec@1 92.308 	Validation Loss 1.0035 	Validation Prec@1 66.667 	
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:33 - INFO - TRAINING - Epoch: [42][0/3]	Time 0.195 (0.195)	Data 0.192 (0.192)	Loss 0.2433 (0.2433)	Prec@1 93.750 (93.750)	
2022-01-19 14:53:33 - INFO - EVALUATING - Epoch: [42][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 1.4398 (1.4398)	Prec@1 72.727 (72.727)	
2022-01-19 14:53:33 - INFO - 
 Epoch: 43	Training Loss 0.1751 	Training Prec@1 93.846 	Validation Loss 1.4398 	Validation Prec@1 72.727 	
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:33 - INFO - TRAINING - Epoch: [43][0/3]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.3203 (0.3203)	Prec@1 93.750 (93.750)	
2022-01-19 14:53:33 - INFO - EVALUATING - Epoch: [43][0/1]	Time 0.237 (0.237)	Data 0.235 (0.235)	Loss 0.9013 (0.9013)	Prec@1 63.636 (63.636)	
2022-01-19 14:53:33 - INFO - 
 Epoch: 44	Training Loss 0.2746 	Training Prec@1 94.615 	Validation Loss 0.9013 	Validation Prec@1 63.636 	
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:33 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:34 - INFO - TRAINING - Epoch: [44][0/3]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.0930 (0.0930)	Prec@1 98.438 (98.438)	
2022-01-19 14:53:34 - INFO - EVALUATING - Epoch: [44][0/1]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 1.0773 (1.0773)	Prec@1 63.636 (63.636)	
2022-01-19 14:53:34 - INFO - 
 Epoch: 45	Training Loss 0.2319 	Training Prec@1 94.615 	Validation Loss 1.0773 	Validation Prec@1 63.636 	
2022-01-19 14:53:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:34 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:34 - INFO - TRAINING - Epoch: [45][0/3]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.2320 (0.2320)	Prec@1 90.625 (90.625)	
2022-01-19 14:53:34 - INFO - EVALUATING - Epoch: [45][0/1]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.7270 (0.7270)	Prec@1 69.697 (69.697)	
2022-01-19 14:53:34 - INFO - 
 Epoch: 46	Training Loss 0.3141 	Training Prec@1 90.769 	Validation Loss 0.7270 	Validation Prec@1 69.697 	
2022-01-19 14:53:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:34 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:35 - INFO - TRAINING - Epoch: [46][0/3]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.3108 (0.3108)	Prec@1 90.625 (90.625)	
2022-01-19 14:53:35 - INFO - EVALUATING - Epoch: [46][0/1]	Time 0.202 (0.202)	Data 0.201 (0.201)	Loss 0.9682 (0.9682)	Prec@1 78.788 (78.788)	
2022-01-19 14:53:35 - INFO - 
 Epoch: 47	Training Loss 0.3964 	Training Prec@1 86.154 	Validation Loss 0.9682 	Validation Prec@1 78.788 	
2022-01-19 14:53:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:35 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:35 - INFO - TRAINING - Epoch: [47][0/3]	Time 0.214 (0.214)	Data 0.210 (0.210)	Loss 0.2015 (0.2015)	Prec@1 95.312 (95.312)	
2022-01-19 14:53:35 - INFO - EVALUATING - Epoch: [47][0/1]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 1.4787 (1.4787)	Prec@1 72.727 (72.727)	
2022-01-19 14:53:35 - INFO - 
 Epoch: 48	Training Loss 0.1379 	Training Prec@1 95.385 	Validation Loss 1.4787 	Validation Prec@1 72.727 	
2022-01-19 14:53:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:35 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:36 - INFO - TRAINING - Epoch: [48][0/3]	Time 0.207 (0.207)	Data 0.202 (0.202)	Loss 0.3895 (0.3895)	Prec@1 89.062 (89.062)	
2022-01-19 14:53:36 - INFO - EVALUATING - Epoch: [48][0/1]	Time 0.202 (0.202)	Data 0.200 (0.200)	Loss 0.9940 (0.9940)	Prec@1 75.758 (75.758)	
2022-01-19 14:53:36 - INFO - 
 Epoch: 49	Training Loss 0.3382 	Training Prec@1 90.769 	Validation Loss 0.9940 	Validation Prec@1 75.758 	
2022-01-19 14:53:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:53:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:53:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:53:36 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:53:36 - INFO - TRAINING - Epoch: [49][0/3]	Time 0.241 (0.241)	Data 0.237 (0.237)	Loss 0.2948 (0.2948)	Prec@1 93.750 (93.750)	
2022-01-19 14:53:36 - INFO - EVALUATING - Epoch: [49][0/1]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 1.0635 (1.0635)	Prec@1 78.788 (78.788)	
2022-01-19 14:53:36 - INFO - 
 Epoch: 50	Training Loss 0.2649 	Training Prec@1 88.462 	Validation Loss 1.0635 	Validation Prec@1 78.788 	
