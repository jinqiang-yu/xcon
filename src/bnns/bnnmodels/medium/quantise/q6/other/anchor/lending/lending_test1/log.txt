2022-01-19 14:38:42 - INFO - saving to ./results/medium/quantise/q6/other/anchor/lending/lending_test1/
2022-01-19 14:38:42 - DEBUG - run arguments: Namespace(config='./configs/config_medium.json', data='../../paper_bench/complete/quantise/q6/other/anchor/lending/lending_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/medium/quantise/q6/other/anchor/lending/lending_test1/', test='../../paper_bench/cv/test/quantise/q6/other/anchor/lending/lending_test1_data.csv', train='../../paper_bench/cv/train/quantise/q6/other/anchor/lending/lending_train1_data.csv')
2022-01-19 14:38:43 - INFO - creating model mlp_binary
2022-01-19 14:38:43 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [32, 16, 8, 2]}
2022-01-19 14:38:43 - INFO - number of parameters: 1946
2022-01-19 14:38:43 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-19 14:38:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][0/128]	Time 0.205 (0.205)	Data 0.197 (0.197)	Loss 1.6725 (1.6725)	Prec@1 48.438 (48.438)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7472 (1.0668)	Prec@1 68.750 (68.182)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.8613 (0.9958)	Prec@1 68.750 (63.244)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6880 (0.9098)	Prec@1 56.250 (66.784)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7798 (0.8687)	Prec@1 57.812 (68.293)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6014 (0.8602)	Prec@1 73.438 (68.964)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4392 (0.8201)	Prec@1 84.375 (70.953)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6310 (0.7935)	Prec@1 79.688 (71.215)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5312 (0.7556)	Prec@1 78.125 (72.434)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5386 (0.7467)	Prec@1 76.562 (72.751)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4797 (0.7297)	Prec@1 82.812 (72.850)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5093 (0.7250)	Prec@1 76.562 (73.142)	
2022-01-19 14:38:43 - INFO - TRAINING - Epoch: [0][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7433 (0.7267)	Prec@1 56.250 (72.637)	
2022-01-19 14:38:44 - INFO - EVALUATING - Epoch: [0][0/32]	Time 0.203 (0.203)	Data 0.201 (0.201)	Loss 0.2880 (0.2880)	Prec@1 93.750 (93.750)	
2022-01-19 14:38:44 - INFO - EVALUATING - Epoch: [0][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.3939 (0.4072)	Prec@1 89.062 (87.216)	
2022-01-19 14:38:44 - INFO - EVALUATING - Epoch: [0][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4379 (0.4386)	Prec@1 85.938 (85.119)	
2022-01-19 14:38:44 - INFO - EVALUATING - Epoch: [0][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5963 (0.5074)	Prec@1 75.000 (81.149)	
2022-01-19 14:38:44 - INFO - 
 Epoch: 1	Training Loss 0.7170 	Training Prec@1 73.037 	Validation Loss 0.5076 	Validation Prec@1 80.990 	
2022-01-19 14:38:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][0/128]	Time 0.243 (0.243)	Data 0.238 (0.238)	Loss 0.4358 (0.4358)	Prec@1 85.938 (85.938)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][10/128]	Time 0.004 (0.026)	Data 0.002 (0.023)	Loss 0.6512 (0.7033)	Prec@1 75.000 (69.886)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.8233 (0.7100)	Prec@1 45.312 (69.420)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][30/128]	Time 0.007 (0.012)	Data 0.002 (0.009)	Loss 0.4740 (0.6694)	Prec@1 81.250 (73.034)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.1939 (0.6558)	Prec@1 75.000 (73.018)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.7006 (0.6632)	Prec@1 53.125 (73.652)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5504 (0.6771)	Prec@1 82.812 (73.463)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5246 (0.6562)	Prec@1 73.438 (73.261)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6816 (0.6589)	Prec@1 54.688 (73.167)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.8402 (0.6508)	Prec@1 75.000 (73.850)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7477 (0.6617)	Prec@1 53.125 (73.345)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6405 (0.6764)	Prec@1 75.000 (73.381)	
2022-01-19 14:38:44 - INFO - TRAINING - Epoch: [1][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7902 (0.6949)	Prec@1 84.375 (72.856)	
2022-01-19 14:38:45 - INFO - EVALUATING - Epoch: [1][0/32]	Time 0.223 (0.223)	Data 0.221 (0.221)	Loss 0.1891 (0.1891)	Prec@1 96.875 (96.875)	
2022-01-19 14:38:45 - INFO - EVALUATING - Epoch: [1][10/32]	Time 0.005 (0.023)	Data 0.004 (0.022)	Loss 0.5338 (0.4211)	Prec@1 79.688 (85.227)	
2022-01-19 14:38:45 - INFO - EVALUATING - Epoch: [1][20/32]	Time 0.003 (0.014)	Data 0.002 (0.012)	Loss 0.2824 (0.4737)	Prec@1 92.188 (82.515)	
2022-01-19 14:38:45 - INFO - EVALUATING - Epoch: [1][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.8059 (0.5513)	Prec@1 65.625 (78.579)	
2022-01-19 14:38:45 - INFO - 
 Epoch: 2	Training Loss 0.7060 	Training Prec@1 72.767 	Validation Loss 0.5596 	Validation Prec@1 78.148 	
2022-01-19 14:38:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][0/128]	Time 0.148 (0.148)	Data 0.144 (0.144)	Loss 0.6513 (0.6513)	Prec@1 73.438 (73.438)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][10/128]	Time 0.005 (0.017)	Data 0.002 (0.015)	Loss 1.0316 (0.7984)	Prec@1 71.875 (73.153)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][20/128]	Time 0.004 (0.011)	Data 0.002 (0.009)	Loss 0.6927 (0.7443)	Prec@1 51.562 (70.908)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][30/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.7972 (0.7421)	Prec@1 79.688 (72.984)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][40/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.9859 (0.7775)	Prec@1 71.875 (69.474)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][50/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7680 (0.7943)	Prec@1 78.125 (68.964)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][60/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6611 (0.7705)	Prec@1 53.125 (69.518)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][70/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7622 (0.7702)	Prec@1 81.250 (70.555)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6872 (0.7419)	Prec@1 76.562 (71.682)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][90/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6932 (0.7203)	Prec@1 51.562 (72.442)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][100/128]	Time 0.004 (0.005)	Data 0.002 (0.003)	Loss 0.6044 (0.7178)	Prec@1 82.812 (72.308)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][110/128]	Time 0.004 (0.005)	Data 0.002 (0.003)	Loss 0.6344 (0.7077)	Prec@1 78.125 (73.156)	
2022-01-19 14:38:45 - INFO - TRAINING - Epoch: [2][120/128]	Time 0.004 (0.005)	Data 0.002 (0.003)	Loss 0.6855 (0.7161)	Prec@1 56.250 (72.908)	
2022-01-19 14:38:46 - INFO - EVALUATING - Epoch: [2][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.0997 (0.0997)	Prec@1 96.875 (96.875)	
2022-01-19 14:38:46 - INFO - EVALUATING - Epoch: [2][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4891 (0.4258)	Prec@1 85.938 (87.784)	
2022-01-19 14:38:46 - INFO - EVALUATING - Epoch: [2][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3327 (0.5001)	Prec@1 87.500 (85.714)	
2022-01-19 14:38:46 - INFO - EVALUATING - Epoch: [2][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.0491 (0.6223)	Prec@1 71.875 (81.804)	
2022-01-19 14:38:46 - INFO - 
 Epoch: 3	Training Loss 0.7120 	Training Prec@1 73.000 	Validation Loss 0.6343 	Validation Prec@1 81.627 	
2022-01-19 14:38:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.5626 (0.5626)	Prec@1 82.812 (82.812)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6620 (0.8352)	Prec@1 39.062 (62.500)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4523 (0.7791)	Prec@1 84.375 (68.973)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4209 (0.7193)	Prec@1 85.938 (70.010)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6879 (0.6899)	Prec@1 78.125 (72.599)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.1751 (0.7027)	Prec@1 73.438 (73.254)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5633 (0.6950)	Prec@1 76.562 (72.746)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7129 (0.7014)	Prec@1 45.312 (72.557)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6613 (0.7018)	Prec@1 53.125 (72.222)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5929 (0.6861)	Prec@1 76.562 (72.047)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8600 (0.7178)	Prec@1 85.938 (71.643)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9151 (0.7364)	Prec@1 70.312 (71.608)	
2022-01-19 14:38:46 - INFO - TRAINING - Epoch: [3][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6479 (0.7373)	Prec@1 81.250 (71.036)	
2022-01-19 14:38:47 - INFO - EVALUATING - Epoch: [3][0/32]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.1499 (0.1499)	Prec@1 90.625 (90.625)	
2022-01-19 14:38:47 - INFO - EVALUATING - Epoch: [3][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4050 (0.4004)	Prec@1 84.375 (82.955)	
2022-01-19 14:38:47 - INFO - EVALUATING - Epoch: [3][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2400 (0.4470)	Prec@1 85.938 (81.622)	
2022-01-19 14:38:47 - INFO - EVALUATING - Epoch: [3][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.9173 (0.5441)	Prec@1 70.312 (78.427)	
2022-01-19 14:38:47 - INFO - 
 Epoch: 4	Training Loss 0.7380 	Training Prec@1 70.954 	Validation Loss 0.5556 	Validation Prec@1 78.344 	
2022-01-19 14:38:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.7589 (0.7589)	Prec@1 76.562 (76.562)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.3017 (1.2614)	Prec@1 50.000 (67.045)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.5751 (1.0040)	Prec@1 78.125 (68.527)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5825 (0.9014)	Prec@1 75.000 (69.909)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5627 (0.8087)	Prec@1 79.688 (72.523)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6887 (0.7964)	Prec@1 78.125 (70.925)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5562 (0.7983)	Prec@1 78.125 (71.235)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5519 (0.7673)	Prec@1 78.125 (71.655)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6017 (0.7472)	Prec@1 78.125 (72.319)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6410 (0.7271)	Prec@1 75.000 (72.424)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5794 (0.7140)	Prec@1 76.562 (72.138)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.2544 (0.7125)	Prec@1 46.875 (72.185)	
2022-01-19 14:38:47 - INFO - TRAINING - Epoch: [4][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4826 (0.7000)	Prec@1 82.812 (72.856)	
2022-01-19 14:38:48 - INFO - EVALUATING - Epoch: [4][0/32]	Time 0.238 (0.238)	Data 0.236 (0.236)	Loss 0.3944 (0.3944)	Prec@1 92.188 (92.188)	
2022-01-19 14:38:48 - INFO - EVALUATING - Epoch: [4][10/32]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.4947 (0.4772)	Prec@1 82.812 (84.091)	
2022-01-19 14:38:48 - INFO - EVALUATING - Epoch: [4][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.5382 (0.5030)	Prec@1 78.125 (81.324)	
2022-01-19 14:38:48 - INFO - EVALUATING - Epoch: [4][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.6181 (0.5312)	Prec@1 68.750 (78.276)	
2022-01-19 14:38:48 - INFO - 
 Epoch: 5	Training Loss 0.6913 	Training Prec@1 73.172 	Validation Loss 0.5326 	Validation Prec@1 78.099 	
2022-01-19 14:38:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:48 - INFO - TRAINING - Epoch: [5][0/128]	Time 0.243 (0.243)	Data 0.239 (0.239)	Loss 0.6764 (0.6764)	Prec@1 64.062 (64.062)	
2022-01-19 14:38:48 - INFO - TRAINING - Epoch: [5][10/128]	Time 0.004 (0.026)	Data 0.002 (0.023)	Loss 0.5100 (0.6024)	Prec@1 78.125 (75.284)	
2022-01-19 14:38:48 - INFO - TRAINING - Epoch: [5][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.4718 (0.7431)	Prec@1 81.250 (72.396)	
2022-01-19 14:38:48 - INFO - TRAINING - Epoch: [5][30/128]	Time 0.004 (0.012)	Data 0.002 (0.009)	Loss 0.6576 (0.6773)	Prec@1 71.875 (74.849)	
2022-01-19 14:38:48 - INFO - TRAINING - Epoch: [5][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.1036 (0.6968)	Prec@1 68.750 (73.704)	
2022-01-19 14:38:48 - INFO - TRAINING - Epoch: [5][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 1.2956 (0.7027)	Prec@1 23.438 (73.866)	
2022-01-19 14:38:48 - INFO - TRAINING - Epoch: [5][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6332 (0.7147)	Prec@1 62.500 (73.181)	
2022-01-19 14:38:48 - INFO - TRAINING - Epoch: [5][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5209 (0.7005)	Prec@1 79.688 (73.239)	
2022-01-19 14:38:48 - INFO - TRAINING - Epoch: [5][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.3056 (0.6990)	Prec@1 42.188 (72.589)	
2022-01-19 14:38:48 - INFO - TRAINING - Epoch: [5][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5305 (0.6794)	Prec@1 79.688 (73.403)	
2022-01-19 14:38:48 - INFO - TRAINING - Epoch: [5][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4050 (0.6727)	Prec@1 85.938 (73.267)	
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [5][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4826 (0.6612)	Prec@1 81.250 (73.522)	
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [5][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5765 (0.6558)	Prec@1 76.562 (73.670)	
2022-01-19 14:38:49 - INFO - EVALUATING - Epoch: [5][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.0709 (0.0709)	Prec@1 98.438 (98.438)	
2022-01-19 14:38:49 - INFO - EVALUATING - Epoch: [5][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5264 (0.4132)	Prec@1 82.812 (85.085)	
2022-01-19 14:38:49 - INFO - EVALUATING - Epoch: [5][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2486 (0.4716)	Prec@1 89.062 (83.036)	
2022-01-19 14:38:49 - INFO - EVALUATING - Epoch: [5][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.9977 (0.5856)	Prec@1 60.938 (78.931)	
2022-01-19 14:38:49 - INFO - 
 Epoch: 6	Training Loss 0.6514 	Training Prec@1 73.882 	Validation Loss 0.5962 	Validation Prec@1 78.540 	
2022-01-19 14:38:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [6][0/128]	Time 0.245 (0.245)	Data 0.241 (0.241)	Loss 0.7372 (0.7372)	Prec@1 78.125 (78.125)	
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [6][10/128]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.6507 (0.7801)	Prec@1 78.125 (68.750)	
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [6][20/128]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.4202 (0.6677)	Prec@1 79.688 (72.024)	
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [6][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.4409 (0.6666)	Prec@1 81.250 (72.933)	
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [6][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.3454 (0.6557)	Prec@1 92.188 (73.895)	
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [6][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.5446 (0.6560)	Prec@1 78.125 (75.337)	
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [6][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.9923 (0.6482)	Prec@1 73.438 (76.178)	
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [6][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4832 (0.6678)	Prec@1 82.812 (75.990)	
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [6][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6477 (0.6730)	Prec@1 64.062 (76.254)	
2022-01-19 14:38:49 - INFO - TRAINING - Epoch: [6][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5086 (0.6684)	Prec@1 79.688 (75.807)	
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [6][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4774 (0.6582)	Prec@1 79.688 (75.340)	
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [6][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7753 (0.6579)	Prec@1 76.562 (75.324)	
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [6][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7190 (0.6605)	Prec@1 82.812 (75.232)	
2022-01-19 14:38:50 - INFO - EVALUATING - Epoch: [6][0/32]	Time 0.221 (0.221)	Data 0.219 (0.219)	Loss 0.1006 (0.1006)	Prec@1 98.438 (98.438)	
2022-01-19 14:38:50 - INFO - EVALUATING - Epoch: [6][10/32]	Time 0.003 (0.023)	Data 0.002 (0.022)	Loss 0.4220 (0.3963)	Prec@1 87.500 (87.074)	
2022-01-19 14:38:50 - INFO - EVALUATING - Epoch: [6][20/32]	Time 0.003 (0.013)	Data 0.002 (0.012)	Loss 0.3396 (0.4450)	Prec@1 90.625 (85.193)	
2022-01-19 14:38:50 - INFO - EVALUATING - Epoch: [6][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.7825 (0.5486)	Prec@1 71.875 (81.300)	
2022-01-19 14:38:50 - INFO - 
 Epoch: 7	Training Loss 0.6580 	Training Prec@1 75.450 	Validation Loss 0.5569 	Validation Prec@1 80.990 	
2022-01-19 14:38:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [7][0/128]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.4744 (0.4744)	Prec@1 84.375 (84.375)	
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [7][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 1.3121 (0.7052)	Prec@1 70.312 (73.438)	
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [7][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6161 (0.6428)	Prec@1 71.875 (76.116)	
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [7][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7103 (0.6982)	Prec@1 70.312 (74.345)	
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [7][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6840 (0.7214)	Prec@1 70.312 (73.819)	
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [7][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5397 (0.7090)	Prec@1 82.812 (73.254)	
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [7][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7438 (0.7150)	Prec@1 43.750 (72.976)	
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [7][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.8364 (0.7373)	Prec@1 73.438 (73.371)	
2022-01-19 14:38:50 - INFO - TRAINING - Epoch: [7][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5495 (0.7414)	Prec@1 78.125 (72.724)	
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [7][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.0999 (0.7839)	Prec@1 65.625 (72.098)	
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [7][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4770 (0.7617)	Prec@1 87.500 (73.113)	
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [7][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5706 (0.7516)	Prec@1 76.562 (73.578)	
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [7][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6685 (0.7425)	Prec@1 85.938 (73.425)	
2022-01-19 14:38:51 - INFO - EVALUATING - Epoch: [7][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.1639 (0.1639)	Prec@1 93.750 (93.750)	
2022-01-19 14:38:51 - INFO - EVALUATING - Epoch: [7][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6003 (0.4856)	Prec@1 79.688 (84.091)	
2022-01-19 14:38:51 - INFO - EVALUATING - Epoch: [7][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3593 (0.5406)	Prec@1 89.062 (82.292)	
2022-01-19 14:38:51 - INFO - EVALUATING - Epoch: [7][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.2043 (0.6461)	Prec@1 59.375 (78.579)	
2022-01-19 14:38:51 - INFO - 
 Epoch: 8	Training Loss 0.7321 	Training Prec@1 73.919 	Validation Loss 0.6588 	Validation Prec@1 78.148 	
2022-01-19 14:38:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [8][0/128]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.5226 (0.5226)	Prec@1 82.812 (82.812)	
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [8][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6807 (0.8984)	Prec@1 82.812 (68.608)	
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [8][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.8517 (0.9058)	Prec@1 71.875 (70.908)	
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [8][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.4687 (0.8304)	Prec@1 82.812 (72.278)	
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [8][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6691 (0.7880)	Prec@1 81.250 (72.294)	
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [8][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7579 (0.7495)	Prec@1 57.812 (71.569)	
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [8][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5583 (0.7330)	Prec@1 75.000 (72.772)	
2022-01-19 14:38:51 - INFO - TRAINING - Epoch: [8][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.0210 (0.7327)	Prec@1 79.688 (73.526)	
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [8][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6725 (0.7156)	Prec@1 71.875 (72.685)	
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [8][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6229 (0.7106)	Prec@1 46.875 (72.218)	
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [8][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6006 (0.6966)	Prec@1 62.500 (71.968)	
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [8][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5773 (0.6815)	Prec@1 75.000 (72.452)	
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [8][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4583 (0.6756)	Prec@1 76.562 (72.947)	
2022-01-19 14:38:52 - INFO - EVALUATING - Epoch: [8][0/32]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.3501 (0.3501)	Prec@1 96.875 (96.875)	
2022-01-19 14:38:52 - INFO - EVALUATING - Epoch: [8][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4714 (0.4413)	Prec@1 85.938 (88.068)	
2022-01-19 14:38:52 - INFO - EVALUATING - Epoch: [8][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3979 (0.4586)	Prec@1 92.188 (85.938)	
2022-01-19 14:38:52 - INFO - EVALUATING - Epoch: [8][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5839 (0.4935)	Prec@1 71.875 (82.056)	
2022-01-19 14:38:52 - INFO - 
 Epoch: 9	Training Loss 0.6692 	Training Prec@1 73.135 	Validation Loss 0.4946 	Validation Prec@1 81.872 	
2022-01-19 14:38:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [9][0/128]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.4562 (0.4562)	Prec@1 85.938 (85.938)	
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [9][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.5472 (0.9544)	Prec@1 81.250 (72.869)	
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [9][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 1.0733 (0.9053)	Prec@1 78.125 (66.964)	
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [9][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5494 (0.8518)	Prec@1 84.375 (68.952)	
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [9][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7239 (0.8447)	Prec@1 75.000 (68.026)	
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [9][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.9147 (0.8662)	Prec@1 79.688 (69.363)	
2022-01-19 14:38:52 - INFO - TRAINING - Epoch: [9][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4977 (0.8527)	Prec@1 82.812 (69.493)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [9][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5260 (0.8300)	Prec@1 79.688 (70.643)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [9][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.5813 (0.8215)	Prec@1 78.125 (70.235)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [9][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6203 (0.8064)	Prec@1 79.688 (70.570)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [9][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5948 (0.8105)	Prec@1 82.812 (70.761)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [9][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8145 (0.8045)	Prec@1 81.250 (70.622)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [9][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 1.5689 (0.8077)	Prec@1 60.938 (70.687)	
2022-01-19 14:38:53 - INFO - EVALUATING - Epoch: [9][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.1865 (0.1865)	Prec@1 96.875 (96.875)	
2022-01-19 14:38:53 - INFO - EVALUATING - Epoch: [9][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5871 (0.5485)	Prec@1 79.688 (83.239)	
2022-01-19 14:38:53 - INFO - EVALUATING - Epoch: [9][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3287 (0.6148)	Prec@1 90.625 (81.622)	
2022-01-19 14:38:53 - INFO - EVALUATING - Epoch: [9][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.2285 (0.7487)	Prec@1 59.375 (77.772)	
2022-01-19 14:38:53 - INFO - 
 Epoch: 10	Training Loss 0.7989 	Training Prec@1 70.856 	Validation Loss 0.7653 	Validation Prec@1 77.266 	
2022-01-19 14:38:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [10][0/128]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.9893 (0.9893)	Prec@1 75.000 (75.000)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [10][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.6658 (0.9915)	Prec@1 81.250 (71.875)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [10][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4111 (0.8000)	Prec@1 90.625 (74.256)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [10][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5656 (0.7185)	Prec@1 75.000 (74.950)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [10][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.3942 (0.7055)	Prec@1 84.375 (73.361)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [10][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7960 (0.7398)	Prec@1 65.625 (73.315)	
2022-01-19 14:38:53 - INFO - TRAINING - Epoch: [10][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6318 (0.7144)	Prec@1 73.438 (73.207)	
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [10][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5522 (0.6939)	Prec@1 85.938 (73.173)	
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [10][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4457 (0.6918)	Prec@1 56.250 (73.708)	
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [10][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7470 (0.6789)	Prec@1 76.562 (73.729)	
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [10][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9601 (0.7006)	Prec@1 70.312 (73.577)	
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [10][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6531 (0.6947)	Prec@1 79.688 (73.128)	
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [10][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5729 (0.6960)	Prec@1 78.125 (72.921)	
2022-01-19 14:38:54 - INFO - EVALUATING - Epoch: [10][0/32]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.6663 (0.6663)	Prec@1 75.000 (75.000)	
2022-01-19 14:38:54 - INFO - EVALUATING - Epoch: [10][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7934 (0.7900)	Prec@1 68.750 (68.892)	
2022-01-19 14:38:54 - INFO - EVALUATING - Epoch: [10][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.7576 (0.7865)	Prec@1 70.312 (68.601)	
2022-01-19 14:38:54 - INFO - EVALUATING - Epoch: [10][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8187 (0.7950)	Prec@1 65.625 (67.843)	
2022-01-19 14:38:54 - INFO - 
 Epoch: 11	Training Loss 0.7012 	Training Prec@1 72.829 	Validation Loss 0.7955 	Validation Prec@1 67.761 	
2022-01-19 14:38:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [11][0/128]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.5721 (0.5721)	Prec@1 76.562 (76.562)	
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [11][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.2143 (0.9152)	Prec@1 68.750 (73.438)	
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [11][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.5640 (0.7868)	Prec@1 85.938 (72.470)	
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [11][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6942 (0.7980)	Prec@1 51.562 (72.127)	
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [11][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9725 (0.7751)	Prec@1 75.000 (72.409)	
2022-01-19 14:38:54 - INFO - TRAINING - Epoch: [11][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5805 (0.7463)	Prec@1 79.688 (71.783)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [11][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6006 (0.7305)	Prec@1 79.688 (72.976)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [11][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7381 (0.7155)	Prec@1 53.125 (73.305)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [11][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4720 (0.7060)	Prec@1 87.500 (73.727)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [11][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7737 (0.7182)	Prec@1 81.250 (73.935)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [11][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.0111 (0.7103)	Prec@1 56.250 (73.979)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [11][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4542 (0.7004)	Prec@1 82.812 (74.296)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [11][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5976 (0.6889)	Prec@1 85.938 (74.522)	
2022-01-19 14:38:55 - INFO - EVALUATING - Epoch: [11][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.2802 (0.2802)	Prec@1 96.875 (96.875)	
2022-01-19 14:38:55 - INFO - EVALUATING - Epoch: [11][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5730 (0.4462)	Prec@1 79.688 (84.233)	
2022-01-19 14:38:55 - INFO - EVALUATING - Epoch: [11][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3786 (0.4564)	Prec@1 87.500 (81.622)	
2022-01-19 14:38:55 - INFO - EVALUATING - Epoch: [11][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6836 (0.4798)	Prec@1 56.250 (77.772)	
2022-01-19 14:38:55 - INFO - 
 Epoch: 12	Training Loss 0.6884 	Training Prec@1 74.397 	Validation Loss 0.4818 	Validation Prec@1 77.266 	
2022-01-19 14:38:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [12][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.4877 (0.4877)	Prec@1 76.562 (76.562)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [12][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 1.1320 (0.7294)	Prec@1 54.688 (69.034)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [12][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.7655 (0.6526)	Prec@1 75.000 (72.693)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [12][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8713 (0.7126)	Prec@1 76.562 (73.337)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [12][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9131 (0.7611)	Prec@1 76.562 (70.884)	
2022-01-19 14:38:55 - INFO - TRAINING - Epoch: [12][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5181 (0.7252)	Prec@1 78.125 (70.619)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [12][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5473 (0.7272)	Prec@1 76.562 (70.799)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [12][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4208 (0.7054)	Prec@1 84.375 (71.391)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [12][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6584 (0.6997)	Prec@1 68.750 (72.029)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [12][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4600 (0.6794)	Prec@1 76.562 (72.356)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [12][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6702 (0.6850)	Prec@1 68.750 (72.324)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [12][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4203 (0.6689)	Prec@1 71.875 (72.846)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [12][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5771 (0.6542)	Prec@1 50.000 (73.050)	
2022-01-19 14:38:56 - INFO - EVALUATING - Epoch: [12][0/32]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.7719 (0.7719)	Prec@1 67.188 (67.188)	
2022-01-19 14:38:56 - INFO - EVALUATING - Epoch: [12][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.9355 (0.9593)	Prec@1 57.812 (56.818)	
2022-01-19 14:38:56 - INFO - EVALUATING - Epoch: [12][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.9301 (0.9972)	Prec@1 60.938 (55.729)	
2022-01-19 14:38:56 - INFO - EVALUATING - Epoch: [12][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.3714 (0.9920)	Prec@1 45.312 (57.611)	
2022-01-19 14:38:56 - INFO - 
 Epoch: 13	Training Loss 0.6577 	Training Prec@1 73.208 	Validation Loss 0.9977 	Validation Prec@1 57.521 	
2022-01-19 14:38:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [13][0/128]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.8870 (0.8870)	Prec@1 62.500 (62.500)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [13][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.6078 (0.9882)	Prec@1 84.375 (72.869)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [13][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.0445 (0.8136)	Prec@1 71.875 (74.330)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [13][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6880 (0.8376)	Prec@1 85.938 (74.042)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [13][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.5003 (0.7903)	Prec@1 79.688 (73.399)	
2022-01-19 14:38:56 - INFO - TRAINING - Epoch: [13][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6519 (0.7680)	Prec@1 43.750 (72.457)	
2022-01-19 14:38:57 - INFO - TRAINING - Epoch: [13][60/128]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.7218 (0.7500)	Prec@1 78.125 (72.720)	
2022-01-19 14:38:57 - INFO - TRAINING - Epoch: [13][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5257 (0.7215)	Prec@1 67.188 (72.557)	
2022-01-19 14:38:57 - INFO - TRAINING - Epoch: [13][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8516 (0.7201)	Prec@1 78.125 (72.724)	
2022-01-19 14:38:57 - INFO - TRAINING - Epoch: [13][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7150 (0.7097)	Prec@1 70.312 (72.442)	
2022-01-19 14:38:57 - INFO - TRAINING - Epoch: [13][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5236 (0.7021)	Prec@1 68.750 (73.082)	
2022-01-19 14:38:57 - INFO - TRAINING - Epoch: [13][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.1239 (0.6876)	Prec@1 68.750 (73.846)	
2022-01-19 14:38:57 - INFO - TRAINING - Epoch: [13][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.8376 (0.6970)	Prec@1 56.250 (73.696)	
2022-01-19 14:38:57 - INFO - EVALUATING - Epoch: [13][0/32]	Time 0.242 (0.242)	Data 0.240 (0.240)	Loss 0.7270 (0.7270)	Prec@1 43.750 (43.750)	
2022-01-19 14:38:57 - INFO - EVALUATING - Epoch: [13][10/32]	Time 0.003 (0.025)	Data 0.002 (0.024)	Loss 0.7731 (0.7442)	Prec@1 29.688 (38.494)	
2022-01-19 14:38:57 - INFO - EVALUATING - Epoch: [13][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.7270 (0.7275)	Prec@1 43.750 (43.601)	
2022-01-19 14:38:57 - INFO - EVALUATING - Epoch: [13][30/32]	Time 0.002 (0.011)	Data 0.001 (0.010)	Loss 0.6553 (0.7098)	Prec@1 65.625 (48.992)	
2022-01-19 14:38:57 - INFO - 
 Epoch: 14	Training Loss 0.6986 	Training Prec@1 73.588 	Validation Loss 0.7074 	Validation Prec@1 49.731 	
2022-01-19 14:38:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:57 - INFO - TRAINING - Epoch: [14][0/128]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.7373 (0.7373)	Prec@1 40.625 (40.625)	
2022-01-19 14:38:57 - INFO - TRAINING - Epoch: [14][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.9621 (0.9024)	Prec@1 53.125 (70.739)	
2022-01-19 14:38:57 - INFO - TRAINING - Epoch: [14][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.5358 (0.7156)	Prec@1 82.812 (72.247)	
2022-01-19 14:38:57 - INFO - TRAINING - Epoch: [14][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7994 (0.6699)	Prec@1 76.562 (74.647)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [14][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5608 (0.6705)	Prec@1 75.000 (74.200)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [14][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5841 (0.6463)	Prec@1 76.562 (75.766)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [14][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5946 (0.6238)	Prec@1 78.125 (76.921)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [14][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5747 (0.6303)	Prec@1 54.688 (76.849)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [14][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6761 (0.6310)	Prec@1 79.688 (76.331)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [14][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6137 (0.6303)	Prec@1 79.688 (75.498)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [14][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.2695 (0.6370)	Prec@1 73.438 (75.433)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [14][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5249 (0.6351)	Prec@1 78.125 (74.958)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [14][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5910 (0.6290)	Prec@1 78.125 (74.613)	
2022-01-19 14:38:58 - INFO - EVALUATING - Epoch: [14][0/32]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.1719 (0.1719)	Prec@1 95.312 (95.312)	
2022-01-19 14:38:58 - INFO - EVALUATING - Epoch: [14][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5168 (0.3778)	Prec@1 85.938 (87.784)	
2022-01-19 14:38:58 - INFO - EVALUATING - Epoch: [14][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3385 (0.4142)	Prec@1 87.500 (85.565)	
2022-01-19 14:38:58 - INFO - EVALUATING - Epoch: [14][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6538 (0.4845)	Prec@1 75.000 (82.157)	
2022-01-19 14:38:58 - INFO - 
 Epoch: 15	Training Loss 0.6337 	Training Prec@1 74.776 	Validation Loss 0.4870 	Validation Prec@1 82.068 	
2022-01-19 14:38:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [15][0/128]	Time 0.186 (0.186)	Data 0.182 (0.182)	Loss 0.5531 (0.5531)	Prec@1 78.125 (78.125)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [15][10/128]	Time 0.004 (0.021)	Data 0.002 (0.018)	Loss 1.1948 (0.7887)	Prec@1 79.688 (71.875)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [15][20/128]	Time 0.004 (0.013)	Data 0.002 (0.010)	Loss 0.7610 (0.8704)	Prec@1 68.750 (70.908)	
2022-01-19 14:38:58 - INFO - TRAINING - Epoch: [15][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.9276 (0.8696)	Prec@1 75.000 (68.599)	
2022-01-19 14:38:59 - INFO - TRAINING - Epoch: [15][40/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6102 (0.8273)	Prec@1 84.375 (71.380)	
2022-01-19 14:38:59 - INFO - TRAINING - Epoch: [15][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.3498 (0.7977)	Prec@1 87.500 (68.964)	
2022-01-19 14:38:59 - INFO - TRAINING - Epoch: [15][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7352 (0.7895)	Prec@1 53.125 (69.928)	
2022-01-19 14:38:59 - INFO - TRAINING - Epoch: [15][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7789 (0.7975)	Prec@1 56.250 (70.489)	
2022-01-19 14:38:59 - INFO - TRAINING - Epoch: [15][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.9940 (0.8062)	Prec@1 50.000 (70.351)	
2022-01-19 14:38:59 - INFO - TRAINING - Epoch: [15][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6748 (0.8051)	Prec@1 48.438 (70.484)	
2022-01-19 14:38:59 - INFO - TRAINING - Epoch: [15][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7245 (0.8122)	Prec@1 76.562 (71.256)	
2022-01-19 14:38:59 - INFO - TRAINING - Epoch: [15][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.8704 (0.8205)	Prec@1 76.562 (70.735)	
2022-01-19 14:38:59 - INFO - TRAINING - Epoch: [15][120/128]	Time 0.004 (0.005)	Data 0.002 (0.003)	Loss 0.6119 (0.8082)	Prec@1 73.438 (70.803)	
2022-01-19 14:38:59 - INFO - EVALUATING - Epoch: [15][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.0956 (0.0956)	Prec@1 92.188 (92.188)	
2022-01-19 14:38:59 - INFO - EVALUATING - Epoch: [15][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5291 (0.4573)	Prec@1 78.125 (76.562)	
2022-01-19 14:38:59 - INFO - EVALUATING - Epoch: [15][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5228 (0.5037)	Prec@1 78.125 (76.488)	
2022-01-19 14:38:59 - INFO - EVALUATING - Epoch: [15][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7867 (0.6013)	Prec@1 73.438 (74.597)	
2022-01-19 14:38:59 - INFO - 
 Epoch: 16	Training Loss 0.7945 	Training Prec@1 71.285 	Validation Loss 0.6042 	Validation Prec@1 74.718 	
2022-01-19 14:38:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:38:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:38:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:38:59 - INFO - TRAINING - Epoch: [16][0/128]	Time 0.241 (0.241)	Data 0.237 (0.237)	Loss 0.6221 (0.6221)	Prec@1 68.750 (68.750)	
2022-01-19 14:38:59 - INFO - TRAINING - Epoch: [16][10/128]	Time 0.004 (0.026)	Data 0.002 (0.023)	Loss 0.4530 (0.8832)	Prec@1 82.812 (71.875)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [16][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.7942 (0.7809)	Prec@1 85.938 (73.958)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [16][30/128]	Time 0.004 (0.012)	Data 0.002 (0.009)	Loss 0.8887 (0.7565)	Prec@1 62.500 (74.143)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [16][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7262 (0.7672)	Prec@1 67.188 (73.666)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [16][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.5133 (0.7153)	Prec@1 79.688 (75.061)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [16][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6775 (0.7043)	Prec@1 81.250 (75.794)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [16][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5814 (0.7024)	Prec@1 89.062 (74.912)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [16][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8164 (0.7139)	Prec@1 81.250 (75.482)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [16][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.4571 (0.7262)	Prec@1 75.000 (74.691)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [16][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5971 (0.7498)	Prec@1 84.375 (74.304)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [16][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4568 (0.7459)	Prec@1 81.250 (74.395)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [16][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8905 (0.7492)	Prec@1 68.750 (74.290)	
2022-01-19 14:39:00 - INFO - EVALUATING - Epoch: [16][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.0880 (0.0880)	Prec@1 98.438 (98.438)	
2022-01-19 14:39:00 - INFO - EVALUATING - Epoch: [16][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4961 (0.4061)	Prec@1 87.500 (87.784)	
2022-01-19 14:39:00 - INFO - EVALUATING - Epoch: [16][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2696 (0.4928)	Prec@1 92.188 (85.045)	
2022-01-19 14:39:00 - INFO - EVALUATING - Epoch: [16][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.9265 (0.5943)	Prec@1 71.875 (81.502)	
2022-01-19 14:39:00 - INFO - 
 Epoch: 17	Training Loss 0.7487 	Training Prec@1 73.992 	Validation Loss 0.6021 	Validation Prec@1 81.382 	
2022-01-19 14:39:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [17][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.7527 (0.7527)	Prec@1 76.562 (76.562)	
2022-01-19 14:39:00 - INFO - TRAINING - Epoch: [17][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.4287 (0.7436)	Prec@1 85.938 (70.597)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [17][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4960 (0.6783)	Prec@1 64.062 (71.131)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [17][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4203 (0.6166)	Prec@1 81.250 (73.992)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [17][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5446 (0.6390)	Prec@1 78.125 (73.819)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [17][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5733 (0.6142)	Prec@1 82.812 (74.387)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [17][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3450 (0.5962)	Prec@1 85.938 (74.795)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [17][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4508 (0.5912)	Prec@1 82.812 (75.000)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [17][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9979 (0.5859)	Prec@1 73.438 (75.521)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [17][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6297 (0.5895)	Prec@1 75.000 (75.206)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [17][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4541 (0.5862)	Prec@1 87.500 (75.820)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [17][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6607 (0.6015)	Prec@1 82.812 (75.901)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [17][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6815 (0.6109)	Prec@1 60.938 (75.426)	
2022-01-19 14:39:01 - INFO - EVALUATING - Epoch: [17][0/32]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.5161 (0.5161)	Prec@1 56.250 (56.250)	
2022-01-19 14:39:01 - INFO - EVALUATING - Epoch: [17][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.9171 (0.8193)	Prec@1 56.250 (48.153)	
2022-01-19 14:39:01 - INFO - EVALUATING - Epoch: [17][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.6107 (0.8535)	Prec@1 57.812 (50.595)	
2022-01-19 14:39:01 - INFO - EVALUATING - Epoch: [17][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.0723 (0.8824)	Prec@1 62.500 (53.679)	
2022-01-19 14:39:01 - INFO - 
 Epoch: 18	Training Loss 0.6133 	Training Prec@1 75.524 	Validation Loss 0.8874 	Validation Prec@1 53.944 	
2022-01-19 14:39:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [18][0/128]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.9096 (0.9096)	Prec@1 56.250 (56.250)	
2022-01-19 14:39:01 - INFO - TRAINING - Epoch: [18][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.7281 (0.7156)	Prec@1 70.312 (71.449)	
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [18][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5296 (0.7600)	Prec@1 81.250 (72.470)	
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [18][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8839 (0.7433)	Prec@1 73.438 (71.472)	
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [18][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6920 (0.7924)	Prec@1 82.812 (70.655)	
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [18][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6836 (0.7826)	Prec@1 81.250 (72.365)	
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [18][60/128]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.5996 (0.7555)	Prec@1 85.938 (72.592)	
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [18][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5865 (0.7631)	Prec@1 76.562 (71.941)	
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [18][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.9510 (0.7799)	Prec@1 71.875 (71.836)	
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [18][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7160 (0.7534)	Prec@1 50.000 (72.287)	
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [18][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.4646 (0.7471)	Prec@1 42.188 (72.463)	
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [18][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3055 (0.7272)	Prec@1 90.625 (73.325)	
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [18][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6376 (0.7195)	Prec@1 79.688 (73.063)	
2022-01-19 14:39:02 - INFO - EVALUATING - Epoch: [18][0/32]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.0954 (0.0954)	Prec@1 98.438 (98.438)	
2022-01-19 14:39:02 - INFO - EVALUATING - Epoch: [18][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.3956 (0.3480)	Prec@1 89.062 (89.489)	
2022-01-19 14:39:02 - INFO - EVALUATING - Epoch: [18][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2504 (0.4469)	Prec@1 89.062 (86.384)	
2022-01-19 14:39:02 - INFO - EVALUATING - Epoch: [18][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.9903 (0.5572)	Prec@1 70.312 (82.460)	
2022-01-19 14:39:02 - INFO - 
 Epoch: 19	Training Loss 0.7227 	Training Prec@1 73.172 	Validation Loss 0.5613 	Validation Prec@1 82.362 	
2022-01-19 14:39:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:02 - INFO - TRAINING - Epoch: [19][0/128]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.4837 (0.4837)	Prec@1 84.375 (84.375)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 1.1064 (0.9254)	Prec@1 54.688 (68.892)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5098 (0.7530)	Prec@1 84.375 (69.196)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5751 (0.7447)	Prec@1 79.688 (72.329)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6991 (0.7446)	Prec@1 78.125 (71.570)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4632 (0.7181)	Prec@1 81.250 (72.733)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5508 (0.6901)	Prec@1 82.812 (73.438)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4779 (0.6886)	Prec@1 85.938 (73.812)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9042 (0.6965)	Prec@1 73.438 (73.110)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.0795 (0.6978)	Prec@1 71.875 (73.283)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9859 (0.7069)	Prec@1 75.000 (73.360)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5141 (0.7127)	Prec@1 81.250 (73.170)	
2022-01-19 14:39:03 - INFO - TRAINING - Epoch: [19][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6998 (0.7240)	Prec@1 75.000 (73.231)	
2022-01-19 14:39:03 - INFO - EVALUATING - Epoch: [19][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.2113 (0.2113)	Prec@1 92.188 (92.188)	
2022-01-19 14:39:03 - INFO - EVALUATING - Epoch: [19][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6308 (0.4342)	Prec@1 67.188 (81.534)	
2022-01-19 14:39:03 - INFO - EVALUATING - Epoch: [19][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4125 (0.4915)	Prec@1 76.562 (80.208)	
2022-01-19 14:39:03 - INFO - EVALUATING - Epoch: [19][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7575 (0.5632)	Prec@1 75.000 (77.722)	
2022-01-19 14:39:03 - INFO - 
 Epoch: 20	Training Loss 0.7261 	Training Prec@1 73.086 	Validation Loss 0.5675 	Validation Prec@1 77.707 	
2022-01-19 14:39:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:03 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][0/128]	Time 0.203 (0.203)	Data 0.200 (0.200)	Loss 0.6902 (0.6902)	Prec@1 68.750 (68.750)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7081 (0.5514)	Prec@1 67.188 (74.006)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.4534 (0.5458)	Prec@1 81.250 (74.777)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5823 (0.5407)	Prec@1 68.750 (75.756)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7262 (0.5281)	Prec@1 59.375 (76.105)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.3837 (0.5172)	Prec@1 82.812 (76.317)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4848 (0.5064)	Prec@1 78.125 (76.972)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5572 (0.4960)	Prec@1 71.875 (77.487)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4359 (0.4939)	Prec@1 78.125 (77.681)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5337 (0.4919)	Prec@1 78.125 (77.970)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4804 (0.4832)	Prec@1 76.562 (78.171)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4279 (0.4806)	Prec@1 82.812 (78.280)	
2022-01-19 14:39:04 - INFO - TRAINING - Epoch: [20][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4038 (0.4822)	Prec@1 85.938 (78.383)	
2022-01-19 14:39:04 - INFO - EVALUATING - Epoch: [20][0/32]	Time 0.193 (0.193)	Data 0.192 (0.192)	Loss 0.2076 (0.2076)	Prec@1 93.750 (93.750)	
2022-01-19 14:39:04 - INFO - EVALUATING - Epoch: [20][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5239 (0.3869)	Prec@1 79.688 (84.801)	
2022-01-19 14:39:04 - INFO - EVALUATING - Epoch: [20][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3428 (0.4056)	Prec@1 82.812 (83.110)	
2022-01-19 14:39:04 - INFO - EVALUATING - Epoch: [20][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5461 (0.4377)	Prec@1 76.562 (80.393)	
2022-01-19 14:39:04 - INFO - 
 Epoch: 21	Training Loss 0.4789 	Training Prec@1 78.525 	Validation Loss 0.4406 	Validation Prec@1 80.353 	
2022-01-19 14:39:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][0/128]	Time 0.208 (0.208)	Data 0.204 (0.204)	Loss 0.4086 (0.4086)	Prec@1 81.250 (81.250)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.6352 (0.4959)	Prec@1 71.875 (77.557)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.3696 (0.4883)	Prec@1 79.688 (78.051)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.4310 (0.4809)	Prec@1 76.562 (78.175)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5111 (0.4731)	Prec@1 84.375 (78.544)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.3662 (0.4760)	Prec@1 81.250 (78.585)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4478 (0.4728)	Prec@1 82.812 (78.740)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6560 (0.4716)	Prec@1 70.312 (78.983)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6284 (0.4722)	Prec@1 75.000 (79.147)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4437 (0.4687)	Prec@1 81.250 (79.378)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6055 (0.4686)	Prec@1 76.562 (79.332)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4053 (0.4646)	Prec@1 92.188 (79.758)	
2022-01-19 14:39:05 - INFO - TRAINING - Epoch: [21][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.3140 (0.4629)	Prec@1 84.375 (79.881)	
2022-01-19 14:39:05 - INFO - EVALUATING - Epoch: [21][0/32]	Time 0.237 (0.237)	Data 0.235 (0.235)	Loss 0.2114 (0.2114)	Prec@1 95.312 (95.312)	
2022-01-19 14:39:05 - INFO - EVALUATING - Epoch: [21][10/32]	Time 0.003 (0.025)	Data 0.002 (0.023)	Loss 0.4088 (0.3565)	Prec@1 89.062 (88.068)	
2022-01-19 14:39:05 - INFO - EVALUATING - Epoch: [21][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.3265 (0.3849)	Prec@1 87.500 (85.565)	
2022-01-19 14:39:05 - INFO - EVALUATING - Epoch: [21][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.6200 (0.4278)	Prec@1 71.875 (82.006)	
2022-01-19 14:39:05 - INFO - 
 Epoch: 22	Training Loss 0.4628 	Training Prec@1 79.726 	Validation Loss 0.4320 	Validation Prec@1 81.774 	
2022-01-19 14:39:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.5328 (0.5328)	Prec@1 73.438 (73.438)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6282 (0.5462)	Prec@1 71.875 (74.574)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.8025 (0.5583)	Prec@1 70.312 (74.330)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4914 (0.5663)	Prec@1 76.562 (74.143)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4654 (0.5610)	Prec@1 75.000 (73.819)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8809 (0.5691)	Prec@1 60.938 (74.357)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4043 (0.5955)	Prec@1 82.812 (73.386)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6740 (0.5790)	Prec@1 76.562 (74.604)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3378 (0.5621)	Prec@1 84.375 (75.463)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3599 (0.5477)	Prec@1 87.500 (76.150)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4542 (0.5367)	Prec@1 82.812 (76.872)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5079 (0.5373)	Prec@1 76.562 (76.886)	
2022-01-19 14:39:06 - INFO - TRAINING - Epoch: [22][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4639 (0.5323)	Prec@1 89.062 (77.118)	
2022-01-19 14:39:06 - INFO - EVALUATING - Epoch: [22][0/32]	Time 0.234 (0.234)	Data 0.232 (0.232)	Loss 0.1265 (0.1265)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:06 - INFO - EVALUATING - Epoch: [22][10/32]	Time 0.003 (0.025)	Data 0.002 (0.024)	Loss 0.4107 (0.3420)	Prec@1 84.375 (87.074)	
2022-01-19 14:39:06 - INFO - EVALUATING - Epoch: [22][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.2345 (0.3913)	Prec@1 92.188 (84.524)	
2022-01-19 14:39:06 - INFO - EVALUATING - Epoch: [22][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.6804 (0.4600)	Prec@1 68.750 (81.200)	
2022-01-19 14:39:06 - INFO - 
 Epoch: 23	Training Loss 0.5322 	Training Prec@1 77.202 	Validation Loss 0.4663 	Validation Prec@1 80.794 	
2022-01-19 14:39:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:06 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][0/128]	Time 0.238 (0.238)	Data 0.234 (0.234)	Loss 0.2584 (0.2584)	Prec@1 90.625 (90.625)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][10/128]	Time 0.004 (0.025)	Data 0.002 (0.023)	Loss 0.6617 (0.5584)	Prec@1 81.250 (79.545)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.4102 (0.5584)	Prec@1 82.812 (79.911)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][30/128]	Time 0.004 (0.012)	Data 0.002 (0.009)	Loss 0.5627 (0.5901)	Prec@1 81.250 (79.133)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][40/128]	Time 0.004 (0.010)	Data 0.002 (0.007)	Loss 0.8006 (0.5784)	Prec@1 54.688 (78.544)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.4048 (0.5781)	Prec@1 89.062 (78.646)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.0597 (0.5802)	Prec@1 60.938 (78.740)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5238 (0.5658)	Prec@1 81.250 (78.631)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6378 (0.5567)	Prec@1 70.312 (78.549)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4800 (0.5448)	Prec@1 78.125 (78.640)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3972 (0.5326)	Prec@1 82.812 (78.929)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.2889 (0.5258)	Prec@1 87.500 (78.843)	
2022-01-19 14:39:07 - INFO - TRAINING - Epoch: [23][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5138 (0.5208)	Prec@1 81.250 (79.081)	
2022-01-19 14:39:07 - INFO - EVALUATING - Epoch: [23][0/32]	Time 0.197 (0.197)	Data 0.194 (0.194)	Loss 0.2016 (0.2016)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:07 - INFO - EVALUATING - Epoch: [23][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4807 (0.3897)	Prec@1 82.812 (86.222)	
2022-01-19 14:39:07 - INFO - EVALUATING - Epoch: [23][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3123 (0.4186)	Prec@1 89.062 (83.705)	
2022-01-19 14:39:08 - INFO - EVALUATING - Epoch: [23][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7133 (0.4668)	Prec@1 65.625 (80.242)	
2022-01-19 14:39:08 - INFO - 
 Epoch: 24	Training Loss 0.5190 	Training Prec@1 79.150 	Validation Loss 0.4738 	Validation Prec@1 79.765 	
2022-01-19 14:39:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.4119 (0.4119)	Prec@1 82.812 (82.812)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4676 (0.5362)	Prec@1 82.812 (79.830)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6125 (0.5327)	Prec@1 76.562 (79.018)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.3470 (0.5692)	Prec@1 84.375 (77.268)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4005 (0.5349)	Prec@1 82.812 (77.744)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.2586 (0.5195)	Prec@1 89.062 (78.033)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.2593 (0.5103)	Prec@1 84.375 (78.304)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4144 (0.5086)	Prec@1 81.250 (78.455)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4262 (0.4966)	Prec@1 81.250 (78.839)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3949 (0.4969)	Prec@1 79.688 (78.674)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6096 (0.4930)	Prec@1 70.312 (78.728)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5573 (0.4889)	Prec@1 73.438 (79.110)	
2022-01-19 14:39:08 - INFO - TRAINING - Epoch: [24][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.2912 (0.4881)	Prec@1 87.500 (79.016)	
2022-01-19 14:39:08 - INFO - EVALUATING - Epoch: [24][0/32]	Time 0.202 (0.202)	Data 0.200 (0.200)	Loss 0.1927 (0.1927)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:08 - INFO - EVALUATING - Epoch: [24][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5860 (0.5477)	Prec@1 79.688 (83.949)	
2022-01-19 14:39:09 - INFO - EVALUATING - Epoch: [24][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4085 (0.6334)	Prec@1 89.062 (81.920)	
2022-01-19 14:39:09 - INFO - EVALUATING - Epoch: [24][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.3753 (0.7636)	Prec@1 57.812 (78.226)	
2022-01-19 14:39:09 - INFO - 
 Epoch: 25	Training Loss 0.4884 	Training Prec@1 79.040 	Validation Loss 0.7796 	Validation Prec@1 77.707 	
2022-01-19 14:39:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][0/128]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.6955 (0.6955)	Prec@1 79.688 (79.688)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.7399 (0.5395)	Prec@1 62.500 (78.693)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4277 (0.4926)	Prec@1 78.125 (81.027)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.2852 (0.4887)	Prec@1 85.938 (80.494)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][40/128]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.4208 (0.5070)	Prec@1 82.812 (80.030)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4427 (0.4935)	Prec@1 82.812 (79.902)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3649 (0.4964)	Prec@1 82.812 (79.355)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][70/128]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.4530 (0.4916)	Prec@1 82.812 (79.357)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5944 (0.4964)	Prec@1 76.562 (79.398)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4663 (0.4928)	Prec@1 82.812 (79.378)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6672 (0.5062)	Prec@1 82.812 (78.790)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4612 (0.5390)	Prec@1 76.562 (77.731)	
2022-01-19 14:39:09 - INFO - TRAINING - Epoch: [25][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6039 (0.5312)	Prec@1 82.812 (78.035)	
2022-01-19 14:39:10 - INFO - EVALUATING - Epoch: [25][0/32]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.1780 (0.1780)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:10 - INFO - EVALUATING - Epoch: [25][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5795 (0.3799)	Prec@1 85.938 (88.210)	
2022-01-19 14:39:10 - INFO - EVALUATING - Epoch: [25][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2643 (0.4050)	Prec@1 90.625 (85.491)	
2022-01-19 14:39:10 - INFO - EVALUATING - Epoch: [25][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6890 (0.4517)	Prec@1 68.750 (81.552)	
2022-01-19 14:39:10 - INFO - 
 Epoch: 26	Training Loss 0.5289 	Training Prec@1 78.280 	Validation Loss 0.4568 	Validation Prec@1 81.284 	
2022-01-19 14:39:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.4001 (0.4001)	Prec@1 87.500 (87.500)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4865 (0.6111)	Prec@1 84.375 (81.960)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4756 (0.6619)	Prec@1 85.938 (80.134)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5102 (0.5988)	Prec@1 76.562 (81.048)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5266 (0.5761)	Prec@1 76.562 (79.840)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5829 (0.5893)	Prec@1 82.812 (79.779)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3221 (0.5645)	Prec@1 84.375 (80.225)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5156 (0.5455)	Prec@1 76.562 (80.238)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4417 (0.5437)	Prec@1 84.375 (80.035)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5432 (0.5425)	Prec@1 71.875 (79.499)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4310 (0.5484)	Prec@1 82.812 (79.425)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4571 (0.5401)	Prec@1 85.938 (79.533)	
2022-01-19 14:39:10 - INFO - TRAINING - Epoch: [26][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4076 (0.5303)	Prec@1 78.125 (79.675)	
2022-01-19 14:39:11 - INFO - EVALUATING - Epoch: [26][0/32]	Time 0.192 (0.192)	Data 0.190 (0.190)	Loss 0.1356 (0.1356)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:11 - INFO - EVALUATING - Epoch: [26][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.3734 (0.3316)	Prec@1 89.062 (87.926)	
2022-01-19 14:39:11 - INFO - EVALUATING - Epoch: [26][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2635 (0.3781)	Prec@1 90.625 (85.417)	
2022-01-19 14:39:11 - INFO - EVALUATING - Epoch: [26][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6931 (0.4533)	Prec@1 70.312 (81.452)	
2022-01-19 14:39:11 - INFO - 
 Epoch: 27	Training Loss 0.5307 	Training Prec@1 79.591 	Validation Loss 0.4590 	Validation Prec@1 81.137 	
2022-01-19 14:39:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.7146 (0.7146)	Prec@1 68.750 (68.750)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 1.0380 (0.8627)	Prec@1 70.312 (70.881)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6236 (0.8052)	Prec@1 75.000 (71.577)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4787 (0.7253)	Prec@1 85.938 (74.597)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4952 (0.6808)	Prec@1 82.812 (75.686)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5277 (0.6559)	Prec@1 75.000 (75.551)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5835 (0.6524)	Prec@1 76.562 (75.666)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5281 (0.6519)	Prec@1 75.000 (76.100)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3317 (0.6430)	Prec@1 84.375 (76.022)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4561 (0.6238)	Prec@1 78.125 (76.322)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3857 (0.6084)	Prec@1 84.375 (76.671)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6045 (0.5995)	Prec@1 73.438 (76.760)	
2022-01-19 14:39:11 - INFO - TRAINING - Epoch: [27][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.3492 (0.5840)	Prec@1 89.062 (77.311)	
2022-01-19 14:39:12 - INFO - EVALUATING - Epoch: [27][0/32]	Time 0.199 (0.199)	Data 0.197 (0.197)	Loss 0.2157 (0.2157)	Prec@1 95.312 (95.312)	
2022-01-19 14:39:12 - INFO - EVALUATING - Epoch: [27][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.4455 (0.3680)	Prec@1 84.375 (87.074)	
2022-01-19 14:39:12 - INFO - EVALUATING - Epoch: [27][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3012 (0.3972)	Prec@1 89.062 (84.449)	
2022-01-19 14:39:12 - INFO - EVALUATING - Epoch: [27][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5970 (0.4381)	Prec@1 71.875 (81.250)	
2022-01-19 14:39:12 - INFO - 
 Epoch: 28	Training Loss 0.5796 	Training Prec@1 77.459 	Validation Loss 0.4422 	Validation Prec@1 81.039 	
2022-01-19 14:39:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][0/128]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.4494 (0.4494)	Prec@1 79.688 (79.688)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.4796 (0.6057)	Prec@1 81.250 (78.409)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6540 (0.5586)	Prec@1 78.125 (78.646)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5051 (0.5521)	Prec@1 78.125 (79.335)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.4626 (0.5244)	Prec@1 81.250 (79.764)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6907 (0.5182)	Prec@1 73.438 (79.657)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4417 (0.5103)	Prec@1 81.250 (79.559)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4244 (0.5041)	Prec@1 76.562 (79.401)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3930 (0.4951)	Prec@1 84.375 (79.668)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5555 (0.4994)	Prec@1 64.062 (79.653)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5406 (0.5011)	Prec@1 81.250 (79.564)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4189 (0.5009)	Prec@1 84.375 (79.490)	
2022-01-19 14:39:12 - INFO - TRAINING - Epoch: [28][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4939 (0.5005)	Prec@1 89.062 (79.597)	
2022-01-19 14:39:13 - INFO - EVALUATING - Epoch: [28][0/32]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 0.1502 (0.1502)	Prec@1 95.312 (95.312)	
2022-01-19 14:39:13 - INFO - EVALUATING - Epoch: [28][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5830 (0.4304)	Prec@1 87.500 (88.210)	
2022-01-19 14:39:13 - INFO - EVALUATING - Epoch: [28][20/32]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.3723 (0.4757)	Prec@1 87.500 (86.310)	
2022-01-19 14:39:13 - INFO - EVALUATING - Epoch: [28][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.1265 (0.5956)	Prec@1 70.312 (82.359)	
2022-01-19 14:39:13 - INFO - 
 Epoch: 29	Training Loss 0.5118 	Training Prec@1 79.640 	Validation Loss 0.6017 	Validation Prec@1 82.166 	
2022-01-19 14:39:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][0/128]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.7339 (0.7339)	Prec@1 82.812 (82.812)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.3270 (0.6267)	Prec@1 87.500 (73.011)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.4807 (0.5770)	Prec@1 78.125 (74.554)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.3667 (0.5659)	Prec@1 85.938 (74.950)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6508 (0.5603)	Prec@1 76.562 (75.991)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6146 (0.5508)	Prec@1 76.562 (76.256)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6596 (0.6047)	Prec@1 84.375 (76.486)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4331 (0.6185)	Prec@1 85.938 (77.047)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6368 (0.6311)	Prec@1 75.000 (76.562)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5882 (0.6386)	Prec@1 79.688 (76.854)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3719 (0.6249)	Prec@1 85.938 (77.197)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4454 (0.6085)	Prec@1 82.812 (77.689)	
2022-01-19 14:39:13 - INFO - TRAINING - Epoch: [29][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4207 (0.5974)	Prec@1 78.125 (77.815)	
2022-01-19 14:39:14 - INFO - EVALUATING - Epoch: [29][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.1531 (0.1531)	Prec@1 98.438 (98.438)	
2022-01-19 14:39:14 - INFO - EVALUATING - Epoch: [29][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6159 (0.5897)	Prec@1 89.062 (86.364)	
2022-01-19 14:39:14 - INFO - EVALUATING - Epoch: [29][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5677 (0.5892)	Prec@1 89.062 (85.045)	
2022-01-19 14:39:14 - INFO - EVALUATING - Epoch: [29][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7477 (0.6724)	Prec@1 75.000 (81.704)	
2022-01-19 14:39:14 - INFO - 
 Epoch: 30	Training Loss 0.5938 	Training Prec@1 77.643 	Validation Loss 0.6716 	Validation Prec@1 81.480 	
2022-01-19 14:39:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:14 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.7635 (0.7635)	Prec@1 81.250 (81.250)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.3799 (0.6986)	Prec@1 85.938 (77.273)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5331 (0.6056)	Prec@1 82.812 (78.646)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4084 (0.5838)	Prec@1 84.375 (79.536)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7542 (0.6128)	Prec@1 71.875 (76.601)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5741 (0.6346)	Prec@1 81.250 (77.022)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5641 (0.6244)	Prec@1 78.125 (77.280)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6125 (0.6118)	Prec@1 71.875 (76.783)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5722 (0.5975)	Prec@1 84.375 (77.508)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4026 (0.5937)	Prec@1 78.125 (77.455)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4356 (0.5831)	Prec@1 87.500 (77.769)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5649 (0.5825)	Prec@1 76.562 (78.055)	
2022-01-19 14:39:14 - INFO - TRAINING - Epoch: [30][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4047 (0.5762)	Prec@1 85.938 (78.099)	
2022-01-19 14:39:15 - INFO - EVALUATING - Epoch: [30][0/32]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.2045 (0.2045)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:15 - INFO - EVALUATING - Epoch: [30][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.3809 (0.3721)	Prec@1 89.062 (87.500)	
2022-01-19 14:39:15 - INFO - EVALUATING - Epoch: [30][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3042 (0.3889)	Prec@1 87.500 (85.640)	
2022-01-19 14:39:15 - INFO - EVALUATING - Epoch: [30][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6207 (0.4325)	Prec@1 70.312 (82.157)	
2022-01-19 14:39:15 - INFO - 
 Epoch: 31	Training Loss 0.5717 	Training Prec@1 78.268 	Validation Loss 0.4361 	Validation Prec@1 81.921 	
2022-01-19 14:39:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:15 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.4019 (0.4019)	Prec@1 84.375 (84.375)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4771 (0.5858)	Prec@1 87.500 (82.244)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5035 (0.6273)	Prec@1 81.250 (79.464)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4042 (0.6037)	Prec@1 84.375 (78.931)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9247 (0.6185)	Prec@1 79.688 (77.058)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4632 (0.6068)	Prec@1 79.688 (77.482)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8810 (0.6213)	Prec@1 78.125 (77.228)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3964 (0.6172)	Prec@1 82.812 (77.839)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8828 (0.6065)	Prec@1 73.438 (78.144)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4054 (0.5949)	Prec@1 85.938 (78.554)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4536 (0.5936)	Prec@1 87.500 (78.713)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4179 (0.5841)	Prec@1 82.812 (79.167)	
2022-01-19 14:39:15 - INFO - TRAINING - Epoch: [31][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4982 (0.5764)	Prec@1 76.562 (79.390)	
2022-01-19 14:39:16 - INFO - EVALUATING - Epoch: [31][0/32]	Time 0.225 (0.225)	Data 0.223 (0.223)	Loss 0.4339 (0.4339)	Prec@1 68.750 (68.750)	
2022-01-19 14:39:16 - INFO - EVALUATING - Epoch: [31][10/32]	Time 0.003 (0.023)	Data 0.002 (0.022)	Loss 0.7792 (0.6673)	Prec@1 45.312 (52.983)	
2022-01-19 14:39:16 - INFO - EVALUATING - Epoch: [31][20/32]	Time 0.003 (0.013)	Data 0.002 (0.012)	Loss 0.5890 (0.6198)	Prec@1 51.562 (58.036)	
2022-01-19 14:39:16 - INFO - EVALUATING - Epoch: [31][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.5615 (0.6197)	Prec@1 71.875 (60.030)	
2022-01-19 14:39:16 - INFO - 
 Epoch: 32	Training Loss 0.5700 	Training Prec@1 79.517 	Validation Loss 0.6150 	Validation Prec@1 60.510 	
2022-01-19 14:39:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][0/128]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.3237 (0.3237)	Prec@1 87.500 (87.500)	
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.3482 (0.6298)	Prec@1 89.062 (79.119)	
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 1.2403 (0.6565)	Prec@1 68.750 (80.208)	
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.9272 (0.6750)	Prec@1 81.250 (78.427)	
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4618 (0.6746)	Prec@1 85.938 (77.973)	
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6925 (0.6600)	Prec@1 75.000 (78.523)	
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5747 (0.6584)	Prec@1 84.375 (77.561)	
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9339 (0.6731)	Prec@1 70.312 (75.946)	
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5143 (0.6585)	Prec@1 81.250 (76.717)	
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][90/128]	Time 0.005 (0.006)	Data 0.002 (0.004)	Loss 0.5902 (0.6541)	Prec@1 75.000 (75.790)	
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3444 (0.6377)	Prec@1 85.938 (76.315)	
2022-01-19 14:39:16 - INFO - TRAINING - Epoch: [32][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4493 (0.6212)	Prec@1 79.688 (76.760)	
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [32][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3419 (0.6025)	Prec@1 87.500 (77.402)	
2022-01-19 14:39:17 - INFO - EVALUATING - Epoch: [32][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.2092 (0.2092)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:17 - INFO - EVALUATING - Epoch: [32][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4359 (0.3543)	Prec@1 85.938 (88.494)	
2022-01-19 14:39:17 - INFO - EVALUATING - Epoch: [32][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3020 (0.3775)	Prec@1 89.062 (86.384)	
2022-01-19 14:39:17 - INFO - EVALUATING - Epoch: [32][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5820 (0.4238)	Prec@1 73.438 (82.712)	
2022-01-19 14:39:17 - INFO - 
 Epoch: 33	Training Loss 0.5948 	Training Prec@1 77.606 	Validation Loss 0.4273 	Validation Prec@1 82.460 	
2022-01-19 14:39:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [33][0/128]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.3403 (0.3403)	Prec@1 89.062 (89.062)	
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [33][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.6985 (0.8158)	Prec@1 57.812 (73.722)	
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [33][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4738 (0.6574)	Prec@1 75.000 (77.530)	
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [33][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.3575 (0.6146)	Prec@1 81.250 (77.823)	
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [33][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.9589 (0.6528)	Prec@1 70.312 (76.486)	
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [33][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5828 (0.6394)	Prec@1 81.250 (76.900)	
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [33][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6356 (0.6409)	Prec@1 76.562 (75.999)	
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [33][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5938 (0.6349)	Prec@1 82.812 (76.607)	
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [33][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6507 (0.6285)	Prec@1 73.438 (76.736)	
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [33][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7056 (0.6153)	Prec@1 70.312 (77.318)	
2022-01-19 14:39:17 - INFO - TRAINING - Epoch: [33][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4983 (0.6127)	Prec@1 87.500 (77.413)	
2022-01-19 14:39:18 - INFO - TRAINING - Epoch: [33][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5142 (0.6066)	Prec@1 81.250 (77.717)	
2022-01-19 14:39:18 - INFO - TRAINING - Epoch: [33][120/128]	Time 0.004 (0.005)	Data 0.002 (0.003)	Loss 0.6853 (0.5988)	Prec@1 75.000 (77.867)	
2022-01-19 14:39:18 - INFO - EVALUATING - Epoch: [33][0/32]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.3933 (0.3933)	Prec@1 98.438 (98.438)	
2022-01-19 14:39:18 - INFO - EVALUATING - Epoch: [33][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5930 (0.5327)	Prec@1 82.812 (85.085)	
2022-01-19 14:39:18 - INFO - EVALUATING - Epoch: [33][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4258 (0.5178)	Prec@1 93.750 (83.780)	
2022-01-19 14:39:18 - INFO - EVALUATING - Epoch: [33][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6175 (0.5232)	Prec@1 62.500 (80.544)	
2022-01-19 14:39:18 - INFO - 
 Epoch: 34	Training Loss 0.5965 	Training Prec@1 78.072 	Validation Loss 0.5227 	Validation Prec@1 80.157 	
2022-01-19 14:39:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:18 - INFO - TRAINING - Epoch: [34][0/128]	Time 0.240 (0.240)	Data 0.236 (0.236)	Loss 0.5325 (0.5325)	Prec@1 76.562 (76.562)	
2022-01-19 14:39:18 - INFO - TRAINING - Epoch: [34][10/128]	Time 0.004 (0.026)	Data 0.002 (0.023)	Loss 0.6003 (0.6693)	Prec@1 73.438 (78.125)	
2022-01-19 14:39:18 - INFO - TRAINING - Epoch: [34][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.5701 (0.6782)	Prec@1 84.375 (76.786)	
2022-01-19 14:39:18 - INFO - TRAINING - Epoch: [34][30/128]	Time 0.004 (0.012)	Data 0.002 (0.009)	Loss 0.5226 (0.6188)	Prec@1 79.688 (78.931)	
2022-01-19 14:39:18 - INFO - TRAINING - Epoch: [34][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4611 (0.6005)	Prec@1 87.500 (79.535)	
2022-01-19 14:39:18 - INFO - TRAINING - Epoch: [34][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.4932 (0.6331)	Prec@1 78.125 (76.746)	
2022-01-19 14:39:18 - INFO - TRAINING - Epoch: [34][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8746 (0.6236)	Prec@1 48.438 (76.230)	
2022-01-19 14:39:18 - INFO - TRAINING - Epoch: [34][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5179 (0.6300)	Prec@1 73.438 (76.761)	
2022-01-19 14:39:18 - INFO - TRAINING - Epoch: [34][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5082 (0.6189)	Prec@1 78.125 (76.736)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [34][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7776 (0.6180)	Prec@1 76.562 (76.923)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [34][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5183 (0.6064)	Prec@1 84.375 (77.351)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [34][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6173 (0.6032)	Prec@1 78.125 (77.562)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [34][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9629 (0.6211)	Prec@1 60.938 (77.402)	
2022-01-19 14:39:19 - INFO - EVALUATING - Epoch: [34][0/32]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.3957 (0.3957)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:19 - INFO - EVALUATING - Epoch: [34][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5913 (0.5217)	Prec@1 79.688 (83.523)	
2022-01-19 14:39:19 - INFO - EVALUATING - Epoch: [34][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4456 (0.5142)	Prec@1 89.062 (82.068)	
2022-01-19 14:39:19 - INFO - EVALUATING - Epoch: [34][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7423 (0.5268)	Prec@1 56.250 (78.175)	
2022-01-19 14:39:19 - INFO - 
 Epoch: 35	Training Loss 0.6201 	Training Prec@1 77.435 	Validation Loss 0.5270 	Validation Prec@1 77.707 	
2022-01-19 14:39:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [35][0/128]	Time 0.206 (0.206)	Data 0.202 (0.202)	Loss 0.4901 (0.4901)	Prec@1 79.688 (79.688)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [35][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.3598 (0.6012)	Prec@1 85.938 (78.267)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [35][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7155 (0.5785)	Prec@1 73.438 (77.753)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [35][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.5298 (0.5856)	Prec@1 75.000 (76.109)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [35][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5372 (0.6041)	Prec@1 79.688 (75.800)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [35][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4330 (0.5751)	Prec@1 87.500 (76.808)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [35][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.2370 (0.5922)	Prec@1 21.875 (75.743)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [35][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7195 (0.5942)	Prec@1 75.000 (76.430)	
2022-01-19 14:39:19 - INFO - TRAINING - Epoch: [35][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5154 (0.5886)	Prec@1 84.375 (76.003)	
2022-01-19 14:39:20 - INFO - TRAINING - Epoch: [35][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7797 (0.5804)	Prec@1 76.562 (76.459)	
2022-01-19 14:39:20 - INFO - TRAINING - Epoch: [35][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3585 (0.6049)	Prec@1 81.250 (75.804)	
2022-01-19 14:39:20 - INFO - TRAINING - Epoch: [35][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6587 (0.6121)	Prec@1 67.188 (75.732)	
2022-01-19 14:39:20 - INFO - TRAINING - Epoch: [35][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.8201 (0.6216)	Prec@1 73.438 (75.439)	
2022-01-19 14:39:20 - INFO - EVALUATING - Epoch: [35][0/32]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.4052 (0.4052)	Prec@1 71.875 (71.875)	
2022-01-19 14:39:20 - INFO - EVALUATING - Epoch: [35][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.8036 (0.6764)	Prec@1 48.438 (55.540)	
2022-01-19 14:39:20 - INFO - EVALUATING - Epoch: [35][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.6567 (0.6315)	Prec@1 56.250 (61.607)	
2022-01-19 14:39:20 - INFO - EVALUATING - Epoch: [35][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6436 (0.6391)	Prec@1 71.875 (63.306)	
2022-01-19 14:39:20 - INFO - 
 Epoch: 36	Training Loss 0.6239 	Training Prec@1 75.769 	Validation Loss 0.6339 	Validation Prec@1 63.694 	
2022-01-19 14:39:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:20 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:20 - INFO - TRAINING - Epoch: [36][0/128]	Time 0.208 (0.208)	Data 0.204 (0.204)	Loss 0.3088 (0.3088)	Prec@1 90.625 (90.625)	
2022-01-19 14:39:20 - INFO - TRAINING - Epoch: [36][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.5668 (0.7348)	Prec@1 82.812 (77.699)	
2022-01-19 14:39:20 - INFO - TRAINING - Epoch: [36][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.4669 (0.6653)	Prec@1 75.000 (77.902)	
2022-01-19 14:39:20 - INFO - TRAINING - Epoch: [36][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.4939 (0.5992)	Prec@1 79.688 (78.327)	
2022-01-19 14:39:20 - INFO - TRAINING - Epoch: [36][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.2529 (0.6134)	Prec@1 56.250 (77.020)	
2022-01-19 14:39:20 - INFO - TRAINING - Epoch: [36][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4764 (0.6065)	Prec@1 75.000 (76.624)	
2022-01-19 14:39:20 - INFO - TRAINING - Epoch: [36][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6553 (0.6152)	Prec@1 78.125 (76.153)	
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [36][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.2659 (0.5948)	Prec@1 90.625 (76.430)	
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [36][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6108 (0.6216)	Prec@1 51.562 (75.328)	
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [36][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4772 (0.6087)	Prec@1 75.000 (75.652)	
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [36][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7820 (0.6027)	Prec@1 56.250 (75.418)	
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [36][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4831 (0.5930)	Prec@1 84.375 (75.718)	
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [36][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4187 (0.5833)	Prec@1 89.062 (76.343)	
2022-01-19 14:39:21 - INFO - EVALUATING - Epoch: [36][0/32]	Time 0.212 (0.212)	Data 0.210 (0.210)	Loss 0.2258 (0.2258)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:21 - INFO - EVALUATING - Epoch: [36][10/32]	Time 0.003 (0.022)	Data 0.002 (0.021)	Loss 0.5952 (0.4298)	Prec@1 81.250 (87.500)	
2022-01-19 14:39:21 - INFO - EVALUATING - Epoch: [36][20/32]	Time 0.003 (0.013)	Data 0.002 (0.012)	Loss 0.3902 (0.4500)	Prec@1 89.062 (85.565)	
2022-01-19 14:39:21 - INFO - EVALUATING - Epoch: [36][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.6484 (0.5067)	Prec@1 73.438 (82.208)	
2022-01-19 14:39:21 - INFO - 
 Epoch: 37	Training Loss 0.5817 	Training Prec@1 76.614 	Validation Loss 0.5104 	Validation Prec@1 81.872 	
2022-01-19 14:39:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:21 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [37][0/128]	Time 0.190 (0.190)	Data 0.186 (0.186)	Loss 0.4773 (0.4773)	Prec@1 82.812 (82.812)	
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [37][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 1.0333 (0.7430)	Prec@1 71.875 (80.256)	
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [37][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.3446 (0.7411)	Prec@1 81.250 (78.348)	
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [37][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5791 (0.6706)	Prec@1 71.875 (78.075)	
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [37][40/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4984 (0.6267)	Prec@1 78.125 (77.630)	
2022-01-19 14:39:21 - INFO - TRAINING - Epoch: [37][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5407 (0.6081)	Prec@1 76.562 (78.125)	
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [37][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6485 (0.5967)	Prec@1 75.000 (78.458)	
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [37][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.3507 (0.5765)	Prec@1 85.938 (79.181)	
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [37][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5037 (0.5734)	Prec@1 78.125 (79.128)	
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [37][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4287 (0.5729)	Prec@1 81.250 (78.726)	
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [37][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4043 (0.5729)	Prec@1 81.250 (78.373)	
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [37][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6673 (0.5712)	Prec@1 82.812 (78.449)	
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [37][120/128]	Time 0.004 (0.005)	Data 0.002 (0.003)	Loss 0.5372 (0.5647)	Prec@1 75.000 (78.745)	
2022-01-19 14:39:22 - INFO - EVALUATING - Epoch: [37][0/32]	Time 0.205 (0.205)	Data 0.203 (0.203)	Loss 0.1424 (0.1424)	Prec@1 98.438 (98.438)	
2022-01-19 14:39:22 - INFO - EVALUATING - Epoch: [37][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5330 (0.4134)	Prec@1 85.938 (87.074)	
2022-01-19 14:39:22 - INFO - EVALUATING - Epoch: [37][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3162 (0.4257)	Prec@1 89.062 (85.565)	
2022-01-19 14:39:22 - INFO - EVALUATING - Epoch: [37][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7752 (0.5016)	Prec@1 71.875 (82.006)	
2022-01-19 14:39:22 - INFO - 
 Epoch: 38	Training Loss 0.5598 	Training Prec@1 78.856 	Validation Loss 0.5043 	Validation Prec@1 81.725 	
2022-01-19 14:39:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:22 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [38][0/128]	Time 0.205 (0.205)	Data 0.202 (0.202)	Loss 0.4699 (0.4699)	Prec@1 82.812 (82.812)	
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [38][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.8875 (0.7994)	Prec@1 64.062 (77.983)	
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [38][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7414 (0.8130)	Prec@1 79.688 (75.372)	
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [38][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5550 (0.7445)	Prec@1 76.562 (76.764)	
2022-01-19 14:39:22 - INFO - TRAINING - Epoch: [38][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.1698 (0.7372)	Prec@1 71.875 (77.134)	
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [38][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6779 (0.7377)	Prec@1 75.000 (77.512)	
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [38][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4199 (0.7045)	Prec@1 84.375 (77.818)	
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [38][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4092 (0.6673)	Prec@1 82.812 (78.433)	
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [38][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4770 (0.6366)	Prec@1 78.125 (79.032)	
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [38][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3452 (0.6146)	Prec@1 90.625 (79.430)	
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [38][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5198 (0.6060)	Prec@1 84.375 (79.548)	
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [38][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5453 (0.5973)	Prec@1 73.438 (79.392)	
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [38][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4461 (0.5894)	Prec@1 82.812 (79.636)	
2022-01-19 14:39:23 - INFO - EVALUATING - Epoch: [38][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.1993 (0.1993)	Prec@1 98.438 (98.438)	
2022-01-19 14:39:23 - INFO - EVALUATING - Epoch: [38][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.4739 (0.4202)	Prec@1 84.375 (86.364)	
2022-01-19 14:39:23 - INFO - EVALUATING - Epoch: [38][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3797 (0.4476)	Prec@1 90.625 (84.598)	
2022-01-19 14:39:23 - INFO - EVALUATING - Epoch: [38][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5345 (0.4879)	Prec@1 75.000 (81.250)	
2022-01-19 14:39:23 - INFO - 
 Epoch: 39	Training Loss 0.5850 	Training Prec@1 79.554 	Validation Loss 0.4934 	Validation Prec@1 80.843 	
2022-01-19 14:39:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:23 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [39][0/128]	Time 0.199 (0.199)	Data 0.196 (0.196)	Loss 0.4231 (0.4231)	Prec@1 87.500 (87.500)	
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [39][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4224 (0.7374)	Prec@1 84.375 (75.852)	
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [39][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5200 (0.6323)	Prec@1 81.250 (78.348)	
2022-01-19 14:39:23 - INFO - TRAINING - Epoch: [39][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8188 (0.6254)	Prec@1 68.750 (77.470)	
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [39][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7310 (0.6026)	Prec@1 48.438 (76.181)	
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [39][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.3541 (0.5964)	Prec@1 82.812 (76.532)	
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [39][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3832 (0.5773)	Prec@1 85.938 (76.921)	
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [39][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4856 (0.5590)	Prec@1 78.125 (77.355)	
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [39][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5486 (0.5484)	Prec@1 75.000 (77.623)	
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [39][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4605 (0.5442)	Prec@1 82.812 (77.387)	
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [39][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4249 (0.5382)	Prec@1 81.250 (77.460)	
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [39][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.0436 (0.5462)	Prec@1 71.875 (77.323)	
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [39][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4037 (0.5429)	Prec@1 82.812 (77.221)	
2022-01-19 14:39:24 - INFO - EVALUATING - Epoch: [39][0/32]	Time 0.190 (0.190)	Data 0.189 (0.189)	Loss 0.2459 (0.2459)	Prec@1 92.188 (92.188)	
2022-01-19 14:39:24 - INFO - EVALUATING - Epoch: [39][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.8557 (0.5558)	Prec@1 71.875 (81.392)	
2022-01-19 14:39:24 - INFO - EVALUATING - Epoch: [39][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5185 (0.5933)	Prec@1 81.250 (80.357)	
2022-01-19 14:39:24 - INFO - EVALUATING - Epoch: [39][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8841 (0.6692)	Prec@1 70.312 (77.671)	
2022-01-19 14:39:24 - INFO - 
 Epoch: 40	Training Loss 0.5414 	Training Prec@1 77.288 	Validation Loss 0.6719 	Validation Prec@1 77.609 	
2022-01-19 14:39:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [40][0/128]	Time 0.206 (0.206)	Data 0.202 (0.202)	Loss 0.8226 (0.8226)	Prec@1 68.750 (68.750)	
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [40][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.3962 (0.6230)	Prec@1 85.938 (76.705)	
2022-01-19 14:39:24 - INFO - TRAINING - Epoch: [40][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6842 (0.8041)	Prec@1 76.562 (71.726)	
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [40][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7499 (0.7807)	Prec@1 78.125 (71.573)	
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [40][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.3806 (0.7634)	Prec@1 84.375 (73.056)	
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [40][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8584 (0.7317)	Prec@1 64.062 (73.683)	
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [40][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6666 (0.7069)	Prec@1 79.688 (74.027)	
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [40][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4934 (0.7174)	Prec@1 87.500 (74.560)	
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [40][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4735 (0.7025)	Prec@1 79.688 (75.058)	
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [40][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5318 (0.7192)	Prec@1 85.938 (75.000)	
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [40][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3986 (0.6971)	Prec@1 87.500 (75.789)	
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [40][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5032 (0.6819)	Prec@1 81.250 (75.732)	
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [40][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7841 (0.6741)	Prec@1 70.312 (75.917)	
2022-01-19 14:39:25 - INFO - EVALUATING - Epoch: [40][0/32]	Time 0.222 (0.222)	Data 0.220 (0.220)	Loss 0.1646 (0.1646)	Prec@1 93.750 (93.750)	
2022-01-19 14:39:25 - INFO - EVALUATING - Epoch: [40][10/32]	Time 0.003 (0.023)	Data 0.002 (0.022)	Loss 0.6011 (0.4479)	Prec@1 79.688 (83.381)	
2022-01-19 14:39:25 - INFO - EVALUATING - Epoch: [40][20/32]	Time 0.003 (0.013)	Data 0.002 (0.012)	Loss 0.3143 (0.4887)	Prec@1 87.500 (81.399)	
2022-01-19 14:39:25 - INFO - EVALUATING - Epoch: [40][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 1.0304 (0.5690)	Prec@1 59.375 (77.621)	
2022-01-19 14:39:25 - INFO - 
 Epoch: 41	Training Loss 0.6685 	Training Prec@1 75.891 	Validation Loss 0.5796 	Validation Prec@1 77.119 	
2022-01-19 14:39:25 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:25 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:25 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [41][0/128]	Time 0.191 (0.191)	Data 0.187 (0.187)	Loss 0.4477 (0.4477)	Prec@1 82.812 (82.812)	
2022-01-19 14:39:25 - INFO - TRAINING - Epoch: [41][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 1.7244 (1.3814)	Prec@1 53.125 (66.903)	
2022-01-19 14:39:26 - INFO - TRAINING - Epoch: [41][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5196 (1.1223)	Prec@1 85.938 (72.247)	
2022-01-19 14:39:26 - INFO - TRAINING - Epoch: [41][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8487 (0.9353)	Prec@1 71.875 (73.740)	
2022-01-19 14:39:26 - INFO - TRAINING - Epoch: [41][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 1.6600 (0.9070)	Prec@1 62.500 (73.628)	
2022-01-19 14:39:26 - INFO - TRAINING - Epoch: [41][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.4923 (0.8563)	Prec@1 76.562 (73.468)	
2022-01-19 14:39:26 - INFO - TRAINING - Epoch: [41][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4929 (0.7970)	Prec@1 82.812 (74.565)	
2022-01-19 14:39:26 - INFO - TRAINING - Epoch: [41][70/128]	Time 0.007 (0.007)	Data 0.003 (0.004)	Loss 0.5048 (0.7526)	Prec@1 73.438 (75.066)	
2022-01-19 14:39:26 - INFO - TRAINING - Epoch: [41][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9138 (0.7329)	Prec@1 68.750 (74.865)	
2022-01-19 14:39:26 - INFO - TRAINING - Epoch: [41][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6696 (0.7357)	Prec@1 76.562 (75.189)	
2022-01-19 14:39:26 - INFO - TRAINING - Epoch: [41][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6781 (0.7256)	Prec@1 75.000 (75.650)	
2022-01-19 14:39:26 - INFO - TRAINING - Epoch: [41][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3224 (0.7032)	Prec@1 87.500 (76.197)	
2022-01-19 14:39:26 - INFO - TRAINING - Epoch: [41][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4559 (0.6857)	Prec@1 81.250 (76.537)	
2022-01-19 14:39:26 - INFO - EVALUATING - Epoch: [41][0/32]	Time 0.241 (0.241)	Data 0.240 (0.240)	Loss 0.0853 (0.0853)	Prec@1 98.438 (98.438)	
2022-01-19 14:39:26 - INFO - EVALUATING - Epoch: [41][10/32]	Time 0.003 (0.025)	Data 0.002 (0.023)	Loss 0.7116 (0.4366)	Prec@1 81.250 (88.068)	
2022-01-19 14:39:26 - INFO - EVALUATING - Epoch: [41][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.2765 (0.4834)	Prec@1 90.625 (85.863)	
2022-01-19 14:39:26 - INFO - EVALUATING - Epoch: [41][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 1.1710 (0.5922)	Prec@1 70.312 (82.157)	
2022-01-19 14:39:26 - INFO - 
 Epoch: 42	Training Loss 0.6796 	Training Prec@1 76.638 	Validation Loss 0.6001 	Validation Prec@1 81.970 	
2022-01-19 14:39:26 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:26 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:26 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:26 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.5145 (0.5145)	Prec@1 85.938 (85.938)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.7188 (0.9192)	Prec@1 79.688 (76.562)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6822 (0.7222)	Prec@1 71.875 (78.274)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8633 (0.6577)	Prec@1 75.000 (77.218)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6726 (0.6610)	Prec@1 79.688 (75.762)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.9534 (0.6869)	Prec@1 60.938 (75.582)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3938 (0.6632)	Prec@1 84.375 (76.076)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4881 (0.6372)	Prec@1 71.875 (76.320)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5621 (0.6190)	Prec@1 79.688 (76.389)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4939 (0.6252)	Prec@1 81.250 (76.545)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4990 (0.6160)	Prec@1 79.688 (76.733)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4845 (0.6163)	Prec@1 78.125 (76.633)	
2022-01-19 14:39:27 - INFO - TRAINING - Epoch: [42][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5047 (0.6092)	Prec@1 79.688 (76.640)	
2022-01-19 14:39:27 - INFO - EVALUATING - Epoch: [42][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.1403 (0.1403)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:27 - INFO - EVALUATING - Epoch: [42][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6047 (0.4279)	Prec@1 78.125 (85.653)	
2022-01-19 14:39:27 - INFO - EVALUATING - Epoch: [42][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2636 (0.4942)	Prec@1 93.750 (84.152)	
2022-01-19 14:39:27 - INFO - EVALUATING - Epoch: [42][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.1454 (0.6123)	Prec@1 59.375 (80.292)	
2022-01-19 14:39:27 - INFO - 
 Epoch: 43	Training Loss 0.6114 	Training Prec@1 76.761 	Validation Loss 0.6210 	Validation Prec@1 80.059 	
2022-01-19 14:39:27 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:27 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:27 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][0/128]	Time 0.191 (0.191)	Data 0.187 (0.187)	Loss 0.5492 (0.5492)	Prec@1 73.438 (73.438)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.5279 (0.8763)	Prec@1 78.125 (72.017)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4487 (0.7808)	Prec@1 90.625 (76.711)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5569 (0.6947)	Prec@1 70.312 (76.210)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.3861 (0.6579)	Prec@1 89.062 (76.715)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4489 (0.6492)	Prec@1 84.375 (76.838)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8870 (0.6659)	Prec@1 75.000 (75.359)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 2.0950 (0.6654)	Prec@1 59.375 (75.968)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6921 (0.6807)	Prec@1 73.438 (75.444)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5942 (0.6556)	Prec@1 78.125 (76.150)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4527 (0.6447)	Prec@1 82.812 (75.758)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4668 (0.6371)	Prec@1 79.688 (75.704)	
2022-01-19 14:39:28 - INFO - TRAINING - Epoch: [43][120/128]	Time 0.005 (0.006)	Data 0.002 (0.003)	Loss 0.5155 (0.6299)	Prec@1 78.125 (75.801)	
2022-01-19 14:39:28 - INFO - EVALUATING - Epoch: [43][0/32]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.2238 (0.2238)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:28 - INFO - EVALUATING - Epoch: [43][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5389 (0.4170)	Prec@1 78.125 (84.375)	
2022-01-19 14:39:28 - INFO - EVALUATING - Epoch: [43][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3600 (0.4343)	Prec@1 87.500 (82.812)	
2022-01-19 14:39:28 - INFO - EVALUATING - Epoch: [43][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7450 (0.4785)	Prec@1 57.812 (79.183)	
2022-01-19 14:39:28 - INFO - 
 Epoch: 44	Training Loss 0.6264 	Training Prec@1 75.916 	Validation Loss 0.4844 	Validation Prec@1 78.785 	
2022-01-19 14:39:28 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:28 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:28 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:28 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][0/128]	Time 0.210 (0.210)	Data 0.206 (0.206)	Loss 0.5016 (0.5016)	Prec@1 76.562 (76.562)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][10/128]	Time 0.004 (0.023)	Data 0.002 (0.021)	Loss 0.8671 (0.7970)	Prec@1 75.000 (70.881)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][20/128]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.5277 (0.6878)	Prec@1 81.250 (74.628)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][30/128]	Time 0.004 (0.011)	Data 0.002 (0.009)	Loss 0.4361 (0.6192)	Prec@1 84.375 (76.210)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8672 (0.6198)	Prec@1 71.875 (75.800)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5664 (0.6265)	Prec@1 79.688 (76.593)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][60/128]	Time 0.006 (0.008)	Data 0.003 (0.005)	Loss 0.4229 (0.6052)	Prec@1 82.812 (76.819)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5981 (0.5955)	Prec@1 75.000 (77.047)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.8961 (0.5990)	Prec@1 68.750 (76.717)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3335 (0.6083)	Prec@1 84.375 (76.185)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4797 (0.5991)	Prec@1 76.562 (76.501)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4433 (0.6035)	Prec@1 84.375 (76.098)	
2022-01-19 14:39:29 - INFO - TRAINING - Epoch: [44][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.0307 (0.6262)	Prec@1 73.438 (75.749)	
2022-01-19 14:39:29 - INFO - EVALUATING - Epoch: [44][0/32]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.3422 (0.3422)	Prec@1 79.688 (79.688)	
2022-01-19 14:39:29 - INFO - EVALUATING - Epoch: [44][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6158 (0.5121)	Prec@1 62.500 (67.472)	
2022-01-19 14:39:29 - INFO - EVALUATING - Epoch: [44][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5062 (0.5047)	Prec@1 67.188 (68.899)	
2022-01-19 14:39:29 - INFO - EVALUATING - Epoch: [44][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6256 (0.5161)	Prec@1 65.625 (68.800)	
2022-01-19 14:39:29 - INFO - 
 Epoch: 45	Training Loss 0.6210 	Training Prec@1 75.769 	Validation Loss 0.5154 	Validation Prec@1 69.035 	
2022-01-19 14:39:29 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:29 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:29 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:29 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][0/128]	Time 0.210 (0.210)	Data 0.206 (0.206)	Loss 0.5975 (0.5975)	Prec@1 67.188 (67.188)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.2677 (0.8451)	Prec@1 89.062 (75.710)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][20/128]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.4270 (0.7091)	Prec@1 82.812 (76.935)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.5177 (0.6709)	Prec@1 82.812 (76.109)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.1299 (0.6771)	Prec@1 68.750 (76.486)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5198 (0.6473)	Prec@1 75.000 (76.501)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8752 (0.6441)	Prec@1 76.562 (76.409)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5932 (0.6391)	Prec@1 67.188 (75.946)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4380 (0.6290)	Prec@1 85.938 (76.601)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6523 (0.6710)	Prec@1 82.812 (75.996)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.1784 (0.6730)	Prec@1 59.375 (76.346)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8627 (0.6862)	Prec@1 73.438 (75.479)	
2022-01-19 14:39:30 - INFO - TRAINING - Epoch: [45][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.8125 (0.7056)	Prec@1 76.562 (75.568)	
2022-01-19 14:39:30 - INFO - EVALUATING - Epoch: [45][0/32]	Time 0.209 (0.209)	Data 0.207 (0.207)	Loss 0.2068 (0.2068)	Prec@1 96.875 (96.875)	
2022-01-19 14:39:30 - INFO - EVALUATING - Epoch: [45][10/32]	Time 0.003 (0.022)	Data 0.002 (0.021)	Loss 0.5589 (0.4154)	Prec@1 78.125 (84.375)	
2022-01-19 14:39:30 - INFO - EVALUATING - Epoch: [45][20/32]	Time 0.003 (0.013)	Data 0.002 (0.012)	Loss 0.3249 (0.4302)	Prec@1 89.062 (82.887)	
2022-01-19 14:39:31 - INFO - EVALUATING - Epoch: [45][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7840 (0.4846)	Prec@1 59.375 (78.982)	
2022-01-19 14:39:31 - INFO - 
 Epoch: 46	Training Loss 0.7072 	Training Prec@1 75.046 	Validation Loss 0.4893 	Validation Prec@1 78.589 	
2022-01-19 14:39:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:31 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][0/128]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.5535 (0.5535)	Prec@1 73.438 (73.438)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.4414 (0.8592)	Prec@1 79.688 (74.148)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.7142 (0.7208)	Prec@1 59.375 (75.446)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5381 (0.6925)	Prec@1 75.000 (75.756)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4967 (0.6418)	Prec@1 82.812 (76.639)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4345 (0.6306)	Prec@1 84.375 (76.562)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5287 (0.6626)	Prec@1 78.125 (75.640)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5365 (0.6564)	Prec@1 71.875 (75.506)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6626 (0.6513)	Prec@1 79.688 (75.694)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4452 (0.6362)	Prec@1 75.000 (76.065)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4933 (0.6269)	Prec@1 78.125 (76.145)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 2.7092 (0.6344)	Prec@1 32.812 (75.873)	
2022-01-19 14:39:31 - INFO - TRAINING - Epoch: [46][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.3640 (0.6245)	Prec@1 82.812 (76.304)	
2022-01-19 14:39:32 - INFO - EVALUATING - Epoch: [46][0/32]	Time 0.238 (0.238)	Data 0.236 (0.236)	Loss 0.1605 (0.1605)	Prec@1 98.438 (98.438)	
2022-01-19 14:39:32 - INFO - EVALUATING - Epoch: [46][10/32]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.4767 (0.3969)	Prec@1 82.812 (86.364)	
2022-01-19 14:39:32 - INFO - EVALUATING - Epoch: [46][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.3180 (0.4143)	Prec@1 89.062 (84.301)	
2022-01-19 14:39:32 - INFO - EVALUATING - Epoch: [46][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.7288 (0.4671)	Prec@1 64.062 (80.796)	
2022-01-19 14:39:32 - INFO - 
 Epoch: 47	Training Loss 0.6182 	Training Prec@1 76.565 	Validation Loss 0.4697 	Validation Prec@1 80.598 	
2022-01-19 14:39:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:32 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][0/128]	Time 0.206 (0.206)	Data 0.201 (0.201)	Loss 0.7585 (0.7585)	Prec@1 70.312 (70.312)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.3590 (1.0294)	Prec@1 84.375 (71.733)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.3981 (0.7950)	Prec@1 84.375 (73.884)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.5620 (0.7130)	Prec@1 75.000 (74.899)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4433 (0.6479)	Prec@1 78.125 (76.258)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7428 (0.6107)	Prec@1 78.125 (77.237)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4861 (0.6270)	Prec@1 82.812 (77.228)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4690 (0.6069)	Prec@1 76.562 (77.399)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5325 (0.5973)	Prec@1 78.125 (77.296)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5524 (0.6144)	Prec@1 78.125 (76.837)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5591 (0.5979)	Prec@1 73.438 (77.027)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5569 (0.5902)	Prec@1 76.562 (76.900)	
2022-01-19 14:39:32 - INFO - TRAINING - Epoch: [47][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7396 (0.5831)	Prec@1 79.688 (77.221)	
2022-01-19 14:39:33 - INFO - EVALUATING - Epoch: [47][0/32]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.2275 (0.2275)	Prec@1 95.312 (95.312)	
2022-01-19 14:39:33 - INFO - EVALUATING - Epoch: [47][10/32]	Time 0.003 (0.021)	Data 0.002 (0.019)	Loss 0.4516 (0.3742)	Prec@1 82.812 (85.653)	
2022-01-19 14:39:33 - INFO - EVALUATING - Epoch: [47][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3600 (0.3963)	Prec@1 82.812 (83.631)	
2022-01-19 14:39:33 - INFO - EVALUATING - Epoch: [47][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5356 (0.4337)	Prec@1 75.000 (80.343)	
2022-01-19 14:39:33 - INFO - 
 Epoch: 48	Training Loss 0.5806 	Training Prec@1 77.374 	Validation Loss 0.4358 	Validation Prec@1 80.304 	
2022-01-19 14:39:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:33 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][0/128]	Time 0.242 (0.242)	Data 0.238 (0.238)	Loss 0.3776 (0.3776)	Prec@1 87.500 (87.500)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][10/128]	Time 0.004 (0.026)	Data 0.002 (0.023)	Loss 0.6480 (0.9284)	Prec@1 85.938 (79.972)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.6360 (0.8053)	Prec@1 81.250 (80.432)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][30/128]	Time 0.004 (0.012)	Data 0.002 (0.009)	Loss 1.0274 (0.7644)	Prec@1 75.000 (80.242)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.3594 (0.7018)	Prec@1 85.938 (80.069)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.3480 (0.6445)	Prec@1 84.375 (80.484)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5490 (0.6252)	Prec@1 84.375 (80.251)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.3891 (0.6246)	Prec@1 78.125 (79.732)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4214 (0.6321)	Prec@1 78.125 (79.745)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4023 (0.6113)	Prec@1 85.938 (80.031)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4621 (0.6196)	Prec@1 81.250 (79.579)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4015 (0.6069)	Prec@1 82.812 (79.490)	
2022-01-19 14:39:33 - INFO - TRAINING - Epoch: [48][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3853 (0.5907)	Prec@1 82.812 (79.584)	
2022-01-19 14:39:34 - INFO - EVALUATING - Epoch: [48][0/32]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.1188 (0.1188)	Prec@1 93.750 (93.750)	
2022-01-19 14:39:34 - INFO - EVALUATING - Epoch: [48][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5568 (0.4198)	Prec@1 81.250 (85.227)	
2022-01-19 14:39:34 - INFO - EVALUATING - Epoch: [48][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4145 (0.5127)	Prec@1 82.812 (82.068)	
2022-01-19 14:39:34 - INFO - EVALUATING - Epoch: [48][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8606 (0.6102)	Prec@1 73.438 (79.083)	
2022-01-19 14:39:34 - INFO - 
 Epoch: 49	Training Loss 0.5910 	Training Prec@1 79.113 	Validation Loss 0.6253 	Validation Prec@1 78.540 	
2022-01-19 14:39:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:39:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:39:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:39:34 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][0/128]	Time 0.246 (0.246)	Data 0.243 (0.243)	Loss 0.4880 (0.4880)	Prec@1 78.125 (78.125)	
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][10/128]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.6447 (0.8497)	Prec@1 71.875 (73.722)	
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][20/128]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.6825 (0.7351)	Prec@1 73.438 (73.810)	
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.3199 (0.6584)	Prec@1 84.375 (75.101)	
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6534 (0.6236)	Prec@1 76.562 (75.457)	
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][50/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5333 (0.6434)	Prec@1 87.500 (74.203)	
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5020 (0.6634)	Prec@1 79.688 (74.206)	
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][70/128]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.5940 (0.6442)	Prec@1 68.750 (74.736)	
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5997 (0.6289)	Prec@1 81.250 (74.865)	
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.8206 (0.6402)	Prec@1 68.750 (74.554)	
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.1570 (0.6462)	Prec@1 67.188 (74.830)	
2022-01-19 14:39:34 - INFO - TRAINING - Epoch: [49][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6343 (0.6385)	Prec@1 76.562 (74.958)	
2022-01-19 14:39:35 - INFO - TRAINING - Epoch: [49][120/128]	Time 0.006 (0.006)	Data 0.003 (0.004)	Loss 0.5778 (0.6260)	Prec@1 76.562 (75.362)	
2022-01-19 14:39:35 - INFO - EVALUATING - Epoch: [49][0/32]	Time 0.237 (0.237)	Data 0.235 (0.235)	Loss 0.2216 (0.2216)	Prec@1 95.312 (95.312)	
2022-01-19 14:39:35 - INFO - EVALUATING - Epoch: [49][10/32]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.9883 (0.8694)	Prec@1 78.125 (82.102)	
2022-01-19 14:39:35 - INFO - EVALUATING - Epoch: [49][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.7004 (1.0029)	Prec@1 87.500 (80.357)	
2022-01-19 14:39:35 - INFO - EVALUATING - Epoch: [49][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 2.5254 (1.2367)	Prec@1 60.938 (76.663)	
2022-01-19 14:39:35 - INFO - 
 Epoch: 50	Training Loss 0.6417 	Training Prec@1 75.144 	Validation Loss 1.2612 	Validation Prec@1 76.139 	
