2022-01-19 14:40:42 - INFO - saving to ./results/medium/quantise/q6/penn-ml/liver-disorder/liver-disorder_test1/
2022-01-19 14:40:42 - DEBUG - run arguments: Namespace(config='./configs/config_medium.json', data='../../paper_bench/complete/quantise/q6/penn-ml/liver-disorder/liver-disorder_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/medium/quantise/q6/penn-ml/liver-disorder/liver-disorder_test1/', test='../../paper_bench/cv/test/quantise/q6/penn-ml/liver-disorder/liver-disorder_test1_data.csv', train='../../paper_bench/cv/train/quantise/q6/penn-ml/liver-disorder/liver-disorder_train1_data.csv')
2022-01-19 14:40:42 - INFO - creating model mlp_binary
2022-01-19 14:40:42 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [32, 16, 8, 2]}
2022-01-19 14:40:42 - INFO - number of parameters: 1978
2022-01-19 14:40:42 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-19 14:40:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:43 - INFO - TRAINING - Epoch: [0][0/5]	Time 0.206 (0.206)	Data 0.199 (0.199)	Loss 2.3484 (2.3484)	Prec@1 48.438 (48.438)	
2022-01-19 14:40:43 - INFO - EVALUATING - Epoch: [0][0/2]	Time 0.202 (0.202)	Data 0.200 (0.200)	Loss 1.8432 (1.8432)	Prec@1 50.000 (50.000)	
2022-01-19 14:40:43 - INFO - 
 Epoch: 1	Training Loss 1.7157 	Training Prec@1 51.087 	Validation Loss 1.7473 	Validation Prec@1 52.174 	
2022-01-19 14:40:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:43 - INFO - TRAINING - Epoch: [1][0/5]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 1.5475 (1.5475)	Prec@1 54.688 (54.688)	
2022-01-19 14:40:43 - INFO - EVALUATING - Epoch: [1][0/2]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 1.6295 (1.6295)	Prec@1 51.562 (51.562)	
2022-01-19 14:40:43 - INFO - 
 Epoch: 2	Training Loss 1.3555 	Training Prec@1 53.261 	Validation Loss 1.6285 	Validation Prec@1 52.174 	
2022-01-19 14:40:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:44 - INFO - TRAINING - Epoch: [2][0/5]	Time 0.193 (0.193)	Data 0.189 (0.189)	Loss 1.0767 (1.0767)	Prec@1 68.750 (68.750)	
2022-01-19 14:40:44 - INFO - EVALUATING - Epoch: [2][0/2]	Time 0.189 (0.189)	Data 0.188 (0.188)	Loss 1.3515 (1.3515)	Prec@1 42.188 (42.188)	
2022-01-19 14:40:44 - INFO - 
 Epoch: 3	Training Loss 1.1736 	Training Prec@1 61.232 	Validation Loss 1.3201 	Validation Prec@1 43.478 	
2022-01-19 14:40:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:44 - INFO - TRAINING - Epoch: [3][0/5]	Time 0.194 (0.194)	Data 0.191 (0.191)	Loss 1.1272 (1.1272)	Prec@1 56.250 (56.250)	
2022-01-19 14:40:44 - INFO - EVALUATING - Epoch: [3][0/2]	Time 0.240 (0.240)	Data 0.239 (0.239)	Loss 1.6410 (1.6410)	Prec@1 45.312 (45.312)	
2022-01-19 14:40:44 - INFO - 
 Epoch: 4	Training Loss 1.0979 	Training Prec@1 63.043 	Validation Loss 1.5884 	Validation Prec@1 46.377 	
2022-01-19 14:40:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:44 - INFO - TRAINING - Epoch: [4][0/5]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 1.2182 (1.2182)	Prec@1 51.562 (51.562)	
2022-01-19 14:40:45 - INFO - EVALUATING - Epoch: [4][0/2]	Time 0.251 (0.251)	Data 0.249 (0.249)	Loss 2.1387 (2.1387)	Prec@1 54.688 (54.688)	
2022-01-19 14:40:45 - INFO - 
 Epoch: 5	Training Loss 1.5408 	Training Prec@1 65.217 	Validation Loss 2.1513 	Validation Prec@1 53.623 	
2022-01-19 14:40:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:45 - INFO - TRAINING - Epoch: [5][0/5]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 1.5837 (1.5837)	Prec@1 67.188 (67.188)	
2022-01-19 14:40:45 - INFO - EVALUATING - Epoch: [5][0/2]	Time 0.236 (0.236)	Data 0.234 (0.234)	Loss 1.4065 (1.4065)	Prec@1 54.688 (54.688)	
2022-01-19 14:40:45 - INFO - 
 Epoch: 6	Training Loss 1.0854 	Training Prec@1 63.043 	Validation Loss 1.4329 	Validation Prec@1 55.072 	
2022-01-19 14:40:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:45 - INFO - TRAINING - Epoch: [6][0/5]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.8852 (0.8852)	Prec@1 67.188 (67.188)	
2022-01-19 14:40:46 - INFO - EVALUATING - Epoch: [6][0/2]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 1.2445 (1.2445)	Prec@1 59.375 (59.375)	
2022-01-19 14:40:46 - INFO - 
 Epoch: 7	Training Loss 1.2199 	Training Prec@1 60.870 	Validation Loss 1.2703 	Validation Prec@1 56.522 	
2022-01-19 14:40:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:46 - INFO - TRAINING - Epoch: [7][0/5]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 0.7412 (0.7412)	Prec@1 76.562 (76.562)	
2022-01-19 14:40:46 - INFO - EVALUATING - Epoch: [7][0/2]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 1.0882 (1.0882)	Prec@1 50.000 (50.000)	
2022-01-19 14:40:46 - INFO - 
 Epoch: 8	Training Loss 0.9716 	Training Prec@1 64.493 	Validation Loss 1.0909 	Validation Prec@1 49.275 	
2022-01-19 14:40:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:46 - INFO - TRAINING - Epoch: [8][0/5]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.7000 (0.7000)	Prec@1 68.750 (68.750)	
2022-01-19 14:40:47 - INFO - EVALUATING - Epoch: [8][0/2]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.9688 (0.9688)	Prec@1 53.125 (53.125)	
2022-01-19 14:40:47 - INFO - 
 Epoch: 9	Training Loss 1.2242 	Training Prec@1 60.507 	Validation Loss 0.9864 	Validation Prec@1 53.623 	
2022-01-19 14:40:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:47 - INFO - TRAINING - Epoch: [9][0/5]	Time 0.208 (0.208)	Data 0.204 (0.204)	Loss 1.0445 (1.0445)	Prec@1 54.688 (54.688)	
2022-01-19 14:40:47 - INFO - EVALUATING - Epoch: [9][0/2]	Time 0.181 (0.181)	Data 0.179 (0.179)	Loss 1.3869 (1.3869)	Prec@1 59.375 (59.375)	
2022-01-19 14:40:47 - INFO - 
 Epoch: 10	Training Loss 1.1793 	Training Prec@1 65.580 	Validation Loss 1.4089 	Validation Prec@1 59.420 	
2022-01-19 14:40:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:47 - INFO - TRAINING - Epoch: [10][0/5]	Time 0.203 (0.203)	Data 0.200 (0.200)	Loss 1.2603 (1.2603)	Prec@1 56.250 (56.250)	
2022-01-19 14:40:47 - INFO - EVALUATING - Epoch: [10][0/2]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 1.2413 (1.2413)	Prec@1 43.750 (43.750)	
2022-01-19 14:40:47 - INFO - 
 Epoch: 11	Training Loss 1.2983 	Training Prec@1 59.783 	Validation Loss 1.2074 	Validation Prec@1 44.928 	
2022-01-19 14:40:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:48 - INFO - TRAINING - Epoch: [11][0/5]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 0.6837 (0.6837)	Prec@1 68.750 (68.750)	
2022-01-19 14:40:48 - INFO - EVALUATING - Epoch: [11][0/2]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 1.7775 (1.7775)	Prec@1 56.250 (56.250)	
2022-01-19 14:40:48 - INFO - 
 Epoch: 12	Training Loss 1.0305 	Training Prec@1 62.681 	Validation Loss 1.8391 	Validation Prec@1 55.072 	
2022-01-19 14:40:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:48 - INFO - TRAINING - Epoch: [12][0/5]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 1.3271 (1.3271)	Prec@1 75.000 (75.000)	
2022-01-19 14:40:48 - INFO - EVALUATING - Epoch: [12][0/2]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 2.1890 (2.1890)	Prec@1 53.125 (53.125)	
2022-01-19 14:40:48 - INFO - 
 Epoch: 13	Training Loss 1.8021 	Training Prec@1 55.072 	Validation Loss 2.2116 	Validation Prec@1 53.623 	
2022-01-19 14:40:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:49 - INFO - TRAINING - Epoch: [13][0/5]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 1.0798 (1.0798)	Prec@1 75.000 (75.000)	
2022-01-19 14:40:49 - INFO - EVALUATING - Epoch: [13][0/2]	Time 0.186 (0.186)	Data 0.184 (0.184)	Loss 1.9665 (1.9665)	Prec@1 50.000 (50.000)	
2022-01-19 14:40:49 - INFO - 
 Epoch: 14	Training Loss 0.9493 	Training Prec@1 64.130 	Validation Loss 1.9479 	Validation Prec@1 49.275 	
2022-01-19 14:40:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:49 - INFO - TRAINING - Epoch: [14][0/5]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 1.0999 (1.0999)	Prec@1 65.625 (65.625)	
2022-01-19 14:40:49 - INFO - EVALUATING - Epoch: [14][0/2]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 1.1206 (1.1206)	Prec@1 64.062 (64.062)	
2022-01-19 14:40:49 - INFO - 
 Epoch: 15	Training Loss 1.1508 	Training Prec@1 57.971 	Validation Loss 1.2214 	Validation Prec@1 62.319 	
2022-01-19 14:40:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:49 - INFO - TRAINING - Epoch: [15][0/5]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.8895 (0.8895)	Prec@1 62.500 (62.500)	
2022-01-19 14:40:50 - INFO - EVALUATING - Epoch: [15][0/2]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 2.3826 (2.3826)	Prec@1 54.688 (54.688)	
2022-01-19 14:40:50 - INFO - 
 Epoch: 16	Training Loss 0.7833 	Training Prec@1 64.493 	Validation Loss 2.4645 	Validation Prec@1 53.623 	
2022-01-19 14:40:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:50 - INFO - TRAINING - Epoch: [16][0/5]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 1.0147 (1.0147)	Prec@1 75.000 (75.000)	
2022-01-19 14:40:50 - INFO - EVALUATING - Epoch: [16][0/2]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 1.5204 (1.5204)	Prec@1 64.062 (64.062)	
2022-01-19 14:40:50 - INFO - 
 Epoch: 17	Training Loss 1.0074 	Training Prec@1 59.058 	Validation Loss 1.5524 	Validation Prec@1 62.319 	
2022-01-19 14:40:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:51 - INFO - TRAINING - Epoch: [17][0/5]	Time 0.370 (0.370)	Data 0.283 (0.283)	Loss 1.9840 (1.9840)	Prec@1 64.062 (64.062)	
2022-01-19 14:40:51 - INFO - EVALUATING - Epoch: [17][0/2]	Time 0.211 (0.211)	Data 0.209 (0.209)	Loss 1.1725 (1.1725)	Prec@1 68.750 (68.750)	
2022-01-19 14:40:51 - INFO - 
 Epoch: 18	Training Loss 1.2560 	Training Prec@1 65.580 	Validation Loss 1.3091 	Validation Prec@1 65.217 	
2022-01-19 14:40:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:51 - INFO - TRAINING - Epoch: [18][0/5]	Time 0.139 (0.139)	Data 0.135 (0.135)	Loss 0.6582 (0.6582)	Prec@1 82.812 (82.812)	
2022-01-19 14:40:51 - INFO - EVALUATING - Epoch: [18][0/2]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 1.7856 (1.7856)	Prec@1 64.062 (64.062)	
2022-01-19 14:40:51 - INFO - 
 Epoch: 19	Training Loss 1.1466 	Training Prec@1 61.594 	Validation Loss 1.9692 	Validation Prec@1 62.319 	
2022-01-19 14:40:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:51 - INFO - TRAINING - Epoch: [19][0/5]	Time 0.209 (0.209)	Data 0.204 (0.204)	Loss 0.9608 (0.9608)	Prec@1 68.750 (68.750)	
2022-01-19 14:40:52 - INFO - EVALUATING - Epoch: [19][0/2]	Time 0.172 (0.172)	Data 0.170 (0.170)	Loss 1.0472 (1.0472)	Prec@1 59.375 (59.375)	
2022-01-19 14:40:52 - INFO - 
 Epoch: 20	Training Loss 1.0082 	Training Prec@1 71.739 	Validation Loss 1.0366 	Validation Prec@1 59.420 	
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:52 - INFO - TRAINING - Epoch: [20][0/5]	Time 0.167 (0.167)	Data 0.161 (0.161)	Loss 0.7450 (0.7450)	Prec@1 71.875 (71.875)	
2022-01-19 14:40:52 - INFO - EVALUATING - Epoch: [20][0/2]	Time 0.180 (0.180)	Data 0.178 (0.178)	Loss 1.0973 (1.0973)	Prec@1 53.125 (53.125)	
2022-01-19 14:40:52 - INFO - 
 Epoch: 21	Training Loss 0.6200 	Training Prec@1 77.174 	Validation Loss 1.1281 	Validation Prec@1 50.725 	
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:52 - INFO - TRAINING - Epoch: [21][0/5]	Time 0.166 (0.166)	Data 0.161 (0.161)	Loss 0.6669 (0.6669)	Prec@1 75.000 (75.000)	
2022-01-19 14:40:52 - INFO - EVALUATING - Epoch: [21][0/2]	Time 0.168 (0.168)	Data 0.166 (0.166)	Loss 1.0515 (1.0515)	Prec@1 57.812 (57.812)	
2022-01-19 14:40:52 - INFO - 
 Epoch: 22	Training Loss 0.7288 	Training Prec@1 63.043 	Validation Loss 1.0857 	Validation Prec@1 55.072 	
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:53 - INFO - TRAINING - Epoch: [22][0/5]	Time 0.173 (0.173)	Data 0.169 (0.169)	Loss 0.7844 (0.7844)	Prec@1 68.750 (68.750)	
2022-01-19 14:40:53 - INFO - EVALUATING - Epoch: [22][0/2]	Time 0.173 (0.173)	Data 0.171 (0.171)	Loss 0.9030 (0.9030)	Prec@1 68.750 (68.750)	
2022-01-19 14:40:53 - INFO - 
 Epoch: 23	Training Loss 0.6570 	Training Prec@1 67.754 	Validation Loss 1.0027 	Validation Prec@1 65.217 	
2022-01-19 14:40:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:53 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:53 - INFO - TRAINING - Epoch: [23][0/5]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.5833 (0.5833)	Prec@1 81.250 (81.250)	
2022-01-19 14:40:53 - INFO - EVALUATING - Epoch: [23][0/2]	Time 0.237 (0.237)	Data 0.235 (0.235)	Loss 1.1255 (1.1255)	Prec@1 59.375 (59.375)	
2022-01-19 14:40:53 - INFO - 
 Epoch: 24	Training Loss 0.5864 	Training Prec@1 75.000 	Validation Loss 1.2176 	Validation Prec@1 57.971 	
2022-01-19 14:40:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:53 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:54 - INFO - TRAINING - Epoch: [24][0/5]	Time 0.246 (0.246)	Data 0.241 (0.241)	Loss 0.7807 (0.7807)	Prec@1 67.188 (67.188)	
2022-01-19 14:40:54 - INFO - EVALUATING - Epoch: [24][0/2]	Time 0.232 (0.232)	Data 0.231 (0.231)	Loss 0.9900 (0.9900)	Prec@1 67.188 (67.188)	
2022-01-19 14:40:54 - INFO - 
 Epoch: 25	Training Loss 0.9184 	Training Prec@1 62.319 	Validation Loss 1.0811 	Validation Prec@1 63.768 	
2022-01-19 14:40:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:54 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:54 - INFO - TRAINING - Epoch: [25][0/5]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.7045 (0.7045)	Prec@1 76.562 (76.562)	
2022-01-19 14:40:54 - INFO - EVALUATING - Epoch: [25][0/2]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.8811 (0.8811)	Prec@1 62.500 (62.500)	
2022-01-19 14:40:54 - INFO - 
 Epoch: 26	Training Loss 0.6834 	Training Prec@1 70.290 	Validation Loss 0.9827 	Validation Prec@1 59.420 	
2022-01-19 14:40:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:54 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:55 - INFO - TRAINING - Epoch: [26][0/5]	Time 0.237 (0.237)	Data 0.233 (0.233)	Loss 0.5696 (0.5696)	Prec@1 71.875 (71.875)	
2022-01-19 14:40:55 - INFO - EVALUATING - Epoch: [26][0/2]	Time 0.185 (0.185)	Data 0.183 (0.183)	Loss 1.0089 (1.0089)	Prec@1 67.188 (67.188)	
2022-01-19 14:40:55 - INFO - 
 Epoch: 27	Training Loss 0.6099 	Training Prec@1 73.188 	Validation Loss 1.1314 	Validation Prec@1 63.768 	
2022-01-19 14:40:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:55 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:55 - INFO - TRAINING - Epoch: [27][0/5]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.7593 (0.7593)	Prec@1 73.438 (73.438)	
2022-01-19 14:40:55 - INFO - EVALUATING - Epoch: [27][0/2]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.8282 (0.8282)	Prec@1 65.625 (65.625)	
2022-01-19 14:40:55 - INFO - 
 Epoch: 28	Training Loss 0.6018 	Training Prec@1 72.826 	Validation Loss 0.8711 	Validation Prec@1 63.768 	
2022-01-19 14:40:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:55 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:55 - INFO - TRAINING - Epoch: [28][0/5]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.6074 (0.6074)	Prec@1 75.000 (75.000)	
2022-01-19 14:40:56 - INFO - EVALUATING - Epoch: [28][0/2]	Time 0.195 (0.195)	Data 0.192 (0.192)	Loss 1.0235 (1.0235)	Prec@1 68.750 (68.750)	
2022-01-19 14:40:56 - INFO - 
 Epoch: 29	Training Loss 0.6341 	Training Prec@1 75.000 	Validation Loss 1.0776 	Validation Prec@1 66.667 	
2022-01-19 14:40:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:56 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:56 - INFO - TRAINING - Epoch: [29][0/5]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.9582 (0.9582)	Prec@1 65.625 (65.625)	
2022-01-19 14:40:56 - INFO - EVALUATING - Epoch: [29][0/2]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 1.3777 (1.3777)	Prec@1 64.062 (64.062)	
2022-01-19 14:40:56 - INFO - 
 Epoch: 30	Training Loss 0.7469 	Training Prec@1 64.493 	Validation Loss 1.5521 	Validation Prec@1 60.870 	
2022-01-19 14:40:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:56 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:56 - INFO - TRAINING - Epoch: [30][0/5]	Time 0.195 (0.195)	Data 0.191 (0.191)	Loss 0.3461 (0.3461)	Prec@1 92.188 (92.188)	
2022-01-19 14:40:57 - INFO - EVALUATING - Epoch: [30][0/2]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.9003 (0.9003)	Prec@1 60.938 (60.938)	
2022-01-19 14:40:57 - INFO - 
 Epoch: 31	Training Loss 0.4866 	Training Prec@1 76.449 	Validation Loss 0.9989 	Validation Prec@1 57.971 	
2022-01-19 14:40:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:57 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:57 - INFO - TRAINING - Epoch: [31][0/5]	Time 0.248 (0.248)	Data 0.244 (0.244)	Loss 0.3246 (0.3246)	Prec@1 87.500 (87.500)	
2022-01-19 14:40:57 - INFO - EVALUATING - Epoch: [31][0/2]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.8763 (0.8763)	Prec@1 60.938 (60.938)	
2022-01-19 14:40:57 - INFO - 
 Epoch: 32	Training Loss 0.5782 	Training Prec@1 76.812 	Validation Loss 0.9064 	Validation Prec@1 59.420 	
2022-01-19 14:40:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:57 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:57 - INFO - TRAINING - Epoch: [32][0/5]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.5530 (0.5530)	Prec@1 73.438 (73.438)	
2022-01-19 14:40:58 - INFO - EVALUATING - Epoch: [32][0/2]	Time 0.200 (0.200)	Data 0.199 (0.199)	Loss 0.9304 (0.9304)	Prec@1 57.812 (57.812)	
2022-01-19 14:40:58 - INFO - 
 Epoch: 33	Training Loss 0.5958 	Training Prec@1 77.174 	Validation Loss 1.0005 	Validation Prec@1 55.072 	
2022-01-19 14:40:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:58 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:58 - INFO - TRAINING - Epoch: [33][0/5]	Time 0.217 (0.217)	Data 0.213 (0.213)	Loss 0.2894 (0.2894)	Prec@1 90.625 (90.625)	
2022-01-19 14:40:58 - INFO - EVALUATING - Epoch: [33][0/2]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 1.2480 (1.2480)	Prec@1 54.688 (54.688)	
2022-01-19 14:40:58 - INFO - 
 Epoch: 34	Training Loss 0.5612 	Training Prec@1 81.159 	Validation Loss 1.3044 	Validation Prec@1 53.623 	
2022-01-19 14:40:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:58 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:58 - INFO - TRAINING - Epoch: [34][0/5]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 0.7913 (0.7913)	Prec@1 76.562 (76.562)	
2022-01-19 14:40:59 - INFO - EVALUATING - Epoch: [34][0/2]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.7411 (0.7411)	Prec@1 60.938 (60.938)	
2022-01-19 14:40:59 - INFO - 
 Epoch: 35	Training Loss 0.6803 	Training Prec@1 77.536 	Validation Loss 0.7454 	Validation Prec@1 59.420 	
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:59 - INFO - TRAINING - Epoch: [35][0/5]	Time 0.212 (0.212)	Data 0.208 (0.208)	Loss 0.6051 (0.6051)	Prec@1 79.688 (79.688)	
2022-01-19 14:40:59 - INFO - EVALUATING - Epoch: [35][0/2]	Time 0.201 (0.201)	Data 0.200 (0.200)	Loss 1.1262 (1.1262)	Prec@1 53.125 (53.125)	
2022-01-19 14:40:59 - INFO - 
 Epoch: 36	Training Loss 0.6489 	Training Prec@1 79.348 	Validation Loss 1.1790 	Validation Prec@1 52.174 	
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:40:59 - INFO - TRAINING - Epoch: [36][0/5]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.6044 (0.6044)	Prec@1 78.125 (78.125)	
2022-01-19 14:40:59 - INFO - EVALUATING - Epoch: [36][0/2]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 1.4427 (1.4427)	Prec@1 62.500 (62.500)	
2022-01-19 14:40:59 - INFO - 
 Epoch: 37	Training Loss 0.5818 	Training Prec@1 81.884 	Validation Loss 1.5116 	Validation Prec@1 60.870 	
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:40:59 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:00 - INFO - TRAINING - Epoch: [37][0/5]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.6103 (0.6103)	Prec@1 78.125 (78.125)	
2022-01-19 14:41:00 - INFO - EVALUATING - Epoch: [37][0/2]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 1.3262 (1.3262)	Prec@1 62.500 (62.500)	
2022-01-19 14:41:00 - INFO - 
 Epoch: 38	Training Loss 0.4895 	Training Prec@1 81.522 	Validation Loss 1.4284 	Validation Prec@1 60.870 	
2022-01-19 14:41:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:00 - INFO - TRAINING - Epoch: [38][0/5]	Time 0.246 (0.246)	Data 0.242 (0.242)	Loss 0.5005 (0.5005)	Prec@1 79.688 (79.688)	
2022-01-19 14:41:00 - INFO - EVALUATING - Epoch: [38][0/2]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 1.5832 (1.5832)	Prec@1 59.375 (59.375)	
2022-01-19 14:41:00 - INFO - 
 Epoch: 39	Training Loss 0.5528 	Training Prec@1 78.261 	Validation Loss 1.6641 	Validation Prec@1 57.971 	
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:01 - INFO - TRAINING - Epoch: [39][0/5]	Time 0.216 (0.216)	Data 0.212 (0.212)	Loss 0.5357 (0.5357)	Prec@1 84.375 (84.375)	
2022-01-19 14:41:01 - INFO - EVALUATING - Epoch: [39][0/2]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.9389 (0.9389)	Prec@1 60.938 (60.938)	
2022-01-19 14:41:01 - INFO - 
 Epoch: 40	Training Loss 0.6086 	Training Prec@1 78.623 	Validation Loss 0.9492 	Validation Prec@1 59.420 	
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:01 - INFO - TRAINING - Epoch: [40][0/5]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 0.4269 (0.4269)	Prec@1 84.375 (84.375)	
2022-01-19 14:41:01 - INFO - EVALUATING - Epoch: [40][0/2]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 2.1000 (2.1000)	Prec@1 59.375 (59.375)	
2022-01-19 14:41:01 - INFO - 
 Epoch: 41	Training Loss 0.5435 	Training Prec@1 78.261 	Validation Loss 2.1287 	Validation Prec@1 59.420 	
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:02 - INFO - TRAINING - Epoch: [41][0/5]	Time 0.195 (0.195)	Data 0.191 (0.191)	Loss 0.8411 (0.8411)	Prec@1 79.688 (79.688)	
2022-01-19 14:41:02 - INFO - EVALUATING - Epoch: [41][0/2]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 2.0528 (2.0528)	Prec@1 60.938 (60.938)	
2022-01-19 14:41:02 - INFO - 
 Epoch: 42	Training Loss 0.6267 	Training Prec@1 76.087 	Validation Loss 2.0850 	Validation Prec@1 60.870 	
2022-01-19 14:41:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:02 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:02 - INFO - TRAINING - Epoch: [42][0/5]	Time 0.247 (0.247)	Data 0.244 (0.244)	Loss 0.3795 (0.3795)	Prec@1 90.625 (90.625)	
2022-01-19 14:41:02 - INFO - EVALUATING - Epoch: [42][0/2]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 1.3344 (1.3344)	Prec@1 60.938 (60.938)	
2022-01-19 14:41:02 - INFO - 
 Epoch: 43	Training Loss 0.4969 	Training Prec@1 82.609 	Validation Loss 1.3405 	Validation Prec@1 59.420 	
2022-01-19 14:41:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:02 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:03 - INFO - TRAINING - Epoch: [43][0/5]	Time 0.224 (0.224)	Data 0.220 (0.220)	Loss 0.6555 (0.6555)	Prec@1 79.688 (79.688)	
2022-01-19 14:41:03 - INFO - EVALUATING - Epoch: [43][0/2]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 1.3452 (1.3452)	Prec@1 56.250 (56.250)	
2022-01-19 14:41:03 - INFO - 
 Epoch: 44	Training Loss 0.5300 	Training Prec@1 80.435 	Validation Loss 1.3701 	Validation Prec@1 56.522 	
2022-01-19 14:41:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:03 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:03 - INFO - TRAINING - Epoch: [44][0/5]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.4083 (0.4083)	Prec@1 84.375 (84.375)	
2022-01-19 14:41:03 - INFO - EVALUATING - Epoch: [44][0/2]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 1.4342 (1.4342)	Prec@1 59.375 (59.375)	
2022-01-19 14:41:03 - INFO - 
 Epoch: 45	Training Loss 0.5516 	Training Prec@1 80.797 	Validation Loss 1.4742 	Validation Prec@1 56.522 	
2022-01-19 14:41:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:03 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:04 - INFO - TRAINING - Epoch: [45][0/5]	Time 0.192 (0.192)	Data 0.188 (0.188)	Loss 0.3442 (0.3442)	Prec@1 87.500 (87.500)	
2022-01-19 14:41:04 - INFO - EVALUATING - Epoch: [45][0/2]	Time 0.185 (0.185)	Data 0.183 (0.183)	Loss 2.2028 (2.2028)	Prec@1 57.812 (57.812)	
2022-01-19 14:41:04 - INFO - 
 Epoch: 46	Training Loss 0.6497 	Training Prec@1 73.913 	Validation Loss 2.2335 	Validation Prec@1 56.522 	
2022-01-19 14:41:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:04 - INFO - TRAINING - Epoch: [46][0/5]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.4702 (0.4702)	Prec@1 90.625 (90.625)	
2022-01-19 14:41:04 - INFO - EVALUATING - Epoch: [46][0/2]	Time 0.237 (0.237)	Data 0.236 (0.236)	Loss 1.4219 (1.4219)	Prec@1 56.250 (56.250)	
2022-01-19 14:41:04 - INFO - 
 Epoch: 47	Training Loss 0.4947 	Training Prec@1 85.145 	Validation Loss 1.4379 	Validation Prec@1 55.072 	
2022-01-19 14:41:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:05 - INFO - TRAINING - Epoch: [47][0/5]	Time 0.206 (0.206)	Data 0.202 (0.202)	Loss 0.5002 (0.5002)	Prec@1 82.812 (82.812)	
2022-01-19 14:41:05 - INFO - EVALUATING - Epoch: [47][0/2]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 0.8614 (0.8614)	Prec@1 64.062 (64.062)	
2022-01-19 14:41:05 - INFO - 
 Epoch: 48	Training Loss 0.6931 	Training Prec@1 73.913 	Validation Loss 0.8927 	Validation Prec@1 62.319 	
2022-01-19 14:41:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:05 - INFO - TRAINING - Epoch: [48][0/5]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.4239 (0.4239)	Prec@1 84.375 (84.375)	
2022-01-19 14:41:05 - INFO - EVALUATING - Epoch: [48][0/2]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 1.0283 (1.0283)	Prec@1 60.938 (60.938)	
2022-01-19 14:41:05 - INFO - 
 Epoch: 49	Training Loss 0.5789 	Training Prec@1 80.797 	Validation Loss 1.1112 	Validation Prec@1 59.420 	
2022-01-19 14:41:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:41:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:41:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:41:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:41:06 - INFO - TRAINING - Epoch: [49][0/5]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.4529 (0.4529)	Prec@1 76.562 (76.562)	
2022-01-19 14:41:06 - INFO - EVALUATING - Epoch: [49][0/2]	Time 0.185 (0.185)	Data 0.183 (0.183)	Loss 1.3121 (1.3121)	Prec@1 59.375 (59.375)	
2022-01-19 14:41:06 - INFO - 
 Epoch: 50	Training Loss 0.5305 	Training Prec@1 77.899 	Validation Loss 1.3580 	Validation Prec@1 57.971 	
