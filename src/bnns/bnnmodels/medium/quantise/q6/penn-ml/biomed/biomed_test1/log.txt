2022-01-19 14:43:32 - INFO - saving to ./results/medium/quantise/q6/penn-ml/biomed/biomed_test1/
2022-01-19 14:43:32 - DEBUG - run arguments: Namespace(config='./configs/config_medium.json', data='../../paper_bench/complete/quantise/q6/penn-ml/biomed/biomed_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/medium/quantise/q6/penn-ml/biomed/biomed_test1/', test='../../paper_bench/cv/test/quantise/q6/penn-ml/biomed/biomed_test1_data.csv', train='../../paper_bench/cv/train/quantise/q6/penn-ml/biomed/biomed_train1_data.csv')
2022-01-19 14:43:32 - INFO - creating model mlp_binary
2022-01-19 14:43:32 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [32, 16, 8, 2]}
2022-01-19 14:43:32 - INFO - number of parameters: 2362
2022-01-19 14:43:32 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-19 14:43:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:32 - INFO - TRAINING - Epoch: [0][0/3]	Time 0.206 (0.206)	Data 0.199 (0.199)	Loss 2.5558 (2.5558)	Prec@1 57.812 (57.812)	
2022-01-19 14:43:33 - INFO - EVALUATING - Epoch: [0][0/1]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 1.4777 (1.4777)	Prec@1 64.286 (64.286)	
2022-01-19 14:43:33 - INFO - 
 Epoch: 1	Training Loss 2.1321 	Training Prec@1 55.689 	Validation Loss 1.4777 	Validation Prec@1 64.286 	
2022-01-19 14:43:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:33 - INFO - TRAINING - Epoch: [1][0/3]	Time 0.194 (0.194)	Data 0.189 (0.189)	Loss 1.7283 (1.7283)	Prec@1 42.188 (42.188)	
2022-01-19 14:43:33 - INFO - EVALUATING - Epoch: [1][0/1]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.9051 (0.9051)	Prec@1 69.048 (69.048)	
2022-01-19 14:43:33 - INFO - 
 Epoch: 2	Training Loss 1.1000 	Training Prec@1 65.269 	Validation Loss 0.9051 	Validation Prec@1 69.048 	
2022-01-19 14:43:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:33 - INFO - TRAINING - Epoch: [2][0/3]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.4440 (0.4440)	Prec@1 78.125 (78.125)	
2022-01-19 14:43:34 - INFO - EVALUATING - Epoch: [2][0/1]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.5500 (0.5500)	Prec@1 78.571 (78.571)	
2022-01-19 14:43:34 - INFO - 
 Epoch: 3	Training Loss 0.9270 	Training Prec@1 74.850 	Validation Loss 0.5500 	Validation Prec@1 78.571 	
2022-01-19 14:43:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:34 - INFO - TRAINING - Epoch: [3][0/3]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.5916 (0.5916)	Prec@1 82.812 (82.812)	
2022-01-19 14:43:34 - INFO - EVALUATING - Epoch: [3][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 1.0275 (1.0275)	Prec@1 66.667 (66.667)	
2022-01-19 14:43:34 - INFO - 
 Epoch: 4	Training Loss 0.7460 	Training Prec@1 81.437 	Validation Loss 1.0275 	Validation Prec@1 66.667 	
2022-01-19 14:43:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:34 - INFO - TRAINING - Epoch: [4][0/3]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.3676 (0.3676)	Prec@1 89.062 (89.062)	
2022-01-19 14:43:34 - INFO - EVALUATING - Epoch: [4][0/1]	Time 0.197 (0.197)	Data 0.196 (0.196)	Loss 0.8919 (0.8919)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:34 - INFO - 
 Epoch: 5	Training Loss 0.6827 	Training Prec@1 85.030 	Validation Loss 0.8919 	Validation Prec@1 83.333 	
2022-01-19 14:43:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:35 - INFO - TRAINING - Epoch: [5][0/3]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.5076 (0.5076)	Prec@1 87.500 (87.500)	
2022-01-19 14:43:35 - INFO - EVALUATING - Epoch: [5][0/1]	Time 0.188 (0.188)	Data 0.187 (0.187)	Loss 0.7512 (0.7512)	Prec@1 80.952 (80.952)	
2022-01-19 14:43:35 - INFO - 
 Epoch: 6	Training Loss 0.5598 	Training Prec@1 86.228 	Validation Loss 0.7512 	Validation Prec@1 80.952 	
2022-01-19 14:43:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:35 - INFO - TRAINING - Epoch: [6][0/3]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.4852 (0.4852)	Prec@1 89.062 (89.062)	
2022-01-19 14:43:35 - INFO - EVALUATING - Epoch: [6][0/1]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 1.0336 (1.0336)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:35 - INFO - 
 Epoch: 7	Training Loss 0.8494 	Training Prec@1 64.072 	Validation Loss 1.0336 	Validation Prec@1 83.333 	
2022-01-19 14:43:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:35 - INFO - TRAINING - Epoch: [7][0/3]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.5407 (0.5407)	Prec@1 85.938 (85.938)	
2022-01-19 14:43:36 - INFO - EVALUATING - Epoch: [7][0/1]	Time 0.242 (0.242)	Data 0.240 (0.240)	Loss 1.1302 (1.1302)	Prec@1 85.714 (85.714)	
2022-01-19 14:43:36 - INFO - 
 Epoch: 8	Training Loss 0.9736 	Training Prec@1 62.874 	Validation Loss 1.1302 	Validation Prec@1 85.714 	
2022-01-19 14:43:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:36 - INFO - TRAINING - Epoch: [8][0/3]	Time 0.208 (0.208)	Data 0.204 (0.204)	Loss 0.4435 (0.4435)	Prec@1 90.625 (90.625)	
2022-01-19 14:43:36 - INFO - EVALUATING - Epoch: [8][0/1]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 1.1433 (1.1433)	Prec@1 59.524 (59.524)	
2022-01-19 14:43:36 - INFO - 
 Epoch: 9	Training Loss 0.4300 	Training Prec@1 89.820 	Validation Loss 1.1433 	Validation Prec@1 59.524 	
2022-01-19 14:43:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:36 - INFO - TRAINING - Epoch: [9][0/3]	Time 0.237 (0.237)	Data 0.233 (0.233)	Loss 0.4371 (0.4371)	Prec@1 84.375 (84.375)	
2022-01-19 14:43:37 - INFO - EVALUATING - Epoch: [9][0/1]	Time 0.243 (0.243)	Data 0.241 (0.241)	Loss 0.7180 (0.7180)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:37 - INFO - 
 Epoch: 10	Training Loss 0.4652 	Training Prec@1 88.024 	Validation Loss 0.7180 	Validation Prec@1 83.333 	
2022-01-19 14:43:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:37 - INFO - TRAINING - Epoch: [10][0/3]	Time 0.201 (0.201)	Data 0.196 (0.196)	Loss 0.2462 (0.2462)	Prec@1 93.750 (93.750)	
2022-01-19 14:43:37 - INFO - EVALUATING - Epoch: [10][0/1]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.6457 (0.6457)	Prec@1 88.095 (88.095)	
2022-01-19 14:43:37 - INFO - 
 Epoch: 11	Training Loss 0.6956 	Training Prec@1 75.449 	Validation Loss 0.6457 	Validation Prec@1 88.095 	
2022-01-19 14:43:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:37 - INFO - TRAINING - Epoch: [11][0/3]	Time 0.206 (0.206)	Data 0.202 (0.202)	Loss 0.2390 (0.2390)	Prec@1 93.750 (93.750)	
2022-01-19 14:43:38 - INFO - EVALUATING - Epoch: [11][0/1]	Time 0.187 (0.187)	Data 0.185 (0.185)	Loss 0.4382 (0.4382)	Prec@1 95.238 (95.238)	
2022-01-19 14:43:38 - INFO - 
 Epoch: 12	Training Loss 0.8276 	Training Prec@1 71.856 	Validation Loss 0.4382 	Validation Prec@1 95.238 	
2022-01-19 14:43:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:38 - INFO - TRAINING - Epoch: [12][0/3]	Time 0.197 (0.197)	Data 0.194 (0.194)	Loss 0.6019 (0.6019)	Prec@1 90.625 (90.625)	
2022-01-19 14:43:38 - INFO - EVALUATING - Epoch: [12][0/1]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 1.0823 (1.0823)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:38 - INFO - 
 Epoch: 13	Training Loss 0.5735 	Training Prec@1 81.437 	Validation Loss 1.0823 	Validation Prec@1 83.333 	
2022-01-19 14:43:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:38 - INFO - TRAINING - Epoch: [13][0/3]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.2206 (0.2206)	Prec@1 95.312 (95.312)	
2022-01-19 14:43:38 - INFO - EVALUATING - Epoch: [13][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.4355 (0.4355)	Prec@1 88.095 (88.095)	
2022-01-19 14:43:38 - INFO - 
 Epoch: 14	Training Loss 0.2232 	Training Prec@1 93.413 	Validation Loss 0.4355 	Validation Prec@1 88.095 	
2022-01-19 14:43:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:39 - INFO - TRAINING - Epoch: [14][0/3]	Time 0.210 (0.210)	Data 0.205 (0.205)	Loss 0.3053 (0.3053)	Prec@1 90.625 (90.625)	
2022-01-19 14:43:39 - INFO - EVALUATING - Epoch: [14][0/1]	Time 0.239 (0.239)	Data 0.237 (0.237)	Loss 0.4759 (0.4759)	Prec@1 90.476 (90.476)	
2022-01-19 14:43:39 - INFO - 
 Epoch: 15	Training Loss 0.3311 	Training Prec@1 86.826 	Validation Loss 0.4759 	Validation Prec@1 90.476 	
2022-01-19 14:43:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:39 - INFO - TRAINING - Epoch: [15][0/3]	Time 0.197 (0.197)	Data 0.194 (0.194)	Loss 0.6717 (0.6717)	Prec@1 87.500 (87.500)	
2022-01-19 14:43:39 - INFO - EVALUATING - Epoch: [15][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.3905 (0.3905)	Prec@1 95.238 (95.238)	
2022-01-19 14:43:39 - INFO - 
 Epoch: 16	Training Loss 0.3663 	Training Prec@1 92.216 	Validation Loss 0.3905 	Validation Prec@1 95.238 	
2022-01-19 14:43:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:40 - INFO - TRAINING - Epoch: [16][0/3]	Time 0.244 (0.244)	Data 0.240 (0.240)	Loss 0.1114 (0.1114)	Prec@1 98.438 (98.438)	
2022-01-19 14:43:40 - INFO - EVALUATING - Epoch: [16][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.4019 (0.4019)	Prec@1 92.857 (92.857)	
2022-01-19 14:43:40 - INFO - 
 Epoch: 17	Training Loss 0.3043 	Training Prec@1 94.012 	Validation Loss 0.4019 	Validation Prec@1 92.857 	
2022-01-19 14:43:40 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:40 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:40 - INFO - TRAINING - Epoch: [17][0/3]	Time 0.203 (0.203)	Data 0.200 (0.200)	Loss 0.2284 (0.2284)	Prec@1 95.312 (95.312)	
2022-01-19 14:43:40 - INFO - EVALUATING - Epoch: [17][0/1]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.7385 (0.7385)	Prec@1 90.476 (90.476)	
2022-01-19 14:43:40 - INFO - 
 Epoch: 18	Training Loss 0.3525 	Training Prec@1 88.623 	Validation Loss 0.7385 	Validation Prec@1 90.476 	
2022-01-19 14:43:40 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:40 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:41 - INFO - TRAINING - Epoch: [18][0/3]	Time 0.244 (0.244)	Data 0.241 (0.241)	Loss 0.7671 (0.7671)	Prec@1 84.375 (84.375)	
2022-01-19 14:43:41 - INFO - EVALUATING - Epoch: [18][0/1]	Time 0.233 (0.233)	Data 0.231 (0.231)	Loss 0.9739 (0.9739)	Prec@1 80.952 (80.952)	
2022-01-19 14:43:41 - INFO - 
 Epoch: 19	Training Loss 0.6216 	Training Prec@1 79.641 	Validation Loss 0.9739 	Validation Prec@1 80.952 	
2022-01-19 14:43:41 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:41 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:41 - INFO - TRAINING - Epoch: [19][0/3]	Time 0.201 (0.201)	Data 0.198 (0.198)	Loss 0.0548 (0.0548)	Prec@1 96.875 (96.875)	
2022-01-19 14:43:41 - INFO - EVALUATING - Epoch: [19][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.8486 (0.8486)	Prec@1 80.952 (80.952)	
2022-01-19 14:43:41 - INFO - 
 Epoch: 20	Training Loss 0.1824 	Training Prec@1 92.216 	Validation Loss 0.8486 	Validation Prec@1 80.952 	
2022-01-19 14:43:41 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:41 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:41 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:42 - INFO - TRAINING - Epoch: [20][0/3]	Time 0.245 (0.245)	Data 0.241 (0.241)	Loss 0.2084 (0.2084)	Prec@1 95.312 (95.312)	
2022-01-19 14:43:42 - INFO - EVALUATING - Epoch: [20][0/1]	Time 0.235 (0.235)	Data 0.233 (0.233)	Loss 0.6336 (0.6336)	Prec@1 88.095 (88.095)	
2022-01-19 14:43:42 - INFO - 
 Epoch: 21	Training Loss 0.3852 	Training Prec@1 91.617 	Validation Loss 0.6336 	Validation Prec@1 88.095 	
2022-01-19 14:43:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:42 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:42 - INFO - TRAINING - Epoch: [21][0/3]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.3430 (0.3430)	Prec@1 92.188 (92.188)	
2022-01-19 14:43:42 - INFO - EVALUATING - Epoch: [21][0/1]	Time 0.192 (0.192)	Data 0.190 (0.190)	Loss 0.3150 (0.3150)	Prec@1 92.857 (92.857)	
2022-01-19 14:43:42 - INFO - 
 Epoch: 22	Training Loss 0.3040 	Training Prec@1 92.814 	Validation Loss 0.3150 	Validation Prec@1 92.857 	
2022-01-19 14:43:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:42 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:42 - INFO - TRAINING - Epoch: [22][0/3]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.2670 (0.2670)	Prec@1 93.750 (93.750)	
2022-01-19 14:43:43 - INFO - EVALUATING - Epoch: [22][0/1]	Time 0.187 (0.187)	Data 0.185 (0.185)	Loss 0.1476 (0.1476)	Prec@1 95.238 (95.238)	
2022-01-19 14:43:43 - INFO - 
 Epoch: 23	Training Loss 0.2679 	Training Prec@1 90.419 	Validation Loss 0.1476 	Validation Prec@1 95.238 	
2022-01-19 14:43:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:43 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:43 - INFO - TRAINING - Epoch: [23][0/3]	Time 0.243 (0.243)	Data 0.240 (0.240)	Loss 0.2388 (0.2388)	Prec@1 93.750 (93.750)	
2022-01-19 14:43:43 - INFO - EVALUATING - Epoch: [23][0/1]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.4226 (0.4226)	Prec@1 76.190 (76.190)	
2022-01-19 14:43:43 - INFO - 
 Epoch: 24	Training Loss 0.1962 	Training Prec@1 95.210 	Validation Loss 0.4226 	Validation Prec@1 76.190 	
2022-01-19 14:43:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:43 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:43 - INFO - TRAINING - Epoch: [24][0/3]	Time 0.242 (0.242)	Data 0.238 (0.238)	Loss 0.1843 (0.1843)	Prec@1 87.500 (87.500)	
2022-01-19 14:43:44 - INFO - EVALUATING - Epoch: [24][0/1]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.2612 (0.2612)	Prec@1 92.857 (92.857)	
2022-01-19 14:43:44 - INFO - 
 Epoch: 25	Training Loss 0.2226 	Training Prec@1 92.216 	Validation Loss 0.2612 	Validation Prec@1 92.857 	
2022-01-19 14:43:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:44 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:44 - INFO - TRAINING - Epoch: [25][0/3]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.2092 (0.2092)	Prec@1 95.312 (95.312)	
2022-01-19 14:43:44 - INFO - EVALUATING - Epoch: [25][0/1]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.4830 (0.4830)	Prec@1 90.476 (90.476)	
2022-01-19 14:43:44 - INFO - 
 Epoch: 26	Training Loss 0.2101 	Training Prec@1 97.006 	Validation Loss 0.4830 	Validation Prec@1 90.476 	
2022-01-19 14:43:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:44 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:44 - INFO - TRAINING - Epoch: [26][0/3]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.2136 (0.2136)	Prec@1 93.750 (93.750)	
2022-01-19 14:43:45 - INFO - EVALUATING - Epoch: [26][0/1]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.3321 (0.3321)	Prec@1 88.095 (88.095)	
2022-01-19 14:43:45 - INFO - 
 Epoch: 27	Training Loss 0.1566 	Training Prec@1 94.012 	Validation Loss 0.3321 	Validation Prec@1 88.095 	
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:45 - INFO - TRAINING - Epoch: [27][0/3]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.2275 (0.2275)	Prec@1 90.625 (90.625)	
2022-01-19 14:43:45 - INFO - EVALUATING - Epoch: [27][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.5244 (0.5244)	Prec@1 78.571 (78.571)	
2022-01-19 14:43:45 - INFO - 
 Epoch: 28	Training Loss 0.1542 	Training Prec@1 92.814 	Validation Loss 0.5244 	Validation Prec@1 78.571 	
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:45 - INFO - TRAINING - Epoch: [28][0/3]	Time 0.191 (0.191)	Data 0.187 (0.187)	Loss 0.0580 (0.0580)	Prec@1 98.438 (98.438)	
2022-01-19 14:43:45 - INFO - EVALUATING - Epoch: [28][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.8559 (0.8559)	Prec@1 76.190 (76.190)	
2022-01-19 14:43:45 - INFO - 
 Epoch: 29	Training Loss 0.0570 	Training Prec@1 97.605 	Validation Loss 0.8559 	Validation Prec@1 76.190 	
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:45 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:46 - INFO - TRAINING - Epoch: [29][0/3]	Time 0.240 (0.240)	Data 0.236 (0.236)	Loss 0.1080 (0.1080)	Prec@1 98.438 (98.438)	
2022-01-19 14:43:46 - INFO - EVALUATING - Epoch: [29][0/1]	Time 0.241 (0.241)	Data 0.240 (0.240)	Loss 0.5904 (0.5904)	Prec@1 80.952 (80.952)	
2022-01-19 14:43:46 - INFO - 
 Epoch: 30	Training Loss 0.1124 	Training Prec@1 97.006 	Validation Loss 0.5904 	Validation Prec@1 80.952 	
2022-01-19 14:43:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:46 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:46 - INFO - TRAINING - Epoch: [30][0/3]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.2899 (0.2899)	Prec@1 92.188 (92.188)	
2022-01-19 14:43:46 - INFO - EVALUATING - Epoch: [30][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.8251 (0.8251)	Prec@1 80.952 (80.952)	
2022-01-19 14:43:46 - INFO - 
 Epoch: 31	Training Loss 0.2442 	Training Prec@1 95.210 	Validation Loss 0.8251 	Validation Prec@1 80.952 	
2022-01-19 14:43:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:46 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:47 - INFO - TRAINING - Epoch: [31][0/3]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.1528 (0.1528)	Prec@1 95.312 (95.312)	
2022-01-19 14:43:47 - INFO - EVALUATING - Epoch: [31][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.6407 (0.6407)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:47 - INFO - 
 Epoch: 32	Training Loss 0.2156 	Training Prec@1 94.611 	Validation Loss 0.6407 	Validation Prec@1 83.333 	
2022-01-19 14:43:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:47 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:47 - INFO - TRAINING - Epoch: [32][0/3]	Time 0.188 (0.188)	Data 0.184 (0.184)	Loss 0.1459 (0.1459)	Prec@1 95.312 (95.312)	
2022-01-19 14:43:47 - INFO - EVALUATING - Epoch: [32][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.8119 (0.8119)	Prec@1 85.714 (85.714)	
2022-01-19 14:43:47 - INFO - 
 Epoch: 33	Training Loss 0.1617 	Training Prec@1 92.814 	Validation Loss 0.8119 	Validation Prec@1 85.714 	
2022-01-19 14:43:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:47 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:47 - INFO - TRAINING - Epoch: [33][0/3]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.0051 (0.0051)	Prec@1 100.000 (100.000)	
2022-01-19 14:43:48 - INFO - EVALUATING - Epoch: [33][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.5763 (0.5763)	Prec@1 88.095 (88.095)	
2022-01-19 14:43:48 - INFO - 
 Epoch: 34	Training Loss 0.0666 	Training Prec@1 97.605 	Validation Loss 0.5763 	Validation Prec@1 88.095 	
2022-01-19 14:43:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:48 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:48 - INFO - TRAINING - Epoch: [34][0/3]	Time 0.193 (0.193)	Data 0.189 (0.189)	Loss 0.2084 (0.2084)	Prec@1 96.875 (96.875)	
2022-01-19 14:43:48 - INFO - EVALUATING - Epoch: [34][0/1]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.6544 (0.6544)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:48 - INFO - 
 Epoch: 35	Training Loss 0.1420 	Training Prec@1 97.006 	Validation Loss 0.6544 	Validation Prec@1 83.333 	
2022-01-19 14:43:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:48 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:48 - INFO - TRAINING - Epoch: [35][0/3]	Time 0.243 (0.243)	Data 0.240 (0.240)	Loss 0.0255 (0.0255)	Prec@1 98.438 (98.438)	
2022-01-19 14:43:49 - INFO - EVALUATING - Epoch: [35][0/1]	Time 0.236 (0.236)	Data 0.234 (0.234)	Loss 1.3088 (1.3088)	Prec@1 78.571 (78.571)	
2022-01-19 14:43:49 - INFO - 
 Epoch: 36	Training Loss 0.0172 	Training Prec@1 98.802 	Validation Loss 1.3088 	Validation Prec@1 78.571 	
2022-01-19 14:43:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:49 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:49 - INFO - TRAINING - Epoch: [36][0/3]	Time 0.198 (0.198)	Data 0.195 (0.195)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	
2022-01-19 14:43:49 - INFO - EVALUATING - Epoch: [36][0/1]	Time 0.197 (0.197)	Data 0.196 (0.196)	Loss 0.5837 (0.5837)	Prec@1 85.714 (85.714)	
2022-01-19 14:43:49 - INFO - 
 Epoch: 37	Training Loss 0.0074 	Training Prec@1 100.000 	Validation Loss 0.5837 	Validation Prec@1 85.714 	
2022-01-19 14:43:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:49 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:49 - INFO - TRAINING - Epoch: [37][0/3]	Time 0.244 (0.244)	Data 0.240 (0.240)	Loss 0.0109 (0.0109)	Prec@1 100.000 (100.000)	
2022-01-19 14:43:50 - INFO - EVALUATING - Epoch: [37][0/1]	Time 0.198 (0.198)	Data 0.197 (0.197)	Loss 1.0734 (1.0734)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:50 - INFO - 
 Epoch: 38	Training Loss 0.0115 	Training Prec@1 100.000 	Validation Loss 1.0734 	Validation Prec@1 83.333 	
2022-01-19 14:43:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:50 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:50 - INFO - TRAINING - Epoch: [38][0/3]	Time 0.189 (0.189)	Data 0.185 (0.185)	Loss 0.0574 (0.0574)	Prec@1 98.438 (98.438)	
2022-01-19 14:43:50 - INFO - EVALUATING - Epoch: [38][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.5484 (0.5484)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:50 - INFO - 
 Epoch: 39	Training Loss 0.0409 	Training Prec@1 98.204 	Validation Loss 0.5484 	Validation Prec@1 83.333 	
2022-01-19 14:43:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:50 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:50 - INFO - TRAINING - Epoch: [39][0/3]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.0159 (0.0159)	Prec@1 100.000 (100.000)	
2022-01-19 14:43:50 - INFO - EVALUATING - Epoch: [39][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.4622 (0.4622)	Prec@1 85.714 (85.714)	
2022-01-19 14:43:51 - INFO - 
 Epoch: 40	Training Loss 0.0962 	Training Prec@1 98.802 	Validation Loss 0.4622 	Validation Prec@1 85.714 	
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:51 - INFO - TRAINING - Epoch: [40][0/3]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.1066 (0.1066)	Prec@1 96.875 (96.875)	
2022-01-19 14:43:51 - INFO - EVALUATING - Epoch: [40][0/1]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 0.8334 (0.8334)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:51 - INFO - 
 Epoch: 41	Training Loss 0.0744 	Training Prec@1 97.605 	Validation Loss 0.8334 	Validation Prec@1 83.333 	
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:51 - INFO - TRAINING - Epoch: [41][0/3]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	
2022-01-19 14:43:51 - INFO - EVALUATING - Epoch: [41][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.7633 (0.7633)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:51 - INFO - 
 Epoch: 42	Training Loss 0.0461 	Training Prec@1 97.605 	Validation Loss 0.7633 	Validation Prec@1 83.333 	
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:51 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:52 - INFO - TRAINING - Epoch: [42][0/3]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.0141 (0.0141)	Prec@1 100.000 (100.000)	
2022-01-19 14:43:52 - INFO - EVALUATING - Epoch: [42][0/1]	Time 0.195 (0.195)	Data 0.194 (0.194)	Loss 0.6093 (0.6093)	Prec@1 85.714 (85.714)	
2022-01-19 14:43:52 - INFO - 
 Epoch: 43	Training Loss 0.0217 	Training Prec@1 99.401 	Validation Loss 0.6093 	Validation Prec@1 85.714 	
2022-01-19 14:43:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:52 - INFO - TRAINING - Epoch: [43][0/3]	Time 0.245 (0.245)	Data 0.241 (0.241)	Loss 0.0081 (0.0081)	Prec@1 100.000 (100.000)	
2022-01-19 14:43:52 - INFO - EVALUATING - Epoch: [43][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.7723 (0.7723)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:52 - INFO - 
 Epoch: 44	Training Loss 0.0807 	Training Prec@1 98.204 	Validation Loss 0.7723 	Validation Prec@1 83.333 	
2022-01-19 14:43:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:53 - INFO - TRAINING - Epoch: [44][0/3]	Time 0.243 (0.243)	Data 0.240 (0.240)	Loss 0.1409 (0.1409)	Prec@1 96.875 (96.875)	
2022-01-19 14:43:53 - INFO - EVALUATING - Epoch: [44][0/1]	Time 0.203 (0.203)	Data 0.201 (0.201)	Loss 0.5107 (0.5107)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:53 - INFO - 
 Epoch: 45	Training Loss 0.0576 	Training Prec@1 98.802 	Validation Loss 0.5107 	Validation Prec@1 83.333 	
2022-01-19 14:43:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:53 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:53 - INFO - TRAINING - Epoch: [45][0/3]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.0226 (0.0226)	Prec@1 98.438 (98.438)	
2022-01-19 14:43:53 - INFO - EVALUATING - Epoch: [45][0/1]	Time 0.222 (0.222)	Data 0.220 (0.220)	Loss 0.6104 (0.6104)	Prec@1 85.714 (85.714)	
2022-01-19 14:43:53 - INFO - 
 Epoch: 46	Training Loss 0.0466 	Training Prec@1 96.407 	Validation Loss 0.6104 	Validation Prec@1 85.714 	
2022-01-19 14:43:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:53 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:54 - INFO - TRAINING - Epoch: [46][0/3]	Time 0.202 (0.202)	Data 0.198 (0.198)	Loss 0.0047 (0.0047)	Prec@1 100.000 (100.000)	
2022-01-19 14:43:54 - INFO - EVALUATING - Epoch: [46][0/1]	Time 0.150 (0.150)	Data 0.148 (0.148)	Loss 1.0090 (1.0090)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:54 - INFO - 
 Epoch: 47	Training Loss 0.0046 	Training Prec@1 100.000 	Validation Loss 1.0090 	Validation Prec@1 83.333 	
2022-01-19 14:43:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:54 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:54 - INFO - TRAINING - Epoch: [47][0/3]	Time 0.240 (0.240)	Data 0.236 (0.236)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	
2022-01-19 14:43:54 - INFO - EVALUATING - Epoch: [47][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.6170 (0.6170)	Prec@1 85.714 (85.714)	
2022-01-19 14:43:54 - INFO - 
 Epoch: 48	Training Loss 0.1221 	Training Prec@1 96.407 	Validation Loss 0.6170 	Validation Prec@1 85.714 	
2022-01-19 14:43:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:54 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:54 - INFO - TRAINING - Epoch: [48][0/3]	Time 0.193 (0.193)	Data 0.189 (0.189)	Loss 0.1460 (0.1460)	Prec@1 96.875 (96.875)	
2022-01-19 14:43:55 - INFO - EVALUATING - Epoch: [48][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.2425 (0.2425)	Prec@1 95.238 (95.238)	
2022-01-19 14:43:55 - INFO - 
 Epoch: 49	Training Loss 0.1109 	Training Prec@1 97.605 	Validation Loss 0.2425 	Validation Prec@1 95.238 	
2022-01-19 14:43:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:43:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:43:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:43:55 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:43:55 - INFO - TRAINING - Epoch: [49][0/3]	Time 0.246 (0.246)	Data 0.242 (0.242)	Loss 0.0398 (0.0398)	Prec@1 96.875 (96.875)	
2022-01-19 14:43:55 - INFO - EVALUATING - Epoch: [49][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 1.1025 (1.1025)	Prec@1 83.333 (83.333)	
2022-01-19 14:43:55 - INFO - 
 Epoch: 50	Training Loss 0.0174 	Training Prec@1 98.802 	Validation Loss 1.1025 	Validation Prec@1 83.333 	
