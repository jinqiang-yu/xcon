2022-01-19 14:56:30 - INFO - saving to ./results/medium/quantise/q4/other/anchor/lending/lending_test1/
2022-01-19 14:56:30 - DEBUG - run arguments: Namespace(config='./configs/config_medium.json', data='../../paper_bench/complete/quantise/q4/other/anchor/lending/lending_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/medium/quantise/q4/other/anchor/lending/lending_test1/', test='../../paper_bench/cv/test/quantise/q4/other/anchor/lending/lending_test1_data.csv', train='../../paper_bench/cv/train/quantise/q4/other/anchor/lending/lending_train1_data.csv')
2022-01-19 14:56:30 - INFO - creating model mlp_binary
2022-01-19 14:56:30 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [32, 16, 8, 2]}
2022-01-19 14:56:30 - INFO - number of parameters: 1946
2022-01-19 14:56:30 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-19 14:56:30 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:30 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:30 - INFO - TRAINING - Epoch: [0][0/128]	Time 0.209 (0.209)	Data 0.203 (0.203)	Loss 2.2763 (2.2763)	Prec@1 43.750 (43.750)	
2022-01-19 14:56:30 - INFO - TRAINING - Epoch: [0][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.8792 (1.0435)	Prec@1 60.938 (68.750)	
2022-01-19 14:56:30 - INFO - TRAINING - Epoch: [0][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.9479 (0.8654)	Prec@1 79.688 (67.857)	
2022-01-19 14:56:30 - INFO - TRAINING - Epoch: [0][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7646 (0.8694)	Prec@1 76.562 (68.296)	
2022-01-19 14:56:30 - INFO - TRAINING - Epoch: [0][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.0098 (0.8354)	Prec@1 59.375 (68.331)	
2022-01-19 14:56:30 - INFO - TRAINING - Epoch: [0][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8848 (0.8225)	Prec@1 75.000 (68.995)	
2022-01-19 14:56:30 - INFO - TRAINING - Epoch: [0][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4930 (0.8036)	Prec@1 81.250 (69.544)	
2022-01-19 14:56:30 - INFO - TRAINING - Epoch: [0][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5780 (0.7717)	Prec@1 76.562 (70.577)	
2022-01-19 14:56:30 - INFO - TRAINING - Epoch: [0][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5743 (0.7518)	Prec@1 76.562 (71.277)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [0][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6526 (0.7328)	Prec@1 68.750 (71.720)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [0][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5750 (0.7183)	Prec@1 78.125 (72.324)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [0][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.2983 (0.7005)	Prec@1 90.625 (73.100)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [0][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5192 (0.6891)	Prec@1 82.812 (73.399)	
2022-01-19 14:56:31 - INFO - EVALUATING - Epoch: [0][0/32]	Time 0.180 (0.180)	Data 0.178 (0.178)	Loss 1.3981 (1.3981)	Prec@1 43.750 (43.750)	
2022-01-19 14:56:31 - INFO - EVALUATING - Epoch: [0][10/32]	Time 0.003 (0.019)	Data 0.002 (0.018)	Loss 1.7242 (1.5200)	Prec@1 29.688 (38.494)	
2022-01-19 14:56:31 - INFO - EVALUATING - Epoch: [0][20/32]	Time 0.003 (0.011)	Data 0.002 (0.010)	Loss 1.3981 (1.4015)	Prec@1 43.750 (43.601)	
2022-01-19 14:56:31 - INFO - EVALUATING - Epoch: [0][30/32]	Time 0.002 (0.008)	Data 0.001 (0.007)	Loss 0.8909 (1.2766)	Prec@1 65.625 (48.992)	
2022-01-19 14:56:31 - INFO - 
 Epoch: 1	Training Loss 0.6838 	Training Prec@1 73.600 	Validation Loss 1.2594 	Validation Prec@1 49.731 	
2022-01-19 14:56:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [1][0/128]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 1.4706 (1.4706)	Prec@1 40.625 (40.625)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [1][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.9489 (1.2209)	Prec@1 78.125 (64.489)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [1][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.7407 (1.0229)	Prec@1 45.312 (65.848)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [1][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6894 (0.8959)	Prec@1 57.812 (67.893)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [1][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6103 (0.8310)	Prec@1 79.688 (68.979)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [1][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7575 (0.8188)	Prec@1 70.312 (69.026)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [1][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.0988 (0.8242)	Prec@1 76.562 (69.211)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [1][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5168 (0.7985)	Prec@1 81.250 (70.070)	
2022-01-19 14:56:31 - INFO - TRAINING - Epoch: [1][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3404 (0.7880)	Prec@1 87.500 (70.583)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [1][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4643 (0.7686)	Prec@1 81.250 (71.154)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [1][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6721 (0.7614)	Prec@1 71.875 (71.426)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [1][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.0505 (0.7502)	Prec@1 64.062 (71.875)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [1][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7185 (0.7378)	Prec@1 43.750 (71.836)	
2022-01-19 14:56:32 - INFO - EVALUATING - Epoch: [1][0/32]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.3593 (0.3593)	Prec@1 95.312 (95.312)	
2022-01-19 14:56:32 - INFO - EVALUATING - Epoch: [1][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4981 (0.4529)	Prec@1 81.250 (85.938)	
2022-01-19 14:56:32 - INFO - EVALUATING - Epoch: [1][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4536 (0.4705)	Prec@1 85.938 (84.301)	
2022-01-19 14:56:32 - INFO - EVALUATING - Epoch: [1][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6630 (0.5053)	Prec@1 65.625 (80.948)	
2022-01-19 14:56:32 - INFO - 
 Epoch: 2	Training Loss 0.7315 	Training Prec@1 72.057 	Validation Loss 0.5079 	Validation Prec@1 80.696 	
2022-01-19 14:56:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [2][0/128]	Time 0.197 (0.197)	Data 0.194 (0.194)	Loss 0.5833 (0.5833)	Prec@1 73.438 (73.438)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [2][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.7716 (0.8295)	Prec@1 40.625 (63.494)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [2][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.8832 (0.9119)	Prec@1 68.750 (68.006)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [2][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4873 (0.8271)	Prec@1 54.688 (66.986)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [2][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.8856 (0.7991)	Prec@1 82.812 (69.550)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [2][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5172 (0.7530)	Prec@1 84.375 (71.140)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [2][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.0428 (0.7513)	Prec@1 76.562 (72.259)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [2][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.1310 (0.7505)	Prec@1 48.438 (71.875)	
2022-01-19 14:56:32 - INFO - TRAINING - Epoch: [2][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4447 (0.7291)	Prec@1 79.688 (72.049)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [2][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7432 (0.7343)	Prec@1 81.250 (71.772)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [2][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5228 (0.7346)	Prec@1 84.375 (72.633)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [2][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4547 (0.7234)	Prec@1 85.938 (73.283)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [2][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7933 (0.7160)	Prec@1 64.062 (72.998)	
2022-01-19 14:56:33 - INFO - EVALUATING - Epoch: [2][0/32]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 1.6143 (1.6143)	Prec@1 51.562 (51.562)	
2022-01-19 14:56:33 - INFO - EVALUATING - Epoch: [2][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 1.7685 (1.4871)	Prec@1 31.250 (51.420)	
2022-01-19 14:56:33 - INFO - EVALUATING - Epoch: [2][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 1.4310 (1.4120)	Prec@1 53.125 (52.753)	
2022-01-19 14:56:33 - INFO - EVALUATING - Epoch: [2][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.0516 (1.2827)	Prec@1 60.938 (56.048)	
2022-01-19 14:56:33 - INFO - 
 Epoch: 3	Training Loss 0.7105 	Training Prec@1 73.110 	Validation Loss 1.2668 	Validation Prec@1 56.639 	
2022-01-19 14:56:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [3][0/128]	Time 0.199 (0.199)	Data 0.196 (0.196)	Loss 0.5469 (0.5469)	Prec@1 76.562 (76.562)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [3][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7416 (0.6375)	Prec@1 79.688 (78.693)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [3][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.4863 (0.7095)	Prec@1 82.812 (76.562)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [3][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5489 (0.6990)	Prec@1 71.875 (75.202)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [3][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7232 (0.6804)	Prec@1 81.250 (74.390)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [3][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.6263 (0.7221)	Prec@1 76.562 (74.020)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [3][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7078 (0.7250)	Prec@1 75.000 (73.181)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [3][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5726 (0.7162)	Prec@1 75.000 (72.535)	
2022-01-19 14:56:33 - INFO - TRAINING - Epoch: [3][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6563 (0.7052)	Prec@1 79.688 (73.110)	
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [3][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5203 (0.7180)	Prec@1 87.500 (72.287)	
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [3][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8959 (0.7174)	Prec@1 78.125 (73.051)	
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [3][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7395 (0.7144)	Prec@1 78.125 (73.043)	
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [3][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5256 (0.7113)	Prec@1 81.250 (73.063)	
2022-01-19 14:56:34 - INFO - EVALUATING - Epoch: [3][0/32]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.1627 (0.1627)	Prec@1 98.438 (98.438)	
2022-01-19 14:56:34 - INFO - EVALUATING - Epoch: [3][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.3373 (0.3535)	Prec@1 90.625 (89.062)	
2022-01-19 14:56:34 - INFO - EVALUATING - Epoch: [3][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3284 (0.4044)	Prec@1 90.625 (86.235)	
2022-01-19 14:56:34 - INFO - EVALUATING - Epoch: [3][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6581 (0.4746)	Prec@1 71.875 (82.460)	
2022-01-19 14:56:34 - INFO - 
 Epoch: 4	Training Loss 0.7137 	Training Prec@1 72.976 	Validation Loss 0.4794 	Validation Prec@1 82.166 	
2022-01-19 14:56:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [4][0/128]	Time 0.245 (0.245)	Data 0.241 (0.241)	Loss 0.4348 (0.4348)	Prec@1 84.375 (84.375)	
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [4][10/128]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.4659 (0.7112)	Prec@1 82.812 (70.739)	
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [4][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.7096 (0.7630)	Prec@1 50.000 (70.164)	
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [4][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.4205 (0.7534)	Prec@1 70.312 (70.716)	
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [4][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6161 (0.7132)	Prec@1 78.125 (71.761)	
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [4][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.4934 (0.6856)	Prec@1 82.812 (72.886)	
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [4][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.9207 (0.6637)	Prec@1 75.000 (73.566)	
2022-01-19 14:56:34 - INFO - TRAINING - Epoch: [4][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5200 (0.6428)	Prec@1 84.375 (74.384)	
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [4][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5122 (0.6357)	Prec@1 79.688 (74.460)	
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [4][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4793 (0.6388)	Prec@1 85.938 (73.592)	
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [4][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7109 (0.6412)	Prec@1 48.438 (73.376)	
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [4][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3836 (0.6423)	Prec@1 85.938 (72.931)	
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [4][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6073 (0.6569)	Prec@1 75.000 (72.456)	
2022-01-19 14:56:35 - INFO - EVALUATING - Epoch: [4][0/32]	Time 0.233 (0.233)	Data 0.231 (0.231)	Loss 0.1749 (0.1749)	Prec@1 87.500 (87.500)	
2022-01-19 14:56:35 - INFO - EVALUATING - Epoch: [4][10/32]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.3812 (0.3919)	Prec@1 87.500 (84.517)	
2022-01-19 14:56:35 - INFO - EVALUATING - Epoch: [4][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.2263 (0.4421)	Prec@1 84.375 (83.557)	
2022-01-19 14:56:35 - INFO - EVALUATING - Epoch: [4][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.9623 (0.5414)	Prec@1 70.312 (80.343)	
2022-01-19 14:56:35 - INFO - 
 Epoch: 5	Training Loss 0.6522 	Training Prec@1 72.608 	Validation Loss 0.5516 	Validation Prec@1 80.206 	
2022-01-19 14:56:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [5][0/128]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.5692 (0.5692)	Prec@1 81.250 (81.250)	
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [5][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.0323 (0.7310)	Prec@1 68.750 (64.347)	
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [5][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5217 (0.7156)	Prec@1 84.375 (62.500)	
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [5][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4843 (0.7937)	Prec@1 85.938 (64.819)	
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [5][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.0900 (0.8078)	Prec@1 70.312 (68.559)	
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [5][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5732 (0.7805)	Prec@1 78.125 (68.873)	
2022-01-19 14:56:35 - INFO - TRAINING - Epoch: [5][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.0404 (0.7771)	Prec@1 71.875 (69.134)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [5][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5385 (0.7438)	Prec@1 78.125 (70.863)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [5][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3915 (0.7093)	Prec@1 85.938 (72.357)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [5][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5294 (0.6876)	Prec@1 78.125 (73.197)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [5][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9039 (0.6911)	Prec@1 78.125 (73.438)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [5][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7476 (0.7004)	Prec@1 50.000 (73.311)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [5][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5525 (0.6939)	Prec@1 75.000 (73.295)	
2022-01-19 14:56:36 - INFO - EVALUATING - Epoch: [5][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.2981 (0.2981)	Prec@1 87.500 (87.500)	
2022-01-19 14:56:36 - INFO - EVALUATING - Epoch: [5][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7044 (0.7525)	Prec@1 87.500 (83.381)	
2022-01-19 14:56:36 - INFO - EVALUATING - Epoch: [5][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5052 (0.9060)	Prec@1 85.938 (81.399)	
2022-01-19 14:56:36 - INFO - EVALUATING - Epoch: [5][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.7463 (1.1266)	Prec@1 75.000 (78.629)	
2022-01-19 14:56:36 - INFO - 
 Epoch: 6	Training Loss 0.6994 	Training Prec@1 73.184 	Validation Loss 1.1343 	Validation Prec@1 78.540 	
2022-01-19 14:56:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [6][0/128]	Time 0.185 (0.185)	Data 0.181 (0.181)	Loss 1.2159 (1.2159)	Prec@1 76.562 (76.562)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [6][10/128]	Time 0.004 (0.021)	Data 0.002 (0.018)	Loss 0.9626 (0.8092)	Prec@1 43.750 (70.881)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [6][20/128]	Time 0.004 (0.013)	Data 0.002 (0.010)	Loss 0.6308 (0.7175)	Prec@1 81.250 (71.875)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [6][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5462 (0.7066)	Prec@1 78.125 (72.782)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [6][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 1.1001 (0.7002)	Prec@1 70.312 (73.285)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [6][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5434 (0.7002)	Prec@1 73.438 (73.315)	
2022-01-19 14:56:36 - INFO - TRAINING - Epoch: [6][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3842 (0.6625)	Prec@1 85.938 (74.539)	
2022-01-19 14:56:37 - INFO - TRAINING - Epoch: [6][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6474 (0.6457)	Prec@1 70.312 (75.704)	
2022-01-19 14:56:37 - INFO - TRAINING - Epoch: [6][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5433 (0.6468)	Prec@1 81.250 (75.251)	
2022-01-19 14:56:37 - INFO - TRAINING - Epoch: [6][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.9046 (0.6636)	Prec@1 51.562 (75.052)	
2022-01-19 14:56:37 - INFO - TRAINING - Epoch: [6][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8885 (0.6904)	Prec@1 81.250 (74.366)	
2022-01-19 14:56:37 - INFO - TRAINING - Epoch: [6][110/128]	Time 0.005 (0.006)	Data 0.002 (0.003)	Loss 1.5592 (0.6915)	Prec@1 42.188 (74.507)	
2022-01-19 14:56:37 - INFO - TRAINING - Epoch: [6][120/128]	Time 0.005 (0.006)	Data 0.002 (0.003)	Loss 0.6175 (0.6996)	Prec@1 78.125 (74.057)	
2022-01-19 14:56:37 - INFO - EVALUATING - Epoch: [6][0/32]	Time 0.178 (0.178)	Data 0.176 (0.176)	Loss 0.3572 (0.3572)	Prec@1 98.438 (98.438)	
2022-01-19 14:56:37 - INFO - EVALUATING - Epoch: [6][10/32]	Time 0.003 (0.019)	Data 0.002 (0.018)	Loss 0.5783 (0.5716)	Prec@1 84.375 (87.642)	
2022-01-19 14:56:37 - INFO - EVALUATING - Epoch: [6][20/32]	Time 0.003 (0.011)	Data 0.002 (0.010)	Loss 0.7504 (0.6097)	Prec@1 89.062 (85.342)	
2022-01-19 14:56:37 - INFO - EVALUATING - Epoch: [6][30/32]	Time 0.002 (0.008)	Data 0.001 (0.007)	Loss 0.5402 (0.6445)	Prec@1 76.562 (82.308)	
2022-01-19 14:56:37 - INFO - 
 Epoch: 7	Training Loss 0.6967 	Training Prec@1 74.115 	Validation Loss 0.6391 	Validation Prec@1 82.117 	
2022-01-19 14:56:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:37 - INFO - TRAINING - Epoch: [7][0/128]	Time 0.223 (0.223)	Data 0.219 (0.219)	Loss 0.6773 (0.6773)	Prec@1 79.688 (79.688)	
2022-01-19 14:56:37 - INFO - TRAINING - Epoch: [7][10/128]	Time 0.004 (0.024)	Data 0.002 (0.022)	Loss 1.3380 (0.8374)	Prec@1 50.000 (75.142)	
2022-01-19 14:56:37 - INFO - TRAINING - Epoch: [7][20/128]	Time 0.004 (0.015)	Data 0.002 (0.012)	Loss 0.6550 (0.7128)	Prec@1 68.750 (74.554)	
2022-01-19 14:56:37 - INFO - TRAINING - Epoch: [7][30/128]	Time 0.004 (0.011)	Data 0.002 (0.009)	Loss 0.5752 (0.6591)	Prec@1 82.812 (75.806)	
2022-01-19 14:56:37 - INFO - TRAINING - Epoch: [7][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7266 (0.6685)	Prec@1 48.438 (75.838)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [7][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5114 (0.6689)	Prec@1 79.688 (76.777)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [7][60/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6977 (0.7299)	Prec@1 84.375 (73.899)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [7][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6617 (0.7516)	Prec@1 48.438 (73.658)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [7][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5721 (0.7382)	Prec@1 76.562 (73.881)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [7][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5570 (0.7257)	Prec@1 81.250 (73.249)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [7][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7219 (0.7393)	Prec@1 46.875 (72.679)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [7][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8268 (0.7255)	Prec@1 84.375 (73.001)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [7][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6187 (0.7299)	Prec@1 78.125 (72.663)	
2022-01-19 14:56:38 - INFO - EVALUATING - Epoch: [7][0/32]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.5229 (0.5229)	Prec@1 43.750 (43.750)	
2022-01-19 14:56:38 - INFO - EVALUATING - Epoch: [7][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.8278 (0.6595)	Prec@1 29.688 (38.494)	
2022-01-19 14:56:38 - INFO - EVALUATING - Epoch: [7][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5631 (0.6262)	Prec@1 43.750 (43.601)	
2022-01-19 14:56:38 - INFO - EVALUATING - Epoch: [7][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6087 (0.6028)	Prec@1 65.625 (48.992)	
2022-01-19 14:56:38 - INFO - 
 Epoch: 8	Training Loss 0.7229 	Training Prec@1 72.449 	Validation Loss 0.5996 	Validation Prec@1 49.731 	
2022-01-19 14:56:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [8][0/128]	Time 0.192 (0.192)	Data 0.189 (0.189)	Loss 0.7885 (0.7885)	Prec@1 42.188 (42.188)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [8][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.5475 (0.6625)	Prec@1 70.312 (70.312)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [8][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5336 (0.6492)	Prec@1 81.250 (69.866)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [8][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6416 (0.6625)	Prec@1 68.750 (70.464)	
2022-01-19 14:56:38 - INFO - TRAINING - Epoch: [8][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.8111 (0.6782)	Prec@1 75.000 (69.474)	
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [8][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.8111 (0.6995)	Prec@1 56.250 (70.251)	
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [8][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6219 (0.6810)	Prec@1 75.000 (71.363)	
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [8][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7539 (0.6762)	Prec@1 53.125 (71.985)	
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [8][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4507 (0.6594)	Prec@1 82.812 (72.415)	
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [8][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4877 (0.6486)	Prec@1 59.375 (71.858)	
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [8][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5498 (0.6350)	Prec@1 76.562 (72.649)	
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [8][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4532 (0.6597)	Prec@1 85.938 (72.480)	
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [8][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6648 (0.6664)	Prec@1 78.125 (72.185)	
2022-01-19 14:56:39 - INFO - EVALUATING - Epoch: [8][0/32]	Time 0.199 (0.199)	Data 0.198 (0.198)	Loss 0.1362 (0.1362)	Prec@1 96.875 (96.875)	
2022-01-19 14:56:39 - INFO - EVALUATING - Epoch: [8][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6182 (0.5323)	Prec@1 81.250 (84.801)	
2022-01-19 14:56:39 - INFO - EVALUATING - Epoch: [8][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3541 (0.5990)	Prec@1 89.062 (83.408)	
2022-01-19 14:56:39 - INFO - EVALUATING - Epoch: [8][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.3950 (0.7294)	Prec@1 62.500 (79.788)	
2022-01-19 14:56:39 - INFO - 
 Epoch: 9	Training Loss 0.6651 	Training Prec@1 72.314 	Validation Loss 0.7509 	Validation Prec@1 79.226 	
2022-01-19 14:56:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [9][0/128]	Time 0.199 (0.199)	Data 0.196 (0.196)	Loss 0.5349 (0.5349)	Prec@1 87.500 (87.500)	
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [9][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.5478 (0.8028)	Prec@1 51.562 (67.188)	
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [9][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6784 (0.7066)	Prec@1 60.938 (73.140)	
2022-01-19 14:56:39 - INFO - TRAINING - Epoch: [9][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4510 (0.6643)	Prec@1 84.375 (74.849)	
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [9][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4185 (0.6272)	Prec@1 89.062 (76.905)	
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [9][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5341 (0.6293)	Prec@1 81.250 (77.237)	
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [9][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6804 (0.6260)	Prec@1 71.875 (77.024)	
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [9][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5295 (0.6293)	Prec@1 78.125 (76.430)	
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [9][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5138 (0.6235)	Prec@1 82.812 (76.447)	
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [9][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.0142 (0.6384)	Prec@1 60.938 (75.910)	
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [9][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5130 (0.6579)	Prec@1 81.250 (75.108)	
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [9][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9679 (0.6568)	Prec@1 65.625 (74.676)	
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [9][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5905 (0.6495)	Prec@1 75.000 (74.832)	
2022-01-19 14:56:40 - INFO - EVALUATING - Epoch: [9][0/32]	Time 0.237 (0.237)	Data 0.235 (0.235)	Loss 0.0374 (0.0374)	Prec@1 98.438 (98.438)	
2022-01-19 14:56:40 - INFO - EVALUATING - Epoch: [9][10/32]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.7171 (0.4734)	Prec@1 75.000 (83.523)	
2022-01-19 14:56:40 - INFO - EVALUATING - Epoch: [9][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.4079 (0.5215)	Prec@1 84.375 (81.473)	
2022-01-19 14:56:40 - INFO - EVALUATING - Epoch: [9][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 1.0163 (0.6308)	Prec@1 68.750 (79.083)	
2022-01-19 14:56:40 - INFO - 
 Epoch: 10	Training Loss 0.6451 	Training Prec@1 74.825 	Validation Loss 0.6396 	Validation Prec@1 78.932 	
2022-01-19 14:56:40 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:40 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [10][0/128]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 1.0235 (1.0235)	Prec@1 70.312 (70.312)	
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [10][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4012 (0.6584)	Prec@1 81.250 (71.591)	
2022-01-19 14:56:40 - INFO - TRAINING - Epoch: [10][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6495 (0.6072)	Prec@1 64.062 (72.321)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [10][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6017 (0.6392)	Prec@1 87.500 (72.631)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [10][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5304 (0.6330)	Prec@1 84.375 (73.361)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [10][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.1691 (0.6590)	Prec@1 76.562 (73.100)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [10][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7574 (0.6737)	Prec@1 78.125 (74.360)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [10][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5198 (0.6753)	Prec@1 85.938 (73.371)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [10][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7188 (0.6829)	Prec@1 40.625 (72.936)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [10][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9252 (0.6911)	Prec@1 46.875 (72.922)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [10][100/128]	Time 0.005 (0.006)	Data 0.002 (0.004)	Loss 0.3102 (0.7046)	Prec@1 90.625 (73.298)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [10][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8328 (0.6964)	Prec@1 76.562 (73.438)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [10][120/128]	Time 0.005 (0.006)	Data 0.002 (0.003)	Loss 0.5273 (0.6956)	Prec@1 75.000 (73.270)	
2022-01-19 14:56:41 - INFO - EVALUATING - Epoch: [10][0/32]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.1083 (0.1083)	Prec@1 96.875 (96.875)	
2022-01-19 14:56:41 - INFO - EVALUATING - Epoch: [10][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.4499 (0.4199)	Prec@1 87.500 (87.926)	
2022-01-19 14:56:41 - INFO - EVALUATING - Epoch: [10][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2672 (0.5041)	Prec@1 87.500 (85.938)	
2022-01-19 14:56:41 - INFO - EVALUATING - Epoch: [10][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.9941 (0.6222)	Prec@1 76.562 (82.460)	
2022-01-19 14:56:41 - INFO - 
 Epoch: 11	Training Loss 0.6977 	Training Prec@1 73.000 	Validation Loss 0.6351 	Validation Prec@1 82.313 	
2022-01-19 14:56:41 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:41 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [11][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.5669 (0.5669)	Prec@1 85.938 (85.938)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.1292 (0.9581)	Prec@1 78.125 (74.858)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7376 (0.8481)	Prec@1 78.125 (74.182)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.4849 (0.8210)	Prec@1 84.375 (74.093)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4384 (0.8014)	Prec@1 82.812 (75.267)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4319 (0.7550)	Prec@1 85.938 (75.582)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][60/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5066 (0.7351)	Prec@1 81.250 (75.999)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4149 (0.7308)	Prec@1 87.500 (75.682)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5083 (0.7103)	Prec@1 84.375 (75.559)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9175 (0.6961)	Prec@1 60.938 (75.532)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5190 (0.6776)	Prec@1 76.562 (75.866)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6699 (0.6794)	Prec@1 71.875 (75.873)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [11][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.8872 (0.6800)	Prec@1 70.312 (75.697)	
2022-01-19 14:56:42 - INFO - EVALUATING - Epoch: [11][0/32]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 1.3352 (1.3352)	Prec@1 3.125 (3.125)	
2022-01-19 14:56:42 - INFO - EVALUATING - Epoch: [11][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 1.2106 (1.2417)	Prec@1 21.875 (15.341)	
2022-01-19 14:56:42 - INFO - EVALUATING - Epoch: [11][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 1.1928 (1.2035)	Prec@1 15.625 (17.039)	
2022-01-19 14:56:42 - INFO - EVALUATING - Epoch: [11][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 1.0795 (1.1476)	Prec@1 23.438 (20.312)	
2022-01-19 14:56:42 - INFO - 
 Epoch: 12	Training Loss 0.6978 	Training Prec@1 75.279 	Validation Loss 1.1420 	Validation Prec@1 20.480 	
2022-01-19 14:56:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [12][0/128]	Time 0.202 (0.202)	Data 0.198 (0.198)	Loss 1.0976 (1.0976)	Prec@1 28.125 (28.125)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.9239 (0.7186)	Prec@1 79.688 (70.170)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5949 (0.6917)	Prec@1 82.812 (70.610)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5350 (0.6612)	Prec@1 76.562 (73.034)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7163 (0.6479)	Prec@1 51.562 (72.561)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7693 (0.6491)	Prec@1 75.000 (72.978)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7133 (0.6465)	Prec@1 76.562 (73.566)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9940 (0.6718)	Prec@1 59.375 (72.667)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4604 (0.6624)	Prec@1 76.562 (72.878)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 2.0067 (0.7210)	Prec@1 70.312 (72.150)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6491 (0.7206)	Prec@1 78.125 (72.169)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5595 (0.7106)	Prec@1 68.750 (72.128)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [12][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.8428 (0.7016)	Prec@1 76.562 (72.469)	
2022-01-19 14:56:43 - INFO - EVALUATING - Epoch: [12][0/32]	Time 0.242 (0.242)	Data 0.240 (0.240)	Loss 0.1539 (0.1539)	Prec@1 96.875 (96.875)	
2022-01-19 14:56:43 - INFO - EVALUATING - Epoch: [12][10/32]	Time 0.003 (0.025)	Data 0.002 (0.024)	Loss 0.5471 (0.4893)	Prec@1 87.500 (86.790)	
2022-01-19 14:56:43 - INFO - EVALUATING - Epoch: [12][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.5748 (0.5861)	Prec@1 85.938 (84.821)	
2022-01-19 14:56:43 - INFO - EVALUATING - Epoch: [12][30/32]	Time 0.002 (0.011)	Data 0.001 (0.009)	Loss 0.9277 (0.7048)	Prec@1 73.438 (81.452)	
2022-01-19 14:56:43 - INFO - 
 Epoch: 13	Training Loss 0.7086 	Training Prec@1 72.375 	Validation Loss 0.7078 	Validation Prec@1 81.333 	
2022-01-19 14:56:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][0/128]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.6917 (0.6917)	Prec@1 79.688 (79.688)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.5916 (0.9299)	Prec@1 48.438 (71.449)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5637 (0.8860)	Prec@1 75.000 (66.741)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5903 (0.8419)	Prec@1 79.688 (68.145)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.8208 (0.7629)	Prec@1 78.125 (70.998)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4643 (0.7356)	Prec@1 81.250 (72.549)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7329 (0.7222)	Prec@1 82.812 (70.671)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7290 (0.7212)	Prec@1 70.312 (71.501)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6287 (0.7267)	Prec@1 78.125 (71.508)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7887 (0.7187)	Prec@1 68.750 (71.927)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5602 (0.6993)	Prec@1 73.438 (72.107)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4487 (0.7049)	Prec@1 84.375 (72.030)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [13][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7754 (0.6942)	Prec@1 78.125 (72.727)	
2022-01-19 14:56:44 - INFO - EVALUATING - Epoch: [13][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.1924 (0.1924)	Prec@1 95.312 (95.312)	
2022-01-19 14:56:44 - INFO - EVALUATING - Epoch: [13][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.5061 (0.3831)	Prec@1 75.000 (84.943)	
2022-01-19 14:56:44 - INFO - EVALUATING - Epoch: [13][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3439 (0.4313)	Prec@1 85.938 (83.110)	
2022-01-19 14:56:44 - INFO - EVALUATING - Epoch: [13][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6582 (0.5003)	Prec@1 75.000 (80.091)	
2022-01-19 14:56:44 - INFO - 
 Epoch: 14	Training Loss 0.6890 	Training Prec@1 72.951 	Validation Loss 0.5037 	Validation Prec@1 80.108 	
2022-01-19 14:56:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.3834 (0.3834)	Prec@1 85.938 (85.938)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7090 (0.8290)	Prec@1 76.562 (74.432)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.5883 (0.7764)	Prec@1 76.562 (73.065)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5389 (0.7118)	Prec@1 78.125 (73.639)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5199 (0.6682)	Prec@1 79.688 (75.267)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.9866 (0.6829)	Prec@1 84.375 (74.357)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9376 (0.7310)	Prec@1 76.562 (74.232)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5438 (0.7189)	Prec@1 76.562 (73.680)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7350 (0.7064)	Prec@1 78.125 (74.344)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6949 (0.6964)	Prec@1 46.875 (74.176)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6737 (0.6873)	Prec@1 82.812 (74.149)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.9758 (0.6857)	Prec@1 76.562 (74.282)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [14][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7210 (0.6757)	Prec@1 64.062 (74.483)	
2022-01-19 14:56:45 - INFO - EVALUATING - Epoch: [14][0/32]	Time 0.239 (0.239)	Data 0.236 (0.236)	Loss 0.2944 (0.2944)	Prec@1 95.312 (95.312)	
2022-01-19 14:56:45 - INFO - EVALUATING - Epoch: [14][10/32]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.7429 (0.5600)	Prec@1 71.875 (77.273)	
2022-01-19 14:56:45 - INFO - EVALUATING - Epoch: [14][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.3754 (0.5456)	Prec@1 85.938 (76.860)	
2022-01-19 14:56:45 - INFO - EVALUATING - Epoch: [14][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.8617 (0.5713)	Prec@1 54.688 (74.798)	
2022-01-19 14:56:45 - INFO - 
 Epoch: 15	Training Loss 0.6710 	Training Prec@1 74.556 	Validation Loss 0.5755 	Validation Prec@1 74.326 	
2022-01-19 14:56:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][0/128]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 0.5480 (0.5480)	Prec@1 75.000 (75.000)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.0617 (0.7482)	Prec@1 75.000 (67.756)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.5558 (0.7053)	Prec@1 78.125 (71.205)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7005 (0.6594)	Prec@1 54.688 (70.161)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5429 (0.6454)	Prec@1 82.812 (73.018)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6782 (0.6333)	Prec@1 65.625 (72.825)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3670 (0.6146)	Prec@1 87.500 (73.412)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6189 (0.6110)	Prec@1 79.688 (73.393)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5662 (0.6067)	Prec@1 73.438 (73.688)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5132 (0.5987)	Prec@1 81.250 (74.210)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6968 (0.6196)	Prec@1 64.062 (74.072)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4957 (0.6299)	Prec@1 84.375 (73.902)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [15][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5239 (0.6237)	Prec@1 76.562 (73.967)	
2022-01-19 14:56:46 - INFO - EVALUATING - Epoch: [15][0/32]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 0.0958 (0.0958)	Prec@1 98.438 (98.438)	
2022-01-19 14:56:46 - INFO - EVALUATING - Epoch: [15][10/32]	Time 0.003 (0.025)	Data 0.002 (0.023)	Loss 0.7777 (0.4818)	Prec@1 81.250 (87.358)	
2022-01-19 14:56:46 - INFO - EVALUATING - Epoch: [15][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.1797 (0.5503)	Prec@1 92.188 (85.268)	
2022-01-19 14:56:46 - INFO - EVALUATING - Epoch: [15][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 1.1779 (0.6819)	Prec@1 67.188 (81.200)	
2022-01-19 14:56:46 - INFO - 
 Epoch: 16	Training Loss 0.6263 	Training Prec@1 73.760 	Validation Loss 0.6964 	Validation Prec@1 80.843 	
2022-01-19 14:56:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][0/128]	Time 0.194 (0.194)	Data 0.191 (0.191)	Loss 1.0029 (1.0029)	Prec@1 78.125 (78.125)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 1.2524 (1.0561)	Prec@1 81.250 (69.034)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.7913 (1.0921)	Prec@1 78.125 (70.238)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7695 (0.9476)	Prec@1 76.562 (71.270)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6682 (0.9470)	Prec@1 76.562 (73.209)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5508 (0.8586)	Prec@1 75.000 (74.755)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7862 (0.8338)	Prec@1 40.625 (73.770)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.8081 (0.8001)	Prec@1 81.250 (74.780)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6092 (0.7839)	Prec@1 73.438 (74.325)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.2353 (0.7750)	Prec@1 79.688 (74.674)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5419 (0.7818)	Prec@1 81.250 (74.010)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6132 (0.7677)	Prec@1 76.562 (73.972)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [16][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 1.0400 (0.7724)	Prec@1 73.438 (74.122)	
2022-01-19 14:56:47 - INFO - EVALUATING - Epoch: [16][0/32]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.2337 (0.2337)	Prec@1 95.312 (95.312)	
2022-01-19 14:56:47 - INFO - EVALUATING - Epoch: [16][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5402 (0.4112)	Prec@1 79.688 (85.511)	
2022-01-19 14:56:47 - INFO - EVALUATING - Epoch: [16][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3845 (0.4327)	Prec@1 87.500 (83.854)	
2022-01-19 14:56:47 - INFO - EVALUATING - Epoch: [16][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7570 (0.5039)	Prec@1 64.062 (79.637)	
2022-01-19 14:56:48 - INFO - 
 Epoch: 17	Training Loss 0.7602 	Training Prec@1 74.446 	Validation Loss 0.5077 	Validation Prec@1 79.324 	
2022-01-19 14:56:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.5372 (0.5372)	Prec@1 78.125 (78.125)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4305 (0.6383)	Prec@1 81.250 (76.847)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.9394 (0.6062)	Prec@1 48.438 (76.711)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4201 (0.6050)	Prec@1 85.938 (76.462)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5783 (0.6385)	Prec@1 78.125 (76.829)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7025 (0.6229)	Prec@1 81.250 (77.267)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8980 (0.6332)	Prec@1 76.562 (75.615)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8569 (0.6499)	Prec@1 79.688 (75.374)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7618 (0.6489)	Prec@1 79.688 (75.444)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4204 (0.6560)	Prec@1 87.500 (75.481)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5919 (0.6606)	Prec@1 82.812 (75.727)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6902 (0.6622)	Prec@1 76.562 (75.915)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [17][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4002 (0.6577)	Prec@1 85.938 (75.852)	
2022-01-19 14:56:48 - INFO - EVALUATING - Epoch: [17][0/32]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.5224 (0.5224)	Prec@1 43.750 (43.750)	
2022-01-19 14:56:48 - INFO - EVALUATING - Epoch: [17][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.8121 (0.6721)	Prec@1 29.688 (38.494)	
2022-01-19 14:56:48 - INFO - EVALUATING - Epoch: [17][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5049 (0.6591)	Prec@1 43.750 (43.601)	
2022-01-19 14:56:49 - INFO - EVALUATING - Epoch: [17][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6714 (0.6628)	Prec@1 65.625 (48.992)	
2022-01-19 14:56:49 - INFO - 
 Epoch: 18	Training Loss 0.6503 	Training Prec@1 75.916 	Validation Loss 0.6574 	Validation Prec@1 49.731 	
2022-01-19 14:56:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][0/128]	Time 0.246 (0.246)	Data 0.242 (0.242)	Loss 0.7904 (0.7904)	Prec@1 43.750 (43.750)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][10/128]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 1.1400 (0.8235)	Prec@1 67.188 (70.739)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][20/128]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.5106 (0.7077)	Prec@1 78.125 (73.810)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.5184 (0.7527)	Prec@1 78.125 (73.236)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.3256 (0.7921)	Prec@1 89.062 (72.980)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][50/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4628 (0.7658)	Prec@1 87.500 (73.284)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6124 (0.7322)	Prec@1 75.000 (74.206)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][70/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5660 (0.7144)	Prec@1 78.125 (75.132)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5322 (0.6960)	Prec@1 85.938 (75.270)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][90/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6102 (0.6904)	Prec@1 79.688 (75.343)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5677 (0.6749)	Prec@1 76.562 (75.588)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5600 (0.6617)	Prec@1 70.312 (75.718)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [18][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5510 (0.6591)	Prec@1 79.688 (75.581)	
2022-01-19 14:56:50 - INFO - EVALUATING - Epoch: [18][0/32]	Time 0.242 (0.242)	Data 0.240 (0.240)	Loss 0.4224 (0.4224)	Prec@1 93.750 (93.750)	
2022-01-19 14:56:50 - INFO - EVALUATING - Epoch: [18][10/32]	Time 0.003 (0.025)	Data 0.002 (0.024)	Loss 0.7713 (0.7341)	Prec@1 78.125 (82.244)	
2022-01-19 14:56:50 - INFO - EVALUATING - Epoch: [18][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.6629 (0.8194)	Prec@1 85.938 (80.208)	
2022-01-19 14:56:50 - INFO - EVALUATING - Epoch: [18][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 1.6439 (0.9530)	Prec@1 56.250 (76.663)	
2022-01-19 14:56:50 - INFO - 
 Epoch: 19	Training Loss 0.6685 	Training Prec@1 75.462 	Validation Loss 0.9750 	Validation Prec@1 76.041 	
2022-01-19 14:56:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][0/128]	Time 0.232 (0.232)	Data 0.228 (0.228)	Loss 0.9588 (0.9588)	Prec@1 75.000 (75.000)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][10/128]	Time 0.004 (0.025)	Data 0.002 (0.022)	Loss 0.6872 (1.1758)	Prec@1 81.250 (73.580)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.6568 (0.9395)	Prec@1 71.875 (72.693)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][30/128]	Time 0.004 (0.011)	Data 0.002 (0.009)	Loss 0.7347 (0.8453)	Prec@1 48.438 (71.875)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][40/128]	Time 0.004 (0.010)	Data 0.002 (0.007)	Loss 0.6313 (0.7541)	Prec@1 76.562 (74.466)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5464 (0.7165)	Prec@1 75.000 (74.632)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.9058 (0.7636)	Prec@1 84.375 (74.898)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.3107 (0.8028)	Prec@1 53.125 (73.878)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4221 (0.7785)	Prec@1 81.250 (74.479)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4479 (0.7838)	Prec@1 82.812 (74.107)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8528 (0.7942)	Prec@1 76.562 (73.654)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6710 (0.7688)	Prec@1 81.250 (74.071)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [19][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5640 (0.7461)	Prec@1 68.750 (74.483)	
2022-01-19 14:56:51 - INFO - EVALUATING - Epoch: [19][0/32]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 0.2338 (0.2338)	Prec@1 87.500 (87.500)	
2022-01-19 14:56:51 - INFO - EVALUATING - Epoch: [19][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5812 (0.4205)	Prec@1 75.000 (81.818)	
2022-01-19 14:56:51 - INFO - EVALUATING - Epoch: [19][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2224 (0.4585)	Prec@1 87.500 (81.994)	
2022-01-19 14:56:51 - INFO - EVALUATING - Epoch: [19][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.9301 (0.5529)	Prec@1 67.188 (79.486)	
2022-01-19 14:56:51 - INFO - 
 Epoch: 20	Training Loss 0.7386 	Training Prec@1 74.507 	Validation Loss 0.5678 	Validation Prec@1 79.177 	
2022-01-19 14:56:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:51 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][0/128]	Time 0.208 (0.208)	Data 0.204 (0.204)	Loss 0.4499 (0.4499)	Prec@1 84.375 (84.375)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.5428 (0.5162)	Prec@1 78.125 (79.972)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.4459 (0.4782)	Prec@1 79.688 (80.655)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4407 (0.4777)	Prec@1 89.062 (80.595)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6141 (0.4892)	Prec@1 73.438 (80.602)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4505 (0.4963)	Prec@1 82.812 (79.841)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4919 (0.4829)	Prec@1 79.688 (80.507)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3503 (0.4848)	Prec@1 87.500 (80.590)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5395 (0.4903)	Prec@1 71.875 (80.401)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5623 (0.4964)	Prec@1 82.812 (80.288)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5334 (0.4967)	Prec@1 76.562 (80.105)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4931 (0.5006)	Prec@1 75.000 (79.955)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [20][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5309 (0.4976)	Prec@1 76.562 (79.997)	
2022-01-19 14:56:52 - INFO - EVALUATING - Epoch: [20][0/32]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 0.1401 (0.1401)	Prec@1 96.875 (96.875)	
2022-01-19 14:56:52 - INFO - EVALUATING - Epoch: [20][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4477 (0.3637)	Prec@1 87.500 (88.494)	
2022-01-19 14:56:52 - INFO - EVALUATING - Epoch: [20][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2924 (0.4046)	Prec@1 89.062 (86.458)	
2022-01-19 14:56:52 - INFO - EVALUATING - Epoch: [20][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8426 (0.4889)	Prec@1 73.438 (82.712)	
2022-01-19 14:56:52 - INFO - 
 Epoch: 21	Training Loss 0.5006 	Training Prec@1 79.811 	Validation Loss 0.4931 	Validation Prec@1 82.460 	
2022-01-19 14:56:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][0/128]	Time 0.241 (0.241)	Data 0.237 (0.237)	Loss 0.2582 (0.2582)	Prec@1 89.062 (89.062)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][10/128]	Time 0.004 (0.026)	Data 0.002 (0.023)	Loss 0.6509 (0.5988)	Prec@1 78.125 (79.545)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.5033 (0.5734)	Prec@1 82.812 (77.232)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][30/128]	Time 0.004 (0.012)	Data 0.002 (0.009)	Loss 0.5071 (0.5654)	Prec@1 79.688 (78.175)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7898 (0.5651)	Prec@1 75.000 (79.611)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.5983 (0.5829)	Prec@1 79.688 (77.298)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5046 (0.5837)	Prec@1 82.812 (77.459)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6165 (0.5728)	Prec@1 75.000 (77.927)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.0909 (0.5725)	Prec@1 60.938 (78.067)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.3716 (0.5805)	Prec@1 84.375 (77.696)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4316 (0.5724)	Prec@1 82.812 (77.816)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4365 (0.5647)	Prec@1 85.938 (78.167)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [21][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3991 (0.5632)	Prec@1 85.938 (78.396)	
2022-01-19 14:56:53 - INFO - EVALUATING - Epoch: [21][0/32]	Time 0.240 (0.240)	Data 0.238 (0.238)	Loss 0.2122 (0.2122)	Prec@1 96.875 (96.875)	
2022-01-19 14:56:53 - INFO - EVALUATING - Epoch: [21][10/32]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.4246 (0.3644)	Prec@1 87.500 (88.352)	
2022-01-19 14:56:53 - INFO - EVALUATING - Epoch: [21][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.3095 (0.3932)	Prec@1 89.062 (86.012)	
2022-01-19 14:56:53 - INFO - EVALUATING - Epoch: [21][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.6013 (0.4534)	Prec@1 75.000 (82.863)	
2022-01-19 14:56:53 - INFO - 
 Epoch: 22	Training Loss 0.5606 	Training Prec@1 78.525 	Validation Loss 0.4558 	Validation Prec@1 82.656 	
2022-01-19 14:56:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:53 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][0/128]	Time 0.241 (0.241)	Data 0.237 (0.237)	Loss 0.3269 (0.3269)	Prec@1 89.062 (89.062)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][10/128]	Time 0.004 (0.026)	Data 0.002 (0.023)	Loss 0.6344 (0.7141)	Prec@1 79.688 (75.426)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.5040 (0.6398)	Prec@1 84.375 (79.092)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][30/128]	Time 0.004 (0.012)	Data 0.002 (0.009)	Loss 0.6019 (0.6210)	Prec@1 78.125 (78.024)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.0741 (0.6163)	Prec@1 60.938 (77.744)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.4009 (0.5903)	Prec@1 87.500 (78.401)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5972 (0.5834)	Prec@1 71.875 (77.920)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4109 (0.5682)	Prec@1 84.375 (78.125)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5336 (0.5627)	Prec@1 78.125 (77.720)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4687 (0.5583)	Prec@1 87.500 (77.764)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4982 (0.5585)	Prec@1 81.250 (77.955)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [22][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6349 (0.5622)	Prec@1 75.000 (78.167)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [22][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7956 (0.5675)	Prec@1 71.875 (78.086)	
2022-01-19 14:56:54 - INFO - EVALUATING - Epoch: [22][0/32]	Time 0.185 (0.185)	Data 0.183 (0.183)	Loss 0.3751 (0.3751)	Prec@1 96.875 (96.875)	
2022-01-19 14:56:54 - INFO - EVALUATING - Epoch: [22][10/32]	Time 0.003 (0.019)	Data 0.002 (0.018)	Loss 0.5061 (0.4789)	Prec@1 87.500 (87.500)	
2022-01-19 14:56:54 - INFO - EVALUATING - Epoch: [22][20/32]	Time 0.003 (0.011)	Data 0.002 (0.010)	Loss 0.4805 (0.4849)	Prec@1 87.500 (85.491)	
2022-01-19 14:56:54 - INFO - EVALUATING - Epoch: [22][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5459 (0.5030)	Prec@1 73.438 (82.308)	
2022-01-19 14:56:54 - INFO - 
 Epoch: 23	Training Loss 0.5677 	Training Prec@1 78.133 	Validation Loss 0.5016 	Validation Prec@1 82.215 	
2022-01-19 14:56:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:54 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [23][0/128]	Time 0.240 (0.240)	Data 0.236 (0.236)	Loss 0.5427 (0.5427)	Prec@1 78.125 (78.125)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [23][10/128]	Time 0.004 (0.025)	Data 0.002 (0.023)	Loss 0.4767 (0.6185)	Prec@1 81.250 (80.966)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [23][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.4859 (0.5874)	Prec@1 82.812 (79.613)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [23][30/128]	Time 0.004 (0.012)	Data 0.002 (0.009)	Loss 1.0468 (0.6322)	Prec@1 73.438 (76.310)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [23][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7740 (0.6412)	Prec@1 71.875 (77.172)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [23][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.5128 (0.6401)	Prec@1 81.250 (76.409)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [23][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4956 (0.6131)	Prec@1 82.812 (77.049)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [23][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5085 (0.5975)	Prec@1 75.000 (77.421)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [23][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4533 (0.5848)	Prec@1 87.500 (77.874)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [23][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5584 (0.5696)	Prec@1 75.000 (78.365)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [23][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.2701 (0.5684)	Prec@1 89.062 (78.218)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [23][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.7836 (0.5696)	Prec@1 68.750 (77.970)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [23][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5672 (0.5628)	Prec@1 67.188 (78.022)	
2022-01-19 14:56:55 - INFO - EVALUATING - Epoch: [23][0/32]	Time 0.203 (0.203)	Data 0.201 (0.201)	Loss 0.2099 (0.2099)	Prec@1 95.312 (95.312)	
2022-01-19 14:56:55 - INFO - EVALUATING - Epoch: [23][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6278 (0.4928)	Prec@1 79.688 (84.091)	
2022-01-19 14:56:55 - INFO - EVALUATING - Epoch: [23][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3249 (0.5283)	Prec@1 87.500 (81.771)	
2022-01-19 14:56:55 - INFO - EVALUATING - Epoch: [23][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.9614 (0.6036)	Prec@1 67.188 (78.327)	
2022-01-19 14:56:55 - INFO - 
 Epoch: 24	Training Loss 0.5574 	Training Prec@1 77.962 	Validation Loss 0.6131 	Validation Prec@1 77.952 	
2022-01-19 14:56:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:55 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [24][0/128]	Time 0.247 (0.247)	Data 0.243 (0.243)	Loss 0.5866 (0.5866)	Prec@1 78.125 (78.125)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [24][10/128]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.4727 (0.6383)	Prec@1 71.875 (75.284)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [24][20/128]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.4490 (0.5815)	Prec@1 78.125 (77.827)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [24][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.4354 (0.5497)	Prec@1 81.250 (76.411)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [24][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6569 (0.5336)	Prec@1 70.312 (76.867)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [24][50/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5461 (0.5226)	Prec@1 73.438 (76.930)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [24][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4199 (0.5377)	Prec@1 84.375 (77.382)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [24][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4875 (0.5411)	Prec@1 73.438 (77.025)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [24][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4933 (0.5462)	Prec@1 82.812 (77.392)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [24][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5968 (0.5436)	Prec@1 79.688 (77.558)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [24][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3642 (0.5451)	Prec@1 82.812 (77.104)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [24][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4379 (0.5399)	Prec@1 82.812 (77.506)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [24][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5599 (0.5372)	Prec@1 79.688 (77.337)	
2022-01-19 14:56:56 - INFO - EVALUATING - Epoch: [24][0/32]	Time 0.181 (0.181)	Data 0.180 (0.180)	Loss 0.1800 (0.1800)	Prec@1 98.438 (98.438)	
2022-01-19 14:56:56 - INFO - EVALUATING - Epoch: [24][10/32]	Time 0.003 (0.019)	Data 0.002 (0.018)	Loss 0.4209 (0.3745)	Prec@1 85.938 (86.648)	
2022-01-19 14:56:56 - INFO - EVALUATING - Epoch: [24][20/32]	Time 0.003 (0.011)	Data 0.002 (0.010)	Loss 0.3280 (0.4135)	Prec@1 89.062 (84.152)	
2022-01-19 14:56:56 - INFO - EVALUATING - Epoch: [24][30/32]	Time 0.002 (0.008)	Data 0.001 (0.007)	Loss 0.7037 (0.4670)	Prec@1 67.188 (80.847)	
2022-01-19 14:56:56 - INFO - 
 Epoch: 25	Training Loss 0.5336 	Training Prec@1 77.619 	Validation Loss 0.4743 	Validation Prec@1 80.451 	
2022-01-19 14:56:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:56 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [25][0/128]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.4777 (0.4777)	Prec@1 75.000 (75.000)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [25][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.4956 (0.6537)	Prec@1 82.812 (74.716)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [25][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4660 (0.5698)	Prec@1 82.812 (78.199)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [25][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4095 (0.5495)	Prec@1 81.250 (78.125)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [25][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4363 (0.5459)	Prec@1 87.500 (79.002)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [25][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.2806 (0.5287)	Prec@1 89.062 (79.596)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [25][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4793 (0.5233)	Prec@1 84.375 (79.483)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [25][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3199 (0.5174)	Prec@1 90.625 (80.084)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [25][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4436 (0.5116)	Prec@1 82.812 (80.208)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [25][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4037 (0.5103)	Prec@1 84.375 (80.237)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [25][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3625 (0.5073)	Prec@1 81.250 (79.827)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [25][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5794 (0.5027)	Prec@1 78.125 (80.011)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [25][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4530 (0.4988)	Prec@1 81.250 (79.933)	
2022-01-19 14:56:57 - INFO - EVALUATING - Epoch: [25][0/32]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.2014 (0.2014)	Prec@1 96.875 (96.875)	
2022-01-19 14:56:57 - INFO - EVALUATING - Epoch: [25][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.4976 (0.3902)	Prec@1 79.688 (84.233)	
2022-01-19 14:56:57 - INFO - EVALUATING - Epoch: [25][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2750 (0.4088)	Prec@1 89.062 (82.143)	
2022-01-19 14:56:57 - INFO - EVALUATING - Epoch: [25][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8348 (0.4660)	Prec@1 57.812 (78.276)	
2022-01-19 14:56:57 - INFO - 
 Epoch: 26	Training Loss 0.4972 	Training Prec@1 79.897 	Validation Loss 0.4724 	Validation Prec@1 77.756 	
2022-01-19 14:56:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:57 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [26][0/128]	Time 0.206 (0.206)	Data 0.203 (0.203)	Loss 0.4020 (0.4020)	Prec@1 78.125 (78.125)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [26][10/128]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.7356 (0.5573)	Prec@1 73.438 (76.562)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [26][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.4436 (0.5190)	Prec@1 87.500 (79.539)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [26][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.3868 (0.5744)	Prec@1 87.500 (79.133)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [26][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7505 (0.5786)	Prec@1 67.188 (78.239)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [26][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4221 (0.5682)	Prec@1 84.375 (77.819)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [26][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5612 (0.5582)	Prec@1 59.375 (77.126)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [26][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5940 (0.5680)	Prec@1 78.125 (77.069)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [26][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 1.1947 (0.5742)	Prec@1 21.875 (76.929)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [26][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4931 (0.5641)	Prec@1 73.438 (77.198)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [26][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4617 (0.5590)	Prec@1 75.000 (77.058)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [26][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5698 (0.5520)	Prec@1 84.375 (77.041)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [26][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7278 (0.5676)	Prec@1 67.188 (76.730)	
2022-01-19 14:56:58 - INFO - EVALUATING - Epoch: [26][0/32]	Time 0.243 (0.243)	Data 0.241 (0.241)	Loss 0.1121 (0.1121)	Prec@1 96.875 (96.875)	
2022-01-19 14:56:58 - INFO - EVALUATING - Epoch: [26][10/32]	Time 0.003 (0.025)	Data 0.002 (0.024)	Loss 0.4631 (0.3503)	Prec@1 85.938 (87.926)	
2022-01-19 14:56:58 - INFO - EVALUATING - Epoch: [26][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.2383 (0.4032)	Prec@1 90.625 (85.714)	
2022-01-19 14:56:58 - INFO - EVALUATING - Epoch: [26][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.8026 (0.4985)	Prec@1 71.875 (81.502)	
2022-01-19 14:56:58 - INFO - 
 Epoch: 27	Training Loss 0.5597 	Training Prec@1 77.141 	Validation Loss 0.5069 	Validation Prec@1 81.284 	
2022-01-19 14:56:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:58 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [27][0/128]	Time 0.193 (0.193)	Data 0.189 (0.189)	Loss 0.3210 (0.3210)	Prec@1 87.500 (87.500)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [27][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.2571 (0.5939)	Prec@1 85.938 (77.557)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [27][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.2668 (0.6118)	Prec@1 82.812 (73.512)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [27][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4351 (0.5819)	Prec@1 85.938 (74.546)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [27][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.8087 (0.5732)	Prec@1 73.438 (75.229)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [27][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.3992 (0.5650)	Prec@1 81.250 (75.766)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [27][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6572 (0.5512)	Prec@1 62.500 (75.897)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [27][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.3989 (0.5394)	Prec@1 84.375 (76.871)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [27][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4651 (0.5565)	Prec@1 81.250 (76.698)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [27][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6547 (0.5537)	Prec@1 75.000 (76.786)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [27][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5485 (0.5445)	Prec@1 71.875 (77.088)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [27][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4454 (0.5351)	Prec@1 82.812 (77.548)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [27][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4364 (0.5431)	Prec@1 81.250 (76.666)	
2022-01-19 14:56:59 - INFO - EVALUATING - Epoch: [27][0/32]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.1931 (0.1931)	Prec@1 95.312 (95.312)	
2022-01-19 14:56:59 - INFO - EVALUATING - Epoch: [27][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.3688 (0.3589)	Prec@1 89.062 (86.506)	
2022-01-19 14:56:59 - INFO - EVALUATING - Epoch: [27][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3031 (0.3828)	Prec@1 85.938 (84.673)	
2022-01-19 14:56:59 - INFO - EVALUATING - Epoch: [27][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6507 (0.4335)	Prec@1 73.438 (81.351)	
2022-01-19 14:56:59 - INFO - 
 Epoch: 28	Training Loss 0.5393 	Training Prec@1 76.736 	Validation Loss 0.4373 	Validation Prec@1 81.284 	
2022-01-19 14:56:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:59 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [28][0/128]	Time 0.190 (0.190)	Data 0.187 (0.187)	Loss 0.5597 (0.5597)	Prec@1 70.312 (70.312)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [28][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.7692 (0.6314)	Prec@1 46.875 (70.881)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [28][20/128]	Time 0.005 (0.013)	Data 0.002 (0.011)	Loss 0.4758 (0.5796)	Prec@1 78.125 (73.735)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [28][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5473 (0.5776)	Prec@1 75.000 (74.546)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [28][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.5476 (0.5580)	Prec@1 79.688 (75.343)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [28][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.3830 (0.5360)	Prec@1 85.938 (76.716)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [28][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5412 (0.5208)	Prec@1 73.438 (77.357)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [28][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5541 (0.5079)	Prec@1 78.125 (77.993)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [28][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4552 (0.5069)	Prec@1 84.375 (78.588)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [28][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5346 (0.5141)	Prec@1 84.375 (79.138)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [28][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5632 (0.5186)	Prec@1 75.000 (79.084)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [28][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5973 (0.5247)	Prec@1 75.000 (78.561)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [28][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4212 (0.5358)	Prec@1 87.500 (77.918)	
2022-01-19 14:57:00 - INFO - EVALUATING - Epoch: [28][0/32]	Time 0.190 (0.190)	Data 0.189 (0.189)	Loss 0.1615 (0.1615)	Prec@1 95.312 (95.312)	
2022-01-19 14:57:00 - INFO - EVALUATING - Epoch: [28][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.3855 (0.3868)	Prec@1 89.062 (87.500)	
2022-01-19 14:57:00 - INFO - EVALUATING - Epoch: [28][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3018 (0.4517)	Prec@1 85.938 (85.193)	
2022-01-19 14:57:00 - INFO - EVALUATING - Epoch: [28][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8130 (0.5412)	Prec@1 73.438 (81.855)	
2022-01-19 14:57:00 - INFO - 
 Epoch: 29	Training Loss 0.5360 	Training Prec@1 78.145 	Validation Loss 0.5512 	Validation Prec@1 81.774 	
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [29][0/128]	Time 0.239 (0.239)	Data 0.235 (0.235)	Loss 0.6745 (0.6745)	Prec@1 79.688 (79.688)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [29][10/128]	Time 0.004 (0.026)	Data 0.002 (0.023)	Loss 0.9975 (0.7239)	Prec@1 50.000 (67.472)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [29][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 1.0358 (0.7093)	Prec@1 70.312 (67.932)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [29][30/128]	Time 0.004 (0.012)	Data 0.002 (0.009)	Loss 0.7089 (0.6806)	Prec@1 78.125 (68.750)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [29][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5988 (0.6388)	Prec@1 73.438 (71.227)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [29][50/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.5654 (0.5990)	Prec@1 78.125 (73.529)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [29][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4346 (0.5850)	Prec@1 87.500 (74.846)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [29][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7434 (0.5835)	Prec@1 78.125 (75.506)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [29][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3592 (0.5829)	Prec@1 82.812 (75.251)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [29][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4735 (0.5789)	Prec@1 73.438 (75.601)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [29][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4033 (0.5678)	Prec@1 84.375 (75.325)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [29][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4057 (0.5587)	Prec@1 78.125 (75.690)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [29][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5550 (0.5553)	Prec@1 64.062 (75.245)	
2022-01-19 14:57:01 - INFO - EVALUATING - Epoch: [29][0/32]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 0.2208 (0.2208)	Prec@1 95.312 (95.312)	
2022-01-19 14:57:01 - INFO - EVALUATING - Epoch: [29][10/32]	Time 0.003 (0.025)	Data 0.002 (0.023)	Loss 0.3671 (0.3482)	Prec@1 89.062 (88.352)	
2022-01-19 14:57:01 - INFO - EVALUATING - Epoch: [29][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.2911 (0.3800)	Prec@1 87.500 (85.863)	
2022-01-19 14:57:01 - INFO - EVALUATING - Epoch: [29][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.6453 (0.4318)	Prec@1 70.312 (82.308)	
2022-01-19 14:57:01 - INFO - 
 Epoch: 30	Training Loss 0.5535 	Training Prec@1 75.291 	Validation Loss 0.4359 	Validation Prec@1 82.215 	
2022-01-19 14:57:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [30][0/128]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.5321 (0.5321)	Prec@1 71.875 (71.875)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.5100 (0.7611)	Prec@1 78.125 (74.858)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4929 (0.7115)	Prec@1 78.125 (75.149)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6333 (0.6478)	Prec@1 54.688 (73.438)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.3908 (0.5919)	Prec@1 78.125 (75.686)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5903 (0.5839)	Prec@1 71.875 (75.827)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6656 (0.5800)	Prec@1 75.000 (75.615)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3531 (0.5631)	Prec@1 87.500 (76.496)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4314 (0.5549)	Prec@1 81.250 (76.620)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4624 (0.5463)	Prec@1 81.250 (77.026)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4782 (0.5351)	Prec@1 79.688 (77.692)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.2505 (0.5322)	Prec@1 93.750 (77.309)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [30][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4748 (0.5266)	Prec@1 82.812 (77.828)	
2022-01-19 14:57:02 - INFO - EVALUATING - Epoch: [30][0/32]	Time 0.201 (0.201)	Data 0.200 (0.200)	Loss 0.1167 (0.1167)	Prec@1 98.438 (98.438)	
2022-01-19 14:57:02 - INFO - EVALUATING - Epoch: [30][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.3934 (0.3527)	Prec@1 87.500 (88.920)	
2022-01-19 14:57:02 - INFO - EVALUATING - Epoch: [30][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2637 (0.4003)	Prec@1 90.625 (86.682)	
2022-01-19 14:57:02 - INFO - EVALUATING - Epoch: [30][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8337 (0.4890)	Prec@1 68.750 (82.762)	
2022-01-19 14:57:02 - INFO - 
 Epoch: 31	Training Loss 0.5268 	Training Prec@1 77.888 	Validation Loss 0.4923 	Validation Prec@1 82.558 	
2022-01-19 14:57:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:02 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][0/128]	Time 0.234 (0.234)	Data 0.230 (0.230)	Loss 0.3057 (0.3057)	Prec@1 87.500 (87.500)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][10/128]	Time 0.004 (0.025)	Data 0.002 (0.023)	Loss 0.4881 (0.7004)	Prec@1 59.375 (76.847)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][20/128]	Time 0.004 (0.015)	Data 0.002 (0.013)	Loss 0.4077 (0.5797)	Prec@1 82.812 (77.827)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][30/128]	Time 0.004 (0.011)	Data 0.002 (0.009)	Loss 0.4707 (0.5619)	Prec@1 82.812 (78.276)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][40/128]	Time 0.004 (0.010)	Data 0.002 (0.007)	Loss 0.4851 (0.5541)	Prec@1 84.375 (79.345)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.0101 (0.5736)	Prec@1 71.875 (79.688)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.2238 (0.6085)	Prec@1 70.312 (78.074)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4421 (0.6034)	Prec@1 81.250 (77.531)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.2909 (0.5824)	Prec@1 89.062 (78.125)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4749 (0.5681)	Prec@1 81.250 (78.262)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6328 (0.5637)	Prec@1 75.000 (77.908)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5952 (0.5609)	Prec@1 75.000 (77.562)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [31][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5390 (0.5587)	Prec@1 81.250 (77.776)	
2022-01-19 14:57:03 - INFO - EVALUATING - Epoch: [31][0/32]	Time 0.192 (0.192)	Data 0.190 (0.190)	Loss 0.3845 (0.3845)	Prec@1 95.312 (95.312)	
2022-01-19 14:57:03 - INFO - EVALUATING - Epoch: [31][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5310 (0.4716)	Prec@1 84.375 (87.074)	
2022-01-19 14:57:03 - INFO - EVALUATING - Epoch: [31][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4518 (0.4735)	Prec@1 89.062 (85.789)	
2022-01-19 14:57:03 - INFO - EVALUATING - Epoch: [31][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5990 (0.4975)	Prec@1 68.750 (82.308)	
2022-01-19 14:57:03 - INFO - 
 Epoch: 32	Training Loss 0.5590 	Training Prec@1 77.582 	Validation Loss 0.4969 	Validation Prec@1 82.166 	
2022-01-19 14:57:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:03 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][0/128]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.4957 (0.4957)	Prec@1 79.688 (79.688)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.7661 (0.7941)	Prec@1 78.125 (68.466)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.3272 (0.7594)	Prec@1 89.062 (75.670)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7177 (0.7155)	Prec@1 75.000 (77.621)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4324 (0.6739)	Prec@1 78.125 (76.639)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4166 (0.6325)	Prec@1 82.812 (77.451)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5242 (0.6093)	Prec@1 81.250 (78.202)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6569 (0.6041)	Prec@1 65.625 (78.125)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4789 (0.5938)	Prec@1 79.688 (78.627)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6391 (0.6231)	Prec@1 79.688 (77.799)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4886 (0.6166)	Prec@1 79.688 (77.351)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4656 (0.6027)	Prec@1 81.250 (77.956)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [32][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4882 (0.6024)	Prec@1 75.000 (77.996)	
2022-01-19 14:57:04 - INFO - EVALUATING - Epoch: [32][0/32]	Time 0.189 (0.189)	Data 0.188 (0.188)	Loss 0.4886 (0.4886)	Prec@1 70.312 (70.312)	
2022-01-19 14:57:04 - INFO - EVALUATING - Epoch: [32][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.8589 (0.7564)	Prec@1 60.938 (60.511)	
2022-01-19 14:57:04 - INFO - EVALUATING - Epoch: [32][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.5765 (0.6993)	Prec@1 65.625 (64.435)	
2022-01-19 14:57:04 - INFO - EVALUATING - Epoch: [32][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8125 (0.6984)	Prec@1 68.750 (66.079)	
2022-01-19 14:57:04 - INFO - 
 Epoch: 33	Training Loss 0.5963 	Training Prec@1 78.084 	Validation Loss 0.6953 	Validation Prec@1 66.389 	
2022-01-19 14:57:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][0/128]	Time 0.201 (0.201)	Data 0.198 (0.198)	Loss 0.5264 (0.5264)	Prec@1 75.000 (75.000)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.5149 (0.6310)	Prec@1 79.688 (77.699)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.8841 (0.7199)	Prec@1 40.625 (75.818)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7884 (0.7030)	Prec@1 65.625 (74.294)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][40/128]	Time 0.005 (0.009)	Data 0.002 (0.007)	Loss 0.4019 (0.6450)	Prec@1 85.938 (76.220)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4216 (0.6065)	Prec@1 84.375 (77.298)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6645 (0.5817)	Prec@1 70.312 (78.023)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4784 (0.5712)	Prec@1 82.812 (77.861)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5441 (0.5612)	Prec@1 84.375 (78.549)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4139 (0.5504)	Prec@1 76.562 (78.777)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6840 (0.5492)	Prec@1 75.000 (78.574)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4699 (0.5464)	Prec@1 82.812 (78.674)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [33][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4229 (0.5418)	Prec@1 84.375 (78.874)	
2022-01-19 14:57:05 - INFO - EVALUATING - Epoch: [33][0/32]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 0.2126 (0.2126)	Prec@1 96.875 (96.875)	
2022-01-19 14:57:05 - INFO - EVALUATING - Epoch: [33][10/32]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.4812 (0.3786)	Prec@1 81.250 (86.506)	
2022-01-19 14:57:05 - INFO - EVALUATING - Epoch: [33][20/32]	Time 0.003 (0.015)	Data 0.002 (0.014)	Loss 0.2702 (0.4043)	Prec@1 89.062 (83.929)	
2022-01-19 14:57:05 - INFO - EVALUATING - Epoch: [33][30/32]	Time 0.002 (0.011)	Data 0.001 (0.010)	Loss 0.6270 (0.4547)	Prec@1 67.188 (79.839)	
2022-01-19 14:57:05 - INFO - 
 Epoch: 34	Training Loss 0.5391 	Training Prec@1 78.782 	Validation Loss 0.4603 	Validation Prec@1 79.373 	
2022-01-19 14:57:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][0/128]	Time 0.243 (0.243)	Data 0.239 (0.239)	Loss 0.4038 (0.4038)	Prec@1 79.688 (79.688)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][10/128]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.4126 (0.5930)	Prec@1 89.062 (76.278)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][20/128]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.6751 (0.5809)	Prec@1 81.250 (77.679)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.4796 (0.6469)	Prec@1 71.875 (77.167)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7270 (0.6343)	Prec@1 78.125 (77.706)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][50/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5171 (0.6380)	Prec@1 78.125 (76.930)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8406 (0.6350)	Prec@1 62.500 (76.306)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4328 (0.6156)	Prec@1 87.500 (76.849)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5190 (0.6078)	Prec@1 78.125 (77.141)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.3641 (0.6000)	Prec@1 90.625 (77.644)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][100/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5161 (0.5961)	Prec@1 73.438 (77.336)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4973 (0.5955)	Prec@1 78.125 (77.520)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [34][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4105 (0.5796)	Prec@1 84.375 (78.073)	
2022-01-19 14:57:06 - INFO - EVALUATING - Epoch: [34][0/32]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.1839 (0.1839)	Prec@1 96.875 (96.875)	
2022-01-19 14:57:07 - INFO - EVALUATING - Epoch: [34][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.3711 (0.3412)	Prec@1 89.062 (88.352)	
2022-01-19 14:57:07 - INFO - EVALUATING - Epoch: [34][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3161 (0.3716)	Prec@1 84.375 (86.012)	
2022-01-19 14:57:07 - INFO - EVALUATING - Epoch: [34][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6665 (0.4238)	Prec@1 71.875 (82.611)	
2022-01-19 14:57:07 - INFO - 
 Epoch: 35	Training Loss 0.5719 	Training Prec@1 78.256 	Validation Loss 0.4286 	Validation Prec@1 82.411 	
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.4211 (0.4211)	Prec@1 82.812 (82.812)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.5191 (0.5368)	Prec@1 84.375 (82.102)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4031 (0.5343)	Prec@1 75.000 (80.432)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4172 (0.5133)	Prec@1 76.562 (79.788)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.3440 (0.4960)	Prec@1 85.938 (80.183)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4033 (0.4839)	Prec@1 85.938 (80.668)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4670 (0.4702)	Prec@1 84.375 (81.199)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5638 (0.4848)	Prec@1 78.125 (80.524)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.0430 (0.4944)	Prec@1 65.625 (80.343)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5058 (0.4959)	Prec@1 78.125 (80.185)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4468 (0.4900)	Prec@1 82.812 (80.152)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4384 (0.4882)	Prec@1 84.375 (80.251)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [35][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.3810 (0.4839)	Prec@1 85.938 (80.501)	
2022-01-19 14:57:08 - INFO - EVALUATING - Epoch: [35][0/32]	Time 0.238 (0.238)	Data 0.237 (0.237)	Loss 0.1175 (0.1175)	Prec@1 96.875 (96.875)	
2022-01-19 14:57:08 - INFO - EVALUATING - Epoch: [35][10/32]	Time 0.004 (0.025)	Data 0.002 (0.023)	Loss 0.4113 (0.3565)	Prec@1 79.688 (85.511)	
2022-01-19 14:57:08 - INFO - EVALUATING - Epoch: [35][20/32]	Time 0.003 (0.015)	Data 0.002 (0.013)	Loss 0.2377 (0.3980)	Prec@1 89.062 (83.259)	
2022-01-19 14:57:08 - INFO - EVALUATING - Epoch: [35][30/32]	Time 0.002 (0.011)	Data 0.001 (0.010)	Loss 0.8164 (0.4732)	Prec@1 57.812 (79.536)	
2022-01-19 14:57:08 - INFO - 
 Epoch: 36	Training Loss 0.4826 	Training Prec@1 80.571 	Validation Loss 0.4824 	Validation Prec@1 79.030 	
2022-01-19 14:57:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][0/128]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 0.4734 (0.4734)	Prec@1 81.250 (81.250)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.0679 (0.9169)	Prec@1 76.562 (74.432)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.4143 (0.7583)	Prec@1 68.750 (74.033)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.3594 (0.6687)	Prec@1 87.500 (76.663)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.3891 (0.6055)	Prec@1 82.812 (78.316)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5353 (0.5712)	Prec@1 70.312 (78.891)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4385 (0.5591)	Prec@1 79.688 (78.330)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3135 (0.5349)	Prec@1 90.625 (79.335)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4520 (0.5223)	Prec@1 81.250 (79.707)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5035 (0.5260)	Prec@1 78.125 (79.413)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5801 (0.5293)	Prec@1 87.500 (78.837)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5147 (0.5301)	Prec@1 79.688 (79.279)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [36][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.7031 (0.5338)	Prec@1 79.688 (79.429)	
2022-01-19 14:57:09 - INFO - EVALUATING - Epoch: [36][0/32]	Time 0.237 (0.237)	Data 0.235 (0.235)	Loss 0.0985 (0.0985)	Prec@1 98.438 (98.438)	
2022-01-19 14:57:09 - INFO - EVALUATING - Epoch: [36][10/32]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.4522 (0.3400)	Prec@1 84.375 (88.352)	
2022-01-19 14:57:09 - INFO - EVALUATING - Epoch: [36][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.2288 (0.3905)	Prec@1 90.625 (86.235)	
2022-01-19 14:57:09 - INFO - EVALUATING - Epoch: [36][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.7718 (0.4703)	Prec@1 71.875 (82.460)	
2022-01-19 14:57:09 - INFO - 
 Epoch: 37	Training Loss 0.5367 	Training Prec@1 79.297 	Validation Loss 0.4813 	Validation Prec@1 82.068 	
2022-01-19 14:57:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [37][0/128]	Time 0.247 (0.247)	Data 0.243 (0.243)	Loss 0.5303 (0.5303)	Prec@1 82.812 (82.812)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [37][10/128]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.5987 (0.9520)	Prec@1 79.688 (74.574)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [37][20/128]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.4035 (0.7596)	Prec@1 84.375 (76.935)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [37][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.3591 (0.6809)	Prec@1 85.938 (77.319)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [37][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4191 (0.6257)	Prec@1 85.938 (78.125)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [37][50/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4404 (0.5972)	Prec@1 82.812 (78.493)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [37][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4998 (0.5721)	Prec@1 79.688 (79.124)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [37][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5663 (0.5600)	Prec@1 71.875 (78.873)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [37][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6488 (0.5500)	Prec@1 70.312 (79.321)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [37][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.4868 (0.5433)	Prec@1 85.938 (79.396)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [37][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4737 (0.5378)	Prec@1 79.688 (79.471)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [37][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4480 (0.5299)	Prec@1 78.125 (79.547)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [37][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6713 (0.5256)	Prec@1 81.250 (79.507)	
2022-01-19 14:57:10 - INFO - EVALUATING - Epoch: [37][0/32]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 0.1949 (0.1949)	Prec@1 98.438 (98.438)	
2022-01-19 14:57:10 - INFO - EVALUATING - Epoch: [37][10/32]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.3749 (0.3408)	Prec@1 89.062 (89.631)	
2022-01-19 14:57:10 - INFO - EVALUATING - Epoch: [37][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2887 (0.3795)	Prec@1 90.625 (86.682)	
2022-01-19 14:57:10 - INFO - EVALUATING - Epoch: [37][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.5982 (0.4303)	Prec@1 73.438 (82.762)	
2022-01-19 14:57:10 - INFO - 
 Epoch: 38	Training Loss 0.5278 	Training Prec@1 79.211 	Validation Loss 0.4353 	Validation Prec@1 82.558 	
2022-01-19 14:57:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [38][0/128]	Time 0.246 (0.246)	Data 0.243 (0.243)	Loss 0.6004 (0.6004)	Prec@1 67.188 (67.188)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [38][10/128]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.7042 (0.5092)	Prec@1 75.000 (81.818)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [38][20/128]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.7626 (0.5185)	Prec@1 78.125 (81.994)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [38][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.5109 (0.5331)	Prec@1 78.125 (80.242)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [38][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.2871 (0.5321)	Prec@1 85.938 (79.726)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [38][50/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4642 (0.5176)	Prec@1 82.812 (80.178)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [38][60/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4617 (0.5110)	Prec@1 81.250 (80.020)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [38][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3267 (0.5064)	Prec@1 89.062 (79.974)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [38][80/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4828 (0.4990)	Prec@1 82.812 (80.228)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [38][90/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5871 (0.5125)	Prec@1 75.000 (79.739)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [38][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3562 (0.5153)	Prec@1 90.625 (79.610)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [38][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4115 (0.5116)	Prec@1 81.250 (79.575)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [38][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6709 (0.5190)	Prec@1 81.250 (79.597)	
2022-01-19 14:57:11 - INFO - EVALUATING - Epoch: [38][0/32]	Time 0.236 (0.236)	Data 0.234 (0.234)	Loss 0.1329 (0.1329)	Prec@1 95.312 (95.312)	
2022-01-19 14:57:11 - INFO - EVALUATING - Epoch: [38][10/32]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.4055 (0.3799)	Prec@1 79.688 (82.386)	
2022-01-19 14:57:11 - INFO - EVALUATING - Epoch: [38][20/32]	Time 0.003 (0.014)	Data 0.002 (0.013)	Loss 0.2476 (0.4221)	Prec@1 87.500 (80.804)	
2022-01-19 14:57:11 - INFO - EVALUATING - Epoch: [38][30/32]	Time 0.002 (0.010)	Data 0.001 (0.009)	Loss 0.7964 (0.4920)	Prec@1 59.375 (77.369)	
2022-01-19 14:57:11 - INFO - 
 Epoch: 39	Training Loss 0.5234 	Training Prec@1 79.419 	Validation Loss 0.5012 	Validation Prec@1 76.825 	
2022-01-19 14:57:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [39][0/128]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.4865 (0.4865)	Prec@1 81.250 (81.250)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [39][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.5344 (0.6300)	Prec@1 78.125 (74.858)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [39][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.4303 (0.5902)	Prec@1 79.688 (73.735)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [39][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7467 (0.6076)	Prec@1 78.125 (74.244)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [39][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5145 (0.5707)	Prec@1 75.000 (76.334)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [39][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.3913 (0.5541)	Prec@1 82.812 (76.930)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [39][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.2554 (0.5271)	Prec@1 92.188 (78.202)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [39][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3736 (0.5105)	Prec@1 89.062 (79.049)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [39][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.9979 (0.5059)	Prec@1 67.188 (79.186)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [39][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5071 (0.5135)	Prec@1 75.000 (78.949)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [39][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5334 (0.5152)	Prec@1 76.562 (79.038)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [39][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5302 (0.5051)	Prec@1 76.562 (79.575)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [39][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4865 (0.4992)	Prec@1 76.562 (79.817)	
2022-01-19 14:57:12 - INFO - EVALUATING - Epoch: [39][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.1269 (0.1269)	Prec@1 96.875 (96.875)	
2022-01-19 14:57:12 - INFO - EVALUATING - Epoch: [39][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.3493 (0.3499)	Prec@1 89.062 (88.210)	
2022-01-19 14:57:12 - INFO - EVALUATING - Epoch: [39][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2282 (0.3890)	Prec@1 92.188 (86.310)	
2022-01-19 14:57:12 - INFO - EVALUATING - Epoch: [39][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6459 (0.4663)	Prec@1 76.562 (82.812)	
2022-01-19 14:57:12 - INFO - 
 Epoch: 40	Training Loss 0.4962 	Training Prec@1 79.811 	Validation Loss 0.4719 	Validation Prec@1 82.656 	
2022-01-19 14:57:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [40][0/128]	Time 0.203 (0.203)	Data 0.200 (0.200)	Loss 0.4072 (0.4072)	Prec@1 85.938 (85.938)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [40][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7698 (0.6966)	Prec@1 60.938 (75.284)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [40][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 1.2380 (0.6845)	Prec@1 75.000 (77.604)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [40][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.4303 (0.6700)	Prec@1 81.250 (78.881)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [40][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.2839 (0.6609)	Prec@1 71.875 (77.973)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [40][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6834 (0.6730)	Prec@1 78.125 (77.819)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [40][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4641 (0.6448)	Prec@1 84.375 (78.048)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [40][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4861 (0.6175)	Prec@1 81.250 (78.477)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [40][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.3875 (0.6087)	Prec@1 84.375 (78.356)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [40][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5571 (0.6002)	Prec@1 73.438 (78.365)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [40][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5533 (0.5903)	Prec@1 78.125 (78.589)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [40][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4790 (0.5880)	Prec@1 84.375 (78.674)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [40][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5215 (0.5828)	Prec@1 82.812 (78.835)	
2022-01-19 14:57:13 - INFO - EVALUATING - Epoch: [40][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.2105 (0.2105)	Prec@1 96.875 (96.875)	
2022-01-19 14:57:13 - INFO - EVALUATING - Epoch: [40][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.4059 (0.3935)	Prec@1 89.062 (88.352)	
2022-01-19 14:57:13 - INFO - EVALUATING - Epoch: [40][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3302 (0.4267)	Prec@1 90.625 (86.384)	
2022-01-19 14:57:13 - INFO - EVALUATING - Epoch: [40][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6281 (0.4899)	Prec@1 75.000 (82.762)	
2022-01-19 14:57:13 - INFO - 
 Epoch: 41	Training Loss 0.5764 	Training Prec@1 79.125 	Validation Loss 0.4957 	Validation Prec@1 82.607 	
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [41][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.6813 (0.6813)	Prec@1 81.250 (81.250)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [41][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.4252 (0.6849)	Prec@1 84.375 (75.426)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [41][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4860 (0.6255)	Prec@1 82.812 (73.884)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [41][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.4687 (0.6073)	Prec@1 79.688 (75.958)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [41][40/128]	Time 0.005 (0.009)	Data 0.002 (0.007)	Loss 0.3078 (0.5773)	Prec@1 87.500 (76.982)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [41][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.3581 (0.5446)	Prec@1 84.375 (78.033)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [41][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8805 (0.5564)	Prec@1 75.000 (78.074)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [41][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4470 (0.5490)	Prec@1 82.812 (78.477)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [41][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5616 (0.5395)	Prec@1 71.875 (78.356)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [41][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5972 (0.5428)	Prec@1 79.688 (77.799)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [41][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5250 (0.5577)	Prec@1 76.562 (76.980)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [41][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6154 (0.5672)	Prec@1 73.438 (77.140)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [41][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5287 (0.5600)	Prec@1 73.438 (77.002)	
2022-01-19 14:57:14 - INFO - EVALUATING - Epoch: [41][0/32]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.0986 (0.0986)	Prec@1 96.875 (96.875)	
2022-01-19 14:57:14 - INFO - EVALUATING - Epoch: [41][10/32]	Time 0.003 (0.021)	Data 0.002 (0.019)	Loss 0.3841 (0.3854)	Prec@1 89.062 (88.494)	
2022-01-19 14:57:14 - INFO - EVALUATING - Epoch: [41][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2834 (0.4436)	Prec@1 89.062 (86.310)	
2022-01-19 14:57:14 - INFO - EVALUATING - Epoch: [41][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.8166 (0.5365)	Prec@1 76.562 (82.863)	
2022-01-19 14:57:14 - INFO - 
 Epoch: 42	Training Loss 0.5564 	Training Prec@1 77.337 	Validation Loss 0.5464 	Validation Prec@1 82.705 	
2022-01-19 14:57:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:14 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [42][0/128]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.6615 (0.6615)	Prec@1 82.812 (82.812)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [42][10/128]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.4741 (0.6233)	Prec@1 78.125 (75.994)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [42][20/128]	Time 0.005 (0.014)	Data 0.002 (0.011)	Loss 0.6939 (0.5946)	Prec@1 68.750 (77.381)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [42][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 1.2891 (0.6056)	Prec@1 65.625 (76.613)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [42][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8841 (0.6180)	Prec@1 64.062 (77.477)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [42][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4421 (0.6325)	Prec@1 89.062 (76.134)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [42][60/128]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.5510 (0.6328)	Prec@1 81.250 (76.588)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [42][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4253 (0.6112)	Prec@1 82.812 (77.157)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [42][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6131 (0.5949)	Prec@1 76.562 (77.566)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [42][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5670 (0.5910)	Prec@1 59.375 (76.923)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [42][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.3644 (0.5891)	Prec@1 89.062 (76.593)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [42][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4488 (0.5806)	Prec@1 84.375 (77.013)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [42][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4527 (0.5680)	Prec@1 76.562 (77.441)	
2022-01-19 14:57:15 - INFO - EVALUATING - Epoch: [42][0/32]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.2216 (0.2216)	Prec@1 85.938 (85.938)	
2022-01-19 14:57:15 - INFO - EVALUATING - Epoch: [42][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.3125 (0.4049)	Prec@1 82.812 (79.403)	
2022-01-19 14:57:15 - INFO - EVALUATING - Epoch: [42][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3683 (0.4645)	Prec@1 78.125 (76.488)	
2022-01-19 14:57:15 - INFO - EVALUATING - Epoch: [42][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.9564 (0.5473)	Prec@1 48.438 (72.379)	
2022-01-19 14:57:15 - INFO - 
 Epoch: 43	Training Loss 0.5672 	Training Prec@1 77.337 	Validation Loss 0.5599 	Validation Prec@1 71.583 	
2022-01-19 14:57:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:15 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [43][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.4966 (0.4966)	Prec@1 73.438 (73.438)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [43][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6993 (0.8591)	Prec@1 73.438 (71.023)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [43][20/128]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6446 (0.7818)	Prec@1 76.562 (73.586)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [43][30/128]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.3376 (0.6966)	Prec@1 89.062 (75.958)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [43][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5136 (0.6517)	Prec@1 79.688 (76.562)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [43][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.3597 (0.6267)	Prec@1 90.625 (77.175)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [43][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5179 (0.6103)	Prec@1 84.375 (77.971)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [43][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5235 (0.5969)	Prec@1 78.125 (77.905)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [43][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5666 (0.5920)	Prec@1 76.562 (77.334)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [43][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4063 (0.5878)	Prec@1 84.375 (77.232)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [43][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4815 (0.5804)	Prec@1 82.812 (76.918)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [43][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8299 (0.5782)	Prec@1 71.875 (77.238)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [43][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5230 (0.5700)	Prec@1 79.688 (77.712)	
2022-01-19 14:57:16 - INFO - EVALUATING - Epoch: [43][0/32]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.1848 (0.1848)	Prec@1 96.875 (96.875)	
2022-01-19 14:57:16 - INFO - EVALUATING - Epoch: [43][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.3970 (0.3533)	Prec@1 89.062 (88.068)	
2022-01-19 14:57:16 - INFO - EVALUATING - Epoch: [43][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2724 (0.3734)	Prec@1 90.625 (86.384)	
2022-01-19 14:57:16 - INFO - EVALUATING - Epoch: [43][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7110 (0.4278)	Prec@1 68.750 (82.560)	
2022-01-19 14:57:16 - INFO - 
 Epoch: 44	Training Loss 0.5679 	Training Prec@1 77.851 	Validation Loss 0.4320 	Validation Prec@1 82.411 	
2022-01-19 14:57:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [44][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.6268 (0.6268)	Prec@1 65.625 (65.625)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.5900 (0.7754)	Prec@1 73.438 (74.148)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.3979 (0.6755)	Prec@1 78.125 (77.083)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.5062 (0.6140)	Prec@1 70.312 (75.151)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][40/128]	Time 0.005 (0.009)	Data 0.003 (0.007)	Loss 0.3691 (0.6035)	Prec@1 84.375 (75.686)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6174 (0.6024)	Prec@1 76.562 (75.582)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][60/128]	Time 0.005 (0.008)	Data 0.003 (0.005)	Loss 0.8505 (0.6008)	Prec@1 75.000 (75.384)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4697 (0.6363)	Prec@1 76.562 (74.450)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5024 (0.6283)	Prec@1 82.812 (74.826)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6752 (0.6178)	Prec@1 78.125 (75.103)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4440 (0.6194)	Prec@1 73.438 (74.087)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6761 (0.6487)	Prec@1 76.562 (73.381)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [44][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.6336 (0.6404)	Prec@1 75.000 (73.567)	
2022-01-19 14:57:17 - INFO - EVALUATING - Epoch: [44][0/32]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.2828 (0.2828)	Prec@1 96.875 (96.875)	
2022-01-19 14:57:17 - INFO - EVALUATING - Epoch: [44][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7216 (0.5115)	Prec@1 78.125 (82.670)	
2022-01-19 14:57:17 - INFO - EVALUATING - Epoch: [44][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3632 (0.4956)	Prec@1 89.062 (81.399)	
2022-01-19 14:57:17 - INFO - EVALUATING - Epoch: [44][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6852 (0.5091)	Prec@1 60.938 (78.226)	
2022-01-19 14:57:17 - INFO - 
 Epoch: 45	Training Loss 0.6412 	Training Prec@1 73.662 	Validation Loss 0.5115 	Validation Prec@1 77.707 	
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][0/128]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.6006 (0.6006)	Prec@1 76.562 (76.562)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7545 (0.9186)	Prec@1 68.750 (69.886)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.4562 (0.7868)	Prec@1 73.438 (68.676)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6121 (0.7529)	Prec@1 76.562 (69.859)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.4720 (0.6980)	Prec@1 78.125 (72.370)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.4062 (0.6563)	Prec@1 81.250 (73.989)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6115 (0.6323)	Prec@1 73.438 (74.027)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.2867 (0.6131)	Prec@1 89.062 (74.736)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5422 (0.6031)	Prec@1 71.875 (75.212)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4645 (0.6161)	Prec@1 81.250 (75.189)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4391 (0.6036)	Prec@1 82.812 (75.402)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5202 (0.5943)	Prec@1 76.562 (75.324)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [45][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4979 (0.6044)	Prec@1 78.125 (75.581)	
2022-01-19 14:57:18 - INFO - EVALUATING - Epoch: [45][0/32]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.1577 (0.1577)	Prec@1 96.875 (96.875)	
2022-01-19 14:57:18 - INFO - EVALUATING - Epoch: [45][10/32]	Time 0.003 (0.021)	Data 0.002 (0.019)	Loss 0.4929 (0.3725)	Prec@1 78.125 (83.807)	
2022-01-19 14:57:18 - INFO - EVALUATING - Epoch: [45][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.2726 (0.4056)	Prec@1 85.938 (81.473)	
2022-01-19 14:57:18 - INFO - EVALUATING - Epoch: [45][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6743 (0.4676)	Prec@1 59.375 (77.923)	
2022-01-19 14:57:18 - INFO - 
 Epoch: 46	Training Loss 0.6077 	Training Prec@1 75.401 	Validation Loss 0.4752 	Validation Prec@1 77.413 	
2022-01-19 14:57:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][0/128]	Time 0.244 (0.244)	Data 0.239 (0.239)	Loss 0.3718 (0.3718)	Prec@1 81.250 (81.250)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][10/128]	Time 0.005 (0.026)	Data 0.002 (0.024)	Loss 0.2626 (0.9183)	Prec@1 89.062 (68.892)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][20/128]	Time 0.004 (0.016)	Data 0.002 (0.014)	Loss 0.8662 (0.7966)	Prec@1 68.750 (71.801)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][30/128]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.5290 (0.7449)	Prec@1 79.688 (72.631)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][40/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6182 (0.6894)	Prec@1 76.562 (72.828)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][50/128]	Time 0.006 (0.009)	Data 0.003 (0.007)	Loss 0.5133 (0.6660)	Prec@1 78.125 (73.346)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][60/128]	Time 0.005 (0.009)	Data 0.002 (0.006)	Loss 0.3413 (0.6456)	Prec@1 87.500 (74.488)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][70/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5887 (0.6362)	Prec@1 73.438 (74.714)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][80/128]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.2466 (0.6146)	Prec@1 89.062 (75.328)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][90/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4659 (0.6104)	Prec@1 82.812 (75.584)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][100/128]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.4952 (0.5992)	Prec@1 75.000 (75.804)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][110/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.5476 (0.6018)	Prec@1 81.250 (75.929)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][120/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6368 (0.5931)	Prec@1 71.875 (76.356)	
2022-01-19 14:57:19 - INFO - EVALUATING - Epoch: [46][0/32]	Time 0.181 (0.181)	Data 0.179 (0.179)	Loss 0.1402 (0.1402)	Prec@1 96.875 (96.875)	
2022-01-19 14:57:19 - INFO - EVALUATING - Epoch: [46][10/32]	Time 0.003 (0.019)	Data 0.002 (0.018)	Loss 0.5549 (0.3916)	Prec@1 78.125 (84.233)	
2022-01-19 14:57:19 - INFO - EVALUATING - Epoch: [46][20/32]	Time 0.003 (0.011)	Data 0.002 (0.010)	Loss 0.2613 (0.4292)	Prec@1 89.062 (82.068)	
2022-01-19 14:57:19 - INFO - EVALUATING - Epoch: [46][30/32]	Time 0.002 (0.009)	Data 0.001 (0.007)	Loss 0.9294 (0.5134)	Prec@1 57.812 (78.024)	
2022-01-19 14:57:20 - INFO - 
 Epoch: 47	Training Loss 0.5893 	Training Prec@1 76.491 	Validation Loss 0.5250 	Validation Prec@1 77.462 	
2022-01-19 14:57:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:20 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][0/128]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 0.5711 (0.5711)	Prec@1 76.562 (76.562)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][10/128]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7046 (1.1013)	Prec@1 50.000 (73.722)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.7875 (0.8654)	Prec@1 75.000 (73.884)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.3773 (0.7860)	Prec@1 85.938 (75.454)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5499 (0.7250)	Prec@1 76.562 (76.296)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.5283 (0.6887)	Prec@1 75.000 (75.490)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.5490 (0.6601)	Prec@1 59.375 (75.666)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4463 (0.6628)	Prec@1 81.250 (75.440)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6771 (0.6692)	Prec@1 78.125 (74.402)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5517 (0.6696)	Prec@1 71.875 (74.519)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5794 (0.6613)	Prec@1 76.562 (74.799)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6245 (0.6484)	Prec@1 70.312 (75.267)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.4900 (0.6362)	Prec@1 81.250 (75.697)	
2022-01-19 14:57:20 - INFO - EVALUATING - Epoch: [47][0/32]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.3415 (0.3415)	Prec@1 84.375 (84.375)	
2022-01-19 14:57:20 - INFO - EVALUATING - Epoch: [47][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5244 (0.4340)	Prec@1 78.125 (81.250)	
2022-01-19 14:57:21 - INFO - EVALUATING - Epoch: [47][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.3577 (0.4650)	Prec@1 84.375 (80.134)	
2022-01-19 14:57:21 - INFO - EVALUATING - Epoch: [47][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.7758 (0.5332)	Prec@1 68.750 (77.520)	
2022-01-19 14:57:21 - INFO - 
 Epoch: 48	Training Loss 0.6293 	Training Prec@1 75.891 	Validation Loss 0.5383 	Validation Prec@1 77.413 	
2022-01-19 14:57:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:21 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][0/128]	Time 0.218 (0.218)	Data 0.214 (0.214)	Loss 0.5065 (0.5065)	Prec@1 82.812 (82.812)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][10/128]	Time 0.004 (0.024)	Data 0.002 (0.021)	Loss 2.2489 (1.4019)	Prec@1 65.625 (74.148)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][20/128]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.8485 (1.1258)	Prec@1 75.000 (69.494)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][30/128]	Time 0.004 (0.011)	Data 0.002 (0.009)	Loss 0.4036 (0.9461)	Prec@1 85.938 (72.379)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][40/128]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5127 (0.8225)	Prec@1 73.438 (74.200)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][50/128]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.3461 (0.7447)	Prec@1 79.688 (75.368)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][60/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.4198 (0.6995)	Prec@1 82.812 (75.871)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][70/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.4234 (0.6830)	Prec@1 82.812 (76.298)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][80/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7531 (0.6994)	Prec@1 78.125 (75.386)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4166 (0.6840)	Prec@1 87.500 (75.910)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6410 (0.6782)	Prec@1 71.875 (75.232)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][110/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.5459 (0.6720)	Prec@1 76.562 (75.619)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][120/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6810 (0.6586)	Prec@1 81.250 (76.072)	
2022-01-19 14:57:21 - INFO - EVALUATING - Epoch: [48][0/32]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.3905 (0.3905)	Prec@1 93.750 (93.750)	
2022-01-19 14:57:22 - INFO - EVALUATING - Epoch: [48][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5510 (0.4823)	Prec@1 79.688 (84.659)	
2022-01-19 14:57:22 - INFO - EVALUATING - Epoch: [48][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4426 (0.4865)	Prec@1 87.500 (82.812)	
2022-01-19 14:57:22 - INFO - EVALUATING - Epoch: [48][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6629 (0.5113)	Prec@1 57.812 (78.780)	
2022-01-19 14:57:22 - INFO - 
 Epoch: 49	Training Loss 0.6732 	Training Prec@1 76.087 	Validation Loss 0.5139 	Validation Prec@1 78.295 	
2022-01-19 14:57:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:22 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][0/128]	Time 0.190 (0.190)	Data 0.187 (0.187)	Loss 0.4877 (0.4877)	Prec@1 81.250 (81.250)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][10/128]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.8371 (0.8326)	Prec@1 67.188 (73.580)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][20/128]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6682 (0.7551)	Prec@1 82.812 (74.405)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][30/128]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6596 (0.6683)	Prec@1 70.312 (76.613)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][40/128]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 1.1946 (0.6378)	Prec@1 53.125 (76.829)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][50/128]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5049 (0.6253)	Prec@1 67.188 (76.838)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][60/128]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.3740 (0.6452)	Prec@1 87.500 (76.511)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][70/128]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7044 (0.6523)	Prec@1 78.125 (76.915)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][80/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.8710 (0.6519)	Prec@1 76.562 (76.620)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][90/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.4889 (0.6415)	Prec@1 78.125 (76.648)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][100/128]	Time 0.004 (0.006)	Data 0.002 (0.004)	Loss 0.6938 (0.6386)	Prec@1 76.562 (76.624)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][110/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5137 (0.6295)	Prec@1 78.125 (76.647)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][120/128]	Time 0.004 (0.006)	Data 0.002 (0.003)	Loss 0.5907 (0.6234)	Prec@1 73.438 (76.743)	
2022-01-19 14:57:23 - INFO - EVALUATING - Epoch: [49][0/32]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.3661 (0.3661)	Prec@1 96.875 (96.875)	
2022-01-19 14:57:23 - INFO - EVALUATING - Epoch: [49][10/32]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.5534 (0.4814)	Prec@1 79.688 (84.943)	
2022-01-19 14:57:23 - INFO - EVALUATING - Epoch: [49][20/32]	Time 0.003 (0.012)	Data 0.002 (0.011)	Loss 0.4361 (0.4854)	Prec@1 89.062 (83.036)	
2022-01-19 14:57:23 - INFO - EVALUATING - Epoch: [49][30/32]	Time 0.002 (0.009)	Data 0.001 (0.008)	Loss 0.6471 (0.5090)	Prec@1 59.375 (79.083)	
2022-01-19 14:57:23 - INFO - 
 Epoch: 50	Training Loss 0.6197 	Training Prec@1 76.785 	Validation Loss 0.5115 	Validation Prec@1 78.589 	
