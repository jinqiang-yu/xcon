2022-01-19 14:56:41 - INFO - saving to ./results/medium/quantise/q4/other/anchor/recidivism/recidivism_test1/
2022-01-19 14:56:41 - DEBUG - run arguments: Namespace(config='./configs/config_medium.json', data='../../paper_bench/complete/quantise/q4/other/anchor/recidivism/recidivism_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/medium/quantise/q4/other/anchor/recidivism/recidivism_test1/', test='../../paper_bench/cv/test/quantise/q4/other/anchor/recidivism/recidivism_test1_data.csv', train='../../paper_bench/cv/train/quantise/q4/other/anchor/recidivism/recidivism_train1_data.csv')
2022-01-19 14:56:41 - INFO - creating model mlp_binary
2022-01-19 14:56:41 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [32, 16, 8, 2]}
2022-01-19 14:56:41 - INFO - number of parameters: 2074
2022-01-19 14:56:41 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-19 14:56:41 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:41 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [0][0/80]	Time 0.210 (0.210)	Data 0.201 (0.201)	Loss 1.8103 (1.8103)	Prec@1 48.438 (48.438)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [0][10/80]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.8918 (1.2100)	Prec@1 51.562 (54.403)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [0][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.8449 (1.1080)	Prec@1 51.562 (52.232)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [0][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 1.2768 (1.0447)	Prec@1 48.438 (51.764)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [0][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9645 (1.0109)	Prec@1 57.812 (51.829)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [0][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.0336 (1.0000)	Prec@1 54.688 (51.440)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [0][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6893 (0.9658)	Prec@1 56.250 (51.665)	
2022-01-19 14:56:41 - INFO - TRAINING - Epoch: [0][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6942 (0.9564)	Prec@1 50.000 (51.430)	
2022-01-19 14:56:41 - INFO - EVALUATING - Epoch: [0][0/20]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 0.6917 (0.6917)	Prec@1 57.812 (57.812)	
2022-01-19 14:56:41 - INFO - EVALUATING - Epoch: [0][10/20]	Time 0.003 (0.025)	Data 0.002 (0.023)	Loss 0.6950 (0.6927)	Prec@1 40.625 (52.415)	
2022-01-19 14:56:42 - INFO - 
 Epoch: 1	Training Loss 0.9518 	Training Prec@1 51.864 	Validation Loss 0.6932 	Validation Prec@1 50.079 	
2022-01-19 14:56:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [1][0/80]	Time 0.203 (0.203)	Data 0.200 (0.200)	Loss 0.6932 (0.6932)	Prec@1 50.000 (50.000)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [1][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6920 (0.8192)	Prec@1 53.125 (52.983)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [1][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6889 (0.9318)	Prec@1 54.688 (53.720)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [1][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6976 (0.8735)	Prec@1 45.312 (52.772)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [1][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6941 (0.9216)	Prec@1 39.062 (50.724)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [1][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.1159 (0.8939)	Prec@1 51.562 (51.624)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [1][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.3909 (0.9025)	Prec@1 43.750 (51.588)	
2022-01-19 14:56:42 - INFO - TRAINING - Epoch: [1][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7144 (0.8986)	Prec@1 35.938 (51.144)	
2022-01-19 14:56:42 - INFO - EVALUATING - Epoch: [1][0/20]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 1.3452 (1.3452)	Prec@1 42.188 (42.188)	
2022-01-19 14:56:42 - INFO - EVALUATING - Epoch: [1][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.8819 (1.1770)	Prec@1 64.062 (50.142)	
2022-01-19 14:56:42 - INFO - 
 Epoch: 2	Training Loss 0.9172 	Training Prec@1 51.331 	Validation Loss 1.1625 	Validation Prec@1 50.710 	
2022-01-19 14:56:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [2][0/80]	Time 0.194 (0.194)	Data 0.189 (0.189)	Loss 1.3632 (1.3632)	Prec@1 40.625 (40.625)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [2][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 1.6152 (1.0879)	Prec@1 53.125 (54.119)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [2][20/80]	Time 0.006 (0.013)	Data 0.003 (0.011)	Loss 0.6913 (1.0062)	Prec@1 53.125 (52.976)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [2][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6880 (0.9827)	Prec@1 56.250 (52.067)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [2][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.7403 (0.9549)	Prec@1 59.375 (53.773)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [2][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6941 (0.9649)	Prec@1 46.875 (52.941)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [2][60/80]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.8909 (0.9644)	Prec@1 62.500 (53.279)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [2][70/80]	Time 0.005 (0.007)	Data 0.002 (0.005)	Loss 0.6893 (0.9504)	Prec@1 56.250 (53.389)	
2022-01-19 14:56:43 - INFO - EVALUATING - Epoch: [2][0/20]	Time 0.206 (0.206)	Data 0.204 (0.204)	Loss 0.6523 (0.6523)	Prec@1 73.438 (73.438)	
2022-01-19 14:56:43 - INFO - EVALUATING - Epoch: [2][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7911 (0.8768)	Prec@1 67.188 (62.358)	
2022-01-19 14:56:43 - INFO - 
 Epoch: 3	Training Loss 0.9312 	Training Prec@1 52.672 	Validation Loss 0.9538 	Validation Prec@1 58.675 	
2022-01-19 14:56:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [3][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.7345 (0.7345)	Prec@1 70.312 (70.312)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [3][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6932 (0.9424)	Prec@1 50.000 (55.114)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [3][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 1.0663 (1.0718)	Prec@1 57.812 (54.539)	
2022-01-19 14:56:43 - INFO - TRAINING - Epoch: [3][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6917 (0.9606)	Prec@1 53.125 (53.931)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [3][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6915 (0.9370)	Prec@1 53.125 (53.735)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [3][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8501 (0.9157)	Prec@1 53.125 (53.585)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [3][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6962 (0.9327)	Prec@1 45.312 (53.356)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [3][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6946 (0.9055)	Prec@1 39.062 (53.081)	
2022-01-19 14:56:44 - INFO - EVALUATING - Epoch: [3][0/20]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 1.0963 (1.0963)	Prec@1 57.812 (57.812)	
2022-01-19 14:56:44 - INFO - EVALUATING - Epoch: [3][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 1.4497 (1.2123)	Prec@1 40.625 (52.273)	
2022-01-19 14:56:44 - INFO - 
 Epoch: 4	Training Loss 0.9049 	Training Prec@1 52.751 	Validation Loss 1.2992 	Validation Prec@1 50.079 	
2022-01-19 14:56:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [4][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 1.6049 (1.6049)	Prec@1 42.188 (42.188)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [4][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.8960 (1.2580)	Prec@1 62.500 (53.977)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [4][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 1.9253 (1.1910)	Prec@1 56.250 (54.539)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [4][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6745 (1.0962)	Prec@1 60.938 (53.226)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [4][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9547 (1.0075)	Prec@1 57.812 (53.239)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [4][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7108 (0.9629)	Prec@1 39.062 (52.696)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [4][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6944 (0.9447)	Prec@1 48.438 (51.793)	
2022-01-19 14:56:44 - INFO - TRAINING - Epoch: [4][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9436 (0.9437)	Prec@1 39.062 (51.276)	
2022-01-19 14:56:45 - INFO - EVALUATING - Epoch: [4][0/20]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 0.6830 (0.6830)	Prec@1 57.812 (57.812)	
2022-01-19 14:56:45 - INFO - EVALUATING - Epoch: [4][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7146 (0.6929)	Prec@1 40.625 (52.415)	
2022-01-19 14:56:45 - INFO - 
 Epoch: 5	Training Loss 0.9452 	Training Prec@1 51.666 	Validation Loss 0.6972 	Validation Prec@1 50.079 	
2022-01-19 14:56:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [5][0/80]	Time 0.197 (0.197)	Data 0.194 (0.194)	Loss 0.6945 (0.6945)	Prec@1 51.562 (51.562)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [5][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.8426 (0.8721)	Prec@1 64.062 (54.545)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [5][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6912 (0.9467)	Prec@1 53.125 (53.869)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [5][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6928 (0.8996)	Prec@1 51.562 (54.234)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [5][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6912 (0.8681)	Prec@1 53.125 (54.535)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [5][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7819 (0.8680)	Prec@1 53.125 (54.350)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [5][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.2544 (0.8625)	Prec@1 40.625 (53.535)	
2022-01-19 14:56:45 - INFO - TRAINING - Epoch: [5][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.1466 (0.8565)	Prec@1 62.500 (53.543)	
2022-01-19 14:56:45 - INFO - EVALUATING - Epoch: [5][0/20]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.8295 (0.8295)	Prec@1 56.250 (56.250)	
2022-01-19 14:56:46 - INFO - EVALUATING - Epoch: [5][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 1.0073 (0.8771)	Prec@1 42.188 (51.989)	
2022-01-19 14:56:46 - INFO - 
 Epoch: 6	Training Loss 0.8659 	Training Prec@1 53.638 	Validation Loss 0.9067 	Validation Prec@1 49.842 	
2022-01-19 14:56:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [6][0/80]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.9530 (0.9530)	Prec@1 45.312 (45.312)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [6][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 1.0667 (1.0110)	Prec@1 62.500 (55.540)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [6][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.3294 (1.0980)	Prec@1 40.625 (51.860)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [6][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7374 (0.9978)	Prec@1 62.500 (53.579)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [6][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.7134 (0.9631)	Prec@1 48.438 (53.430)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [6][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8451 (0.9485)	Prec@1 67.188 (53.799)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [6][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.3274 (0.9418)	Prec@1 46.875 (53.765)	
2022-01-19 14:56:46 - INFO - TRAINING - Epoch: [6][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.9113 (0.9570)	Prec@1 57.812 (53.565)	
2022-01-19 14:56:46 - INFO - EVALUATING - Epoch: [6][0/20]	Time 0.193 (0.193)	Data 0.192 (0.192)	Loss 0.8779 (0.8779)	Prec@1 60.938 (60.938)	
2022-01-19 14:56:46 - INFO - EVALUATING - Epoch: [6][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.8783 (0.9529)	Prec@1 64.062 (58.097)	
2022-01-19 14:56:46 - INFO - 
 Epoch: 7	Training Loss 0.9543 	Training Prec@1 53.520 	Validation Loss 0.9893 	Validation Prec@1 56.546 	
2022-01-19 14:56:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [7][0/80]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.8294 (0.8294)	Prec@1 64.062 (64.062)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [7][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.9469 (1.0703)	Prec@1 57.812 (55.966)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [7][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7046 (1.0076)	Prec@1 48.438 (54.762)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [7][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6854 (0.9453)	Prec@1 56.250 (54.788)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [7][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.0136 (0.9184)	Prec@1 64.062 (54.802)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [7][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8622 (0.9305)	Prec@1 75.000 (55.484)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [7][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7809 (0.9044)	Prec@1 54.688 (55.558)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [7][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8184 (0.8883)	Prec@1 68.750 (55.524)	
2022-01-19 14:56:47 - INFO - EVALUATING - Epoch: [7][0/20]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.7271 (0.7271)	Prec@1 57.812 (57.812)	
2022-01-19 14:56:47 - INFO - EVALUATING - Epoch: [7][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 1.0266 (0.8918)	Prec@1 40.625 (52.415)	
2022-01-19 14:56:47 - INFO - 
 Epoch: 8	Training Loss 0.8909 	Training Prec@1 55.650 	Validation Loss 1.0001 	Validation Prec@1 50.079 	
2022-01-19 14:56:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [8][0/80]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 1.2226 (1.2226)	Prec@1 45.312 (45.312)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [8][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 1.0361 (1.1411)	Prec@1 57.812 (52.841)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [8][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6988 (1.0918)	Prec@1 48.438 (53.497)	
2022-01-19 14:56:47 - INFO - TRAINING - Epoch: [8][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.9733 (1.0867)	Prec@1 48.438 (53.175)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [8][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.9591 (1.0708)	Prec@1 60.938 (54.192)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [8][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6532 (0.9992)	Prec@1 68.750 (54.626)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [8][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6791 (0.9868)	Prec@1 59.375 (54.790)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [8][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 1.0529 (0.9757)	Prec@1 54.688 (54.423)	
2022-01-19 14:56:48 - INFO - EVALUATING - Epoch: [8][0/20]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.6459 (0.6459)	Prec@1 67.188 (67.188)	
2022-01-19 14:56:48 - INFO - EVALUATING - Epoch: [8][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7589 (0.7041)	Prec@1 57.812 (61.790)	
2022-01-19 14:56:48 - INFO - 
 Epoch: 9	Training Loss 0.9655 	Training Prec@1 54.112 	Validation Loss 0.7154 	Validation Prec@1 60.883 	
2022-01-19 14:56:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [9][0/80]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.6994 (0.6994)	Prec@1 62.500 (62.500)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [9][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.4353 (1.1844)	Prec@1 48.438 (59.091)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [9][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 1.1299 (1.1404)	Prec@1 45.312 (57.143)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [9][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.2147 (1.0885)	Prec@1 51.562 (55.897)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [9][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.3646 (1.0661)	Prec@1 39.062 (56.250)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [9][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8221 (1.0399)	Prec@1 57.812 (56.342)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [9][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7385 (1.0014)	Prec@1 48.438 (55.763)	
2022-01-19 14:56:48 - INFO - TRAINING - Epoch: [9][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9968 (0.9846)	Prec@1 56.250 (55.678)	
2022-01-19 14:56:49 - INFO - EVALUATING - Epoch: [9][0/20]	Time 0.205 (0.205)	Data 0.203 (0.203)	Loss 0.9078 (0.9078)	Prec@1 32.812 (32.812)	
2022-01-19 14:56:49 - INFO - EVALUATING - Epoch: [9][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.9103 (0.9043)	Prec@1 42.188 (37.358)	
2022-01-19 14:56:49 - INFO - 
 Epoch: 10	Training Loss 0.9861 	Training Prec@1 55.591 	Validation Loss 0.8931 	Validation Prec@1 39.826 	
2022-01-19 14:56:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [10][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.8961 (0.8961)	Prec@1 37.500 (37.500)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [10][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.3484 (0.9913)	Prec@1 70.312 (53.551)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [10][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7653 (0.9586)	Prec@1 70.312 (53.571)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [10][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 1.1812 (0.9634)	Prec@1 43.750 (54.435)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [10][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.2488 (1.0583)	Prec@1 57.812 (55.831)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [10][50/80]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.8827 (1.0475)	Prec@1 59.375 (55.760)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [10][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.8818 (1.0205)	Prec@1 62.500 (55.174)	
2022-01-19 14:56:49 - INFO - TRAINING - Epoch: [10][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.0066 (0.9994)	Prec@1 53.125 (54.930)	
2022-01-19 14:56:50 - INFO - EVALUATING - Epoch: [10][0/20]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 1.4245 (1.4245)	Prec@1 32.812 (32.812)	
2022-01-19 14:56:50 - INFO - EVALUATING - Epoch: [10][10/20]	Time 0.003 (0.021)	Data 0.002 (0.019)	Loss 1.5131 (1.3494)	Prec@1 32.812 (38.494)	
2022-01-19 14:56:50 - INFO - 
 Epoch: 11	Training Loss 1.0097 	Training Prec@1 54.881 	Validation Loss 1.3102 	Validation Prec@1 40.931 	
2022-01-19 14:56:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [11][0/80]	Time 0.206 (0.206)	Data 0.203 (0.203)	Loss 1.5065 (1.5065)	Prec@1 31.250 (31.250)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [11][10/80]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 1.2392 (1.3181)	Prec@1 59.375 (47.869)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [11][20/80]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.9784 (1.1178)	Prec@1 51.562 (51.190)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [11][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 1.0776 (1.1183)	Prec@1 43.750 (52.923)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [11][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7391 (1.1480)	Prec@1 64.062 (52.591)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [11][50/80]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.7588 (1.0826)	Prec@1 64.062 (53.922)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [11][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.7492 (1.0309)	Prec@1 45.312 (54.124)	
2022-01-19 14:56:50 - INFO - TRAINING - Epoch: [11][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7311 (1.0236)	Prec@1 45.312 (54.269)	
2022-01-19 14:56:50 - INFO - EVALUATING - Epoch: [11][0/20]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.7826 (0.7826)	Prec@1 67.188 (67.188)	
2022-01-19 14:56:50 - INFO - EVALUATING - Epoch: [11][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.8806 (0.8240)	Prec@1 53.125 (60.795)	
2022-01-19 14:56:50 - INFO - 
 Epoch: 12	Training Loss 1.0155 	Training Prec@1 54.171 	Validation Loss 0.8808 	Validation Prec@1 57.729 	
2022-01-19 14:56:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [12][0/80]	Time 0.214 (0.214)	Data 0.210 (0.210)	Loss 0.6273 (0.6273)	Prec@1 71.875 (71.875)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [12][10/80]	Time 0.004 (0.023)	Data 0.002 (0.021)	Loss 1.0739 (1.8469)	Prec@1 60.938 (52.415)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [12][20/80]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 2.5604 (1.4442)	Prec@1 42.188 (55.952)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [12][30/80]	Time 0.004 (0.011)	Data 0.002 (0.009)	Loss 0.9294 (1.3749)	Prec@1 57.812 (54.385)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [12][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9185 (1.2261)	Prec@1 43.750 (53.316)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [12][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7536 (1.1450)	Prec@1 57.812 (53.952)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [12][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.0734 (1.0994)	Prec@1 53.125 (54.175)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [12][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6516 (1.0628)	Prec@1 65.625 (54.071)	
2022-01-19 14:56:51 - INFO - EVALUATING - Epoch: [12][0/20]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 1.0059 (1.0059)	Prec@1 64.062 (64.062)	
2022-01-19 14:56:51 - INFO - EVALUATING - Epoch: [12][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.8935 (0.9676)	Prec@1 67.188 (62.784)	
2022-01-19 14:56:51 - INFO - 
 Epoch: 13	Training Loss 1.0321 	Training Prec@1 54.171 	Validation Loss 1.0210 	Validation Prec@1 61.278 	
2022-01-19 14:56:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [13][0/80]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 1.0578 (1.0578)	Prec@1 62.500 (62.500)	
2022-01-19 14:56:51 - INFO - TRAINING - Epoch: [13][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 1.1283 (1.0777)	Prec@1 62.500 (52.983)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [13][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.9686 (0.9788)	Prec@1 70.312 (54.390)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [13][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8869 (1.1074)	Prec@1 62.500 (54.587)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [13][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6956 (1.0283)	Prec@1 43.750 (53.811)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [13][50/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 1.2303 (1.0444)	Prec@1 70.312 (54.013)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [13][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.4803 (1.0220)	Prec@1 65.625 (53.996)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [13][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.7198 (0.9801)	Prec@1 59.375 (54.137)	
2022-01-19 14:56:52 - INFO - EVALUATING - Epoch: [13][0/20]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 0.8856 (0.8856)	Prec@1 43.750 (43.750)	
2022-01-19 14:56:52 - INFO - EVALUATING - Epoch: [13][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 1.0350 (0.9242)	Prec@1 31.250 (40.625)	
2022-01-19 14:56:52 - INFO - 
 Epoch: 14	Training Loss 0.9547 	Training Prec@1 54.171 	Validation Loss 0.9265 	Validation Prec@1 40.773 	
2022-01-19 14:56:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [14][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.8940 (0.8940)	Prec@1 42.188 (42.188)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [14][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.0553 (1.1943)	Prec@1 53.125 (53.551)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [14][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6927 (0.9694)	Prec@1 51.562 (54.315)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [14][30/80]	Time 0.005 (0.011)	Data 0.002 (0.008)	Loss 1.0146 (0.9462)	Prec@1 56.250 (52.621)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [14][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.2498 (1.0178)	Prec@1 51.562 (53.087)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [14][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.0747 (1.0549)	Prec@1 54.688 (52.911)	
2022-01-19 14:56:52 - INFO - TRAINING - Epoch: [14][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7821 (1.0255)	Prec@1 67.188 (54.073)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [14][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.3943 (1.0138)	Prec@1 50.000 (53.697)	
2022-01-19 14:56:53 - INFO - EVALUATING - Epoch: [14][0/20]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 1.0668 (1.0668)	Prec@1 60.938 (60.938)	
2022-01-19 14:56:53 - INFO - EVALUATING - Epoch: [14][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 1.3216 (1.2592)	Prec@1 57.812 (59.517)	
2022-01-19 14:56:53 - INFO - 
 Epoch: 15	Training Loss 0.9901 	Training Prec@1 54.289 	Validation Loss 1.3464 	Validation Prec@1 57.019 	
2022-01-19 14:56:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [15][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 1.5059 (1.5059)	Prec@1 51.562 (51.562)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [15][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7909 (0.9982)	Prec@1 64.062 (56.818)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [15][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.8536 (0.9369)	Prec@1 64.062 (54.464)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [15][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6955 (0.9343)	Prec@1 46.875 (54.990)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [15][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6950 (0.9030)	Prec@1 48.438 (55.297)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [15][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.2162 (0.8967)	Prec@1 45.312 (54.473)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [15][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.4439 (0.9099)	Prec@1 59.375 (54.201)	
2022-01-19 14:56:53 - INFO - TRAINING - Epoch: [15][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6935 (0.9143)	Prec@1 50.000 (53.301)	
2022-01-19 14:56:54 - INFO - EVALUATING - Epoch: [15][0/20]	Time 0.207 (0.207)	Data 0.204 (0.204)	Loss 0.6954 (0.6954)	Prec@1 42.188 (42.188)	
2022-01-19 14:56:54 - INFO - EVALUATING - Epoch: [15][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6906 (0.6939)	Prec@1 59.375 (47.585)	
2022-01-19 14:56:54 - INFO - 
 Epoch: 16	Training Loss 0.9129 	Training Prec@1 53.638 	Validation Loss 0.6933 	Validation Prec@1 49.921 	
2022-01-19 14:56:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [16][0/80]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 0.6915 (0.6915)	Prec@1 56.250 (56.250)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [16][10/80]	Time 0.004 (0.024)	Data 0.002 (0.021)	Loss 1.2636 (0.9986)	Prec@1 43.750 (53.409)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [16][20/80]	Time 0.005 (0.014)	Data 0.002 (0.012)	Loss 1.0583 (1.0389)	Prec@1 37.500 (51.116)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [16][30/80]	Time 0.004 (0.011)	Data 0.002 (0.009)	Loss 0.6916 (0.9905)	Prec@1 54.688 (52.873)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [16][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8044 (0.9549)	Prec@1 71.875 (54.154)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [16][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.2595 (0.9450)	Prec@1 64.062 (53.002)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [16][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 1.0241 (0.9522)	Prec@1 29.688 (52.818)	
2022-01-19 14:56:54 - INFO - TRAINING - Epoch: [16][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.1965 (0.9364)	Prec@1 31.250 (53.477)	
2022-01-19 14:56:54 - INFO - EVALUATING - Epoch: [16][0/20]	Time 0.243 (0.243)	Data 0.241 (0.241)	Loss 0.6860 (0.6860)	Prec@1 57.812 (57.812)	
2022-01-19 14:56:55 - INFO - EVALUATING - Epoch: [16][10/20]	Time 0.003 (0.025)	Data 0.002 (0.024)	Loss 0.6823 (0.6889)	Prec@1 43.750 (52.841)	
2022-01-19 14:56:55 - INFO - 
 Epoch: 17	Training Loss 0.9425 	Training Prec@1 52.633 	Validation Loss 0.6955 	Validation Prec@1 50.237 	
2022-01-19 14:56:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [17][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.7017 (0.7017)	Prec@1 43.750 (43.750)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [17][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.1875 (1.0230)	Prec@1 46.875 (51.705)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [17][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.0264 (0.9713)	Prec@1 51.562 (52.381)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [17][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6906 (0.9503)	Prec@1 54.688 (52.974)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [17][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7469 (0.9717)	Prec@1 64.062 (54.535)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [17][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 1.2447 (0.9781)	Prec@1 54.688 (54.412)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [17][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.2725 (1.0197)	Prec@1 51.562 (53.842)	
2022-01-19 14:56:55 - INFO - TRAINING - Epoch: [17][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.3572 (1.0345)	Prec@1 51.562 (53.719)	
2022-01-19 14:56:55 - INFO - EVALUATING - Epoch: [17][0/20]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.9475 (0.9475)	Prec@1 57.812 (57.812)	
2022-01-19 14:56:55 - INFO - EVALUATING - Epoch: [17][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 1.0283 (0.9670)	Prec@1 40.625 (52.415)	
2022-01-19 14:56:55 - INFO - 
 Epoch: 18	Training Loss 1.0488 	Training Prec@1 53.875 	Validation Loss 1.0162 	Validation Prec@1 50.079 	
2022-01-19 14:56:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [18][0/80]	Time 0.199 (0.199)	Data 0.196 (0.196)	Loss 1.1370 (1.1370)	Prec@1 53.125 (53.125)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [18][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.8514 (1.1185)	Prec@1 68.750 (55.114)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [18][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.9954 (1.1589)	Prec@1 53.125 (51.711)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [18][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 1.0888 (1.0474)	Prec@1 60.938 (53.629)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [18][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7141 (0.9778)	Prec@1 57.812 (54.459)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [18][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7291 (0.9493)	Prec@1 45.312 (54.228)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [18][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7170 (0.9266)	Prec@1 40.625 (53.868)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [18][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7247 (0.9198)	Prec@1 56.250 (53.675)	
2022-01-19 14:56:56 - INFO - EVALUATING - Epoch: [18][0/20]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.7926 (0.7926)	Prec@1 48.438 (48.438)	
2022-01-19 14:56:56 - INFO - EVALUATING - Epoch: [18][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6784 (0.7422)	Prec@1 62.500 (54.688)	
2022-01-19 14:56:56 - INFO - 
 Epoch: 19	Training Loss 0.9257 	Training Prec@1 53.481 	Validation Loss 0.7408 	Validation Prec@1 55.126 	
2022-01-19 14:56:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [19][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.7155 (0.7155)	Prec@1 57.812 (57.812)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [19][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.3764 (1.1833)	Prec@1 59.375 (53.551)	
2022-01-19 14:56:56 - INFO - TRAINING - Epoch: [19][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.0623 (1.1126)	Prec@1 57.812 (54.092)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [19][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.9620 (1.0571)	Prec@1 64.062 (55.544)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [19][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6892 (0.9998)	Prec@1 54.688 (54.306)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [19][50/80]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 1.3764 (1.0235)	Prec@1 67.188 (55.116)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [19][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6951 (0.9734)	Prec@1 50.000 (54.329)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [19][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6915 (0.9609)	Prec@1 45.312 (54.599)	
2022-01-19 14:56:57 - INFO - EVALUATING - Epoch: [19][0/20]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.6859 (0.6859)	Prec@1 57.812 (57.812)	
2022-01-19 14:56:57 - INFO - EVALUATING - Epoch: [19][10/20]	Time 0.004 (0.021)	Data 0.003 (0.020)	Loss 0.7054 (0.6920)	Prec@1 40.625 (52.415)	
2022-01-19 14:56:57 - INFO - 
 Epoch: 20	Training Loss 0.9404 	Training Prec@1 54.683 	Validation Loss 0.6947 	Validation Prec@1 50.079 	
2022-01-19 14:56:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:57 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [20][0/80]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.6965 (0.6965)	Prec@1 48.438 (48.438)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [20][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6965 (0.7960)	Prec@1 48.438 (53.409)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [20][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7187 (0.7696)	Prec@1 57.812 (55.878)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [20][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6861 (0.7479)	Prec@1 64.062 (55.141)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [20][40/80]	Time 0.005 (0.009)	Data 0.002 (0.007)	Loss 0.6763 (0.7366)	Prec@1 62.500 (55.526)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [20][50/80]	Time 0.005 (0.008)	Data 0.003 (0.006)	Loss 0.6951 (0.7394)	Prec@1 50.000 (56.281)	
2022-01-19 14:56:57 - INFO - TRAINING - Epoch: [20][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.7205 (0.7400)	Prec@1 59.375 (56.096)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [20][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8273 (0.7477)	Prec@1 46.875 (56.008)	
2022-01-19 14:56:58 - INFO - EVALUATING - Epoch: [20][0/20]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 0.6855 (0.6855)	Prec@1 57.812 (57.812)	
2022-01-19 14:56:58 - INFO - EVALUATING - Epoch: [20][10/20]	Time 0.003 (0.025)	Data 0.002 (0.023)	Loss 0.7064 (0.6921)	Prec@1 40.625 (52.415)	
2022-01-19 14:56:58 - INFO - 
 Epoch: 21	Training Loss 0.7423 	Training Prec@1 55.354 	Validation Loss 0.6949 	Validation Prec@1 50.079 	
2022-01-19 14:56:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:58 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [21][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.6931 (0.6931)	Prec@1 51.562 (51.562)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [21][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.8069 (0.7214)	Prec@1 50.000 (56.676)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [21][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6974 (0.7245)	Prec@1 48.438 (55.432)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [21][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7025 (0.7167)	Prec@1 45.312 (55.897)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [21][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6927 (0.7123)	Prec@1 59.375 (55.335)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [21][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6866 (0.7044)	Prec@1 56.250 (56.924)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [21][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7198 (0.7051)	Prec@1 59.375 (56.352)	
2022-01-19 14:56:58 - INFO - TRAINING - Epoch: [21][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6891 (0.6993)	Prec@1 54.688 (57.350)	
2022-01-19 14:56:59 - INFO - EVALUATING - Epoch: [21][0/20]	Time 0.182 (0.182)	Data 0.180 (0.180)	Loss 0.6825 (0.6825)	Prec@1 60.938 (60.938)	
2022-01-19 14:56:59 - INFO - EVALUATING - Epoch: [21][10/20]	Time 0.003 (0.019)	Data 0.002 (0.018)	Loss 0.6434 (0.7028)	Prec@1 67.188 (59.943)	
2022-01-19 14:56:59 - INFO - 
 Epoch: 22	Training Loss 0.7003 	Training Prec@1 57.050 	Validation Loss 0.7000 	Validation Prec@1 60.568 	
2022-01-19 14:56:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:56:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:56:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:56:59 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [22][0/80]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.7129 (0.7129)	Prec@1 60.938 (60.938)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [22][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7011 (0.7352)	Prec@1 45.312 (52.131)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [22][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7066 (0.7190)	Prec@1 60.938 (56.622)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [22][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6893 (0.7090)	Prec@1 54.688 (55.444)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [22][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6928 (0.7011)	Prec@1 51.562 (57.165)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [22][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6581 (0.7056)	Prec@1 65.625 (57.690)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [22][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6180 (0.6988)	Prec@1 68.750 (58.171)	
2022-01-19 14:56:59 - INFO - TRAINING - Epoch: [22][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6110 (0.6963)	Prec@1 70.312 (58.473)	
2022-01-19 14:56:59 - INFO - EVALUATING - Epoch: [22][0/20]	Time 0.200 (0.200)	Data 0.198 (0.198)	Loss 0.6865 (0.6865)	Prec@1 57.812 (57.812)	
2022-01-19 14:56:59 - INFO - EVALUATING - Epoch: [22][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7040 (0.6920)	Prec@1 40.625 (52.415)	
2022-01-19 14:56:59 - INFO - 
 Epoch: 23	Training Loss 0.6968 	Training Prec@1 58.608 	Validation Loss 0.6944 	Validation Prec@1 50.079 	
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [23][0/80]	Time 0.246 (0.246)	Data 0.241 (0.241)	Loss 0.6945 (0.6945)	Prec@1 50.000 (50.000)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [23][10/80]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.6619 (0.7359)	Prec@1 65.625 (53.693)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [23][20/80]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.7005 (0.7155)	Prec@1 43.750 (54.167)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [23][30/80]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.7268 (0.7421)	Prec@1 59.375 (55.847)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [23][40/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6898 (0.7266)	Prec@1 54.688 (57.241)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [23][50/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.9085 (0.7251)	Prec@1 53.125 (56.710)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [23][60/80]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.6962 (0.7224)	Prec@1 48.438 (56.276)	
2022-01-19 14:57:00 - INFO - TRAINING - Epoch: [23][70/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6946 (0.7234)	Prec@1 50.000 (56.932)	
2022-01-19 14:57:00 - INFO - EVALUATING - Epoch: [23][0/20]	Time 0.238 (0.238)	Data 0.236 (0.236)	Loss 0.6861 (0.6861)	Prec@1 57.812 (57.812)	
2022-01-19 14:57:00 - INFO - EVALUATING - Epoch: [23][10/20]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.7049 (0.6920)	Prec@1 40.625 (52.415)	
2022-01-19 14:57:00 - INFO - 
 Epoch: 24	Training Loss 0.7203 	Training Prec@1 56.301 	Validation Loss 0.6946 	Validation Prec@1 50.079 	
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [24][0/80]	Time 0.240 (0.240)	Data 0.235 (0.235)	Loss 0.6998 (0.6998)	Prec@1 45.312 (45.312)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [24][10/80]	Time 0.004 (0.026)	Data 0.002 (0.023)	Loss 0.9718 (0.7879)	Prec@1 62.500 (51.562)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [24][20/80]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.6927 (0.7654)	Prec@1 51.562 (52.307)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [24][30/80]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.6944 (0.7425)	Prec@1 48.438 (51.210)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [24][40/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7841 (0.7516)	Prec@1 67.188 (53.049)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [24][50/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.0227 (0.7648)	Prec@1 53.125 (53.523)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [24][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6951 (0.7810)	Prec@1 46.875 (53.484)	
2022-01-19 14:57:01 - INFO - TRAINING - Epoch: [24][70/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.7425 (0.7716)	Prec@1 57.812 (53.961)	
2022-01-19 14:57:01 - INFO - EVALUATING - Epoch: [24][0/20]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 0.6896 (0.6896)	Prec@1 57.812 (57.812)	
2022-01-19 14:57:01 - INFO - EVALUATING - Epoch: [24][10/20]	Time 0.003 (0.022)	Data 0.002 (0.020)	Loss 0.6981 (0.6923)	Prec@1 40.625 (52.415)	
2022-01-19 14:57:01 - INFO - 
 Epoch: 25	Training Loss 0.7641 	Training Prec@1 53.264 	Validation Loss 0.6934 	Validation Prec@1 50.079 	
2022-01-19 14:57:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [25][0/80]	Time 0.206 (0.206)	Data 0.201 (0.201)	Loss 0.6981 (0.6981)	Prec@1 40.625 (40.625)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [25][10/80]	Time 0.005 (0.023)	Data 0.002 (0.020)	Loss 0.8753 (0.7295)	Prec@1 45.312 (49.716)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [25][20/80]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.7722 (0.7540)	Prec@1 53.125 (52.827)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [25][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6938 (0.7340)	Prec@1 50.000 (52.722)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [25][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.2893 (0.7771)	Prec@1 56.250 (54.764)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [25][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6979 (0.7776)	Prec@1 45.312 (53.248)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [25][60/80]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 1.0734 (0.7793)	Prec@1 54.688 (53.817)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [25][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6886 (0.7864)	Prec@1 56.250 (54.137)	
2022-01-19 14:57:02 - INFO - EVALUATING - Epoch: [25][0/20]	Time 0.243 (0.243)	Data 0.241 (0.241)	Loss 0.8630 (0.8630)	Prec@1 42.188 (42.188)	
2022-01-19 14:57:02 - INFO - EVALUATING - Epoch: [25][10/20]	Time 0.003 (0.025)	Data 0.002 (0.024)	Loss 0.7074 (0.8141)	Prec@1 59.375 (47.585)	
2022-01-19 14:57:02 - INFO - 
 Epoch: 26	Training Loss 0.7776 	Training Prec@1 54.368 	Validation Loss 0.7930 	Validation Prec@1 49.921 	
2022-01-19 14:57:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:02 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [26][0/80]	Time 0.243 (0.243)	Data 0.239 (0.239)	Loss 0.8771 (0.8771)	Prec@1 40.625 (40.625)	
2022-01-19 14:57:02 - INFO - TRAINING - Epoch: [26][10/80]	Time 0.005 (0.027)	Data 0.002 (0.024)	Loss 0.8030 (0.7745)	Prec@1 59.375 (54.545)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [26][20/80]	Time 0.005 (0.017)	Data 0.002 (0.014)	Loss 0.6971 (0.7567)	Prec@1 46.875 (53.274)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [26][30/80]	Time 0.004 (0.013)	Data 0.002 (0.010)	Loss 0.7545 (0.7447)	Prec@1 50.000 (54.738)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [26][40/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7492 (0.7571)	Prec@1 57.812 (55.450)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [26][50/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7288 (0.7511)	Prec@1 59.375 (54.013)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [26][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7489 (0.7450)	Prec@1 64.062 (55.584)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [26][70/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5545 (0.7417)	Prec@1 75.000 (55.370)	
2022-01-19 14:57:03 - INFO - EVALUATING - Epoch: [26][0/20]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.7601 (0.7601)	Prec@1 53.125 (53.125)	
2022-01-19 14:57:03 - INFO - EVALUATING - Epoch: [26][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6533 (0.7403)	Prec@1 65.625 (55.966)	
2022-01-19 14:57:03 - INFO - 
 Epoch: 27	Training Loss 0.7431 	Training Prec@1 56.103 	Validation Loss 0.7298 	Validation Prec@1 57.177 	
2022-01-19 14:57:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:03 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [27][0/80]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 0.7574 (0.7574)	Prec@1 54.688 (54.688)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [27][10/80]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.6817 (0.7171)	Prec@1 54.688 (55.114)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [27][20/80]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.7047 (0.7516)	Prec@1 59.375 (53.646)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [27][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.8026 (0.7395)	Prec@1 57.812 (54.083)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [27][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.5514 (0.7403)	Prec@1 70.312 (55.450)	
2022-01-19 14:57:03 - INFO - TRAINING - Epoch: [27][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7661 (0.7387)	Prec@1 53.125 (56.066)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [27][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.5834 (0.7298)	Prec@1 73.438 (55.302)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [27][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7034 (0.7481)	Prec@1 59.375 (55.326)	
2022-01-19 14:57:04 - INFO - EVALUATING - Epoch: [27][0/20]	Time 0.237 (0.237)	Data 0.235 (0.235)	Loss 1.1912 (1.1912)	Prec@1 45.312 (45.312)	
2022-01-19 14:57:04 - INFO - EVALUATING - Epoch: [27][10/20]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.7883 (1.0274)	Prec@1 67.188 (53.693)	
2022-01-19 14:57:04 - INFO - 
 Epoch: 28	Training Loss 0.7562 	Training Prec@1 55.985 	Validation Loss 0.9986 	Validation Prec@1 54.811 	
2022-01-19 14:57:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [28][0/80]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 0.9797 (0.9797)	Prec@1 56.250 (56.250)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [28][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.8261 (0.7412)	Prec@1 45.312 (57.102)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [28][20/80]	Time 0.005 (0.014)	Data 0.002 (0.011)	Loss 0.9621 (0.7533)	Prec@1 53.125 (54.539)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [28][30/80]	Time 0.005 (0.011)	Data 0.002 (0.008)	Loss 0.7424 (0.7560)	Prec@1 56.250 (55.796)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [28][40/80]	Time 0.005 (0.009)	Data 0.002 (0.007)	Loss 0.6581 (0.7417)	Prec@1 67.188 (56.593)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [28][50/80]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.6658 (0.7288)	Prec@1 65.625 (57.874)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [28][60/80]	Time 0.006 (0.008)	Data 0.003 (0.005)	Loss 0.7432 (0.7314)	Prec@1 60.938 (58.555)	
2022-01-19 14:57:04 - INFO - TRAINING - Epoch: [28][70/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.9560 (0.7313)	Prec@1 46.875 (58.363)	
2022-01-19 14:57:05 - INFO - EVALUATING - Epoch: [28][0/20]	Time 0.202 (0.202)	Data 0.200 (0.200)	Loss 0.8320 (0.8320)	Prec@1 62.500 (62.500)	
2022-01-19 14:57:05 - INFO - EVALUATING - Epoch: [28][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7601 (0.8587)	Prec@1 60.938 (62.216)	
2022-01-19 14:57:05 - INFO - 
 Epoch: 29	Training Loss 0.7462 	Training Prec@1 57.918 	Validation Loss 0.9077 	Validation Prec@1 59.385 	
2022-01-19 14:57:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [29][0/80]	Time 0.200 (0.200)	Data 0.196 (0.196)	Loss 0.8137 (0.8137)	Prec@1 59.375 (59.375)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [29][10/80]	Time 0.005 (0.022)	Data 0.002 (0.020)	Loss 0.9668 (0.9231)	Prec@1 59.375 (56.960)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [29][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6951 (0.9127)	Prec@1 50.000 (55.952)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [29][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6641 (0.8434)	Prec@1 64.062 (55.897)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [29][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6552 (0.7959)	Prec@1 70.312 (56.555)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [29][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7307 (0.8079)	Prec@1 56.250 (57.353)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [29][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6913 (0.7895)	Prec@1 53.125 (56.173)	
2022-01-19 14:57:05 - INFO - TRAINING - Epoch: [29][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7382 (0.7794)	Prec@1 42.188 (55.634)	
2022-01-19 14:57:06 - INFO - EVALUATING - Epoch: [29][0/20]	Time 0.234 (0.234)	Data 0.232 (0.232)	Loss 0.7241 (0.7241)	Prec@1 56.250 (56.250)	
2022-01-19 14:57:06 - INFO - EVALUATING - Epoch: [29][10/20]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.7498 (0.7837)	Prec@1 56.250 (50.994)	
2022-01-19 14:57:06 - INFO - 
 Epoch: 30	Training Loss 0.7727 	Training Prec@1 55.393 	Validation Loss 0.7884 	Validation Prec@1 50.946 	
2022-01-19 14:57:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:06 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [30][0/80]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.7445 (0.7445)	Prec@1 56.250 (56.250)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [30][10/80]	Time 0.005 (0.022)	Data 0.002 (0.020)	Loss 0.7129 (0.7707)	Prec@1 57.812 (55.966)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [30][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6554 (0.7985)	Prec@1 67.188 (57.515)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [30][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6969 (0.7672)	Prec@1 50.000 (56.351)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [30][40/80]	Time 0.005 (0.009)	Data 0.002 (0.007)	Loss 0.8818 (0.7804)	Prec@1 56.250 (56.250)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [30][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7085 (0.7779)	Prec@1 43.750 (56.250)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [30][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.8548 (0.7690)	Prec@1 42.188 (56.045)	
2022-01-19 14:57:06 - INFO - TRAINING - Epoch: [30][70/80]	Time 0.005 (0.008)	Data 0.002 (0.005)	Loss 0.7134 (0.7620)	Prec@1 42.188 (55.414)	
2022-01-19 14:57:07 - INFO - EVALUATING - Epoch: [30][0/20]	Time 0.205 (0.205)	Data 0.203 (0.203)	Loss 0.6993 (0.6993)	Prec@1 57.812 (57.812)	
2022-01-19 14:57:07 - INFO - EVALUATING - Epoch: [30][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6198 (0.7010)	Prec@1 68.750 (58.665)	
2022-01-19 14:57:07 - INFO - 
 Epoch: 31	Training Loss 0.7650 	Training Prec@1 56.044 	Validation Loss 0.6986 	Validation Prec@1 59.306 	
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [31][0/80]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 0.6858 (0.6858)	Prec@1 60.938 (60.938)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [31][10/80]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.6856 (0.8341)	Prec@1 59.375 (55.256)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [31][20/80]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 0.7189 (0.7762)	Prec@1 57.812 (53.199)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [31][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 1.1129 (0.7798)	Prec@1 46.875 (55.091)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [31][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8351 (0.7745)	Prec@1 51.562 (54.878)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [31][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6024 (0.7545)	Prec@1 70.312 (56.250)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [31][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6860 (0.7443)	Prec@1 56.250 (56.096)	
2022-01-19 14:57:07 - INFO - TRAINING - Epoch: [31][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7485 (0.7370)	Prec@1 59.375 (56.888)	
2022-01-19 14:57:07 - INFO - EVALUATING - Epoch: [31][0/20]	Time 0.191 (0.191)	Data 0.189 (0.189)	Loss 0.6830 (0.6830)	Prec@1 57.812 (57.812)	
2022-01-19 14:57:07 - INFO - EVALUATING - Epoch: [31][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7144 (0.6929)	Prec@1 40.625 (52.415)	
2022-01-19 14:57:07 - INFO - 
 Epoch: 32	Training Loss 0.7338 	Training Prec@1 56.754 	Validation Loss 0.6972 	Validation Prec@1 50.079 	
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:07 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [32][0/80]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 0.6945 (0.6945)	Prec@1 51.562 (51.562)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [32][10/80]	Time 0.005 (0.023)	Data 0.002 (0.021)	Loss 0.7306 (0.9195)	Prec@1 54.688 (55.398)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [32][20/80]	Time 0.004 (0.014)	Data 0.002 (0.012)	Loss 1.1721 (0.8583)	Prec@1 67.188 (53.869)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [32][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7868 (0.9115)	Prec@1 50.000 (52.772)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [32][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7047 (0.8553)	Prec@1 45.312 (54.611)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [32][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7601 (0.8241)	Prec@1 53.125 (54.075)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [32][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.7051 (0.8045)	Prec@1 45.312 (54.688)	
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [32][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7572 (0.8028)	Prec@1 68.750 (54.533)	
2022-01-19 14:57:08 - INFO - EVALUATING - Epoch: [32][0/20]	Time 0.196 (0.196)	Data 0.194 (0.194)	Loss 0.6834 (0.6834)	Prec@1 57.812 (57.812)	
2022-01-19 14:57:08 - INFO - EVALUATING - Epoch: [32][10/20]	Time 0.003 (0.021)	Data 0.002 (0.019)	Loss 0.7131 (0.6927)	Prec@1 40.625 (52.415)	
2022-01-19 14:57:08 - INFO - 
 Epoch: 33	Training Loss 0.7913 	Training Prec@1 55.157 	Validation Loss 0.6967 	Validation Prec@1 50.079 	
2022-01-19 14:57:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:08 - INFO - TRAINING - Epoch: [33][0/80]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.7023 (0.7023)	Prec@1 46.875 (46.875)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [33][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.6951 (0.7889)	Prec@1 60.938 (54.688)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [33][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.8312 (0.7831)	Prec@1 62.500 (55.655)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [33][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7835 (0.7702)	Prec@1 51.562 (56.905)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [33][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7071 (0.7640)	Prec@1 43.750 (56.174)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [33][50/80]	Time 0.005 (0.008)	Data 0.002 (0.006)	Loss 0.7634 (0.7484)	Prec@1 53.125 (56.158)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [33][60/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.6079 (0.7338)	Prec@1 68.750 (57.608)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [33][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.1811 (0.7425)	Prec@1 59.375 (57.438)	
2022-01-19 14:57:09 - INFO - EVALUATING - Epoch: [33][0/20]	Time 0.201 (0.201)	Data 0.199 (0.199)	Loss 0.6837 (0.6837)	Prec@1 57.812 (57.812)	
2022-01-19 14:57:09 - INFO - EVALUATING - Epoch: [33][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7118 (0.6925)	Prec@1 40.625 (52.415)	
2022-01-19 14:57:09 - INFO - 
 Epoch: 34	Training Loss 0.7629 	Training Prec@1 57.287 	Validation Loss 0.6963 	Validation Prec@1 50.079 	
2022-01-19 14:57:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [34][0/80]	Time 0.247 (0.247)	Data 0.243 (0.243)	Loss 0.6812 (0.6812)	Prec@1 59.375 (59.375)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [34][10/80]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.9409 (0.8958)	Prec@1 50.000 (52.983)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [34][20/80]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.6859 (0.8119)	Prec@1 56.250 (56.696)	
2022-01-19 14:57:09 - INFO - TRAINING - Epoch: [34][30/80]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 1.1704 (0.8023)	Prec@1 54.688 (55.444)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [34][40/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7134 (0.7862)	Prec@1 40.625 (55.145)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [34][50/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.8131 (0.7828)	Prec@1 70.312 (56.679)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [34][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6835 (0.7711)	Prec@1 57.812 (56.019)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [34][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9018 (0.7787)	Prec@1 53.125 (56.250)	
2022-01-19 14:57:10 - INFO - EVALUATING - Epoch: [34][0/20]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.6833 (0.6833)	Prec@1 57.812 (57.812)	
2022-01-19 14:57:10 - INFO - EVALUATING - Epoch: [34][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7132 (0.6927)	Prec@1 40.625 (52.415)	
2022-01-19 14:57:10 - INFO - 
 Epoch: 35	Training Loss 0.7835 	Training Prec@1 56.241 	Validation Loss 0.6968 	Validation Prec@1 50.079 	
2022-01-19 14:57:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [35][0/80]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.6969 (0.6969)	Prec@1 50.000 (50.000)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [35][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.6401 (0.8381)	Prec@1 75.000 (52.415)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [35][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6971 (0.8138)	Prec@1 50.000 (54.464)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [35][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6761 (0.7784)	Prec@1 64.062 (54.990)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [35][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6529 (0.7470)	Prec@1 65.625 (57.698)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [35][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6981 (0.7391)	Prec@1 48.438 (57.690)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [35][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7964 (0.7536)	Prec@1 51.562 (58.248)	
2022-01-19 14:57:10 - INFO - TRAINING - Epoch: [35][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7624 (0.7599)	Prec@1 56.250 (58.539)	
2022-01-19 14:57:11 - INFO - EVALUATING - Epoch: [35][0/20]	Time 0.236 (0.236)	Data 0.234 (0.234)	Loss 0.8430 (0.8430)	Prec@1 62.500 (62.500)	
2022-01-19 14:57:11 - INFO - EVALUATING - Epoch: [35][10/20]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.7398 (0.9233)	Prec@1 68.750 (58.949)	
2022-01-19 14:57:11 - INFO - 
 Epoch: 36	Training Loss 0.7557 	Training Prec@1 57.957 	Validation Loss 0.9133 	Validation Prec@1 59.543 	
2022-01-19 14:57:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [36][0/80]	Time 0.193 (0.193)	Data 0.189 (0.189)	Loss 1.0433 (1.0433)	Prec@1 53.125 (53.125)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [36][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.6699 (0.7594)	Prec@1 65.625 (56.392)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [36][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6964 (0.7205)	Prec@1 48.438 (57.887)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [36][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7124 (0.7009)	Prec@1 53.125 (59.022)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [36][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6524 (0.7014)	Prec@1 65.625 (59.223)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [36][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6896 (0.7083)	Prec@1 54.688 (58.119)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [36][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6709 (0.7045)	Prec@1 67.188 (58.735)	
2022-01-19 14:57:11 - INFO - TRAINING - Epoch: [36][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6942 (0.7110)	Prec@1 50.000 (58.561)	
2022-01-19 14:57:12 - INFO - EVALUATING - Epoch: [36][0/20]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.6880 (0.6880)	Prec@1 57.812 (57.812)	
2022-01-19 14:57:12 - INFO - EVALUATING - Epoch: [36][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.7008 (0.6920)	Prec@1 40.625 (52.415)	
2022-01-19 14:57:12 - INFO - 
 Epoch: 37	Training Loss 0.7127 	Training Prec@1 57.937 	Validation Loss 0.6938 	Validation Prec@1 50.079 	
2022-01-19 14:57:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [37][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 0.6927 (0.6927)	Prec@1 51.562 (51.562)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [37][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7602 (0.9294)	Prec@1 56.250 (55.114)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [37][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6918 (0.8261)	Prec@1 53.125 (51.562)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [37][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7145 (0.8244)	Prec@1 68.750 (53.175)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [37][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.2765 (0.8397)	Prec@1 43.750 (54.992)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [37][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6688 (0.8431)	Prec@1 64.062 (55.270)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [37][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6773 (0.8232)	Prec@1 64.062 (56.250)	
2022-01-19 14:57:12 - INFO - TRAINING - Epoch: [37][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6854 (0.8046)	Prec@1 65.625 (57.020)	
2022-01-19 14:57:12 - INFO - EVALUATING - Epoch: [37][0/20]	Time 0.240 (0.240)	Data 0.238 (0.238)	Loss 0.8468 (0.8468)	Prec@1 64.062 (64.062)	
2022-01-19 14:57:12 - INFO - EVALUATING - Epoch: [37][10/20]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.6615 (0.8185)	Prec@1 73.438 (65.483)	
2022-01-19 14:57:12 - INFO - 
 Epoch: 38	Training Loss 0.7968 	Training Prec@1 56.498 	Validation Loss 0.8634 	Validation Prec@1 63.328 	
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [38][0/80]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.6616 (0.6616)	Prec@1 73.438 (73.438)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [38][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.9132 (0.8509)	Prec@1 60.938 (55.398)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [38][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6705 (0.7706)	Prec@1 64.062 (57.961)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [38][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6862 (0.7491)	Prec@1 65.625 (55.948)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [38][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7840 (0.7486)	Prec@1 67.188 (55.526)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [38][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6947 (0.7532)	Prec@1 43.750 (55.025)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [38][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6941 (0.7843)	Prec@1 46.875 (54.585)	
2022-01-19 14:57:13 - INFO - TRAINING - Epoch: [38][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6938 (0.7715)	Prec@1 48.438 (53.697)	
2022-01-19 14:57:13 - INFO - EVALUATING - Epoch: [38][0/20]	Time 0.199 (0.199)	Data 0.197 (0.197)	Loss 0.6246 (0.6246)	Prec@1 68.750 (68.750)	
2022-01-19 14:57:13 - INFO - EVALUATING - Epoch: [38][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6124 (0.6511)	Prec@1 70.312 (66.193)	
2022-01-19 14:57:13 - INFO - 
 Epoch: 39	Training Loss 0.7635 	Training Prec@1 53.106 	Validation Loss 0.6735 	Validation Prec@1 64.038 	
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [39][0/80]	Time 0.195 (0.195)	Data 0.191 (0.191)	Loss 0.7186 (0.7186)	Prec@1 59.375 (59.375)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [39][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.7021 (0.8148)	Prec@1 60.938 (54.545)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [39][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 1.1475 (0.8321)	Prec@1 48.438 (52.827)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [39][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6279 (0.8165)	Prec@1 68.750 (53.881)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [39][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6927 (0.7830)	Prec@1 51.562 (55.259)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [39][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8751 (0.7836)	Prec@1 56.250 (54.534)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [39][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6377 (0.8007)	Prec@1 67.188 (54.406)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [39][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.6934 (0.7850)	Prec@1 50.000 (54.379)	
2022-01-19 14:57:14 - INFO - EVALUATING - Epoch: [39][0/20]	Time 0.195 (0.195)	Data 0.193 (0.193)	Loss 1.1303 (1.1303)	Prec@1 42.188 (42.188)	
2022-01-19 14:57:14 - INFO - EVALUATING - Epoch: [39][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.8416 (1.0735)	Prec@1 59.375 (47.585)	
2022-01-19 14:57:14 - INFO - 
 Epoch: 40	Training Loss 0.7815 	Training Prec@1 54.841 	Validation Loss 1.0408 	Validation Prec@1 49.921 	
2022-01-19 14:57:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:14 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [40][0/80]	Time 0.205 (0.205)	Data 0.201 (0.201)	Loss 1.1402 (1.1402)	Prec@1 42.188 (42.188)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [40][10/80]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.7706 (0.8203)	Prec@1 65.625 (60.085)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [40][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6927 (0.7761)	Prec@1 51.562 (55.878)	
2022-01-19 14:57:14 - INFO - TRAINING - Epoch: [40][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7425 (0.7872)	Prec@1 64.062 (56.603)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [40][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6701 (0.7878)	Prec@1 64.062 (55.259)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [40][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8023 (0.8136)	Prec@1 40.625 (54.504)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [40][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7675 (0.8284)	Prec@1 54.688 (54.585)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [40][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9140 (0.8262)	Prec@1 60.938 (53.829)	
2022-01-19 14:57:15 - INFO - EVALUATING - Epoch: [40][0/20]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.6911 (0.6911)	Prec@1 57.812 (57.812)	
2022-01-19 14:57:15 - INFO - EVALUATING - Epoch: [40][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6958 (0.6926)	Prec@1 40.625 (52.415)	
2022-01-19 14:57:15 - INFO - 
 Epoch: 41	Training Loss 0.8173 	Training Prec@1 53.303 	Validation Loss 0.6932 	Validation Prec@1 50.079 	
2022-01-19 14:57:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:15 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [41][0/80]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.6928 (0.6928)	Prec@1 51.562 (51.562)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [41][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.2540 (0.8749)	Prec@1 53.125 (53.835)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [41][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6938 (0.8380)	Prec@1 46.875 (52.381)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [41][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6888 (0.8241)	Prec@1 71.875 (54.335)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [41][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6924 (0.8178)	Prec@1 54.688 (54.306)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [41][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7043 (0.7933)	Prec@1 60.938 (55.178)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [41][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7625 (0.7847)	Prec@1 64.062 (55.456)	
2022-01-19 14:57:15 - INFO - TRAINING - Epoch: [41][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6942 (0.7834)	Prec@1 42.188 (55.766)	
2022-01-19 14:57:16 - INFO - EVALUATING - Epoch: [41][0/20]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 0.7028 (0.7028)	Prec@1 65.625 (65.625)	
2022-01-19 14:57:16 - INFO - EVALUATING - Epoch: [41][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6099 (0.7141)	Prec@1 62.500 (61.932)	
2022-01-19 14:57:16 - INFO - 
 Epoch: 42	Training Loss 0.7748 	Training Prec@1 55.906 	Validation Loss 0.7177 	Validation Prec@1 59.227 	
2022-01-19 14:57:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [42][0/80]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.7165 (0.7165)	Prec@1 59.375 (59.375)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [42][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.1645 (1.2368)	Prec@1 67.188 (54.972)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [42][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6943 (1.0568)	Prec@1 43.750 (50.818)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [42][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6548 (0.9431)	Prec@1 65.625 (53.125)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [42][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6929 (0.9157)	Prec@1 51.562 (54.268)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [42][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6924 (0.8721)	Prec@1 56.250 (53.401)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [42][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8276 (0.8566)	Prec@1 48.438 (53.714)	
2022-01-19 14:57:16 - INFO - TRAINING - Epoch: [42][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 1.3497 (0.8626)	Prec@1 46.875 (53.631)	
2022-01-19 14:57:17 - INFO - EVALUATING - Epoch: [42][0/20]	Time 0.204 (0.204)	Data 0.202 (0.202)	Loss 0.5935 (0.5935)	Prec@1 71.875 (71.875)	
2022-01-19 14:57:17 - INFO - EVALUATING - Epoch: [42][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.6101 (0.6604)	Prec@1 70.312 (65.199)	
2022-01-19 14:57:17 - INFO - 
 Epoch: 43	Training Loss 0.8523 	Training Prec@1 53.737 	Validation Loss 0.6826 	Validation Prec@1 63.013 	
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [43][0/80]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.6407 (0.6407)	Prec@1 67.188 (67.188)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [43][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 0.7593 (1.0472)	Prec@1 62.500 (56.108)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [43][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.7033 (0.8947)	Prec@1 60.938 (54.985)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [43][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.6932 (0.8304)	Prec@1 50.000 (56.300)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [43][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.1756 (0.8436)	Prec@1 45.312 (56.631)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [43][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.6928 (0.8121)	Prec@1 51.562 (57.384)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [43][60/80]	Time 0.006 (0.007)	Data 0.003 (0.005)	Loss 0.6740 (0.8074)	Prec@1 64.062 (57.838)	
2022-01-19 14:57:17 - INFO - TRAINING - Epoch: [43][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6918 (0.7972)	Prec@1 62.500 (57.284)	
2022-01-19 14:57:17 - INFO - EVALUATING - Epoch: [43][0/20]	Time 0.210 (0.210)	Data 0.208 (0.208)	Loss 0.6940 (0.6940)	Prec@1 71.875 (71.875)	
2022-01-19 14:57:17 - INFO - EVALUATING - Epoch: [43][10/20]	Time 0.003 (0.022)	Data 0.002 (0.021)	Loss 0.8850 (0.8820)	Prec@1 62.500 (62.500)	
2022-01-19 14:57:17 - INFO - 
 Epoch: 44	Training Loss 0.7872 	Training Prec@1 57.267 	Validation Loss 0.9450 	Validation Prec@1 59.385 	
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [44][0/80]	Time 0.189 (0.189)	Data 0.186 (0.186)	Loss 0.8837 (0.8837)	Prec@1 62.500 (62.500)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [44][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 0.6949 (0.8229)	Prec@1 45.312 (57.812)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [44][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6928 (0.7806)	Prec@1 51.562 (55.580)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [44][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.6922 (0.7744)	Prec@1 57.812 (55.444)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [44][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.6930 (0.7780)	Prec@1 57.812 (55.107)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [44][50/80]	Time 0.004 (0.008)	Data 0.002 (0.005)	Loss 0.9691 (0.7722)	Prec@1 57.812 (54.688)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [44][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8489 (0.7871)	Prec@1 46.875 (54.995)	
2022-01-19 14:57:18 - INFO - TRAINING - Epoch: [44][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.8885 (0.8012)	Prec@1 56.250 (55.326)	
2022-01-19 14:57:18 - INFO - EVALUATING - Epoch: [44][0/20]	Time 0.194 (0.194)	Data 0.193 (0.193)	Loss 0.6225 (0.6225)	Prec@1 70.312 (70.312)	
2022-01-19 14:57:18 - INFO - EVALUATING - Epoch: [44][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6932 (0.7624)	Prec@1 60.938 (62.216)	
2022-01-19 14:57:18 - INFO - 
 Epoch: 45	Training Loss 0.8086 	Training Prec@1 55.098 	Validation Loss 0.7956 	Validation Prec@1 59.464 	
2022-01-19 14:57:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [45][0/80]	Time 0.208 (0.208)	Data 0.204 (0.204)	Loss 0.8416 (0.8416)	Prec@1 54.688 (54.688)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [45][10/80]	Time 0.004 (0.023)	Data 0.002 (0.020)	Loss 0.6931 (0.9871)	Prec@1 59.375 (53.551)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [45][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 1.0635 (0.9103)	Prec@1 53.125 (53.869)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [45][30/80]	Time 0.004 (0.011)	Data 0.002 (0.008)	Loss 0.7217 (0.8521)	Prec@1 70.312 (54.183)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [45][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.6930 (0.8540)	Prec@1 51.562 (53.544)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [45][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.9405 (0.8274)	Prec@1 59.375 (53.002)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [45][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6929 (0.8174)	Prec@1 53.125 (53.535)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [45][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.9706 (0.8038)	Prec@1 57.812 (52.861)	
2022-01-19 14:57:19 - INFO - EVALUATING - Epoch: [45][0/20]	Time 0.190 (0.190)	Data 0.188 (0.188)	Loss 0.6941 (0.6941)	Prec@1 42.188 (42.188)	
2022-01-19 14:57:19 - INFO - EVALUATING - Epoch: [45][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6920 (0.6935)	Prec@1 59.375 (47.585)	
2022-01-19 14:57:19 - INFO - 
 Epoch: 46	Training Loss 0.8016 	Training Prec@1 52.889 	Validation Loss 0.6932 	Validation Prec@1 49.921 	
2022-01-19 14:57:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][0/80]	Time 0.194 (0.194)	Data 0.191 (0.191)	Loss 0.6924 (0.6924)	Prec@1 56.250 (56.250)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][10/80]	Time 0.004 (0.021)	Data 0.002 (0.019)	Loss 1.0631 (0.8979)	Prec@1 56.250 (52.273)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6931 (0.8788)	Prec@1 50.000 (51.786)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.8240 (0.8782)	Prec@1 68.750 (53.528)	
2022-01-19 14:57:19 - INFO - TRAINING - Epoch: [46][40/80]	Time 0.004 (0.009)	Data 0.002 (0.006)	Loss 0.9127 (0.8554)	Prec@1 40.625 (53.277)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [46][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.8012 (0.8464)	Prec@1 51.562 (54.197)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [46][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7832 (0.8371)	Prec@1 67.188 (54.457)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [46][70/80]	Time 0.004 (0.007)	Data 0.002 (0.004)	Loss 0.9828 (0.8209)	Prec@1 67.188 (54.291)	
2022-01-19 14:57:20 - INFO - EVALUATING - Epoch: [46][0/20]	Time 0.240 (0.240)	Data 0.238 (0.238)	Loss 0.7829 (0.7829)	Prec@1 67.188 (67.188)	
2022-01-19 14:57:20 - INFO - EVALUATING - Epoch: [46][10/20]	Time 0.003 (0.024)	Data 0.002 (0.023)	Loss 0.7201 (0.7490)	Prec@1 70.312 (68.892)	
2022-01-19 14:57:20 - INFO - 
 Epoch: 47	Training Loss 0.8338 	Training Prec@1 54.762 	Validation Loss 0.8301 	Validation Prec@1 64.826 	
2022-01-19 14:57:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:20 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][0/80]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.6270 (0.6270)	Prec@1 75.000 (75.000)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][10/80]	Time 0.004 (0.022)	Data 0.002 (0.020)	Loss 1.0662 (1.0603)	Prec@1 42.188 (53.693)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][20/80]	Time 0.004 (0.014)	Data 0.002 (0.011)	Loss 0.6909 (0.8875)	Prec@1 65.625 (57.366)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.9386 (0.8834)	Prec@1 59.375 (55.897)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7971 (0.8469)	Prec@1 51.562 (56.402)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7038 (0.8180)	Prec@1 60.938 (55.300)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6931 (0.7986)	Prec@1 59.375 (56.250)	
2022-01-19 14:57:20 - INFO - TRAINING - Epoch: [47][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6915 (0.7837)	Prec@1 59.375 (55.744)	
2022-01-19 14:57:21 - INFO - EVALUATING - Epoch: [47][0/20]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.6959 (0.6959)	Prec@1 42.188 (42.188)	
2022-01-19 14:57:21 - INFO - EVALUATING - Epoch: [47][10/20]	Time 0.003 (0.020)	Data 0.002 (0.019)	Loss 0.6902 (0.6941)	Prec@1 59.375 (47.585)	
2022-01-19 14:57:21 - INFO - 
 Epoch: 48	Training Loss 0.7968 	Training Prec@1 55.078 	Validation Loss 0.6933 	Validation Prec@1 49.921 	
2022-01-19 14:57:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:21 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][0/80]	Time 0.198 (0.198)	Data 0.195 (0.195)	Loss 0.6902 (0.6902)	Prec@1 59.375 (59.375)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][10/80]	Time 0.004 (0.022)	Data 0.002 (0.019)	Loss 0.8941 (0.9924)	Prec@1 57.812 (54.261)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][20/80]	Time 0.004 (0.013)	Data 0.002 (0.011)	Loss 0.6342 (0.8783)	Prec@1 60.938 (56.473)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][30/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 0.7030 (0.8378)	Prec@1 60.938 (54.486)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][40/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 1.0116 (0.8328)	Prec@1 56.250 (56.555)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][50/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.7380 (0.8559)	Prec@1 68.750 (56.618)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][60/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.8058 (0.8524)	Prec@1 56.250 (56.148)	
2022-01-19 14:57:21 - INFO - TRAINING - Epoch: [48][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.7020 (0.8636)	Prec@1 73.438 (55.722)	
2022-01-19 14:57:22 - INFO - EVALUATING - Epoch: [48][0/20]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.8963 (0.8963)	Prec@1 42.188 (42.188)	
2022-01-19 14:57:22 - INFO - EVALUATING - Epoch: [48][10/20]	Time 0.003 (0.021)	Data 0.002 (0.020)	Loss 0.7217 (0.8415)	Prec@1 59.375 (47.585)	
2022-01-19 14:57:22 - INFO - 
 Epoch: 49	Training Loss 0.8568 	Training Prec@1 56.655 	Validation Loss 0.8178 	Validation Prec@1 49.921 	
2022-01-19 14:57:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-19 14:57:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-19 14:57:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-19 14:57:22 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][0/80]	Time 0.246 (0.246)	Data 0.242 (0.242)	Loss 0.8328 (0.8328)	Prec@1 48.438 (48.438)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][10/80]	Time 0.004 (0.026)	Data 0.002 (0.024)	Loss 0.8043 (1.0799)	Prec@1 51.562 (56.676)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][20/80]	Time 0.004 (0.016)	Data 0.002 (0.013)	Loss 0.8136 (0.9448)	Prec@1 65.625 (54.464)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][30/80]	Time 0.004 (0.012)	Data 0.002 (0.010)	Loss 0.6929 (0.8784)	Prec@1 53.125 (54.637)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][40/80]	Time 0.004 (0.010)	Data 0.002 (0.008)	Loss 2.1013 (0.9337)	Prec@1 31.250 (53.697)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][50/80]	Time 0.004 (0.009)	Data 0.002 (0.007)	Loss 0.7762 (0.9171)	Prec@1 50.000 (54.228)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][60/80]	Time 0.004 (0.008)	Data 0.002 (0.006)	Loss 0.9390 (0.9005)	Prec@1 59.375 (54.688)	
2022-01-19 14:57:22 - INFO - TRAINING - Epoch: [49][70/80]	Time 0.004 (0.007)	Data 0.002 (0.005)	Loss 0.6929 (0.8795)	Prec@1 51.562 (54.247)	
2022-01-19 14:57:22 - INFO - EVALUATING - Epoch: [49][0/20]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 0.6940 (0.6940)	Prec@1 42.188 (42.188)	
2022-01-19 14:57:22 - INFO - EVALUATING - Epoch: [49][10/20]	Time 0.003 (0.025)	Data 0.002 (0.023)	Loss 0.6922 (0.6934)	Prec@1 59.375 (47.585)	
2022-01-19 14:57:22 - INFO - 
 Epoch: 50	Training Loss 0.8666 	Training Prec@1 55.196 	Validation Loss 0.6932 	Validation Prec@1 49.921 	
