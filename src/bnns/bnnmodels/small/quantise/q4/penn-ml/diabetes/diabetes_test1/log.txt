2022-01-05 15:45:21 - INFO - saving to ./results/small/quantise/q4/penn-ml/diabetes/diabetes_test1/
2022-01-05 15:45:21 - DEBUG - run arguments: Namespace(config='./configs/config_small.json', data='../../paper_bench/complete/quantise/q4/penn-ml/diabetes/diabetes_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/small/quantise/q4/penn-ml/diabetes/diabetes_test1/', test='../../paper_bench/cv/test/quantise/q4/penn-ml/diabetes/diabetes_test1_data.csv', train='../../paper_bench/cv/train/quantise/q4/penn-ml/diabetes/diabetes_train1_data.csv')
2022-01-05 15:45:22 - INFO - creating model mlp_binary
2022-01-05 15:45:22 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [10, 5, 5, 2]}
2022-01-05 15:45:22 - INFO - number of parameters: 467
2022-01-05 15:45:22 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-05 15:45:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:22 - INFO - TRAINING - Epoch: [0][0/10]	Time 0.155 (0.155)	Data 0.147 (0.147)	Loss 1.7135 (1.7135)	Prec@1 57.812 (57.812)	
2022-01-05 15:45:22 - INFO - EVALUATING - Epoch: [0][0/3]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.9012 (0.9012)	Prec@1 59.375 (59.375)	
2022-01-05 15:45:22 - INFO - 
 Epoch: 1	Training Loss 1.0116 	Training Prec@1 64.332 	Validation Loss 1.0035 	Validation Prec@1 55.844 	
2022-01-05 15:45:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:22 - INFO - TRAINING - Epoch: [1][0/10]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.9298 (0.9298)	Prec@1 59.375 (59.375)	
2022-01-05 15:45:22 - INFO - EVALUATING - Epoch: [1][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.6463 (0.6463)	Prec@1 73.438 (73.438)	
2022-01-05 15:45:22 - INFO - 
 Epoch: 2	Training Loss 0.8804 	Training Prec@1 62.866 	Validation Loss 0.8199 	Validation Prec@1 68.182 	
2022-01-05 15:45:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:22 - INFO - TRAINING - Epoch: [2][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.7523 (0.7523)	Prec@1 71.875 (71.875)	
2022-01-05 15:45:23 - INFO - EVALUATING - Epoch: [2][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.6380 (0.6380)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:23 - INFO - 
 Epoch: 3	Training Loss 0.8125 	Training Prec@1 61.889 	Validation Loss 0.6651 	Validation Prec@1 64.286 	
2022-01-05 15:45:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:23 - INFO - TRAINING - Epoch: [3][0/10]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.6380 (0.6380)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:23 - INFO - EVALUATING - Epoch: [3][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.6469 (0.6469)	Prec@1 65.625 (65.625)	
2022-01-05 15:45:23 - INFO - 
 Epoch: 4	Training Loss 0.8092 	Training Prec@1 64.495 	Validation Loss 0.8513 	Validation Prec@1 59.091 	
2022-01-05 15:45:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:23 - INFO - TRAINING - Epoch: [4][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.9526 (0.9526)	Prec@1 62.500 (62.500)	
2022-01-05 15:45:23 - INFO - EVALUATING - Epoch: [4][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.8625 (0.8625)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:23 - INFO - 
 Epoch: 5	Training Loss 0.7897 	Training Prec@1 64.007 	Validation Loss 1.0240 	Validation Prec@1 65.584 	
2022-01-05 15:45:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:24 - INFO - TRAINING - Epoch: [5][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.9225 (0.9225)	Prec@1 70.312 (70.312)	
2022-01-05 15:45:24 - INFO - EVALUATING - Epoch: [5][0/3]	Time 0.120 (0.120)	Data 0.117 (0.117)	Loss 0.6342 (0.6342)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:24 - INFO - 
 Epoch: 6	Training Loss 0.8166 	Training Prec@1 63.029 	Validation Loss 0.6518 	Validation Prec@1 64.286 	
2022-01-05 15:45:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:24 - INFO - TRAINING - Epoch: [6][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.7007 (0.7007)	Prec@1 56.250 (56.250)	
2022-01-05 15:45:24 - INFO - EVALUATING - Epoch: [6][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6344 (0.6344)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:24 - INFO - 
 Epoch: 7	Training Loss 0.8121 	Training Prec@1 58.632 	Validation Loss 0.6518 	Validation Prec@1 64.286 	
2022-01-05 15:45:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:24 - INFO - TRAINING - Epoch: [7][0/10]	Time 0.147 (0.147)	Data 0.143 (0.143)	Loss 0.7093 (0.7093)	Prec@1 54.688 (54.688)	
2022-01-05 15:45:24 - INFO - EVALUATING - Epoch: [7][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.6210 (0.6210)	Prec@1 71.875 (71.875)	
2022-01-05 15:45:24 - INFO - 
 Epoch: 8	Training Loss 0.7784 	Training Prec@1 65.635 	Validation Loss 0.8335 	Validation Prec@1 61.039 	
2022-01-05 15:45:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:25 - INFO - TRAINING - Epoch: [8][0/10]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.7620 (0.7620)	Prec@1 65.625 (65.625)	
2022-01-05 15:45:25 - INFO - EVALUATING - Epoch: [8][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.8114 (0.8114)	Prec@1 68.750 (68.750)	
2022-01-05 15:45:25 - INFO - 
 Epoch: 9	Training Loss 0.7410 	Training Prec@1 63.192 	Validation Loss 0.7623 	Validation Prec@1 71.429 	
2022-01-05 15:45:25 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:25 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:25 - INFO - TRAINING - Epoch: [9][0/10]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 0.6921 (0.6921)	Prec@1 70.312 (70.312)	
2022-01-05 15:45:25 - INFO - EVALUATING - Epoch: [9][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 1.3167 (1.3167)	Prec@1 35.938 (35.938)	
2022-01-05 15:45:25 - INFO - 
 Epoch: 10	Training Loss 0.9811 	Training Prec@1 60.586 	Validation Loss 1.2988 	Validation Prec@1 42.857 	
2022-01-05 15:45:25 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:25 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:25 - INFO - TRAINING - Epoch: [10][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 1.2954 (1.2954)	Prec@1 35.938 (35.938)	
2022-01-05 15:45:26 - INFO - EVALUATING - Epoch: [10][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6406 (0.6406)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:26 - INFO - 
 Epoch: 11	Training Loss 1.0206 	Training Prec@1 61.401 	Validation Loss 0.6693 	Validation Prec@1 64.286 	
2022-01-05 15:45:26 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:26 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:26 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:26 - INFO - TRAINING - Epoch: [11][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.6560 (0.6560)	Prec@1 65.625 (65.625)	
2022-01-05 15:45:26 - INFO - EVALUATING - Epoch: [11][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.6341 (0.6341)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:26 - INFO - 
 Epoch: 12	Training Loss 0.9721 	Training Prec@1 62.541 	Validation Loss 0.6581 	Validation Prec@1 64.286 	
2022-01-05 15:45:26 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:26 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:26 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:26 - INFO - TRAINING - Epoch: [12][0/10]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.6986 (0.6986)	Prec@1 59.375 (59.375)	
2022-01-05 15:45:26 - INFO - EVALUATING - Epoch: [12][0/3]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.1157 (1.1157)	Prec@1 32.812 (32.812)	
2022-01-05 15:45:26 - INFO - 
 Epoch: 13	Training Loss 0.8645 	Training Prec@1 64.332 	Validation Loss 1.0244 	Validation Prec@1 40.260 	
2022-01-05 15:45:26 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:26 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:26 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:26 - INFO - TRAINING - Epoch: [13][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 1.1590 (1.1590)	Prec@1 34.375 (34.375)	
2022-01-05 15:45:27 - INFO - EVALUATING - Epoch: [13][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.6863 (0.6863)	Prec@1 64.062 (64.062)	
2022-01-05 15:45:27 - INFO - 
 Epoch: 14	Training Loss 0.8628 	Training Prec@1 63.029 	Validation Loss 0.7616 	Validation Prec@1 58.442 	
2022-01-05 15:45:27 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:27 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:27 - INFO - TRAINING - Epoch: [14][0/10]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.9933 (0.9933)	Prec@1 39.062 (39.062)	
2022-01-05 15:45:27 - INFO - EVALUATING - Epoch: [14][0/3]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.6402 (0.6402)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:27 - INFO - 
 Epoch: 15	Training Loss 0.7837 	Training Prec@1 59.935 	Validation Loss 0.6687 	Validation Prec@1 64.286 	
2022-01-05 15:45:27 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:27 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:27 - INFO - TRAINING - Epoch: [15][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5790 (0.5790)	Prec@1 73.438 (73.438)	
2022-01-05 15:45:27 - INFO - EVALUATING - Epoch: [15][0/3]	Time 0.148 (0.148)	Data 0.146 (0.146)	Loss 0.6418 (0.6418)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:27 - INFO - 
 Epoch: 16	Training Loss 0.7695 	Training Prec@1 69.218 	Validation Loss 0.6710 	Validation Prec@1 64.286 	
2022-01-05 15:45:27 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:27 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:28 - INFO - TRAINING - Epoch: [16][0/10]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.6575 (0.6575)	Prec@1 65.625 (65.625)	
2022-01-05 15:45:28 - INFO - EVALUATING - Epoch: [16][0/3]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.9881 (0.9881)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:28 - INFO - 
 Epoch: 17	Training Loss 0.7428 	Training Prec@1 68.241 	Validation Loss 1.0704 	Validation Prec@1 64.286 	
2022-01-05 15:45:28 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:28 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:28 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:28 - INFO - TRAINING - Epoch: [17][0/10]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 1.1688 (1.1688)	Prec@1 60.938 (60.938)	
2022-01-05 15:45:28 - INFO - EVALUATING - Epoch: [17][0/3]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.7549 (0.7549)	Prec@1 73.438 (73.438)	
2022-01-05 15:45:28 - INFO - 
 Epoch: 18	Training Loss 0.7905 	Training Prec@1 58.632 	Validation Loss 1.0813 	Validation Prec@1 61.688 	
2022-01-05 15:45:28 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:28 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:28 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:28 - INFO - TRAINING - Epoch: [18][0/10]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.7459 (0.7459)	Prec@1 71.875 (71.875)	
2022-01-05 15:45:29 - INFO - EVALUATING - Epoch: [18][0/3]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.0766 (1.0766)	Prec@1 40.625 (40.625)	
2022-01-05 15:45:29 - INFO - 
 Epoch: 19	Training Loss 1.0275 	Training Prec@1 67.101 	Validation Loss 1.1474 	Validation Prec@1 45.455 	
2022-01-05 15:45:29 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:29 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:29 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:29 - INFO - TRAINING - Epoch: [19][0/10]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.8452 (0.8452)	Prec@1 70.312 (70.312)	
2022-01-05 15:45:29 - INFO - EVALUATING - Epoch: [19][0/3]	Time 0.150 (0.150)	Data 0.147 (0.147)	Loss 1.2739 (1.2739)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:29 - INFO - 
 Epoch: 20	Training Loss 1.0894 	Training Prec@1 64.495 	Validation Loss 1.3638 	Validation Prec@1 64.286 	
2022-01-05 15:45:29 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:29 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:29 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:29 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:29 - INFO - TRAINING - Epoch: [20][0/10]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.6701 (0.6701)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:29 - INFO - EVALUATING - Epoch: [20][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.5970 (0.5970)	Prec@1 68.750 (68.750)	
2022-01-05 15:45:29 - INFO - 
 Epoch: 21	Training Loss 0.7202 	Training Prec@1 69.707 	Validation Loss 0.6144 	Validation Prec@1 65.584 	
2022-01-05 15:45:29 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:29 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:29 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:29 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:30 - INFO - TRAINING - Epoch: [21][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.6520 (0.6520)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:30 - INFO - EVALUATING - Epoch: [21][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.5958 (0.5958)	Prec@1 73.438 (73.438)	
2022-01-05 15:45:30 - INFO - 
 Epoch: 22	Training Loss 0.7142 	Training Prec@1 67.915 	Validation Loss 0.6169 	Validation Prec@1 69.481 	
2022-01-05 15:45:30 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:30 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:30 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:30 - INFO - TRAINING - Epoch: [22][0/10]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.6489 (0.6489)	Prec@1 70.312 (70.312)	
2022-01-05 15:45:30 - INFO - EVALUATING - Epoch: [22][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.5903 (0.5903)	Prec@1 70.312 (70.312)	
2022-01-05 15:45:30 - INFO - 
 Epoch: 23	Training Loss 0.6548 	Training Prec@1 67.427 	Validation Loss 0.6756 	Validation Prec@1 65.584 	
2022-01-05 15:45:30 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:30 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:30 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:30 - INFO - TRAINING - Epoch: [23][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.6975 (0.6975)	Prec@1 59.375 (59.375)	
2022-01-05 15:45:31 - INFO - EVALUATING - Epoch: [23][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.5763 (0.5763)	Prec@1 70.312 (70.312)	
2022-01-05 15:45:31 - INFO - 
 Epoch: 24	Training Loss 0.6753 	Training Prec@1 63.518 	Validation Loss 0.6066 	Validation Prec@1 66.883 	
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:31 - INFO - TRAINING - Epoch: [24][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5107 (0.5107)	Prec@1 81.250 (81.250)	
2022-01-05 15:45:31 - INFO - EVALUATING - Epoch: [24][0/3]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.5202 (0.5202)	Prec@1 81.250 (81.250)	
2022-01-05 15:45:31 - INFO - 
 Epoch: 25	Training Loss 0.6109 	Training Prec@1 72.150 	Validation Loss 0.5876 	Validation Prec@1 76.623 	
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:31 - INFO - TRAINING - Epoch: [25][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4854 (0.4854)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:31 - INFO - EVALUATING - Epoch: [25][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.5217 (0.5217)	Prec@1 76.562 (76.562)	
2022-01-05 15:45:31 - INFO - 
 Epoch: 26	Training Loss 0.6840 	Training Prec@1 71.498 	Validation Loss 0.5661 	Validation Prec@1 71.429 	
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:31 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:31 - INFO - TRAINING - Epoch: [26][0/10]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.5608 (0.5608)	Prec@1 73.438 (73.438)	
2022-01-05 15:45:32 - INFO - EVALUATING - Epoch: [26][0/3]	Time 0.149 (0.149)	Data 0.147 (0.147)	Loss 0.5369 (0.5369)	Prec@1 73.438 (73.438)	
2022-01-05 15:45:32 - INFO - 
 Epoch: 27	Training Loss 0.6327 	Training Prec@1 69.218 	Validation Loss 0.5657 	Validation Prec@1 70.130 	
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:32 - INFO - TRAINING - Epoch: [27][0/10]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.5543 (0.5543)	Prec@1 75.000 (75.000)	
2022-01-05 15:45:32 - INFO - EVALUATING - Epoch: [27][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.4941 (0.4941)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:32 - INFO - 
 Epoch: 28	Training Loss 0.6831 	Training Prec@1 74.267 	Validation Loss 0.5753 	Validation Prec@1 68.831 	
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:32 - INFO - TRAINING - Epoch: [28][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5642 (0.5642)	Prec@1 75.000 (75.000)	
2022-01-05 15:45:32 - INFO - EVALUATING - Epoch: [28][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.4842 (0.4842)	Prec@1 79.688 (79.688)	
2022-01-05 15:45:32 - INFO - 
 Epoch: 29	Training Loss 0.5857 	Training Prec@1 73.127 	Validation Loss 0.5928 	Validation Prec@1 74.675 	
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:32 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:33 - INFO - TRAINING - Epoch: [29][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5598 (0.5598)	Prec@1 75.000 (75.000)	
2022-01-05 15:45:33 - INFO - EVALUATING - Epoch: [29][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6878 (0.6878)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:33 - INFO - 
 Epoch: 30	Training Loss 0.6057 	Training Prec@1 70.847 	Validation Loss 0.7390 	Validation Prec@1 62.987 	
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:33 - INFO - TRAINING - Epoch: [30][0/10]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.5376 (0.5376)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:33 - INFO - EVALUATING - Epoch: [30][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.4709 (0.4709)	Prec@1 81.250 (81.250)	
2022-01-05 15:45:33 - INFO - 
 Epoch: 31	Training Loss 0.6434 	Training Prec@1 70.847 	Validation Loss 0.5433 	Validation Prec@1 72.727 	
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:33 - INFO - TRAINING - Epoch: [31][0/10]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.5871 (0.5871)	Prec@1 75.000 (75.000)	
2022-01-05 15:45:34 - INFO - EVALUATING - Epoch: [31][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.4945 (0.4945)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:34 - INFO - 
 Epoch: 32	Training Loss 0.5652 	Training Prec@1 73.941 	Validation Loss 0.5601 	Validation Prec@1 70.130 	
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:34 - INFO - TRAINING - Epoch: [32][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4581 (0.4581)	Prec@1 79.688 (79.688)	
2022-01-05 15:45:34 - INFO - EVALUATING - Epoch: [32][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.5137 (0.5137)	Prec@1 76.562 (76.562)	
2022-01-05 15:45:34 - INFO - 
 Epoch: 33	Training Loss 0.6347 	Training Prec@1 68.404 	Validation Loss 0.5657 	Validation Prec@1 70.130 	
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:34 - INFO - TRAINING - Epoch: [33][0/10]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 0.5466 (0.5466)	Prec@1 73.438 (73.438)	
2022-01-05 15:45:34 - INFO - EVALUATING - Epoch: [33][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.5227 (0.5227)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:34 - INFO - 
 Epoch: 34	Training Loss 0.5770 	Training Prec@1 71.498 	Validation Loss 0.5917 	Validation Prec@1 74.675 	
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:35 - INFO - TRAINING - Epoch: [34][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.6144 (0.6144)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:35 - INFO - EVALUATING - Epoch: [34][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.4938 (0.4938)	Prec@1 79.688 (79.688)	
2022-01-05 15:45:35 - INFO - 
 Epoch: 35	Training Loss 0.6165 	Training Prec@1 72.801 	Validation Loss 0.5961 	Validation Prec@1 74.675 	
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:35 - INFO - TRAINING - Epoch: [35][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4698 (0.4698)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:35 - INFO - EVALUATING - Epoch: [35][0/3]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.6357 (0.6357)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:35 - INFO - 
 Epoch: 36	Training Loss 0.5613 	Training Prec@1 73.453 	Validation Loss 0.6519 	Validation Prec@1 64.286 	
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:35 - INFO - TRAINING - Epoch: [36][0/10]	Time 0.148 (0.148)	Data 0.144 (0.144)	Loss 0.6444 (0.6444)	Prec@1 65.625 (65.625)	
2022-01-05 15:45:36 - INFO - EVALUATING - Epoch: [36][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.4941 (0.4941)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:36 - INFO - 
 Epoch: 37	Training Loss 0.6247 	Training Prec@1 70.195 	Validation Loss 0.5446 	Validation Prec@1 72.078 	
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:36 - INFO - TRAINING - Epoch: [37][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4641 (0.4641)	Prec@1 82.812 (82.812)	
2022-01-05 15:45:36 - INFO - EVALUATING - Epoch: [37][0/3]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.5838 (0.5838)	Prec@1 81.250 (81.250)	
2022-01-05 15:45:36 - INFO - 
 Epoch: 38	Training Loss 0.6276 	Training Prec@1 73.779 	Validation Loss 0.7254 	Validation Prec@1 74.675 	
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:36 - INFO - TRAINING - Epoch: [38][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.6412 (0.6412)	Prec@1 71.875 (71.875)	
2022-01-05 15:45:36 - INFO - EVALUATING - Epoch: [38][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.4943 (0.4943)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:36 - INFO - 
 Epoch: 39	Training Loss 0.5924 	Training Prec@1 69.381 	Validation Loss 0.5272 	Validation Prec@1 74.026 	
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:36 - INFO - TRAINING - Epoch: [39][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.6784 (0.6784)	Prec@1 50.000 (50.000)	
2022-01-05 15:45:37 - INFO - EVALUATING - Epoch: [39][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.6175 (0.6175)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:37 - INFO - 
 Epoch: 40	Training Loss 0.6765 	Training Prec@1 68.241 	Validation Loss 0.7715 	Validation Prec@1 72.078 	
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:37 - INFO - TRAINING - Epoch: [40][0/10]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.7975 (0.7975)	Prec@1 70.312 (70.312)	
2022-01-05 15:45:37 - INFO - EVALUATING - Epoch: [40][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.4942 (0.4942)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:37 - INFO - 
 Epoch: 41	Training Loss 0.5894 	Training Prec@1 70.033 	Validation Loss 0.5692 	Validation Prec@1 70.130 	
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:37 - INFO - TRAINING - Epoch: [41][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5582 (0.5582)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:37 - INFO - EVALUATING - Epoch: [41][0/3]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.4683 (0.4683)	Prec@1 81.250 (81.250)	
2022-01-05 15:45:37 - INFO - 
 Epoch: 42	Training Loss 0.6370 	Training Prec@1 70.521 	Validation Loss 0.6252 	Validation Prec@1 72.727 	
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:38 - INFO - TRAINING - Epoch: [42][0/10]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.6623 (0.6623)	Prec@1 71.875 (71.875)	
2022-01-05 15:45:38 - INFO - EVALUATING - Epoch: [42][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.4490 (0.4490)	Prec@1 79.688 (79.688)	
2022-01-05 15:45:38 - INFO - 
 Epoch: 43	Training Loss 0.5815 	Training Prec@1 72.638 	Validation Loss 0.5931 	Validation Prec@1 74.026 	
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:38 - INFO - TRAINING - Epoch: [43][0/10]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.5381 (0.5381)	Prec@1 75.000 (75.000)	
2022-01-05 15:45:38 - INFO - EVALUATING - Epoch: [43][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.5090 (0.5090)	Prec@1 67.188 (67.188)	
2022-01-05 15:45:38 - INFO - 
 Epoch: 44	Training Loss 0.5629 	Training Prec@1 74.593 	Validation Loss 0.6175 	Validation Prec@1 64.935 	
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:38 - INFO - TRAINING - Epoch: [44][0/10]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.5310 (0.5310)	Prec@1 70.312 (70.312)	
2022-01-05 15:45:39 - INFO - EVALUATING - Epoch: [44][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.4429 (0.4429)	Prec@1 82.812 (82.812)	
2022-01-05 15:45:39 - INFO - 
 Epoch: 45	Training Loss 0.5438 	Training Prec@1 74.104 	Validation Loss 0.5476 	Validation Prec@1 72.078 	
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:39 - INFO - TRAINING - Epoch: [45][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5514 (0.5514)	Prec@1 71.875 (71.875)	
2022-01-05 15:45:39 - INFO - EVALUATING - Epoch: [45][0/3]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.4492 (0.4492)	Prec@1 79.688 (79.688)	
2022-01-05 15:45:39 - INFO - 
 Epoch: 46	Training Loss 0.5444 	Training Prec@1 76.710 	Validation Loss 0.6010 	Validation Prec@1 74.026 	
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:39 - INFO - TRAINING - Epoch: [46][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.6102 (0.6102)	Prec@1 75.000 (75.000)	
2022-01-05 15:45:39 - INFO - EVALUATING - Epoch: [46][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.4545 (0.4545)	Prec@1 81.250 (81.250)	
2022-01-05 15:45:39 - INFO - 
 Epoch: 47	Training Loss 0.5944 	Training Prec@1 71.661 	Validation Loss 0.5812 	Validation Prec@1 67.532 	
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:40 - INFO - TRAINING - Epoch: [47][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5844 (0.5844)	Prec@1 68.750 (68.750)	
2022-01-05 15:45:40 - INFO - EVALUATING - Epoch: [47][0/3]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.5253 (0.5253)	Prec@1 75.000 (75.000)	
2022-01-05 15:45:40 - INFO - 
 Epoch: 48	Training Loss 0.5800 	Training Prec@1 73.941 	Validation Loss 0.5801 	Validation Prec@1 68.182 	
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:40 - INFO - TRAINING - Epoch: [48][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4564 (0.4564)	Prec@1 81.250 (81.250)	
2022-01-05 15:45:40 - INFO - EVALUATING - Epoch: [48][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.5624 (0.5624)	Prec@1 76.562 (76.562)	
2022-01-05 15:45:40 - INFO - 
 Epoch: 49	Training Loss 0.6023 	Training Prec@1 70.195 	Validation Loss 0.6518 	Validation Prec@1 71.429 	
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:40 - INFO - TRAINING - Epoch: [49][0/10]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.6119 (0.6119)	Prec@1 75.000 (75.000)	
2022-01-05 15:45:41 - INFO - EVALUATING - Epoch: [49][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.4532 (0.4532)	Prec@1 81.250 (81.250)	
2022-01-05 15:45:41 - INFO - 
 Epoch: 50	Training Loss 0.6336 	Training Prec@1 70.847 	Validation Loss 0.6519 	Validation Prec@1 70.130 	
