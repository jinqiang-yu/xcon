2022-01-05 15:45:33 - INFO - saving to ./results/small/quantise/q4/penn-ml/hepatitis/hepatitis_test1/
2022-01-05 15:45:33 - DEBUG - run arguments: Namespace(config='./configs/config_small.json', data='../../paper_bench/complete/quantise/q4/penn-ml/hepatitis/hepatitis_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/small/quantise/q4/penn-ml/hepatitis/hepatitis_test1/', test='../../paper_bench/cv/test/quantise/q4/penn-ml/hepatitis/hepatitis_test1_data.csv', train='../../paper_bench/cv/train/quantise/q4/penn-ml/hepatitis/hepatitis_train1_data.csv')
2022-01-05 15:45:33 - INFO - creating model mlp_binary
2022-01-05 15:45:33 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [10, 5, 5, 2]}
2022-01-05 15:45:33 - INFO - number of parameters: 747
2022-01-05 15:45:33 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:33 - INFO - TRAINING - Epoch: [0][0/2]	Time 0.154 (0.154)	Data 0.147 (0.147)	Loss 1.5287 (1.5287)	Prec@1 54.688 (54.688)	
2022-01-05 15:45:33 - INFO - EVALUATING - Epoch: [0][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.8369 (0.8369)	Prec@1 64.516 (64.516)	
2022-01-05 15:45:33 - INFO - 
 Epoch: 1	Training Loss 1.5208 	Training Prec@1 58.065 	Validation Loss 0.8369 	Validation Prec@1 64.516 	
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:33 - INFO - TRAINING - Epoch: [1][0/2]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 1.3547 (1.3547)	Prec@1 60.938 (60.938)	
2022-01-05 15:45:34 - INFO - EVALUATING - Epoch: [1][0/1]	Time 0.148 (0.148)	Data 0.146 (0.146)	Loss 0.6402 (0.6402)	Prec@1 83.871 (83.871)	
2022-01-05 15:45:34 - INFO - 
 Epoch: 2	Training Loss 1.0525 	Training Prec@1 66.129 	Validation Loss 0.6402 	Validation Prec@1 83.871 	
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:34 - INFO - TRAINING - Epoch: [2][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.7989 (0.7989)	Prec@1 73.438 (73.438)	
2022-01-05 15:45:34 - INFO - EVALUATING - Epoch: [2][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.7513 (0.7513)	Prec@1 64.516 (64.516)	
2022-01-05 15:45:34 - INFO - 
 Epoch: 3	Training Loss 0.7398 	Training Prec@1 76.613 	Validation Loss 0.7513 	Validation Prec@1 64.516 	
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:34 - INFO - TRAINING - Epoch: [3][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.8367 (0.8367)	Prec@1 57.812 (57.812)	
2022-01-05 15:45:34 - INFO - EVALUATING - Epoch: [3][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 2.0596 (2.0596)	Prec@1 25.806 (25.806)	
2022-01-05 15:45:34 - INFO - 
 Epoch: 4	Training Loss 0.8641 	Training Prec@1 65.323 	Validation Loss 2.0596 	Validation Prec@1 25.806 	
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:34 - INFO - TRAINING - Epoch: [4][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 1.7220 (1.7220)	Prec@1 34.375 (34.375)	
2022-01-05 15:45:35 - INFO - EVALUATING - Epoch: [4][0/1]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.9172 (0.9172)	Prec@1 67.742 (67.742)	
2022-01-05 15:45:35 - INFO - 
 Epoch: 5	Training Loss 1.2152 	Training Prec@1 54.839 	Validation Loss 0.9172 	Validation Prec@1 67.742 	
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:35 - INFO - TRAINING - Epoch: [5][0/2]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.8245 (0.8245)	Prec@1 76.562 (76.562)	
2022-01-05 15:45:35 - INFO - EVALUATING - Epoch: [5][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.6025 (1.6025)	Prec@1 48.387 (48.387)	
2022-01-05 15:45:35 - INFO - 
 Epoch: 6	Training Loss 0.6199 	Training Prec@1 79.839 	Validation Loss 1.6025 	Validation Prec@1 48.387 	
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:35 - INFO - TRAINING - Epoch: [6][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 1.5561 (1.5561)	Prec@1 48.438 (48.438)	
2022-01-05 15:45:35 - INFO - EVALUATING - Epoch: [6][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 0.4222 (0.4222)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:35 - INFO - 
 Epoch: 7	Training Loss 1.2014 	Training Prec@1 56.452 	Validation Loss 0.4222 	Validation Prec@1 87.097 	
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:35 - INFO - TRAINING - Epoch: [7][0/2]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.7686 (0.7686)	Prec@1 73.438 (73.438)	
2022-01-05 15:45:36 - INFO - EVALUATING - Epoch: [7][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 0.4751 (0.4751)	Prec@1 77.419 (77.419)	
2022-01-05 15:45:36 - INFO - 
 Epoch: 8	Training Loss 1.1087 	Training Prec@1 64.516 	Validation Loss 0.4751 	Validation Prec@1 77.419 	
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:36 - INFO - TRAINING - Epoch: [8][0/2]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.4546 (0.4546)	Prec@1 79.688 (79.688)	
2022-01-05 15:45:36 - INFO - EVALUATING - Epoch: [8][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.5151 (0.5151)	Prec@1 80.645 (80.645)	
2022-01-05 15:45:36 - INFO - 
 Epoch: 9	Training Loss 0.7258 	Training Prec@1 78.226 	Validation Loss 0.5151 	Validation Prec@1 80.645 	
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:36 - INFO - TRAINING - Epoch: [9][0/2]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.8634 (0.8634)	Prec@1 70.312 (70.312)	
2022-01-05 15:45:36 - INFO - EVALUATING - Epoch: [9][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.5246 (0.5246)	Prec@1 83.871 (83.871)	
2022-01-05 15:45:36 - INFO - 
 Epoch: 10	Training Loss 0.8810 	Training Prec@1 71.774 	Validation Loss 0.5246 	Validation Prec@1 83.871 	
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:36 - INFO - TRAINING - Epoch: [10][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.8189 (0.8189)	Prec@1 75.000 (75.000)	
2022-01-05 15:45:37 - INFO - EVALUATING - Epoch: [10][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 1.4359 (1.4359)	Prec@1 16.129 (16.129)	
2022-01-05 15:45:37 - INFO - 
 Epoch: 11	Training Loss 0.7232 	Training Prec@1 76.613 	Validation Loss 1.4359 	Validation Prec@1 16.129 	
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:37 - INFO - TRAINING - Epoch: [11][0/2]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 1.3706 (1.3706)	Prec@1 23.438 (23.438)	
2022-01-05 15:45:37 - INFO - EVALUATING - Epoch: [11][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.9977 (0.9977)	Prec@1 67.742 (67.742)	
2022-01-05 15:45:37 - INFO - 
 Epoch: 12	Training Loss 1.0991 	Training Prec@1 50.000 	Validation Loss 0.9977 	Validation Prec@1 67.742 	
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:37 - INFO - TRAINING - Epoch: [12][0/2]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.9253 (0.9253)	Prec@1 75.000 (75.000)	
2022-01-05 15:45:37 - INFO - EVALUATING - Epoch: [12][0/1]	Time 0.138 (0.138)	Data 0.136 (0.136)	Loss 1.0345 (1.0345)	Prec@1 77.419 (77.419)	
2022-01-05 15:45:37 - INFO - 
 Epoch: 13	Training Loss 0.7401 	Training Prec@1 79.032 	Validation Loss 1.0345 	Validation Prec@1 77.419 	
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:37 - INFO - TRAINING - Epoch: [13][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.7337 (0.7337)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:38 - INFO - EVALUATING - Epoch: [13][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.7988 (0.7988)	Prec@1 77.419 (77.419)	
2022-01-05 15:45:38 - INFO - 
 Epoch: 14	Training Loss 0.6290 	Training Prec@1 82.258 	Validation Loss 0.7988 	Validation Prec@1 77.419 	
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:38 - INFO - TRAINING - Epoch: [14][0/2]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.6325 (0.6325)	Prec@1 79.688 (79.688)	
2022-01-05 15:45:38 - INFO - EVALUATING - Epoch: [14][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 0.9952 (0.9952)	Prec@1 19.355 (19.355)	
2022-01-05 15:45:38 - INFO - 
 Epoch: 15	Training Loss 0.5483 	Training Prec@1 75.000 	Validation Loss 0.9952 	Validation Prec@1 19.355 	
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:38 - INFO - TRAINING - Epoch: [15][0/2]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 1.0207 (1.0207)	Prec@1 23.438 (23.438)	
2022-01-05 15:45:38 - INFO - EVALUATING - Epoch: [15][0/1]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.7389 (0.7389)	Prec@1 83.871 (83.871)	
2022-01-05 15:45:38 - INFO - 
 Epoch: 16	Training Loss 0.7315 	Training Prec@1 54.839 	Validation Loss 0.7389 	Validation Prec@1 83.871 	
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:38 - INFO - TRAINING - Epoch: [16][0/2]	Time 0.149 (0.149)	Data 0.143 (0.143)	Loss 0.4657 (0.4657)	Prec@1 84.375 (84.375)	
2022-01-05 15:45:39 - INFO - EVALUATING - Epoch: [16][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.8485 (0.8485)	Prec@1 51.613 (51.613)	
2022-01-05 15:45:39 - INFO - 
 Epoch: 17	Training Loss 0.4858 	Training Prec@1 82.258 	Validation Loss 0.8485 	Validation Prec@1 51.613 	
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:39 - INFO - TRAINING - Epoch: [17][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.7608 (0.7608)	Prec@1 60.938 (60.938)	
2022-01-05 15:45:39 - INFO - EVALUATING - Epoch: [17][0/1]	Time 0.143 (0.143)	Data 0.141 (0.141)	Loss 0.8882 (0.8882)	Prec@1 80.645 (80.645)	
2022-01-05 15:45:39 - INFO - 
 Epoch: 18	Training Loss 0.6830 	Training Prec@1 72.581 	Validation Loss 0.8882 	Validation Prec@1 80.645 	
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:39 - INFO - TRAINING - Epoch: [18][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3715 (0.3715)	Prec@1 90.625 (90.625)	
2022-01-05 15:45:39 - INFO - EVALUATING - Epoch: [18][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.4739 (0.4739)	Prec@1 90.323 (90.323)	
2022-01-05 15:45:39 - INFO - 
 Epoch: 19	Training Loss 0.3828 	Training Prec@1 88.710 	Validation Loss 0.4739 	Validation Prec@1 90.323 	
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:39 - INFO - TRAINING - Epoch: [19][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2992 (0.2992)	Prec@1 89.062 (89.062)	
2022-01-05 15:45:40 - INFO - EVALUATING - Epoch: [19][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.7056 (0.7056)	Prec@1 67.742 (67.742)	
2022-01-05 15:45:40 - INFO - 
 Epoch: 20	Training Loss 0.3989 	Training Prec@1 85.484 	Validation Loss 0.7056 	Validation Prec@1 67.742 	
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:40 - INFO - TRAINING - Epoch: [20][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5746 (0.5746)	Prec@1 76.562 (76.562)	
2022-01-05 15:45:40 - INFO - EVALUATING - Epoch: [20][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.8795 (0.8795)	Prec@1 64.516 (64.516)	
2022-01-05 15:45:40 - INFO - 
 Epoch: 21	Training Loss 0.4948 	Training Prec@1 80.645 	Validation Loss 0.8795 	Validation Prec@1 64.516 	
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:40 - INFO - TRAINING - Epoch: [21][0/2]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 0.3518 (0.3518)	Prec@1 85.938 (85.938)	
2022-01-05 15:45:40 - INFO - EVALUATING - Epoch: [21][0/1]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.4290 (0.4290)	Prec@1 80.645 (80.645)	
2022-01-05 15:45:40 - INFO - 
 Epoch: 22	Training Loss 0.3853 	Training Prec@1 79.839 	Validation Loss 0.4290 	Validation Prec@1 80.645 	
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:40 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:40 - INFO - TRAINING - Epoch: [22][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2853 (0.2853)	Prec@1 89.062 (89.062)	
2022-01-05 15:45:41 - INFO - EVALUATING - Epoch: [22][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.4070 (0.4070)	Prec@1 80.645 (80.645)	
2022-01-05 15:45:41 - INFO - 
 Epoch: 23	Training Loss 0.2966 	Training Prec@1 88.710 	Validation Loss 0.4070 	Validation Prec@1 80.645 	
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:41 - INFO - TRAINING - Epoch: [23][0/2]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 0.3972 (0.3972)	Prec@1 85.938 (85.938)	
2022-01-05 15:45:41 - INFO - EVALUATING - Epoch: [23][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.4474 (0.4474)	Prec@1 83.871 (83.871)	
2022-01-05 15:45:41 - INFO - 
 Epoch: 24	Training Loss 0.3356 	Training Prec@1 87.097 	Validation Loss 0.4474 	Validation Prec@1 83.871 	
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:41 - INFO - TRAINING - Epoch: [24][0/2]	Time 0.160 (0.160)	Data 0.155 (0.155)	Loss 0.4957 (0.4957)	Prec@1 76.562 (76.562)	
2022-01-05 15:45:41 - INFO - EVALUATING - Epoch: [24][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.5190 (0.5190)	Prec@1 83.871 (83.871)	
2022-01-05 15:45:41 - INFO - 
 Epoch: 25	Training Loss 0.4145 	Training Prec@1 83.871 	Validation Loss 0.5190 	Validation Prec@1 83.871 	
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:41 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:41 - INFO - TRAINING - Epoch: [25][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4944 (0.4944)	Prec@1 87.500 (87.500)	
2022-01-05 15:45:42 - INFO - EVALUATING - Epoch: [25][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 0.3507 (0.3507)	Prec@1 83.871 (83.871)	
2022-01-05 15:45:42 - INFO - 
 Epoch: 26	Training Loss 0.5439 	Training Prec@1 79.032 	Validation Loss 0.3507 	Validation Prec@1 83.871 	
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:42 - INFO - TRAINING - Epoch: [26][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3320 (0.3320)	Prec@1 76.562 (76.562)	
2022-01-05 15:45:42 - INFO - EVALUATING - Epoch: [26][0/1]	Time 0.143 (0.143)	Data 0.140 (0.140)	Loss 0.7900 (0.7900)	Prec@1 80.645 (80.645)	
2022-01-05 15:45:42 - INFO - 
 Epoch: 27	Training Loss 0.3787 	Training Prec@1 77.419 	Validation Loss 0.7900 	Validation Prec@1 80.645 	
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:42 - INFO - TRAINING - Epoch: [27][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2117 (0.2117)	Prec@1 92.188 (92.188)	
2022-01-05 15:45:42 - INFO - EVALUATING - Epoch: [27][0/1]	Time 0.143 (0.143)	Data 0.140 (0.140)	Loss 0.5864 (0.5864)	Prec@1 70.968 (70.968)	
2022-01-05 15:45:42 - INFO - 
 Epoch: 28	Training Loss 0.3169 	Training Prec@1 89.516 	Validation Loss 0.5864 	Validation Prec@1 70.968 	
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:42 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:42 - INFO - TRAINING - Epoch: [28][0/2]	Time 0.149 (0.149)	Data 0.143 (0.143)	Loss 0.3876 (0.3876)	Prec@1 81.250 (81.250)	
2022-01-05 15:45:43 - INFO - EVALUATING - Epoch: [28][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.5257 (0.5257)	Prec@1 83.871 (83.871)	
2022-01-05 15:45:43 - INFO - 
 Epoch: 29	Training Loss 0.3635 	Training Prec@1 83.871 	Validation Loss 0.5257 	Validation Prec@1 83.871 	
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:43 - INFO - TRAINING - Epoch: [29][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2165 (0.2165)	Prec@1 90.625 (90.625)	
2022-01-05 15:45:43 - INFO - EVALUATING - Epoch: [29][0/1]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.5877 (0.5877)	Prec@1 70.968 (70.968)	
2022-01-05 15:45:43 - INFO - 
 Epoch: 30	Training Loss 0.3043 	Training Prec@1 87.097 	Validation Loss 0.5877 	Validation Prec@1 70.968 	
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:43 - INFO - TRAINING - Epoch: [30][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4042 (0.4042)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:43 - INFO - EVALUATING - Epoch: [30][0/1]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.5040 (0.5040)	Prec@1 83.871 (83.871)	
2022-01-05 15:45:43 - INFO - 
 Epoch: 31	Training Loss 0.3098 	Training Prec@1 87.097 	Validation Loss 0.5040 	Validation Prec@1 83.871 	
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:43 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:43 - INFO - TRAINING - Epoch: [31][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3095 (0.3095)	Prec@1 93.750 (93.750)	
2022-01-05 15:45:44 - INFO - EVALUATING - Epoch: [31][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 0.4980 (0.4980)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:44 - INFO - 
 Epoch: 32	Training Loss 0.3333 	Training Prec@1 90.323 	Validation Loss 0.4980 	Validation Prec@1 87.097 	
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:44 - INFO - TRAINING - Epoch: [32][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.1147 (0.1147)	Prec@1 96.875 (96.875)	
2022-01-05 15:45:44 - INFO - EVALUATING - Epoch: [32][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.3575 (0.3575)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:44 - INFO - 
 Epoch: 33	Training Loss 0.2356 	Training Prec@1 91.935 	Validation Loss 0.3575 	Validation Prec@1 87.097 	
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:44 - INFO - TRAINING - Epoch: [33][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3670 (0.3670)	Prec@1 89.062 (89.062)	
2022-01-05 15:45:44 - INFO - EVALUATING - Epoch: [33][0/1]	Time 0.143 (0.143)	Data 0.141 (0.141)	Loss 0.3814 (0.3814)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:44 - INFO - 
 Epoch: 34	Training Loss 0.2950 	Training Prec@1 90.323 	Validation Loss 0.3814 	Validation Prec@1 87.097 	
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:44 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:44 - INFO - TRAINING - Epoch: [34][0/2]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.4486 (0.4486)	Prec@1 82.812 (82.812)	
2022-01-05 15:45:45 - INFO - EVALUATING - Epoch: [34][0/1]	Time 0.143 (0.143)	Data 0.141 (0.141)	Loss 0.3938 (0.3938)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:45 - INFO - 
 Epoch: 35	Training Loss 0.3801 	Training Prec@1 81.452 	Validation Loss 0.3938 	Validation Prec@1 87.097 	
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:45 - INFO - TRAINING - Epoch: [35][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3669 (0.3669)	Prec@1 73.438 (73.438)	
2022-01-05 15:45:45 - INFO - EVALUATING - Epoch: [35][0/1]	Time 0.143 (0.143)	Data 0.140 (0.140)	Loss 0.3573 (0.3573)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:45 - INFO - 
 Epoch: 36	Training Loss 0.3486 	Training Prec@1 80.645 	Validation Loss 0.3573 	Validation Prec@1 87.097 	
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:45 - INFO - TRAINING - Epoch: [36][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3262 (0.3262)	Prec@1 90.625 (90.625)	
2022-01-05 15:45:45 - INFO - EVALUATING - Epoch: [36][0/1]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.3950 (0.3950)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:45 - INFO - 
 Epoch: 37	Training Loss 0.3146 	Training Prec@1 87.903 	Validation Loss 0.3950 	Validation Prec@1 87.097 	
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:45 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:45 - INFO - TRAINING - Epoch: [37][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3286 (0.3286)	Prec@1 90.625 (90.625)	
2022-01-05 15:45:46 - INFO - EVALUATING - Epoch: [37][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.3820 (0.3820)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:46 - INFO - 
 Epoch: 38	Training Loss 0.3219 	Training Prec@1 87.097 	Validation Loss 0.3820 	Validation Prec@1 87.097 	
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:46 - INFO - TRAINING - Epoch: [38][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4031 (0.4031)	Prec@1 85.938 (85.938)	
2022-01-05 15:45:46 - INFO - EVALUATING - Epoch: [38][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.2812 (0.2812)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:46 - INFO - 
 Epoch: 39	Training Loss 0.3269 	Training Prec@1 88.710 	Validation Loss 0.2812 	Validation Prec@1 87.097 	
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:46 - INFO - TRAINING - Epoch: [39][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2561 (0.2561)	Prec@1 89.062 (89.062)	
2022-01-05 15:45:46 - INFO - EVALUATING - Epoch: [39][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.3571 (0.3571)	Prec@1 90.323 (90.323)	
2022-01-05 15:45:46 - INFO - 
 Epoch: 40	Training Loss 0.3424 	Training Prec@1 86.290 	Validation Loss 0.3571 	Validation Prec@1 90.323 	
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:46 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:46 - INFO - TRAINING - Epoch: [40][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2051 (0.2051)	Prec@1 89.062 (89.062)	
2022-01-05 15:45:47 - INFO - EVALUATING - Epoch: [40][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 0.3746 (0.3746)	Prec@1 83.871 (83.871)	
2022-01-05 15:45:47 - INFO - 
 Epoch: 41	Training Loss 0.2489 	Training Prec@1 89.516 	Validation Loss 0.3746 	Validation Prec@1 83.871 	
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:47 - INFO - TRAINING - Epoch: [41][0/2]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.2906 (0.2906)	Prec@1 89.062 (89.062)	
2022-01-05 15:45:47 - INFO - EVALUATING - Epoch: [41][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 0.3516 (0.3516)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:47 - INFO - 
 Epoch: 42	Training Loss 0.3031 	Training Prec@1 90.323 	Validation Loss 0.3516 	Validation Prec@1 87.097 	
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:47 - INFO - TRAINING - Epoch: [42][0/2]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.4691 (0.4691)	Prec@1 84.375 (84.375)	
2022-01-05 15:45:47 - INFO - EVALUATING - Epoch: [42][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.3245 (0.3245)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:47 - INFO - 
 Epoch: 43	Training Loss 0.3283 	Training Prec@1 90.323 	Validation Loss 0.3245 	Validation Prec@1 87.097 	
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:47 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:47 - INFO - TRAINING - Epoch: [43][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2225 (0.2225)	Prec@1 92.188 (92.188)	
2022-01-05 15:45:48 - INFO - EVALUATING - Epoch: [43][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.3514 (0.3514)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:48 - INFO - 
 Epoch: 44	Training Loss 0.3503 	Training Prec@1 87.903 	Validation Loss 0.3514 	Validation Prec@1 87.097 	
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:48 - INFO - TRAINING - Epoch: [44][0/2]	Time 0.171 (0.171)	Data 0.166 (0.166)	Loss 0.2933 (0.2933)	Prec@1 93.750 (93.750)	
2022-01-05 15:45:48 - INFO - EVALUATING - Epoch: [44][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.4051 (0.4051)	Prec@1 83.871 (83.871)	
2022-01-05 15:45:48 - INFO - 
 Epoch: 45	Training Loss 0.3178 	Training Prec@1 91.935 	Validation Loss 0.4051 	Validation Prec@1 83.871 	
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:48 - INFO - TRAINING - Epoch: [45][0/2]	Time 0.148 (0.148)	Data 0.144 (0.144)	Loss 0.2956 (0.2956)	Prec@1 89.062 (89.062)	
2022-01-05 15:45:48 - INFO - EVALUATING - Epoch: [45][0/1]	Time 0.143 (0.143)	Data 0.141 (0.141)	Loss 0.2895 (0.2895)	Prec@1 87.097 (87.097)	
2022-01-05 15:45:48 - INFO - 
 Epoch: 46	Training Loss 0.2646 	Training Prec@1 91.935 	Validation Loss 0.2895 	Validation Prec@1 87.097 	
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:48 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:49 - INFO - TRAINING - Epoch: [46][0/2]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.3052 (0.3052)	Prec@1 92.188 (92.188)	
2022-01-05 15:45:49 - INFO - EVALUATING - Epoch: [46][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 0.2735 (0.2735)	Prec@1 93.548 (93.548)	
2022-01-05 15:45:49 - INFO - 
 Epoch: 47	Training Loss 0.2612 	Training Prec@1 91.935 	Validation Loss 0.2735 	Validation Prec@1 93.548 	
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:49 - INFO - TRAINING - Epoch: [47][0/2]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4043 (0.4043)	Prec@1 78.125 (78.125)	
2022-01-05 15:45:49 - INFO - EVALUATING - Epoch: [47][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 0.2031 (0.2031)	Prec@1 90.323 (90.323)	
2022-01-05 15:45:49 - INFO - 
 Epoch: 48	Training Loss 0.3159 	Training Prec@1 83.871 	Validation Loss 0.2031 	Validation Prec@1 90.323 	
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:49 - INFO - TRAINING - Epoch: [48][0/2]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.1931 (0.1931)	Prec@1 95.312 (95.312)	
2022-01-05 15:45:49 - INFO - EVALUATING - Epoch: [48][0/1]	Time 0.143 (0.143)	Data 0.140 (0.140)	Loss 0.4090 (0.4090)	Prec@1 90.323 (90.323)	
2022-01-05 15:45:49 - INFO - 
 Epoch: 49	Training Loss 0.3319 	Training Prec@1 87.097 	Validation Loss 0.4090 	Validation Prec@1 90.323 	
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:49 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:50 - INFO - TRAINING - Epoch: [49][0/2]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.2585 (0.2585)	Prec@1 93.750 (93.750)	
2022-01-05 15:45:50 - INFO - EVALUATING - Epoch: [49][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.1522 (0.1522)	Prec@1 93.548 (93.548)	
2022-01-05 15:45:50 - INFO - 
 Epoch: 50	Training Loss 0.2373 	Training Prec@1 94.355 	Validation Loss 0.1522 	Validation Prec@1 93.548 	
