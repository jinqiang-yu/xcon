2022-01-05 15:44:44 - INFO - saving to ./results/small/quantise/q4/other/mlic/parkinsons_test1/
2022-01-05 15:44:44 - DEBUG - run arguments: Namespace(config='./configs/config_small.json', data='../../paper_bench/complete/quantise/q4/other/mlic/parkinsons_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/small/quantise/q4/other/mlic/parkinsons_test1/', test='../../paper_bench/cv/test/quantise/q4/other/mlic/parkinsons_test1_data.csv', train='../../paper_bench/cv/train/quantise/q4/other/mlic/parkinsons_train1_data.csv')
2022-01-05 15:44:44 - INFO - creating model mlp_binary
2022-01-05 15:44:44 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [10, 5, 5, 2]}
2022-01-05 15:44:44 - INFO - number of parameters: 857
2022-01-05 15:44:44 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-05 15:44:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:44 - INFO - TRAINING - Epoch: [0][0/3]	Time 0.156 (0.156)	Data 0.148 (0.148)	Loss 1.7614 (1.7614)	Prec@1 45.312 (45.312)	
2022-01-05 15:44:45 - INFO - EVALUATING - Epoch: [0][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.0191 (1.0191)	Prec@1 66.667 (66.667)	
2022-01-05 15:44:45 - INFO - 
 Epoch: 1	Training Loss 1.3209 	Training Prec@1 61.538 	Validation Loss 1.0191 	Validation Prec@1 66.667 	
2022-01-05 15:44:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:45 - INFO - TRAINING - Epoch: [1][0/3]	Time 0.154 (0.154)	Data 0.149 (0.149)	Loss 0.7126 (0.7126)	Prec@1 84.375 (84.375)	
2022-01-05 15:44:45 - INFO - EVALUATING - Epoch: [1][0/1]	Time 0.154 (0.154)	Data 0.152 (0.152)	Loss 0.8878 (0.8878)	Prec@1 79.487 (79.487)	
2022-01-05 15:44:45 - INFO - 
 Epoch: 2	Training Loss 0.6474 	Training Prec@1 82.692 	Validation Loss 0.8878 	Validation Prec@1 79.487 	
2022-01-05 15:44:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:45 - INFO - TRAINING - Epoch: [2][0/3]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.6576 (0.6576)	Prec@1 78.125 (78.125)	
2022-01-05 15:44:45 - INFO - EVALUATING - Epoch: [2][0/1]	Time 0.152 (0.152)	Data 0.150 (0.150)	Loss 0.6563 (0.6563)	Prec@1 69.231 (69.231)	
2022-01-05 15:44:45 - INFO - 
 Epoch: 3	Training Loss 0.5286 	Training Prec@1 82.692 	Validation Loss 0.6563 	Validation Prec@1 69.231 	
2022-01-05 15:44:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:46 - INFO - TRAINING - Epoch: [3][0/3]	Time 0.183 (0.183)	Data 0.177 (0.177)	Loss 0.5924 (0.5924)	Prec@1 75.000 (75.000)	
2022-01-05 15:44:46 - INFO - EVALUATING - Epoch: [3][0/1]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.6740 (0.6740)	Prec@1 61.538 (61.538)	
2022-01-05 15:44:46 - INFO - 
 Epoch: 4	Training Loss 0.5429 	Training Prec@1 80.769 	Validation Loss 0.6740 	Validation Prec@1 61.538 	
2022-01-05 15:44:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:46 - INFO - TRAINING - Epoch: [4][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3450 (0.3450)	Prec@1 85.938 (85.938)	
2022-01-05 15:44:46 - INFO - EVALUATING - Epoch: [4][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.5322 (0.5322)	Prec@1 79.487 (79.487)	
2022-01-05 15:44:46 - INFO - 
 Epoch: 5	Training Loss 0.3785 	Training Prec@1 85.256 	Validation Loss 0.5322 	Validation Prec@1 79.487 	
2022-01-05 15:44:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:46 - INFO - TRAINING - Epoch: [5][0/3]	Time 0.182 (0.182)	Data 0.176 (0.176)	Loss 0.5824 (0.5824)	Prec@1 73.438 (73.438)	
2022-01-05 15:44:47 - INFO - EVALUATING - Epoch: [5][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.5857 (0.5857)	Prec@1 79.487 (79.487)	
2022-01-05 15:44:47 - INFO - 
 Epoch: 6	Training Loss 0.4434 	Training Prec@1 80.769 	Validation Loss 0.5857 	Validation Prec@1 79.487 	
2022-01-05 15:44:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:47 - INFO - TRAINING - Epoch: [6][0/3]	Time 0.166 (0.166)	Data 0.160 (0.160)	Loss 0.1947 (0.1947)	Prec@1 92.188 (92.188)	
2022-01-05 15:44:47 - INFO - EVALUATING - Epoch: [6][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.4106 (0.4106)	Prec@1 74.359 (74.359)	
2022-01-05 15:44:47 - INFO - 
 Epoch: 7	Training Loss 0.2810 	Training Prec@1 86.538 	Validation Loss 0.4106 	Validation Prec@1 74.359 	
2022-01-05 15:44:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:47 - INFO - TRAINING - Epoch: [7][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.2697 (0.2697)	Prec@1 90.625 (90.625)	
2022-01-05 15:44:47 - INFO - EVALUATING - Epoch: [7][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.4629 (0.4629)	Prec@1 76.923 (76.923)	
2022-01-05 15:44:47 - INFO - 
 Epoch: 8	Training Loss 0.3567 	Training Prec@1 87.821 	Validation Loss 0.4629 	Validation Prec@1 76.923 	
2022-01-05 15:44:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:47 - INFO - TRAINING - Epoch: [8][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.3788 (0.3788)	Prec@1 76.562 (76.562)	
2022-01-05 15:44:48 - INFO - EVALUATING - Epoch: [8][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.7832 (0.7832)	Prec@1 71.795 (71.795)	
2022-01-05 15:44:48 - INFO - 
 Epoch: 9	Training Loss 0.3280 	Training Prec@1 85.897 	Validation Loss 0.7832 	Validation Prec@1 71.795 	
2022-01-05 15:44:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:48 - INFO - TRAINING - Epoch: [9][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1897 (0.1897)	Prec@1 95.312 (95.312)	
2022-01-05 15:44:48 - INFO - EVALUATING - Epoch: [9][0/1]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.5670 (0.5670)	Prec@1 79.487 (79.487)	
2022-01-05 15:44:48 - INFO - 
 Epoch: 10	Training Loss 0.3003 	Training Prec@1 91.667 	Validation Loss 0.5670 	Validation Prec@1 79.487 	
2022-01-05 15:44:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:48 - INFO - TRAINING - Epoch: [10][0/3]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4950 (0.4950)	Prec@1 82.812 (82.812)	
2022-01-05 15:44:48 - INFO - EVALUATING - Epoch: [10][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.5088 (0.5088)	Prec@1 79.487 (79.487)	
2022-01-05 15:44:48 - INFO - 
 Epoch: 11	Training Loss 0.3963 	Training Prec@1 82.051 	Validation Loss 0.5088 	Validation Prec@1 79.487 	
2022-01-05 15:44:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:48 - INFO - TRAINING - Epoch: [11][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.5830 (0.5830)	Prec@1 73.438 (73.438)	
2022-01-05 15:44:49 - INFO - EVALUATING - Epoch: [11][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.5769 (0.5769)	Prec@1 69.231 (69.231)	
2022-01-05 15:44:49 - INFO - 
 Epoch: 12	Training Loss 0.4116 	Training Prec@1 83.974 	Validation Loss 0.5769 	Validation Prec@1 69.231 	
2022-01-05 15:44:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:49 - INFO - TRAINING - Epoch: [12][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3189 (0.3189)	Prec@1 81.250 (81.250)	
2022-01-05 15:44:49 - INFO - EVALUATING - Epoch: [12][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.4578 (0.4578)	Prec@1 79.487 (79.487)	
2022-01-05 15:44:49 - INFO - 
 Epoch: 13	Training Loss 0.3016 	Training Prec@1 85.897 	Validation Loss 0.4578 	Validation Prec@1 79.487 	
2022-01-05 15:44:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:49 - INFO - TRAINING - Epoch: [13][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.5731 (0.5731)	Prec@1 75.000 (75.000)	
2022-01-05 15:44:49 - INFO - EVALUATING - Epoch: [13][0/1]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.6566 (0.6566)	Prec@1 82.051 (82.051)	
2022-01-05 15:44:49 - INFO - 
 Epoch: 14	Training Loss 0.4229 	Training Prec@1 84.615 	Validation Loss 0.6566 	Validation Prec@1 82.051 	
2022-01-05 15:44:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:49 - INFO - TRAINING - Epoch: [14][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.2455 (0.2455)	Prec@1 93.750 (93.750)	
2022-01-05 15:44:50 - INFO - EVALUATING - Epoch: [14][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.4729 (0.4729)	Prec@1 66.667 (66.667)	
2022-01-05 15:44:50 - INFO - 
 Epoch: 15	Training Loss 0.2718 	Training Prec@1 92.308 	Validation Loss 0.4729 	Validation Prec@1 66.667 	
2022-01-05 15:44:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:50 - INFO - TRAINING - Epoch: [15][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.5599 (0.5599)	Prec@1 87.500 (87.500)	
2022-01-05 15:44:50 - INFO - EVALUATING - Epoch: [15][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.5226 (0.5226)	Prec@1 66.667 (66.667)	
2022-01-05 15:44:50 - INFO - 
 Epoch: 16	Training Loss 0.5694 	Training Prec@1 80.769 	Validation Loss 0.5226 	Validation Prec@1 66.667 	
2022-01-05 15:44:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:50 - INFO - TRAINING - Epoch: [16][0/3]	Time 0.153 (0.153)	Data 0.146 (0.146)	Loss 0.1830 (0.1830)	Prec@1 93.750 (93.750)	
2022-01-05 15:44:50 - INFO - EVALUATING - Epoch: [16][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.8376 (0.8376)	Prec@1 71.795 (71.795)	
2022-01-05 15:44:50 - INFO - 
 Epoch: 17	Training Loss 0.1764 	Training Prec@1 94.872 	Validation Loss 0.8376 	Validation Prec@1 71.795 	
2022-01-05 15:44:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:50 - INFO - TRAINING - Epoch: [17][0/3]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.2998 (0.2998)	Prec@1 92.188 (92.188)	
2022-01-05 15:44:51 - INFO - EVALUATING - Epoch: [17][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.1345 (1.1345)	Prec@1 71.795 (71.795)	
2022-01-05 15:44:51 - INFO - 
 Epoch: 18	Training Loss 0.3108 	Training Prec@1 87.179 	Validation Loss 1.1345 	Validation Prec@1 71.795 	
2022-01-05 15:44:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:51 - INFO - TRAINING - Epoch: [18][0/3]	Time 0.154 (0.154)	Data 0.149 (0.149)	Loss 0.3830 (0.3830)	Prec@1 92.188 (92.188)	
2022-01-05 15:44:51 - INFO - EVALUATING - Epoch: [18][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.4266 (0.4266)	Prec@1 69.231 (69.231)	
2022-01-05 15:44:51 - INFO - 
 Epoch: 19	Training Loss 0.3009 	Training Prec@1 91.026 	Validation Loss 0.4266 	Validation Prec@1 69.231 	
2022-01-05 15:44:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:51 - INFO - TRAINING - Epoch: [19][0/3]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.2369 (0.2369)	Prec@1 92.188 (92.188)	
2022-01-05 15:44:51 - INFO - EVALUATING - Epoch: [19][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.8725 (0.8725)	Prec@1 82.051 (82.051)	
2022-01-05 15:44:51 - INFO - 
 Epoch: 20	Training Loss 0.2091 	Training Prec@1 94.231 	Validation Loss 0.8725 	Validation Prec@1 82.051 	
2022-01-05 15:44:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:51 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:51 - INFO - TRAINING - Epoch: [20][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.2531 (0.2531)	Prec@1 92.188 (92.188)	
2022-01-05 15:44:52 - INFO - EVALUATING - Epoch: [20][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.9042 (0.9042)	Prec@1 71.795 (71.795)	
2022-01-05 15:44:52 - INFO - 
 Epoch: 21	Training Loss 0.2825 	Training Prec@1 90.385 	Validation Loss 0.9042 	Validation Prec@1 71.795 	
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:52 - INFO - TRAINING - Epoch: [21][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.2515 (0.2515)	Prec@1 89.062 (89.062)	
2022-01-05 15:44:52 - INFO - EVALUATING - Epoch: [21][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.7644 (0.7644)	Prec@1 74.359 (74.359)	
2022-01-05 15:44:52 - INFO - 
 Epoch: 22	Training Loss 0.3647 	Training Prec@1 88.462 	Validation Loss 0.7644 	Validation Prec@1 74.359 	
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:52 - INFO - TRAINING - Epoch: [22][0/3]	Time 0.157 (0.157)	Data 0.151 (0.151)	Loss 0.2332 (0.2332)	Prec@1 90.625 (90.625)	
2022-01-05 15:44:52 - INFO - EVALUATING - Epoch: [22][0/1]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.6013 (0.6013)	Prec@1 76.923 (76.923)	
2022-01-05 15:44:52 - INFO - 
 Epoch: 23	Training Loss 0.2260 	Training Prec@1 92.949 	Validation Loss 0.6013 	Validation Prec@1 76.923 	
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:53 - INFO - TRAINING - Epoch: [23][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3201 (0.3201)	Prec@1 92.188 (92.188)	
2022-01-05 15:44:53 - INFO - EVALUATING - Epoch: [23][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.7508 (0.7508)	Prec@1 74.359 (74.359)	
2022-01-05 15:44:53 - INFO - 
 Epoch: 24	Training Loss 0.2247 	Training Prec@1 94.231 	Validation Loss 0.7508 	Validation Prec@1 74.359 	
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:53 - INFO - TRAINING - Epoch: [24][0/3]	Time 0.154 (0.154)	Data 0.149 (0.149)	Loss 0.1729 (0.1729)	Prec@1 93.750 (93.750)	
2022-01-05 15:44:53 - INFO - EVALUATING - Epoch: [24][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.7597 (0.7597)	Prec@1 69.231 (69.231)	
2022-01-05 15:44:53 - INFO - 
 Epoch: 25	Training Loss 0.1934 	Training Prec@1 94.872 	Validation Loss 0.7597 	Validation Prec@1 69.231 	
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:53 - INFO - TRAINING - Epoch: [25][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.0728 (0.0728)	Prec@1 100.000 (100.000)	
2022-01-05 15:44:53 - INFO - EVALUATING - Epoch: [25][0/1]	Time 0.148 (0.148)	Data 0.146 (0.146)	Loss 1.0181 (1.0181)	Prec@1 61.538 (61.538)	
2022-01-05 15:44:53 - INFO - 
 Epoch: 26	Training Loss 0.1876 	Training Prec@1 96.154 	Validation Loss 1.0181 	Validation Prec@1 61.538 	
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:53 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:54 - INFO - TRAINING - Epoch: [26][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.0701 (0.0701)	Prec@1 98.438 (98.438)	
2022-01-05 15:44:54 - INFO - EVALUATING - Epoch: [26][0/1]	Time 0.178 (0.178)	Data 0.175 (0.175)	Loss 0.8510 (0.8510)	Prec@1 66.667 (66.667)	
2022-01-05 15:44:54 - INFO - 
 Epoch: 27	Training Loss 0.1055 	Training Prec@1 95.513 	Validation Loss 0.8510 	Validation Prec@1 66.667 	
2022-01-05 15:44:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:54 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:54 - INFO - TRAINING - Epoch: [27][0/3]	Time 0.157 (0.157)	Data 0.152 (0.152)	Loss 0.1584 (0.1584)	Prec@1 93.750 (93.750)	
2022-01-05 15:44:54 - INFO - EVALUATING - Epoch: [27][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.7200 (0.7200)	Prec@1 76.923 (76.923)	
2022-01-05 15:44:54 - INFO - 
 Epoch: 28	Training Loss 0.1758 	Training Prec@1 95.513 	Validation Loss 0.7200 	Validation Prec@1 76.923 	
2022-01-05 15:44:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:54 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:54 - INFO - TRAINING - Epoch: [28][0/3]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.0460 (0.0460)	Prec@1 100.000 (100.000)	
2022-01-05 15:44:54 - INFO - EVALUATING - Epoch: [28][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.7452 (0.7452)	Prec@1 71.795 (71.795)	
2022-01-05 15:44:54 - INFO - 
 Epoch: 29	Training Loss 0.3169 	Training Prec@1 84.615 	Validation Loss 0.7452 	Validation Prec@1 71.795 	
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:55 - INFO - TRAINING - Epoch: [29][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1603 (0.1603)	Prec@1 92.188 (92.188)	
2022-01-05 15:44:55 - INFO - EVALUATING - Epoch: [29][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.5119 (0.5119)	Prec@1 79.487 (79.487)	
2022-01-05 15:44:55 - INFO - 
 Epoch: 30	Training Loss 0.2359 	Training Prec@1 89.103 	Validation Loss 0.5119 	Validation Prec@1 79.487 	
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:55 - INFO - TRAINING - Epoch: [30][0/3]	Time 0.152 (0.152)	Data 0.146 (0.146)	Loss 0.0771 (0.0771)	Prec@1 96.875 (96.875)	
2022-01-05 15:44:55 - INFO - EVALUATING - Epoch: [30][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.7091 (0.7091)	Prec@1 71.795 (71.795)	
2022-01-05 15:44:55 - INFO - 
 Epoch: 31	Training Loss 0.1677 	Training Prec@1 85.897 	Validation Loss 0.7091 	Validation Prec@1 71.795 	
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:55 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:55 - INFO - TRAINING - Epoch: [31][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.2043 (0.2043)	Prec@1 98.438 (98.438)	
2022-01-05 15:44:56 - INFO - EVALUATING - Epoch: [31][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.9070 (0.9070)	Prec@1 71.795 (71.795)	
2022-01-05 15:44:56 - INFO - 
 Epoch: 32	Training Loss 0.1841 	Training Prec@1 96.795 	Validation Loss 0.9070 	Validation Prec@1 71.795 	
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:56 - INFO - TRAINING - Epoch: [32][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1528 (0.1528)	Prec@1 95.312 (95.312)	
2022-01-05 15:44:56 - INFO - EVALUATING - Epoch: [32][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 0.4611 (0.4611)	Prec@1 71.795 (71.795)	
2022-01-05 15:44:56 - INFO - 
 Epoch: 33	Training Loss 0.1475 	Training Prec@1 95.513 	Validation Loss 0.4611 	Validation Prec@1 71.795 	
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:56 - INFO - TRAINING - Epoch: [33][0/3]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.1158 (0.1158)	Prec@1 98.438 (98.438)	
2022-01-05 15:44:56 - INFO - EVALUATING - Epoch: [33][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.9991 (0.9991)	Prec@1 71.795 (71.795)	
2022-01-05 15:44:56 - INFO - 
 Epoch: 34	Training Loss 0.1247 	Training Prec@1 97.436 	Validation Loss 0.9991 	Validation Prec@1 71.795 	
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:56 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:56 - INFO - TRAINING - Epoch: [34][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1260 (0.1260)	Prec@1 98.438 (98.438)	
2022-01-05 15:44:57 - INFO - EVALUATING - Epoch: [34][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.9984 (0.9984)	Prec@1 71.795 (71.795)	
2022-01-05 15:44:57 - INFO - 
 Epoch: 35	Training Loss 0.1471 	Training Prec@1 96.795 	Validation Loss 0.9984 	Validation Prec@1 71.795 	
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:57 - INFO - TRAINING - Epoch: [35][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1351 (0.1351)	Prec@1 96.875 (96.875)	
2022-01-05 15:44:57 - INFO - EVALUATING - Epoch: [35][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.7135 (0.7135)	Prec@1 76.923 (76.923)	
2022-01-05 15:44:57 - INFO - 
 Epoch: 36	Training Loss 0.1206 	Training Prec@1 97.436 	Validation Loss 0.7135 	Validation Prec@1 76.923 	
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:57 - INFO - TRAINING - Epoch: [36][0/3]	Time 0.154 (0.154)	Data 0.149 (0.149)	Loss 0.0782 (0.0782)	Prec@1 98.438 (98.438)	
2022-01-05 15:44:57 - INFO - EVALUATING - Epoch: [36][0/1]	Time 0.151 (0.151)	Data 0.149 (0.149)	Loss 0.5160 (0.5160)	Prec@1 66.667 (66.667)	
2022-01-05 15:44:57 - INFO - 
 Epoch: 37	Training Loss 0.1322 	Training Prec@1 94.872 	Validation Loss 0.5160 	Validation Prec@1 66.667 	
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:57 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:57 - INFO - TRAINING - Epoch: [37][0/3]	Time 0.157 (0.157)	Data 0.151 (0.151)	Loss 0.1790 (0.1790)	Prec@1 98.438 (98.438)	
2022-01-05 15:44:58 - INFO - EVALUATING - Epoch: [37][0/1]	Time 0.152 (0.152)	Data 0.149 (0.149)	Loss 1.4882 (1.4882)	Prec@1 58.974 (58.974)	
2022-01-05 15:44:58 - INFO - 
 Epoch: 38	Training Loss 0.1312 	Training Prec@1 96.795 	Validation Loss 1.4882 	Validation Prec@1 58.974 	
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:58 - INFO - TRAINING - Epoch: [38][0/3]	Time 0.156 (0.156)	Data 0.150 (0.150)	Loss 0.2380 (0.2380)	Prec@1 87.500 (87.500)	
2022-01-05 15:44:58 - INFO - EVALUATING - Epoch: [38][0/1]	Time 0.150 (0.150)	Data 0.147 (0.147)	Loss 0.5156 (0.5156)	Prec@1 66.667 (66.667)	
2022-01-05 15:44:58 - INFO - 
 Epoch: 39	Training Loss 0.1767 	Training Prec@1 90.385 	Validation Loss 0.5156 	Validation Prec@1 66.667 	
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:58 - INFO - TRAINING - Epoch: [39][0/3]	Time 0.155 (0.155)	Data 0.150 (0.150)	Loss 0.1836 (0.1836)	Prec@1 95.312 (95.312)	
2022-01-05 15:44:58 - INFO - EVALUATING - Epoch: [39][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 1.3938 (1.3938)	Prec@1 58.974 (58.974)	
2022-01-05 15:44:58 - INFO - 
 Epoch: 40	Training Loss 0.1272 	Training Prec@1 96.154 	Validation Loss 1.3938 	Validation Prec@1 58.974 	
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:58 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:59 - INFO - TRAINING - Epoch: [40][0/3]	Time 0.167 (0.167)	Data 0.162 (0.162)	Loss 0.3204 (0.3204)	Prec@1 85.938 (85.938)	
2022-01-05 15:44:59 - INFO - EVALUATING - Epoch: [40][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.5426 (0.5426)	Prec@1 64.103 (64.103)	
2022-01-05 15:44:59 - INFO - 
 Epoch: 41	Training Loss 0.2094 	Training Prec@1 92.308 	Validation Loss 0.5426 	Validation Prec@1 64.103 	
2022-01-05 15:44:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:59 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:59 - INFO - TRAINING - Epoch: [41][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.1612 (0.1612)	Prec@1 96.875 (96.875)	
2022-01-05 15:44:59 - INFO - EVALUATING - Epoch: [41][0/1]	Time 0.156 (0.156)	Data 0.153 (0.153)	Loss 0.9427 (0.9427)	Prec@1 69.231 (69.231)	
2022-01-05 15:44:59 - INFO - 
 Epoch: 42	Training Loss 0.1612 	Training Prec@1 96.154 	Validation Loss 0.9427 	Validation Prec@1 69.231 	
2022-01-05 15:44:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:44:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:44:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:44:59 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:44:59 - INFO - TRAINING - Epoch: [42][0/3]	Time 0.156 (0.156)	Data 0.151 (0.151)	Loss 0.1470 (0.1470)	Prec@1 96.875 (96.875)	
2022-01-05 15:44:59 - INFO - EVALUATING - Epoch: [42][0/1]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.8711 (0.8711)	Prec@1 64.103 (64.103)	
2022-01-05 15:45:00 - INFO - 
 Epoch: 43	Training Loss 0.1584 	Training Prec@1 96.795 	Validation Loss 0.8711 	Validation Prec@1 64.103 	
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:00 - INFO - TRAINING - Epoch: [43][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.0513 (0.0513)	Prec@1 98.438 (98.438)	
2022-01-05 15:45:00 - INFO - EVALUATING - Epoch: [43][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.2944 (1.2944)	Prec@1 64.103 (64.103)	
2022-01-05 15:45:00 - INFO - 
 Epoch: 44	Training Loss 0.0768 	Training Prec@1 96.795 	Validation Loss 1.2944 	Validation Prec@1 64.103 	
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:00 - INFO - TRAINING - Epoch: [44][0/3]	Time 0.153 (0.153)	Data 0.147 (0.147)	Loss 0.1175 (0.1175)	Prec@1 92.188 (92.188)	
2022-01-05 15:45:00 - INFO - EVALUATING - Epoch: [44][0/1]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.6542 (0.6542)	Prec@1 69.231 (69.231)	
2022-01-05 15:45:00 - INFO - 
 Epoch: 45	Training Loss 0.0975 	Training Prec@1 95.513 	Validation Loss 0.6542 	Validation Prec@1 69.231 	
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:00 - INFO - TRAINING - Epoch: [45][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1011 (0.1011)	Prec@1 98.438 (98.438)	
2022-01-05 15:45:01 - INFO - EVALUATING - Epoch: [45][0/1]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 1.4944 (1.4944)	Prec@1 74.359 (74.359)	
2022-01-05 15:45:01 - INFO - 
 Epoch: 46	Training Loss 0.1390 	Training Prec@1 97.436 	Validation Loss 1.4944 	Validation Prec@1 74.359 	
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:01 - INFO - TRAINING - Epoch: [46][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.1314 (0.1314)	Prec@1 95.312 (95.312)	
2022-01-05 15:45:01 - INFO - EVALUATING - Epoch: [46][0/1]	Time 0.151 (0.151)	Data 0.149 (0.149)	Loss 1.0287 (1.0287)	Prec@1 71.795 (71.795)	
2022-01-05 15:45:01 - INFO - 
 Epoch: 47	Training Loss 0.0698 	Training Prec@1 96.795 	Validation Loss 1.0287 	Validation Prec@1 71.795 	
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:01 - INFO - TRAINING - Epoch: [47][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.0216 (0.0216)	Prec@1 98.438 (98.438)	
2022-01-05 15:45:01 - INFO - EVALUATING - Epoch: [47][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.0022 (1.0022)	Prec@1 74.359 (74.359)	
2022-01-05 15:45:01 - INFO - 
 Epoch: 48	Training Loss 0.0996 	Training Prec@1 97.436 	Validation Loss 1.0022 	Validation Prec@1 74.359 	
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:01 - INFO - TRAINING - Epoch: [48][0/3]	Time 0.154 (0.154)	Data 0.149 (0.149)	Loss 0.0358 (0.0358)	Prec@1 98.438 (98.438)	
2022-01-05 15:45:02 - INFO - EVALUATING - Epoch: [48][0/1]	Time 0.152 (0.152)	Data 0.149 (0.149)	Loss 1.0293 (1.0293)	Prec@1 71.795 (71.795)	
2022-01-05 15:45:02 - INFO - 
 Epoch: 49	Training Loss 0.0975 	Training Prec@1 96.795 	Validation Loss 1.0293 	Validation Prec@1 71.795 	
2022-01-05 15:45:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:45:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:45:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:45:02 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:45:02 - INFO - TRAINING - Epoch: [49][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.0585 (0.0585)	Prec@1 100.000 (100.000)	
2022-01-05 15:45:02 - INFO - EVALUATING - Epoch: [49][0/1]	Time 0.150 (0.150)	Data 0.148 (0.148)	Loss 0.7025 (0.7025)	Prec@1 76.923 (76.923)	
2022-01-05 15:45:02 - INFO - 
 Epoch: 50	Training Loss 0.1992 	Training Prec@1 92.308 	Validation Loss 0.7025 	Validation Prec@1 76.923 	
