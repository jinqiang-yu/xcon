2022-01-05 15:42:41 - INFO - saving to ./results/small/quantise/q6/other/mlic/parkinsons_test1/
2022-01-05 15:42:41 - DEBUG - run arguments: Namespace(config='./configs/config_small.json', data='../../paper_bench/complete/quantise/q6/other/mlic/parkinsons_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/small/quantise/q6/other/mlic/parkinsons_test1/', test='../../paper_bench/cv/test/quantise/q6/other/mlic/parkinsons_test1_data.csv', train='../../paper_bench/cv/train/quantise/q6/other/mlic/parkinsons_train1_data.csv')
2022-01-05 15:42:41 - INFO - creating model mlp_binary
2022-01-05 15:42:41 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [10, 5, 5, 2]}
2022-01-05 15:42:41 - INFO - number of parameters: 1157
2022-01-05 15:42:41 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-05 15:42:41 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:41 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:42 - INFO - TRAINING - Epoch: [0][0/3]	Time 0.190 (0.190)	Data 0.156 (0.156)	Loss 0.9989 (0.9989)	Prec@1 70.312 (70.312)	
2022-01-05 15:42:42 - INFO - EVALUATING - Epoch: [0][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.8348 (0.8348)	Prec@1 71.795 (71.795)	
2022-01-05 15:42:42 - INFO - 
 Epoch: 1	Training Loss 1.0064 	Training Prec@1 67.949 	Validation Loss 0.8348 	Validation Prec@1 71.795 	
2022-01-05 15:42:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:42 - INFO - TRAINING - Epoch: [1][0/3]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.6855 (0.6855)	Prec@1 78.125 (78.125)	
2022-01-05 15:42:42 - INFO - EVALUATING - Epoch: [1][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.9075 (0.9075)	Prec@1 66.667 (66.667)	
2022-01-05 15:42:42 - INFO - 
 Epoch: 2	Training Loss 0.6018 	Training Prec@1 74.359 	Validation Loss 0.9075 	Validation Prec@1 66.667 	
2022-01-05 15:42:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:42 - INFO - TRAINING - Epoch: [2][0/3]	Time 0.153 (0.153)	Data 0.148 (0.148)	Loss 0.5566 (0.5566)	Prec@1 75.000 (75.000)	
2022-01-05 15:42:42 - INFO - EVALUATING - Epoch: [2][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8260 (0.8260)	Prec@1 58.974 (58.974)	
2022-01-05 15:42:42 - INFO - 
 Epoch: 3	Training Loss 0.5810 	Training Prec@1 71.795 	Validation Loss 0.8260 	Validation Prec@1 58.974 	
2022-01-05 15:42:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:43 - INFO - TRAINING - Epoch: [3][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.6755 (0.6755)	Prec@1 57.812 (57.812)	
2022-01-05 15:42:43 - INFO - EVALUATING - Epoch: [3][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.6053 (0.6053)	Prec@1 66.667 (66.667)	
2022-01-05 15:42:43 - INFO - 
 Epoch: 4	Training Loss 0.7320 	Training Prec@1 67.308 	Validation Loss 0.6053 	Validation Prec@1 66.667 	
2022-01-05 15:42:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:43 - INFO - TRAINING - Epoch: [4][0/3]	Time 0.154 (0.154)	Data 0.148 (0.148)	Loss 0.3134 (0.3134)	Prec@1 89.062 (89.062)	
2022-01-05 15:42:43 - INFO - EVALUATING - Epoch: [4][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.5106 (0.5106)	Prec@1 82.051 (82.051)	
2022-01-05 15:42:43 - INFO - 
 Epoch: 5	Training Loss 0.4801 	Training Prec@1 78.846 	Validation Loss 0.5106 	Validation Prec@1 82.051 	
2022-01-05 15:42:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:43 - INFO - TRAINING - Epoch: [5][0/3]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.4668 (0.4668)	Prec@1 79.688 (79.688)	
2022-01-05 15:42:43 - INFO - EVALUATING - Epoch: [5][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.5300 (0.5300)	Prec@1 66.667 (66.667)	
2022-01-05 15:42:43 - INFO - 
 Epoch: 6	Training Loss 0.5486 	Training Prec@1 77.564 	Validation Loss 0.5300 	Validation Prec@1 66.667 	
2022-01-05 15:42:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:44 - INFO - TRAINING - Epoch: [6][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3047 (0.3047)	Prec@1 87.500 (87.500)	
2022-01-05 15:42:44 - INFO - EVALUATING - Epoch: [6][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.5124 (0.5124)	Prec@1 79.487 (79.487)	
2022-01-05 15:42:44 - INFO - 
 Epoch: 7	Training Loss 0.4633 	Training Prec@1 82.051 	Validation Loss 0.5124 	Validation Prec@1 79.487 	
2022-01-05 15:42:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:44 - INFO - TRAINING - Epoch: [7][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.5102 (0.5102)	Prec@1 79.688 (79.688)	
2022-01-05 15:42:44 - INFO - EVALUATING - Epoch: [7][0/1]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.5087 (0.5087)	Prec@1 79.487 (79.487)	
2022-01-05 15:42:44 - INFO - 
 Epoch: 8	Training Loss 0.6775 	Training Prec@1 74.359 	Validation Loss 0.5087 	Validation Prec@1 79.487 	
2022-01-05 15:42:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:44 - INFO - TRAINING - Epoch: [8][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.6407 (0.6407)	Prec@1 68.750 (68.750)	
2022-01-05 15:42:44 - INFO - EVALUATING - Epoch: [8][0/1]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.9263 (0.9263)	Prec@1 76.923 (76.923)	
2022-01-05 15:42:44 - INFO - 
 Epoch: 9	Training Loss 0.5360 	Training Prec@1 78.846 	Validation Loss 0.9263 	Validation Prec@1 76.923 	
2022-01-05 15:42:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:45 - INFO - TRAINING - Epoch: [9][0/3]	Time 0.164 (0.164)	Data 0.159 (0.159)	Loss 0.3110 (0.3110)	Prec@1 93.750 (93.750)	
2022-01-05 15:42:45 - INFO - EVALUATING - Epoch: [9][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.9105 (0.9105)	Prec@1 71.795 (71.795)	
2022-01-05 15:42:45 - INFO - 
 Epoch: 10	Training Loss 0.2506 	Training Prec@1 94.231 	Validation Loss 0.9105 	Validation Prec@1 71.795 	
2022-01-05 15:42:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:45 - INFO - TRAINING - Epoch: [10][0/3]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 0.3991 (0.3991)	Prec@1 84.375 (84.375)	
2022-01-05 15:42:45 - INFO - EVALUATING - Epoch: [10][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.5180 (0.5180)	Prec@1 84.615 (84.615)	
2022-01-05 15:42:45 - INFO - 
 Epoch: 11	Training Loss 0.3012 	Training Prec@1 88.462 	Validation Loss 0.5180 	Validation Prec@1 84.615 	
2022-01-05 15:42:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:45 - INFO - TRAINING - Epoch: [11][0/3]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.2949 (0.2949)	Prec@1 92.188 (92.188)	
2022-01-05 15:42:45 - INFO - EVALUATING - Epoch: [11][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.5037 (1.5037)	Prec@1 66.667 (66.667)	
2022-01-05 15:42:45 - INFO - 
 Epoch: 12	Training Loss 0.2478 	Training Prec@1 94.872 	Validation Loss 1.5037 	Validation Prec@1 66.667 	
2022-01-05 15:42:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:46 - INFO - TRAINING - Epoch: [12][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3458 (0.3458)	Prec@1 90.625 (90.625)	
2022-01-05 15:42:46 - INFO - EVALUATING - Epoch: [12][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.4739 (0.4739)	Prec@1 79.487 (79.487)	
2022-01-05 15:42:46 - INFO - 
 Epoch: 13	Training Loss 0.3424 	Training Prec@1 89.103 	Validation Loss 0.4739 	Validation Prec@1 79.487 	
2022-01-05 15:42:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:46 - INFO - TRAINING - Epoch: [13][0/3]	Time 0.153 (0.153)	Data 0.148 (0.148)	Loss 0.1397 (0.1397)	Prec@1 100.000 (100.000)	
2022-01-05 15:42:46 - INFO - EVALUATING - Epoch: [13][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.7997 (0.7997)	Prec@1 79.487 (79.487)	
2022-01-05 15:42:46 - INFO - 
 Epoch: 14	Training Loss 0.2404 	Training Prec@1 96.154 	Validation Loss 0.7997 	Validation Prec@1 79.487 	
2022-01-05 15:42:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:46 - INFO - TRAINING - Epoch: [14][0/3]	Time 0.164 (0.164)	Data 0.159 (0.159)	Loss 0.0792 (0.0792)	Prec@1 96.875 (96.875)	
2022-01-05 15:42:46 - INFO - EVALUATING - Epoch: [14][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.9413 (0.9413)	Prec@1 76.923 (76.923)	
2022-01-05 15:42:47 - INFO - 
 Epoch: 15	Training Loss 0.1480 	Training Prec@1 92.308 	Validation Loss 0.9413 	Validation Prec@1 76.923 	
2022-01-05 15:42:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:47 - INFO - TRAINING - Epoch: [15][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.2754 (0.2754)	Prec@1 93.750 (93.750)	
2022-01-05 15:42:47 - INFO - EVALUATING - Epoch: [15][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.0111 (1.0111)	Prec@1 66.667 (66.667)	
2022-01-05 15:42:47 - INFO - 
 Epoch: 16	Training Loss 0.1888 	Training Prec@1 92.949 	Validation Loss 1.0111 	Validation Prec@1 66.667 	
2022-01-05 15:42:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:47 - INFO - TRAINING - Epoch: [16][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.2912 (0.2912)	Prec@1 90.625 (90.625)	
2022-01-05 15:42:47 - INFO - EVALUATING - Epoch: [16][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.5075 (0.5075)	Prec@1 79.487 (79.487)	
2022-01-05 15:42:47 - INFO - 
 Epoch: 17	Training Loss 0.2977 	Training Prec@1 90.385 	Validation Loss 0.5075 	Validation Prec@1 79.487 	
2022-01-05 15:42:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:47 - INFO - TRAINING - Epoch: [17][0/3]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5464 (0.5464)	Prec@1 76.562 (76.562)	
2022-01-05 15:42:48 - INFO - EVALUATING - Epoch: [17][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.5224 (0.5224)	Prec@1 82.051 (82.051)	
2022-01-05 15:42:48 - INFO - 
 Epoch: 18	Training Loss 0.3818 	Training Prec@1 87.179 	Validation Loss 0.5224 	Validation Prec@1 82.051 	
2022-01-05 15:42:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:48 - INFO - TRAINING - Epoch: [18][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.2420 (0.2420)	Prec@1 85.938 (85.938)	
2022-01-05 15:42:48 - INFO - EVALUATING - Epoch: [18][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6127 (0.6127)	Prec@1 76.923 (76.923)	
2022-01-05 15:42:48 - INFO - 
 Epoch: 19	Training Loss 0.2364 	Training Prec@1 89.103 	Validation Loss 0.6127 	Validation Prec@1 76.923 	
2022-01-05 15:42:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:48 - INFO - TRAINING - Epoch: [19][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1233 (0.1233)	Prec@1 95.312 (95.312)	
2022-01-05 15:42:48 - INFO - EVALUATING - Epoch: [19][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6067 (0.6067)	Prec@1 82.051 (82.051)	
2022-01-05 15:42:48 - INFO - 
 Epoch: 20	Training Loss 0.1586 	Training Prec@1 95.513 	Validation Loss 0.6067 	Validation Prec@1 82.051 	
2022-01-05 15:42:48 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:48 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:48 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:48 - INFO - TRAINING - Epoch: [20][0/3]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.1616 (0.1616)	Prec@1 98.438 (98.438)	
2022-01-05 15:42:49 - INFO - EVALUATING - Epoch: [20][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.5331 (0.5331)	Prec@1 84.615 (84.615)	
2022-01-05 15:42:49 - INFO - 
 Epoch: 21	Training Loss 0.2479 	Training Prec@1 93.590 	Validation Loss 0.5331 	Validation Prec@1 84.615 	
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:49 - INFO - TRAINING - Epoch: [21][0/3]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.2223 (0.2223)	Prec@1 93.750 (93.750)	
2022-01-05 15:42:49 - INFO - EVALUATING - Epoch: [21][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.4602 (0.4602)	Prec@1 87.179 (87.179)	
2022-01-05 15:42:49 - INFO - 
 Epoch: 22	Training Loss 0.1938 	Training Prec@1 95.513 	Validation Loss 0.4602 	Validation Prec@1 87.179 	
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:49 - INFO - TRAINING - Epoch: [22][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1749 (0.1749)	Prec@1 96.875 (96.875)	
2022-01-05 15:42:49 - INFO - EVALUATING - Epoch: [22][0/1]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.7500 (0.7500)	Prec@1 74.359 (74.359)	
2022-01-05 15:42:49 - INFO - 
 Epoch: 23	Training Loss 0.1744 	Training Prec@1 96.154 	Validation Loss 0.7500 	Validation Prec@1 74.359 	
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:49 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:49 - INFO - TRAINING - Epoch: [23][0/3]	Time 0.153 (0.153)	Data 0.148 (0.148)	Loss 0.2725 (0.2725)	Prec@1 95.312 (95.312)	
2022-01-05 15:42:50 - INFO - EVALUATING - Epoch: [23][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.5384 (0.5384)	Prec@1 74.359 (74.359)	
2022-01-05 15:42:50 - INFO - 
 Epoch: 24	Training Loss 0.1995 	Training Prec@1 95.513 	Validation Loss 0.5384 	Validation Prec@1 74.359 	
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:50 - INFO - TRAINING - Epoch: [24][0/3]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.2151 (0.2151)	Prec@1 96.875 (96.875)	
2022-01-05 15:42:50 - INFO - EVALUATING - Epoch: [24][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.7191 (0.7191)	Prec@1 74.359 (74.359)	
2022-01-05 15:42:50 - INFO - 
 Epoch: 25	Training Loss 0.1661 	Training Prec@1 95.513 	Validation Loss 0.7191 	Validation Prec@1 74.359 	
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:50 - INFO - TRAINING - Epoch: [25][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1927 (0.1927)	Prec@1 95.312 (95.312)	
2022-01-05 15:42:50 - INFO - EVALUATING - Epoch: [25][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.6167 (0.6167)	Prec@1 74.359 (74.359)	
2022-01-05 15:42:50 - INFO - 
 Epoch: 26	Training Loss 0.1519 	Training Prec@1 94.872 	Validation Loss 0.6167 	Validation Prec@1 74.359 	
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:50 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:50 - INFO - TRAINING - Epoch: [26][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1407 (0.1407)	Prec@1 93.750 (93.750)	
2022-01-05 15:42:51 - INFO - EVALUATING - Epoch: [26][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.9721 (0.9721)	Prec@1 71.795 (71.795)	
2022-01-05 15:42:51 - INFO - 
 Epoch: 27	Training Loss 0.1139 	Training Prec@1 97.436 	Validation Loss 0.9721 	Validation Prec@1 71.795 	
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:51 - INFO - TRAINING - Epoch: [27][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.0407 (0.0407)	Prec@1 98.438 (98.438)	
2022-01-05 15:42:51 - INFO - EVALUATING - Epoch: [27][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.0324 (1.0324)	Prec@1 76.923 (76.923)	
2022-01-05 15:42:51 - INFO - 
 Epoch: 28	Training Loss 0.0521 	Training Prec@1 98.718 	Validation Loss 1.0324 	Validation Prec@1 76.923 	
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:51 - INFO - TRAINING - Epoch: [28][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.0764 (0.0764)	Prec@1 96.875 (96.875)	
2022-01-05 15:42:51 - INFO - EVALUATING - Epoch: [28][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.9736 (0.9736)	Prec@1 71.795 (71.795)	
2022-01-05 15:42:51 - INFO - 
 Epoch: 29	Training Loss 0.0722 	Training Prec@1 97.436 	Validation Loss 0.9736 	Validation Prec@1 71.795 	
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:51 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:51 - INFO - TRAINING - Epoch: [29][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.0655 (0.0655)	Prec@1 98.438 (98.438)	
2022-01-05 15:42:52 - INFO - EVALUATING - Epoch: [29][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.2969 (1.2969)	Prec@1 74.359 (74.359)	
2022-01-05 15:42:52 - INFO - 
 Epoch: 30	Training Loss 0.1023 	Training Prec@1 98.718 	Validation Loss 1.2969 	Validation Prec@1 74.359 	
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:52 - INFO - TRAINING - Epoch: [30][0/3]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.1061 (0.1061)	Prec@1 96.875 (96.875)	
2022-01-05 15:42:52 - INFO - EVALUATING - Epoch: [30][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 1.3004 (1.3004)	Prec@1 74.359 (74.359)	
2022-01-05 15:42:52 - INFO - 
 Epoch: 31	Training Loss 0.1011 	Training Prec@1 98.077 	Validation Loss 1.3004 	Validation Prec@1 74.359 	
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:52 - INFO - TRAINING - Epoch: [31][0/3]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.0507 (0.0507)	Prec@1 96.875 (96.875)	
2022-01-05 15:42:52 - INFO - EVALUATING - Epoch: [31][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.7613 (0.7613)	Prec@1 74.359 (74.359)	
2022-01-05 15:42:52 - INFO - 
 Epoch: 32	Training Loss 0.0657 	Training Prec@1 97.436 	Validation Loss 0.7613 	Validation Prec@1 74.359 	
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:52 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:53 - INFO - TRAINING - Epoch: [32][0/3]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.0198 (0.0198)	Prec@1 100.000 (100.000)	
2022-01-05 15:42:53 - INFO - EVALUATING - Epoch: [32][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.6925 (0.6925)	Prec@1 76.923 (76.923)	
2022-01-05 15:42:53 - INFO - 
 Epoch: 33	Training Loss 0.0855 	Training Prec@1 96.154 	Validation Loss 0.6925 	Validation Prec@1 76.923 	
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:53 - INFO - TRAINING - Epoch: [33][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.0540 (0.0540)	Prec@1 98.438 (98.438)	
2022-01-05 15:42:53 - INFO - EVALUATING - Epoch: [33][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.7038 (0.7038)	Prec@1 76.923 (76.923)	
2022-01-05 15:42:53 - INFO - 
 Epoch: 34	Training Loss 0.0543 	Training Prec@1 97.436 	Validation Loss 0.7038 	Validation Prec@1 76.923 	
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:53 - INFO - TRAINING - Epoch: [34][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1281 (0.1281)	Prec@1 96.875 (96.875)	
2022-01-05 15:42:53 - INFO - EVALUATING - Epoch: [34][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.7280 (0.7280)	Prec@1 74.359 (74.359)	
2022-01-05 15:42:53 - INFO - 
 Epoch: 35	Training Loss 0.2348 	Training Prec@1 93.590 	Validation Loss 0.7280 	Validation Prec@1 74.359 	
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:53 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:54 - INFO - TRAINING - Epoch: [35][0/3]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.0624 (0.0624)	Prec@1 96.875 (96.875)	
2022-01-05 15:42:54 - INFO - EVALUATING - Epoch: [35][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.1519 (1.1519)	Prec@1 74.359 (74.359)	
2022-01-05 15:42:54 - INFO - 
 Epoch: 36	Training Loss 0.0683 	Training Prec@1 97.436 	Validation Loss 1.1519 	Validation Prec@1 74.359 	
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:54 - INFO - TRAINING - Epoch: [36][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.1291 (0.1291)	Prec@1 95.312 (95.312)	
2022-01-05 15:42:54 - INFO - EVALUATING - Epoch: [36][0/1]	Time 0.143 (0.143)	Data 0.141 (0.141)	Loss 0.6368 (0.6368)	Prec@1 66.667 (66.667)	
2022-01-05 15:42:54 - INFO - 
 Epoch: 37	Training Loss 0.1257 	Training Prec@1 96.154 	Validation Loss 0.6368 	Validation Prec@1 66.667 	
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:54 - INFO - TRAINING - Epoch: [37][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.2558 (0.2558)	Prec@1 87.500 (87.500)	
2022-01-05 15:42:54 - INFO - EVALUATING - Epoch: [37][0/1]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 1.5490 (1.5490)	Prec@1 69.231 (69.231)	
2022-01-05 15:42:54 - INFO - 
 Epoch: 38	Training Loss 0.1442 	Training Prec@1 93.590 	Validation Loss 1.5490 	Validation Prec@1 69.231 	
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:54 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:55 - INFO - TRAINING - Epoch: [38][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.0298 (0.0298)	Prec@1 98.438 (98.438)	
2022-01-05 15:42:55 - INFO - EVALUATING - Epoch: [38][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.7029 (0.7029)	Prec@1 76.923 (76.923)	
2022-01-05 15:42:55 - INFO - 
 Epoch: 39	Training Loss 0.1019 	Training Prec@1 97.436 	Validation Loss 0.7029 	Validation Prec@1 76.923 	
2022-01-05 15:42:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:55 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:55 - INFO - TRAINING - Epoch: [39][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1046 (0.1046)	Prec@1 100.000 (100.000)	
2022-01-05 15:42:55 - INFO - EVALUATING - Epoch: [39][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.3587 (1.3587)	Prec@1 69.231 (69.231)	
2022-01-05 15:42:55 - INFO - 
 Epoch: 40	Training Loss 0.1567 	Training Prec@1 98.077 	Validation Loss 1.3587 	Validation Prec@1 69.231 	
2022-01-05 15:42:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:55 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:55 - INFO - TRAINING - Epoch: [40][0/3]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.0283 (0.0283)	Prec@1 98.438 (98.438)	
2022-01-05 15:42:55 - INFO - EVALUATING - Epoch: [40][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.6927 (0.6927)	Prec@1 74.359 (74.359)	
2022-01-05 15:42:55 - INFO - 
 Epoch: 41	Training Loss 0.1001 	Training Prec@1 97.436 	Validation Loss 0.6927 	Validation Prec@1 74.359 	
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:56 - INFO - TRAINING - Epoch: [41][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1175 (0.1175)	Prec@1 96.875 (96.875)	
2022-01-05 15:42:56 - INFO - EVALUATING - Epoch: [41][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.3794 (1.3794)	Prec@1 71.795 (71.795)	
2022-01-05 15:42:56 - INFO - 
 Epoch: 42	Training Loss 0.0602 	Training Prec@1 98.077 	Validation Loss 1.3794 	Validation Prec@1 71.795 	
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:56 - INFO - TRAINING - Epoch: [42][0/3]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.0079 (0.0079)	Prec@1 100.000 (100.000)	
2022-01-05 15:42:56 - INFO - EVALUATING - Epoch: [42][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.3813 (1.3813)	Prec@1 71.795 (71.795)	
2022-01-05 15:42:56 - INFO - 
 Epoch: 43	Training Loss 0.0810 	Training Prec@1 96.795 	Validation Loss 1.3813 	Validation Prec@1 71.795 	
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:56 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:56 - INFO - TRAINING - Epoch: [43][0/3]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.1134 (0.1134)	Prec@1 98.438 (98.438)	
2022-01-05 15:42:57 - INFO - EVALUATING - Epoch: [43][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.1269 (1.1269)	Prec@1 71.795 (71.795)	
2022-01-05 15:42:57 - INFO - 
 Epoch: 44	Training Loss 0.0540 	Training Prec@1 99.359 	Validation Loss 1.1269 	Validation Prec@1 71.795 	
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:57 - INFO - TRAINING - Epoch: [44][0/3]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.0081 (0.0081)	Prec@1 100.000 (100.000)	
2022-01-05 15:42:57 - INFO - EVALUATING - Epoch: [44][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.4627 (1.4627)	Prec@1 69.231 (69.231)	
2022-01-05 15:42:57 - INFO - 
 Epoch: 45	Training Loss 0.0295 	Training Prec@1 99.359 	Validation Loss 1.4627 	Validation Prec@1 69.231 	
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:57 - INFO - TRAINING - Epoch: [45][0/3]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.2084 (0.2084)	Prec@1 93.750 (93.750)	
2022-01-05 15:42:57 - INFO - EVALUATING - Epoch: [45][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.0557 (1.0557)	Prec@1 69.231 (69.231)	
2022-01-05 15:42:57 - INFO - 
 Epoch: 46	Training Loss 0.1306 	Training Prec@1 96.154 	Validation Loss 1.0557 	Validation Prec@1 69.231 	
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:57 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:57 - INFO - TRAINING - Epoch: [46][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.0282 (0.0282)	Prec@1 100.000 (100.000)	
2022-01-05 15:42:58 - INFO - EVALUATING - Epoch: [46][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.6510 (1.6510)	Prec@1 69.231 (69.231)	
2022-01-05 15:42:58 - INFO - 
 Epoch: 47	Training Loss 0.0567 	Training Prec@1 98.718 	Validation Loss 1.6510 	Validation Prec@1 69.231 	
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:58 - INFO - TRAINING - Epoch: [47][0/3]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.0276 (0.0276)	Prec@1 98.438 (98.438)	
2022-01-05 15:42:58 - INFO - EVALUATING - Epoch: [47][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.3470 (1.3470)	Prec@1 69.231 (69.231)	
2022-01-05 15:42:58 - INFO - 
 Epoch: 48	Training Loss 0.0480 	Training Prec@1 98.718 	Validation Loss 1.3470 	Validation Prec@1 69.231 	
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:58 - INFO - TRAINING - Epoch: [48][0/3]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.2298 (0.2298)	Prec@1 93.750 (93.750)	
2022-01-05 15:42:58 - INFO - EVALUATING - Epoch: [48][0/1]	Time 0.167 (0.167)	Data 0.164 (0.164)	Loss 1.2400 (1.2400)	Prec@1 71.795 (71.795)	
2022-01-05 15:42:58 - INFO - 
 Epoch: 49	Training Loss 0.1340 	Training Prec@1 95.513 	Validation Loss 1.2400 	Validation Prec@1 71.795 	
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:42:58 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:42:59 - INFO - TRAINING - Epoch: [49][0/3]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.1113 (0.1113)	Prec@1 96.875 (96.875)	
2022-01-05 15:42:59 - INFO - EVALUATING - Epoch: [49][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.1947 (1.1947)	Prec@1 71.795 (71.795)	
2022-01-05 15:42:59 - INFO - 
 Epoch: 50	Training Loss 0.0819 	Training Prec@1 97.436 	Validation Loss 1.1947 	Validation Prec@1 71.795 	
