2022-01-05 15:43:01 - INFO - saving to ./results/small/quantise/q6/penn-ml/australian/australian_test1/
2022-01-05 15:43:01 - DEBUG - run arguments: Namespace(config='./configs/config_small.json', data='../../paper_bench/complete/quantise/q6/penn-ml/australian/australian_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/small/quantise/q6/penn-ml/australian/australian_test1/', test='../../paper_bench/cv/test/quantise/q6/penn-ml/australian/australian_test1_data.csv', train='../../paper_bench/cv/train/quantise/q6/penn-ml/australian/australian_train1_data.csv')
2022-01-05 15:43:01 - INFO - creating model mlp_binary
2022-01-05 15:43:01 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [10, 5, 5, 2]}
2022-01-05 15:43:01 - INFO - number of parameters: 767
2022-01-05 15:43:01 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-05 15:43:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:01 - INFO - TRAINING - Epoch: [0][0/9]	Time 0.161 (0.161)	Data 0.153 (0.153)	Loss 1.9942 (1.9942)	Prec@1 43.750 (43.750)	
2022-01-05 15:43:01 - INFO - EVALUATING - Epoch: [0][0/3]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 1.0330 (1.0330)	Prec@1 51.562 (51.562)	
2022-01-05 15:43:01 - INFO - 
 Epoch: 1	Training Loss 1.1594 	Training Prec@1 59.239 	Validation Loss 0.8684 	Validation Prec@1 60.870 	
2022-01-05 15:43:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:01 - INFO - TRAINING - Epoch: [1][0/9]	Time 0.155 (0.155)	Data 0.150 (0.150)	Loss 0.7267 (0.7267)	Prec@1 70.312 (70.312)	
2022-01-05 15:43:01 - INFO - EVALUATING - Epoch: [1][0/3]	Time 0.152 (0.152)	Data 0.150 (0.150)	Loss 0.6810 (0.6810)	Prec@1 57.812 (57.812)	
2022-01-05 15:43:01 - INFO - 
 Epoch: 2	Training Loss 0.6347 	Training Prec@1 71.558 	Validation Loss 0.6805 	Validation Prec@1 57.971 	
2022-01-05 15:43:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:02 - INFO - TRAINING - Epoch: [2][0/9]	Time 0.157 (0.157)	Data 0.150 (0.150)	Loss 0.6537 (0.6537)	Prec@1 67.188 (67.188)	
2022-01-05 15:43:02 - INFO - EVALUATING - Epoch: [2][0/3]	Time 0.182 (0.182)	Data 0.179 (0.179)	Loss 1.2642 (1.2642)	Prec@1 75.000 (75.000)	
2022-01-05 15:43:02 - INFO - 
 Epoch: 3	Training Loss 0.6357 	Training Prec@1 72.283 	Validation Loss 1.0984 	Validation Prec@1 78.261 	
2022-01-05 15:43:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:02 - INFO - TRAINING - Epoch: [3][0/9]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.3149 (0.3149)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:02 - INFO - EVALUATING - Epoch: [3][0/3]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 1.4588 (1.4588)	Prec@1 50.000 (50.000)	
2022-01-05 15:43:02 - INFO - 
 Epoch: 4	Training Loss 0.6697 	Training Prec@1 78.080 	Validation Loss 1.2764 	Validation Prec@1 54.348 	
2022-01-05 15:43:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:02 - INFO - TRAINING - Epoch: [4][0/9]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.6992 (0.6992)	Prec@1 59.375 (59.375)	
2022-01-05 15:43:03 - INFO - EVALUATING - Epoch: [4][0/3]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.6906 (0.6906)	Prec@1 71.875 (71.875)	
2022-01-05 15:43:03 - INFO - 
 Epoch: 5	Training Loss 0.6814 	Training Prec@1 78.442 	Validation Loss 0.6125 	Validation Prec@1 72.464 	
2022-01-05 15:43:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:03 - INFO - TRAINING - Epoch: [5][0/9]	Time 0.153 (0.153)	Data 0.148 (0.148)	Loss 0.6319 (0.6319)	Prec@1 70.312 (70.312)	
2022-01-05 15:43:03 - INFO - EVALUATING - Epoch: [5][0/3]	Time 0.152 (0.152)	Data 0.150 (0.150)	Loss 0.6967 (0.6967)	Prec@1 71.875 (71.875)	
2022-01-05 15:43:03 - INFO - 
 Epoch: 6	Training Loss 0.5466 	Training Prec@1 76.268 	Validation Loss 0.6303 	Validation Prec@1 75.362 	
2022-01-05 15:43:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:03 - INFO - TRAINING - Epoch: [6][0/9]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.4797 (0.4797)	Prec@1 82.812 (82.812)	
2022-01-05 15:43:03 - INFO - EVALUATING - Epoch: [6][0/3]	Time 0.150 (0.150)	Data 0.146 (0.146)	Loss 1.1966 (1.1966)	Prec@1 70.312 (70.312)	
2022-01-05 15:43:03 - INFO - 
 Epoch: 7	Training Loss 0.5988 	Training Prec@1 81.884 	Validation Loss 1.0170 	Validation Prec@1 72.464 	
2022-01-05 15:43:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:04 - INFO - TRAINING - Epoch: [7][0/9]	Time 0.153 (0.153)	Data 0.148 (0.148)	Loss 0.8193 (0.8193)	Prec@1 65.625 (65.625)	
2022-01-05 15:43:04 - INFO - EVALUATING - Epoch: [7][0/3]	Time 0.148 (0.148)	Data 0.146 (0.146)	Loss 1.0666 (1.0666)	Prec@1 73.438 (73.438)	
2022-01-05 15:43:04 - INFO - 
 Epoch: 8	Training Loss 0.6656 	Training Prec@1 75.000 	Validation Loss 0.7909 	Validation Prec@1 79.710 	
2022-01-05 15:43:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:04 - INFO - TRAINING - Epoch: [8][0/9]	Time 0.153 (0.153)	Data 0.148 (0.148)	Loss 0.6341 (0.6341)	Prec@1 79.688 (79.688)	
2022-01-05 15:43:04 - INFO - EVALUATING - Epoch: [8][0/3]	Time 0.159 (0.159)	Data 0.156 (0.156)	Loss 0.7926 (0.7926)	Prec@1 65.625 (65.625)	
2022-01-05 15:43:04 - INFO - 
 Epoch: 9	Training Loss 0.5028 	Training Prec@1 83.877 	Validation Loss 0.8588 	Validation Prec@1 62.319 	
2022-01-05 15:43:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:04 - INFO - TRAINING - Epoch: [9][0/9]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 1.0213 (1.0213)	Prec@1 53.125 (53.125)	
2022-01-05 15:43:05 - INFO - EVALUATING - Epoch: [9][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.7347 (0.7347)	Prec@1 78.125 (78.125)	
2022-01-05 15:43:05 - INFO - 
 Epoch: 10	Training Loss 0.7481 	Training Prec@1 76.268 	Validation Loss 0.6316 	Validation Prec@1 80.435 	
2022-01-05 15:43:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:05 - INFO - TRAINING - Epoch: [10][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.7134 (0.7134)	Prec@1 82.812 (82.812)	
2022-01-05 15:43:05 - INFO - EVALUATING - Epoch: [10][0/3]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.6826 (0.6826)	Prec@1 57.812 (57.812)	
2022-01-05 15:43:05 - INFO - 
 Epoch: 11	Training Loss 0.6014 	Training Prec@1 79.710 	Validation Loss 0.6819 	Validation Prec@1 57.971 	
2022-01-05 15:43:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:05 - INFO - TRAINING - Epoch: [11][0/9]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.7096 (0.7096)	Prec@1 51.562 (51.562)	
2022-01-05 15:43:05 - INFO - EVALUATING - Epoch: [11][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 1.1334 (1.1334)	Prec@1 71.875 (71.875)	
2022-01-05 15:43:05 - INFO - 
 Epoch: 12	Training Loss 0.5660 	Training Prec@1 78.623 	Validation Loss 1.1233 	Validation Prec@1 71.739 	
2022-01-05 15:43:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:05 - INFO - TRAINING - Epoch: [12][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3150 (0.3150)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:06 - INFO - EVALUATING - Epoch: [12][0/3]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.8124 (0.8124)	Prec@1 67.188 (67.188)	
2022-01-05 15:43:06 - INFO - 
 Epoch: 13	Training Loss 0.5132 	Training Prec@1 84.239 	Validation Loss 0.7230 	Validation Prec@1 71.739 	
2022-01-05 15:43:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:06 - INFO - TRAINING - Epoch: [13][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3846 (0.3846)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:06 - INFO - EVALUATING - Epoch: [13][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.7133 (0.7133)	Prec@1 73.438 (73.438)	
2022-01-05 15:43:06 - INFO - 
 Epoch: 14	Training Loss 0.5307 	Training Prec@1 79.348 	Validation Loss 0.6499 	Validation Prec@1 77.536 	
2022-01-05 15:43:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:06 - INFO - TRAINING - Epoch: [14][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3048 (0.3048)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:06 - INFO - EVALUATING - Epoch: [14][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.8050 (1.8050)	Prec@1 67.188 (67.188)	
2022-01-05 15:43:06 - INFO - 
 Epoch: 15	Training Loss 0.7710 	Training Prec@1 73.913 	Validation Loss 1.2731 	Validation Prec@1 73.913 	
2022-01-05 15:43:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:07 - INFO - TRAINING - Epoch: [15][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.6796 (0.6796)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:07 - INFO - EVALUATING - Epoch: [15][0/3]	Time 0.154 (0.154)	Data 0.151 (0.151)	Loss 0.8048 (0.8048)	Prec@1 70.312 (70.312)	
2022-01-05 15:43:07 - INFO - 
 Epoch: 16	Training Loss 0.5719 	Training Prec@1 76.630 	Validation Loss 0.9415 	Validation Prec@1 71.739 	
2022-01-05 15:43:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:07 - INFO - TRAINING - Epoch: [16][0/9]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.4576 (0.4576)	Prec@1 84.375 (84.375)	
2022-01-05 15:43:07 - INFO - EVALUATING - Epoch: [16][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.0023 (1.0023)	Prec@1 57.812 (57.812)	
2022-01-05 15:43:07 - INFO - 
 Epoch: 17	Training Loss 0.7523 	Training Prec@1 72.826 	Validation Loss 0.9989 	Validation Prec@1 57.971 	
2022-01-05 15:43:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:07 - INFO - TRAINING - Epoch: [17][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 1.1008 (1.1008)	Prec@1 53.125 (53.125)	
2022-01-05 15:43:08 - INFO - EVALUATING - Epoch: [17][0/3]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.8329 (0.8329)	Prec@1 75.000 (75.000)	
2022-01-05 15:43:08 - INFO - 
 Epoch: 18	Training Loss 0.6015 	Training Prec@1 80.616 	Validation Loss 0.7775 	Validation Prec@1 78.986 	
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:08 - INFO - TRAINING - Epoch: [18][0/9]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.5204 (0.5204)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:08 - INFO - EVALUATING - Epoch: [18][0/3]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.5694 (0.5694)	Prec@1 78.125 (78.125)	
2022-01-05 15:43:08 - INFO - 
 Epoch: 19	Training Loss 0.6677 	Training Prec@1 83.514 	Validation Loss 0.5191 	Validation Prec@1 80.435 	
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:08 - INFO - TRAINING - Epoch: [19][0/9]	Time 0.153 (0.153)	Data 0.148 (0.148)	Loss 0.3491 (0.3491)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:08 - INFO - EVALUATING - Epoch: [19][0/3]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.7742 (0.7742)	Prec@1 78.125 (78.125)	
2022-01-05 15:43:08 - INFO - 
 Epoch: 20	Training Loss 0.6262 	Training Prec@1 66.123 	Validation Loss 0.8299 	Validation Prec@1 76.812 	
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:08 - INFO - TRAINING - Epoch: [20][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5479 (0.5479)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:09 - INFO - EVALUATING - Epoch: [20][0/3]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.5990 (0.5990)	Prec@1 76.562 (76.562)	
2022-01-05 15:43:09 - INFO - 
 Epoch: 21	Training Loss 0.5505 	Training Prec@1 83.877 	Validation Loss 0.5959 	Validation Prec@1 76.812 	
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:09 - INFO - TRAINING - Epoch: [21][0/9]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.3752 (0.3752)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:09 - INFO - EVALUATING - Epoch: [21][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6290 (0.6290)	Prec@1 75.000 (75.000)	
2022-01-05 15:43:09 - INFO - 
 Epoch: 22	Training Loss 0.4158 	Training Prec@1 85.688 	Validation Loss 0.6078 	Validation Prec@1 76.087 	
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:09 - INFO - TRAINING - Epoch: [22][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3461 (0.3461)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:09 - INFO - EVALUATING - Epoch: [22][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.6759 (0.6759)	Prec@1 73.438 (73.438)	
2022-01-05 15:43:09 - INFO - 
 Epoch: 23	Training Loss 0.3789 	Training Prec@1 87.681 	Validation Loss 0.5718 	Validation Prec@1 77.536 	
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:10 - INFO - TRAINING - Epoch: [23][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.4210 (0.4210)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:10 - INFO - EVALUATING - Epoch: [23][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.6270 (0.6270)	Prec@1 75.000 (75.000)	
2022-01-05 15:43:10 - INFO - 
 Epoch: 24	Training Loss 0.3754 	Training Prec@1 87.681 	Validation Loss 0.5907 	Validation Prec@1 76.812 	
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:10 - INFO - TRAINING - Epoch: [24][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3457 (0.3457)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:10 - INFO - EVALUATING - Epoch: [24][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6869 (0.6869)	Prec@1 76.562 (76.562)	
2022-01-05 15:43:10 - INFO - 
 Epoch: 25	Training Loss 0.3718 	Training Prec@1 88.043 	Validation Loss 0.6229 	Validation Prec@1 78.986 	
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:10 - INFO - TRAINING - Epoch: [25][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3984 (0.3984)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:11 - INFO - EVALUATING - Epoch: [25][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6514 (0.6514)	Prec@1 76.562 (76.562)	
2022-01-05 15:43:11 - INFO - 
 Epoch: 26	Training Loss 0.3730 	Training Prec@1 83.514 	Validation Loss 0.5747 	Validation Prec@1 78.986 	
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:11 - INFO - TRAINING - Epoch: [26][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.4069 (0.4069)	Prec@1 84.375 (84.375)	
2022-01-05 15:43:11 - INFO - EVALUATING - Epoch: [26][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.6268 (0.6268)	Prec@1 75.000 (75.000)	
2022-01-05 15:43:11 - INFO - 
 Epoch: 27	Training Loss 0.3695 	Training Prec@1 83.877 	Validation Loss 0.5762 	Validation Prec@1 77.536 	
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:11 - INFO - TRAINING - Epoch: [27][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.4401 (0.4401)	Prec@1 84.375 (84.375)	
2022-01-05 15:43:11 - INFO - EVALUATING - Epoch: [27][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.7951 (0.7951)	Prec@1 73.438 (73.438)	
2022-01-05 15:43:11 - INFO - 
 Epoch: 28	Training Loss 0.3575 	Training Prec@1 87.500 	Validation Loss 0.6765 	Validation Prec@1 76.812 	
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:12 - INFO - TRAINING - Epoch: [28][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.1358 (0.1358)	Prec@1 96.875 (96.875)	
2022-01-05 15:43:12 - INFO - EVALUATING - Epoch: [28][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6952 (0.6952)	Prec@1 73.438 (73.438)	
2022-01-05 15:43:12 - INFO - 
 Epoch: 29	Training Loss 0.3280 	Training Prec@1 88.949 	Validation Loss 0.6144 	Validation Prec@1 76.812 	
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:12 - INFO - TRAINING - Epoch: [29][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1828 (0.1828)	Prec@1 95.312 (95.312)	
2022-01-05 15:43:12 - INFO - EVALUATING - Epoch: [29][0/3]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.6524 (0.6524)	Prec@1 75.000 (75.000)	
2022-01-05 15:43:12 - INFO - 
 Epoch: 30	Training Loss 0.3718 	Training Prec@1 88.949 	Validation Loss 0.5785 	Validation Prec@1 77.536 	
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:12 - INFO - TRAINING - Epoch: [30][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3113 (0.3113)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:12 - INFO - EVALUATING - Epoch: [30][0/3]	Time 0.148 (0.148)	Data 0.146 (0.146)	Loss 0.7494 (0.7494)	Prec@1 79.688 (79.688)	
2022-01-05 15:43:12 - INFO - 
 Epoch: 31	Training Loss 0.3329 	Training Prec@1 87.138 	Validation Loss 0.6475 	Validation Prec@1 81.159 	
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:13 - INFO - TRAINING - Epoch: [31][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2159 (0.2159)	Prec@1 95.312 (95.312)	
2022-01-05 15:43:13 - INFO - EVALUATING - Epoch: [31][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.9978 (0.9978)	Prec@1 73.438 (73.438)	
2022-01-05 15:43:13 - INFO - 
 Epoch: 32	Training Loss 0.3604 	Training Prec@1 84.420 	Validation Loss 0.8154 	Validation Prec@1 78.986 	
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:13 - INFO - TRAINING - Epoch: [32][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.1852 (0.1852)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:13 - INFO - EVALUATING - Epoch: [32][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8085 (0.8085)	Prec@1 70.312 (70.312)	
2022-01-05 15:43:13 - INFO - 
 Epoch: 33	Training Loss 0.3130 	Training Prec@1 90.761 	Validation Loss 0.6135 	Validation Prec@1 76.812 	
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:13 - INFO - TRAINING - Epoch: [33][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3506 (0.3506)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:14 - INFO - EVALUATING - Epoch: [33][0/3]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.7513 (0.7513)	Prec@1 68.750 (68.750)	
2022-01-05 15:43:14 - INFO - 
 Epoch: 34	Training Loss 0.3710 	Training Prec@1 90.399 	Validation Loss 0.6489 	Validation Prec@1 73.913 	
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:14 - INFO - TRAINING - Epoch: [34][0/9]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.4064 (0.4064)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:14 - INFO - EVALUATING - Epoch: [34][0/3]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.8491 (0.8491)	Prec@1 68.750 (68.750)	
2022-01-05 15:43:14 - INFO - 
 Epoch: 35	Training Loss 0.3306 	Training Prec@1 90.217 	Validation Loss 0.7513 	Validation Prec@1 73.913 	
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:14 - INFO - TRAINING - Epoch: [35][0/9]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.3115 (0.3115)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:14 - INFO - EVALUATING - Epoch: [35][0/3]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.7510 (0.7510)	Prec@1 68.750 (68.750)	
2022-01-05 15:43:14 - INFO - 
 Epoch: 36	Training Loss 0.3190 	Training Prec@1 90.399 	Validation Loss 0.6052 	Validation Prec@1 76.087 	
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:15 - INFO - TRAINING - Epoch: [36][0/9]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.2522 (0.2522)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:15 - INFO - EVALUATING - Epoch: [36][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.2030 (1.2030)	Prec@1 68.750 (68.750)	
2022-01-05 15:43:15 - INFO - 
 Epoch: 37	Training Loss 0.3143 	Training Prec@1 90.942 	Validation Loss 0.8815 	Validation Prec@1 76.087 	
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:15 - INFO - TRAINING - Epoch: [37][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.6055 (0.6055)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:15 - INFO - EVALUATING - Epoch: [37][0/3]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.8692 (0.8692)	Prec@1 70.312 (70.312)	
2022-01-05 15:43:15 - INFO - 
 Epoch: 38	Training Loss 0.3838 	Training Prec@1 89.493 	Validation Loss 0.7047 	Validation Prec@1 76.087 	
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:15 - INFO - TRAINING - Epoch: [38][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3329 (0.3329)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:16 - INFO - EVALUATING - Epoch: [38][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 1.1727 (1.1727)	Prec@1 68.750 (68.750)	
2022-01-05 15:43:16 - INFO - 
 Epoch: 39	Training Loss 0.3180 	Training Prec@1 90.580 	Validation Loss 0.8977 	Validation Prec@1 75.362 	
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:16 - INFO - TRAINING - Epoch: [39][0/9]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.3413 (0.3413)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:16 - INFO - EVALUATING - Epoch: [39][0/3]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.7202 (0.7202)	Prec@1 70.312 (70.312)	
2022-01-05 15:43:16 - INFO - 
 Epoch: 40	Training Loss 0.3503 	Training Prec@1 90.942 	Validation Loss 0.6199 	Validation Prec@1 75.362 	
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:16 - INFO - TRAINING - Epoch: [40][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3771 (0.3771)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:16 - INFO - EVALUATING - Epoch: [40][0/3]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.7212 (0.7212)	Prec@1 70.312 (70.312)	
2022-01-05 15:43:16 - INFO - 
 Epoch: 41	Training Loss 0.3105 	Training Prec@1 90.580 	Validation Loss 0.6197 	Validation Prec@1 75.362 	
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:16 - INFO - TRAINING - Epoch: [41][0/9]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.5013 (0.5013)	Prec@1 81.250 (81.250)	
2022-01-05 15:43:17 - INFO - EVALUATING - Epoch: [41][0/3]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 1.2724 (1.2724)	Prec@1 71.875 (71.875)	
2022-01-05 15:43:17 - INFO - 
 Epoch: 42	Training Loss 0.3052 	Training Prec@1 91.304 	Validation Loss 1.1370 	Validation Prec@1 75.362 	
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:17 - INFO - TRAINING - Epoch: [42][0/9]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5109 (0.5109)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:17 - INFO - EVALUATING - Epoch: [42][0/3]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.7967 (0.7967)	Prec@1 71.875 (71.875)	
2022-01-05 15:43:17 - INFO - 
 Epoch: 43	Training Loss 0.3380 	Training Prec@1 90.399 	Validation Loss 0.7130 	Validation Prec@1 75.362 	
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:17 - INFO - TRAINING - Epoch: [43][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1891 (0.1891)	Prec@1 95.312 (95.312)	
2022-01-05 15:43:17 - INFO - EVALUATING - Epoch: [43][0/3]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.6935 (0.6935)	Prec@1 71.875 (71.875)	
2022-01-05 15:43:17 - INFO - 
 Epoch: 44	Training Loss 0.3275 	Training Prec@1 90.036 	Validation Loss 0.6197 	Validation Prec@1 75.362 	
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:18 - INFO - TRAINING - Epoch: [44][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3134 (0.3134)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:18 - INFO - EVALUATING - Epoch: [44][0/3]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.8511 (0.8511)	Prec@1 73.438 (73.438)	
2022-01-05 15:43:18 - INFO - 
 Epoch: 45	Training Loss 0.3590 	Training Prec@1 89.855 	Validation Loss 0.7427 	Validation Prec@1 76.812 	
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:18 - INFO - TRAINING - Epoch: [45][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.4366 (0.4366)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:18 - INFO - EVALUATING - Epoch: [45][0/3]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.0507 (1.0507)	Prec@1 71.875 (71.875)	
2022-01-05 15:43:18 - INFO - 
 Epoch: 46	Training Loss 0.3160 	Training Prec@1 90.942 	Validation Loss 0.8826 	Validation Prec@1 76.812 	
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:18 - INFO - TRAINING - Epoch: [46][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1434 (0.1434)	Prec@1 96.875 (96.875)	
2022-01-05 15:43:19 - INFO - EVALUATING - Epoch: [46][0/3]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6326 (0.6326)	Prec@1 75.000 (75.000)	
2022-01-05 15:43:19 - INFO - 
 Epoch: 47	Training Loss 0.3386 	Training Prec@1 89.674 	Validation Loss 0.5469 	Validation Prec@1 78.986 	
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:19 - INFO - TRAINING - Epoch: [47][0/9]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.2263 (0.2263)	Prec@1 95.312 (95.312)	
2022-01-05 15:43:19 - INFO - EVALUATING - Epoch: [47][0/3]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.6606 (0.6606)	Prec@1 73.438 (73.438)	
2022-01-05 15:43:19 - INFO - 
 Epoch: 48	Training Loss 0.4172 	Training Prec@1 88.768 	Validation Loss 0.5884 	Validation Prec@1 76.812 	
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:19 - INFO - TRAINING - Epoch: [48][0/9]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3527 (0.3527)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:19 - INFO - EVALUATING - Epoch: [48][0/3]	Time 0.166 (0.166)	Data 0.163 (0.163)	Loss 0.5643 (0.5643)	Prec@1 78.125 (78.125)	
2022-01-05 15:43:19 - INFO - 
 Epoch: 49	Training Loss 0.3341 	Training Prec@1 90.761 	Validation Loss 0.5433 	Validation Prec@1 78.986 	
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:20 - INFO - TRAINING - Epoch: [49][0/9]	Time 0.157 (0.157)	Data 0.151 (0.151)	Loss 0.4099 (0.4099)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:20 - INFO - EVALUATING - Epoch: [49][0/3]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.6282 (0.6282)	Prec@1 75.000 (75.000)	
2022-01-05 15:43:20 - INFO - 
 Epoch: 50	Training Loss 0.3583 	Training Prec@1 89.674 	Validation Loss 0.5739 	Validation Prec@1 77.536 	
