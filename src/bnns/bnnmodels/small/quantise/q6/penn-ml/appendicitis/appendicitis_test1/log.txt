2022-01-29 12:53:51 - INFO - saving to ./results/small/quantise/q6/penn-ml/appendicitis/appendicitis_test1/
2022-01-29 12:53:51 - DEBUG - run arguments: Namespace(config='./configs/config_small.json', data='../../paper_bench/complete/quantise/q6/penn-ml/appendicitis/appendicitis_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/small/quantise/q6/penn-ml/appendicitis/appendicitis_test1/', test='../../paper_bench/cv/test/quantise/q6/penn-ml/appendicitis/appendicitis_test1_data.csv', train='../../paper_bench/cv/train/quantise/q6/penn-ml/appendicitis/appendicitis_train1_data.csv')
2022-01-29 12:53:51 - INFO - creating model mlp_binary
2022-01-29 12:53:51 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [10, 5, 5, 2]}
2022-01-29 12:53:51 - INFO - number of parameters: 567
2022-01-29 12:53:51 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:51 - INFO - TRAINING - Epoch: [0][0/2]	Time 0.255 (0.255)	Data 0.200 (0.200)	Loss 1.5388 (1.5388)	Prec@1 25.000 (25.000)	
2022-01-29 12:53:51 - INFO - EVALUATING - Epoch: [0][0/1]	Time 0.237 (0.237)	Data 0.235 (0.235)	Loss 1.5116 (1.5116)	Prec@1 54.545 (54.545)	
2022-01-29 12:53:51 - INFO - 
 Epoch: 1	Training Loss 1.4470 	Training Prec@1 28.571 	Validation Loss 1.5116 	Validation Prec@1 54.545 	
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:52 - INFO - TRAINING - Epoch: [1][0/2]	Time 0.192 (0.192)	Data 0.188 (0.188)	Loss 1.4488 (1.4488)	Prec@1 40.625 (40.625)	
2022-01-29 12:53:52 - INFO - EVALUATING - Epoch: [1][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.9239 (0.9239)	Prec@1 72.727 (72.727)	
2022-01-29 12:53:52 - INFO - 
 Epoch: 2	Training Loss 1.4529 	Training Prec@1 39.286 	Validation Loss 0.9239 	Validation Prec@1 72.727 	
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:52 - INFO - TRAINING - Epoch: [2][0/2]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 1.1163 (1.1163)	Prec@1 70.312 (70.312)	
2022-01-29 12:53:52 - INFO - EVALUATING - Epoch: [2][0/1]	Time 0.192 (0.192)	Data 0.191 (0.191)	Loss 0.9242 (0.9242)	Prec@1 63.636 (63.636)	
2022-01-29 12:53:52 - INFO - 
 Epoch: 3	Training Loss 1.0959 	Training Prec@1 66.667 	Validation Loss 0.9242 	Validation Prec@1 63.636 	
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:52 - INFO - TRAINING - Epoch: [3][0/2]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 1.0799 (1.0799)	Prec@1 57.812 (57.812)	
2022-01-29 12:53:53 - INFO - EVALUATING - Epoch: [3][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.9082 (0.9082)	Prec@1 63.636 (63.636)	
2022-01-29 12:53:53 - INFO - 
 Epoch: 4	Training Loss 1.0638 	Training Prec@1 58.333 	Validation Loss 0.9082 	Validation Prec@1 63.636 	
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:53 - INFO - TRAINING - Epoch: [4][0/2]	Time 0.192 (0.192)	Data 0.188 (0.188)	Loss 0.9004 (0.9004)	Prec@1 64.062 (64.062)	
2022-01-29 12:53:53 - INFO - EVALUATING - Epoch: [4][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 1.1896 (1.1896)	Prec@1 63.636 (63.636)	
2022-01-29 12:53:53 - INFO - 
 Epoch: 5	Training Loss 0.8639 	Training Prec@1 65.476 	Validation Loss 1.1896 	Validation Prec@1 63.636 	
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:53 - INFO - TRAINING - Epoch: [5][0/2]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 1.1185 (1.1185)	Prec@1 56.250 (56.250)	
2022-01-29 12:53:53 - INFO - EVALUATING - Epoch: [5][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.7586 (0.7586)	Prec@1 68.182 (68.182)	
2022-01-29 12:53:53 - INFO - 
 Epoch: 6	Training Loss 0.9548 	Training Prec@1 63.095 	Validation Loss 0.7586 	Validation Prec@1 68.182 	
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:54 - INFO - TRAINING - Epoch: [6][0/2]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.9907 (0.9907)	Prec@1 56.250 (56.250)	
2022-01-29 12:53:54 - INFO - EVALUATING - Epoch: [6][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.7458 (0.7458)	Prec@1 68.182 (68.182)	
2022-01-29 12:53:54 - INFO - 
 Epoch: 7	Training Loss 0.8697 	Training Prec@1 60.714 	Validation Loss 0.7458 	Validation Prec@1 68.182 	
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:54 - INFO - TRAINING - Epoch: [7][0/2]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.4246 (0.4246)	Prec@1 84.375 (84.375)	
2022-01-29 12:53:54 - INFO - EVALUATING - Epoch: [7][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 1.1955 (1.1955)	Prec@1 59.091 (59.091)	
2022-01-29 12:53:54 - INFO - 
 Epoch: 8	Training Loss 0.7364 	Training Prec@1 73.810 	Validation Loss 1.1955 	Validation Prec@1 59.091 	
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:55 - INFO - TRAINING - Epoch: [8][0/2]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.7985 (0.7985)	Prec@1 67.188 (67.188)	
2022-01-29 12:53:55 - INFO - EVALUATING - Epoch: [8][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.6476 (0.6476)	Prec@1 68.182 (68.182)	
2022-01-29 12:53:55 - INFO - 
 Epoch: 9	Training Loss 0.7498 	Training Prec@1 72.619 	Validation Loss 0.6476 	Validation Prec@1 68.182 	
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:55 - INFO - TRAINING - Epoch: [9][0/2]	Time 0.246 (0.246)	Data 0.243 (0.243)	Loss 0.5856 (0.5856)	Prec@1 87.500 (87.500)	
2022-01-29 12:53:55 - INFO - EVALUATING - Epoch: [9][0/1]	Time 0.239 (0.239)	Data 0.237 (0.237)	Loss 1.0554 (1.0554)	Prec@1 72.727 (72.727)	
2022-01-29 12:53:55 - INFO - 
 Epoch: 10	Training Loss 0.5352 	Training Prec@1 86.905 	Validation Loss 1.0554 	Validation Prec@1 72.727 	
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:55 - INFO - TRAINING - Epoch: [10][0/2]	Time 0.189 (0.189)	Data 0.185 (0.185)	Loss 0.6475 (0.6475)	Prec@1 84.375 (84.375)	
2022-01-29 12:53:56 - INFO - EVALUATING - Epoch: [10][0/1]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 0.2998 (0.2998)	Prec@1 90.909 (90.909)	
2022-01-29 12:53:56 - INFO - 
 Epoch: 11	Training Loss 0.6315 	Training Prec@1 83.333 	Validation Loss 0.2998 	Validation Prec@1 90.909 	
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:56 - INFO - TRAINING - Epoch: [11][0/2]	Time 0.192 (0.192)	Data 0.188 (0.188)	Loss 0.6121 (0.6121)	Prec@1 70.312 (70.312)	
2022-01-29 12:53:56 - INFO - EVALUATING - Epoch: [11][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.6278 (0.6278)	Prec@1 68.182 (68.182)	
2022-01-29 12:53:56 - INFO - 
 Epoch: 12	Training Loss 0.6004 	Training Prec@1 72.619 	Validation Loss 0.6278 	Validation Prec@1 68.182 	
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:56 - INFO - TRAINING - Epoch: [12][0/2]	Time 0.191 (0.191)	Data 0.188 (0.188)	Loss 0.5473 (0.5473)	Prec@1 81.250 (81.250)	
2022-01-29 12:53:57 - INFO - EVALUATING - Epoch: [12][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.8248 (0.8248)	Prec@1 63.636 (63.636)	
2022-01-29 12:53:57 - INFO - 
 Epoch: 13	Training Loss 0.5095 	Training Prec@1 83.333 	Validation Loss 0.8248 	Validation Prec@1 63.636 	
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:57 - INFO - TRAINING - Epoch: [13][0/2]	Time 0.231 (0.231)	Data 0.227 (0.227)	Loss 0.8857 (0.8857)	Prec@1 82.812 (82.812)	
2022-01-29 12:53:57 - INFO - EVALUATING - Epoch: [13][0/1]	Time 0.192 (0.192)	Data 0.190 (0.190)	Loss 0.5112 (0.5112)	Prec@1 68.182 (68.182)	
2022-01-29 12:53:57 - INFO - 
 Epoch: 14	Training Loss 0.8000 	Training Prec@1 83.333 	Validation Loss 0.5112 	Validation Prec@1 68.182 	
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:57 - INFO - TRAINING - Epoch: [14][0/2]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.5393 (0.5393)	Prec@1 79.688 (79.688)	
2022-01-29 12:53:57 - INFO - EVALUATING - Epoch: [14][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.9780 (0.9780)	Prec@1 68.182 (68.182)	
2022-01-29 12:53:57 - INFO - 
 Epoch: 15	Training Loss 0.4781 	Training Prec@1 80.952 	Validation Loss 0.9780 	Validation Prec@1 68.182 	
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:58 - INFO - TRAINING - Epoch: [15][0/2]	Time 0.193 (0.193)	Data 0.190 (0.190)	Loss 0.7504 (0.7504)	Prec@1 65.625 (65.625)	
2022-01-29 12:53:58 - INFO - EVALUATING - Epoch: [15][0/1]	Time 0.189 (0.189)	Data 0.188 (0.188)	Loss 1.0033 (1.0033)	Prec@1 68.182 (68.182)	
2022-01-29 12:53:58 - INFO - 
 Epoch: 16	Training Loss 0.6608 	Training Prec@1 67.857 	Validation Loss 1.0033 	Validation Prec@1 68.182 	
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:58 - INFO - TRAINING - Epoch: [16][0/2]	Time 0.193 (0.193)	Data 0.189 (0.189)	Loss 0.3810 (0.3810)	Prec@1 92.188 (92.188)	
2022-01-29 12:53:58 - INFO - EVALUATING - Epoch: [16][0/1]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 1.6777 (1.6777)	Prec@1 68.182 (68.182)	
2022-01-29 12:53:58 - INFO - 
 Epoch: 17	Training Loss 0.4118 	Training Prec@1 89.286 	Validation Loss 1.6777 	Validation Prec@1 68.182 	
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:58 - INFO - TRAINING - Epoch: [17][0/2]	Time 0.196 (0.196)	Data 0.193 (0.193)	Loss 0.8556 (0.8556)	Prec@1 78.125 (78.125)	
2022-01-29 12:53:59 - INFO - EVALUATING - Epoch: [17][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.6349 (0.6349)	Prec@1 68.182 (68.182)	
2022-01-29 12:53:59 - INFO - 
 Epoch: 18	Training Loss 0.7238 	Training Prec@1 83.333 	Validation Loss 0.6349 	Validation Prec@1 68.182 	
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:59 - INFO - TRAINING - Epoch: [18][0/2]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.5127 (0.5127)	Prec@1 79.688 (79.688)	
2022-01-29 12:53:59 - INFO - EVALUATING - Epoch: [18][0/1]	Time 0.192 (0.192)	Data 0.191 (0.191)	Loss 1.5472 (1.5472)	Prec@1 68.182 (68.182)	
2022-01-29 12:53:59 - INFO - 
 Epoch: 19	Training Loss 0.4092 	Training Prec@1 84.524 	Validation Loss 1.5472 	Validation Prec@1 68.182 	
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:59 - INFO - TRAINING - Epoch: [19][0/2]	Time 0.238 (0.238)	Data 0.235 (0.235)	Loss 0.4509 (0.4509)	Prec@1 84.375 (84.375)	
2022-01-29 12:54:00 - INFO - EVALUATING - Epoch: [19][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.6425 (0.6425)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:00 - INFO - 
 Epoch: 20	Training Loss 0.4797 	Training Prec@1 84.524 	Validation Loss 0.6425 	Validation Prec@1 68.182 	
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:00 - INFO - TRAINING - Epoch: [20][0/2]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.5111 (0.5111)	Prec@1 79.688 (79.688)	
2022-01-29 12:54:00 - INFO - EVALUATING - Epoch: [20][0/1]	Time 0.192 (0.192)	Data 0.190 (0.190)	Loss 0.6437 (0.6437)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:00 - INFO - 
 Epoch: 21	Training Loss 0.4672 	Training Prec@1 83.333 	Validation Loss 0.6437 	Validation Prec@1 68.182 	
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:00 - INFO - TRAINING - Epoch: [21][0/2]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.4520 (0.4520)	Prec@1 84.375 (84.375)	
2022-01-29 12:54:00 - INFO - EVALUATING - Epoch: [21][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.8719 (0.8719)	Prec@1 63.636 (63.636)	
2022-01-29 12:54:00 - INFO - 
 Epoch: 22	Training Loss 0.4262 	Training Prec@1 83.333 	Validation Loss 0.8719 	Validation Prec@1 63.636 	
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:01 - INFO - TRAINING - Epoch: [22][0/2]	Time 0.193 (0.193)	Data 0.189 (0.189)	Loss 0.3577 (0.3577)	Prec@1 82.812 (82.812)	
2022-01-29 12:54:01 - INFO - EVALUATING - Epoch: [22][0/1]	Time 0.192 (0.192)	Data 0.191 (0.191)	Loss 0.4375 (0.4375)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:01 - INFO - 
 Epoch: 23	Training Loss 0.4099 	Training Prec@1 79.762 	Validation Loss 0.4375 	Validation Prec@1 68.182 	
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:01 - INFO - TRAINING - Epoch: [23][0/2]	Time 0.196 (0.196)	Data 0.193 (0.193)	Loss 0.3345 (0.3345)	Prec@1 85.938 (85.938)	
2022-01-29 12:54:01 - INFO - EVALUATING - Epoch: [23][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.3410 (0.3410)	Prec@1 81.818 (81.818)	
2022-01-29 12:54:01 - INFO - 
 Epoch: 24	Training Loss 0.3966 	Training Prec@1 83.333 	Validation Loss 0.3410 	Validation Prec@1 81.818 	
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:02 - INFO - TRAINING - Epoch: [24][0/2]	Time 0.248 (0.248)	Data 0.244 (0.244)	Loss 0.3735 (0.3735)	Prec@1 84.375 (84.375)	
2022-01-29 12:54:02 - INFO - EVALUATING - Epoch: [24][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.4153 (0.4153)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:02 - INFO - 
 Epoch: 25	Training Loss 0.3749 	Training Prec@1 84.524 	Validation Loss 0.4153 	Validation Prec@1 68.182 	
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:02 - INFO - TRAINING - Epoch: [25][0/2]	Time 0.198 (0.198)	Data 0.195 (0.195)	Loss 0.4171 (0.4171)	Prec@1 79.688 (79.688)	
2022-01-29 12:54:02 - INFO - EVALUATING - Epoch: [25][0/1]	Time 0.192 (0.192)	Data 0.191 (0.191)	Loss 0.3669 (0.3669)	Prec@1 81.818 (81.818)	
2022-01-29 12:54:02 - INFO - 
 Epoch: 26	Training Loss 0.4117 	Training Prec@1 77.381 	Validation Loss 0.3669 	Validation Prec@1 81.818 	
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:03 - INFO - TRAINING - Epoch: [26][0/2]	Time 0.242 (0.242)	Data 0.237 (0.237)	Loss 0.3087 (0.3087)	Prec@1 87.500 (87.500)	
2022-01-29 12:54:03 - INFO - EVALUATING - Epoch: [26][0/1]	Time 0.188 (0.188)	Data 0.187 (0.187)	Loss 0.3937 (0.3937)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:03 - INFO - 
 Epoch: 27	Training Loss 0.3694 	Training Prec@1 84.524 	Validation Loss 0.3937 	Validation Prec@1 68.182 	
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:03 - INFO - TRAINING - Epoch: [27][0/2]	Time 0.188 (0.188)	Data 0.184 (0.184)	Loss 0.3412 (0.3412)	Prec@1 85.938 (85.938)	
2022-01-29 12:54:03 - INFO - EVALUATING - Epoch: [27][0/1]	Time 0.194 (0.194)	Data 0.192 (0.192)	Loss 0.5281 (0.5281)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:03 - INFO - 
 Epoch: 28	Training Loss 0.3769 	Training Prec@1 83.333 	Validation Loss 0.5281 	Validation Prec@1 68.182 	
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:03 - INFO - TRAINING - Epoch: [28][0/2]	Time 0.201 (0.201)	Data 0.198 (0.198)	Loss 0.2996 (0.2996)	Prec@1 84.375 (84.375)	
2022-01-29 12:54:04 - INFO - EVALUATING - Epoch: [28][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.3461 (0.3461)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:04 - INFO - 
 Epoch: 29	Training Loss 0.3598 	Training Prec@1 79.762 	Validation Loss 0.3461 	Validation Prec@1 68.182 	
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:04 - INFO - TRAINING - Epoch: [29][0/2]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.3970 (0.3970)	Prec@1 84.375 (84.375)	
2022-01-29 12:54:04 - INFO - EVALUATING - Epoch: [29][0/1]	Time 0.179 (0.179)	Data 0.177 (0.177)	Loss 0.5272 (0.5272)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:04 - INFO - 
 Epoch: 30	Training Loss 0.4222 	Training Prec@1 83.333 	Validation Loss 0.5272 	Validation Prec@1 68.182 	
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:04 - INFO - TRAINING - Epoch: [30][0/2]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.3413 (0.3413)	Prec@1 82.812 (82.812)	
2022-01-29 12:54:04 - INFO - EVALUATING - Epoch: [30][0/1]	Time 0.192 (0.192)	Data 0.190 (0.190)	Loss 0.5168 (0.5168)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:04 - INFO - 
 Epoch: 31	Training Loss 0.3442 	Training Prec@1 80.952 	Validation Loss 0.5168 	Validation Prec@1 68.182 	
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:05 - INFO - TRAINING - Epoch: [31][0/2]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.3780 (0.3780)	Prec@1 84.375 (84.375)	
2022-01-29 12:54:05 - INFO - EVALUATING - Epoch: [31][0/1]	Time 0.192 (0.192)	Data 0.191 (0.191)	Loss 0.2993 (0.2993)	Prec@1 86.364 (86.364)	
2022-01-29 12:54:05 - INFO - 
 Epoch: 32	Training Loss 0.3668 	Training Prec@1 83.333 	Validation Loss 0.2993 	Validation Prec@1 86.364 	
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:05 - INFO - TRAINING - Epoch: [32][0/2]	Time 0.252 (0.252)	Data 0.249 (0.249)	Loss 0.5054 (0.5054)	Prec@1 71.875 (71.875)	
2022-01-29 12:54:05 - INFO - EVALUATING - Epoch: [32][0/1]	Time 0.237 (0.237)	Data 0.235 (0.235)	Loss 1.0652 (1.0652)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:05 - INFO - 
 Epoch: 33	Training Loss 0.4194 	Training Prec@1 77.381 	Validation Loss 1.0652 	Validation Prec@1 68.182 	
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:06 - INFO - TRAINING - Epoch: [33][0/2]	Time 0.193 (0.193)	Data 0.189 (0.189)	Loss 0.3648 (0.3648)	Prec@1 85.938 (85.938)	
2022-01-29 12:54:06 - INFO - EVALUATING - Epoch: [33][0/1]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 0.4811 (0.4811)	Prec@1 77.273 (77.273)	
2022-01-29 12:54:06 - INFO - 
 Epoch: 34	Training Loss 0.3518 	Training Prec@1 85.714 	Validation Loss 0.4811 	Validation Prec@1 77.273 	
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:06 - INFO - TRAINING - Epoch: [34][0/2]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.4172 (0.4172)	Prec@1 73.438 (73.438)	
2022-01-29 12:54:06 - INFO - EVALUATING - Epoch: [34][0/1]	Time 0.188 (0.188)	Data 0.187 (0.187)	Loss 0.6083 (0.6083)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:06 - INFO - 
 Epoch: 35	Training Loss 0.4274 	Training Prec@1 75.000 	Validation Loss 0.6083 	Validation Prec@1 68.182 	
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:07 - INFO - TRAINING - Epoch: [35][0/2]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.2719 (0.2719)	Prec@1 90.625 (90.625)	
2022-01-29 12:54:07 - INFO - EVALUATING - Epoch: [35][0/1]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.4095 (0.4095)	Prec@1 90.909 (90.909)	
2022-01-29 12:54:07 - INFO - 
 Epoch: 36	Training Loss 0.2786 	Training Prec@1 90.476 	Validation Loss 0.4095 	Validation Prec@1 90.909 	
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:07 - INFO - TRAINING - Epoch: [36][0/2]	Time 0.194 (0.194)	Data 0.190 (0.190)	Loss 0.3409 (0.3409)	Prec@1 89.062 (89.062)	
2022-01-29 12:54:07 - INFO - EVALUATING - Epoch: [36][0/1]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 1.0663 (1.0663)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:07 - INFO - 
 Epoch: 37	Training Loss 0.3086 	Training Prec@1 90.476 	Validation Loss 1.0663 	Validation Prec@1 68.182 	
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:07 - INFO - TRAINING - Epoch: [37][0/2]	Time 0.199 (0.199)	Data 0.195 (0.195)	Loss 0.3371 (0.3371)	Prec@1 85.938 (85.938)	
2022-01-29 12:54:08 - INFO - EVALUATING - Epoch: [37][0/1]	Time 0.197 (0.197)	Data 0.196 (0.196)	Loss 0.5038 (0.5038)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:08 - INFO - 
 Epoch: 38	Training Loss 0.3353 	Training Prec@1 85.714 	Validation Loss 0.5038 	Validation Prec@1 68.182 	
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:08 - INFO - TRAINING - Epoch: [38][0/2]	Time 0.195 (0.195)	Data 0.191 (0.191)	Loss 0.3468 (0.3468)	Prec@1 87.500 (87.500)	
2022-01-29 12:54:08 - INFO - EVALUATING - Epoch: [38][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.6494 (0.6494)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:08 - INFO - 
 Epoch: 39	Training Loss 0.3423 	Training Prec@1 89.286 	Validation Loss 0.6494 	Validation Prec@1 68.182 	
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:08 - INFO - TRAINING - Epoch: [39][0/2]	Time 0.241 (0.241)	Data 0.238 (0.238)	Loss 0.4864 (0.4864)	Prec@1 81.250 (81.250)	
2022-01-29 12:54:09 - INFO - EVALUATING - Epoch: [39][0/1]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.6859 (0.6859)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:09 - INFO - 
 Epoch: 40	Training Loss 0.4358 	Training Prec@1 83.333 	Validation Loss 0.6859 	Validation Prec@1 68.182 	
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:09 - INFO - TRAINING - Epoch: [40][0/2]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.5020 (0.5020)	Prec@1 82.812 (82.812)	
2022-01-29 12:54:09 - INFO - EVALUATING - Epoch: [40][0/1]	Time 0.234 (0.234)	Data 0.232 (0.232)	Loss 0.6506 (0.6506)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:09 - INFO - 
 Epoch: 41	Training Loss 0.4805 	Training Prec@1 82.143 	Validation Loss 0.6506 	Validation Prec@1 68.182 	
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:09 - INFO - TRAINING - Epoch: [41][0/2]	Time 0.246 (0.246)	Data 0.242 (0.242)	Loss 0.4466 (0.4466)	Prec@1 84.375 (84.375)	
2022-01-29 12:54:10 - INFO - EVALUATING - Epoch: [41][0/1]	Time 0.241 (0.241)	Data 0.239 (0.239)	Loss 0.5074 (0.5074)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:10 - INFO - 
 Epoch: 42	Training Loss 0.4241 	Training Prec@1 85.714 	Validation Loss 0.5074 	Validation Prec@1 68.182 	
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:10 - INFO - TRAINING - Epoch: [42][0/2]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.3129 (0.3129)	Prec@1 82.812 (82.812)	
2022-01-29 12:54:10 - INFO - EVALUATING - Epoch: [42][0/1]	Time 0.188 (0.188)	Data 0.186 (0.186)	Loss 0.4806 (0.4806)	Prec@1 77.273 (77.273)	
2022-01-29 12:54:10 - INFO - 
 Epoch: 43	Training Loss 0.2860 	Training Prec@1 84.524 	Validation Loss 0.4806 	Validation Prec@1 77.273 	
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:10 - INFO - TRAINING - Epoch: [43][0/2]	Time 0.193 (0.193)	Data 0.189 (0.189)	Loss 0.3598 (0.3598)	Prec@1 78.125 (78.125)	
2022-01-29 12:54:10 - INFO - EVALUATING - Epoch: [43][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.3045 (0.3045)	Prec@1 95.455 (95.455)	
2022-01-29 12:54:11 - INFO - 
 Epoch: 44	Training Loss 0.3617 	Training Prec@1 78.571 	Validation Loss 0.3045 	Validation Prec@1 95.455 	
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:11 - INFO - TRAINING - Epoch: [44][0/2]	Time 0.204 (0.204)	Data 0.200 (0.200)	Loss 0.3191 (0.3191)	Prec@1 89.062 (89.062)	
2022-01-29 12:54:11 - INFO - EVALUATING - Epoch: [44][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.4888 (0.4888)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:11 - INFO - 
 Epoch: 45	Training Loss 0.3210 	Training Prec@1 88.095 	Validation Loss 0.4888 	Validation Prec@1 68.182 	
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:11 - INFO - TRAINING - Epoch: [45][0/2]	Time 0.198 (0.198)	Data 0.194 (0.194)	Loss 0.2810 (0.2810)	Prec@1 89.062 (89.062)	
2022-01-29 12:54:11 - INFO - EVALUATING - Epoch: [45][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.5343 (0.5343)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:11 - INFO - 
 Epoch: 46	Training Loss 0.3407 	Training Prec@1 83.333 	Validation Loss 0.5343 	Validation Prec@1 68.182 	
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:12 - INFO - TRAINING - Epoch: [46][0/2]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.2615 (0.2615)	Prec@1 89.062 (89.062)	
2022-01-29 12:54:12 - INFO - EVALUATING - Epoch: [46][0/1]	Time 0.234 (0.234)	Data 0.232 (0.232)	Loss 0.4897 (0.4897)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:12 - INFO - 
 Epoch: 47	Training Loss 0.3539 	Training Prec@1 80.952 	Validation Loss 0.4897 	Validation Prec@1 68.182 	
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:12 - INFO - TRAINING - Epoch: [47][0/2]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.2907 (0.2907)	Prec@1 82.812 (82.812)	
2022-01-29 12:54:12 - INFO - EVALUATING - Epoch: [47][0/1]	Time 0.192 (0.192)	Data 0.190 (0.190)	Loss 0.7060 (0.7060)	Prec@1 68.182 (68.182)	
2022-01-29 12:54:12 - INFO - 
 Epoch: 48	Training Loss 0.3392 	Training Prec@1 83.333 	Validation Loss 0.7060 	Validation Prec@1 68.182 	
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:13 - INFO - TRAINING - Epoch: [48][0/2]	Time 0.196 (0.196)	Data 0.193 (0.193)	Loss 0.3586 (0.3586)	Prec@1 84.375 (84.375)	
2022-01-29 12:54:13 - INFO - EVALUATING - Epoch: [48][0/1]	Time 0.197 (0.197)	Data 0.196 (0.196)	Loss 0.4315 (0.4315)	Prec@1 81.818 (81.818)	
2022-01-29 12:54:13 - INFO - 
 Epoch: 49	Training Loss 0.3892 	Training Prec@1 84.524 	Validation Loss 0.4315 	Validation Prec@1 81.818 	
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:13 - INFO - TRAINING - Epoch: [49][0/2]	Time 0.189 (0.189)	Data 0.185 (0.185)	Loss 0.4526 (0.4526)	Prec@1 68.750 (68.750)	
2022-01-29 12:54:13 - INFO - EVALUATING - Epoch: [49][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.3531 (0.3531)	Prec@1 90.909 (90.909)	
2022-01-29 12:54:13 - INFO - 
 Epoch: 50	Training Loss 0.4167 	Training Prec@1 71.429 	Validation Loss 0.3531 	Validation Prec@1 90.909 	
