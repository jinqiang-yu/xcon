2022-01-05 15:43:29 - INFO - saving to ./results/small/quantise/q6/penn-ml/heart-h/heart-h_test1/
2022-01-05 15:43:29 - DEBUG - run arguments: Namespace(config='./configs/config_small.json', data='../../paper_bench/complete/quantise/q6/penn-ml/heart-h/heart-h_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/small/quantise/q6/penn-ml/heart-h/heart-h_test1/', test='../../paper_bench/cv/test/quantise/q6/penn-ml/heart-h/heart-h_test1_data.csv', train='../../paper_bench/cv/train/quantise/q6/penn-ml/heart-h/heart-h_train1_data.csv')
2022-01-05 15:43:29 - INFO - creating model mlp_binary
2022-01-05 15:43:29 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [10, 5, 5, 2]}
2022-01-05 15:43:29 - INFO - number of parameters: 707
2022-01-05 15:43:29 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-05 15:43:29 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:29 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:29 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:30 - INFO - TRAINING - Epoch: [0][0/4]	Time 0.154 (0.154)	Data 0.146 (0.146)	Loss 1.7815 (1.7815)	Prec@1 53.125 (53.125)	
2022-01-05 15:43:30 - INFO - EVALUATING - Epoch: [0][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.8224 (0.8224)	Prec@1 66.102 (66.102)	
2022-01-05 15:43:30 - INFO - 
 Epoch: 1	Training Loss 1.4608 	Training Prec@1 56.170 	Validation Loss 0.8224 	Validation Prec@1 66.102 	
2022-01-05 15:43:30 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:30 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:30 - INFO - TRAINING - Epoch: [1][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.9362 (0.9362)	Prec@1 75.000 (75.000)	
2022-01-05 15:43:30 - INFO - EVALUATING - Epoch: [1][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.0779 (1.0779)	Prec@1 52.542 (52.542)	
2022-01-05 15:43:30 - INFO - 
 Epoch: 2	Training Loss 0.9974 	Training Prec@1 64.255 	Validation Loss 1.0779 	Validation Prec@1 52.542 	
2022-01-05 15:43:30 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:30 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:30 - INFO - TRAINING - Epoch: [2][0/4]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 0.9937 (0.9937)	Prec@1 51.562 (51.562)	
2022-01-05 15:43:30 - INFO - EVALUATING - Epoch: [2][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 1.1086 (1.1086)	Prec@1 67.797 (67.797)	
2022-01-05 15:43:30 - INFO - 
 Epoch: 3	Training Loss 0.9029 	Training Prec@1 65.532 	Validation Loss 1.1086 	Validation Prec@1 67.797 	
2022-01-05 15:43:30 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:30 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:31 - INFO - TRAINING - Epoch: [3][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3697 (0.3697)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:31 - INFO - EVALUATING - Epoch: [3][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.7444 (0.7444)	Prec@1 45.763 (45.763)	
2022-01-05 15:43:31 - INFO - 
 Epoch: 4	Training Loss 0.8774 	Training Prec@1 74.468 	Validation Loss 0.7444 	Validation Prec@1 45.763 	
2022-01-05 15:43:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:31 - INFO - TRAINING - Epoch: [4][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.6739 (0.6739)	Prec@1 57.812 (57.812)	
2022-01-05 15:43:31 - INFO - EVALUATING - Epoch: [4][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.1716 (1.1716)	Prec@1 66.102 (66.102)	
2022-01-05 15:43:31 - INFO - 
 Epoch: 5	Training Loss 0.6964 	Training Prec@1 73.617 	Validation Loss 1.1716 	Validation Prec@1 66.102 	
2022-01-05 15:43:31 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:31 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:31 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:31 - INFO - TRAINING - Epoch: [5][0/4]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.3478 (0.3478)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:31 - INFO - EVALUATING - Epoch: [5][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.0829 (1.0829)	Prec@1 67.797 (67.797)	
2022-01-05 15:43:31 - INFO - 
 Epoch: 6	Training Loss 0.5799 	Training Prec@1 76.170 	Validation Loss 1.0829 	Validation Prec@1 67.797 	
2022-01-05 15:43:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:32 - INFO - TRAINING - Epoch: [6][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.4766 (0.4766)	Prec@1 82.812 (82.812)	
2022-01-05 15:43:32 - INFO - EVALUATING - Epoch: [6][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.4038 (1.4038)	Prec@1 69.492 (69.492)	
2022-01-05 15:43:32 - INFO - 
 Epoch: 7	Training Loss 0.5757 	Training Prec@1 76.170 	Validation Loss 1.4038 	Validation Prec@1 69.492 	
2022-01-05 15:43:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:32 - INFO - TRAINING - Epoch: [7][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.8688 (0.8688)	Prec@1 81.250 (81.250)	
2022-01-05 15:43:32 - INFO - EVALUATING - Epoch: [7][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.2246 (1.2246)	Prec@1 66.102 (66.102)	
2022-01-05 15:43:32 - INFO - 
 Epoch: 8	Training Loss 0.6855 	Training Prec@1 78.298 	Validation Loss 1.2246 	Validation Prec@1 66.102 	
2022-01-05 15:43:32 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:32 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:32 - INFO - TRAINING - Epoch: [8][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.7552 (0.7552)	Prec@1 81.250 (81.250)	
2022-01-05 15:43:33 - INFO - EVALUATING - Epoch: [8][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.4133 (1.4133)	Prec@1 74.576 (74.576)	
2022-01-05 15:43:33 - INFO - 
 Epoch: 9	Training Loss 0.7766 	Training Prec@1 75.319 	Validation Loss 1.4133 	Validation Prec@1 74.576 	
2022-01-05 15:43:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:33 - INFO - TRAINING - Epoch: [9][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 1.3217 (1.3217)	Prec@1 76.562 (76.562)	
2022-01-05 15:43:33 - INFO - EVALUATING - Epoch: [9][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.0824 (1.0824)	Prec@1 71.186 (71.186)	
2022-01-05 15:43:33 - INFO - 
 Epoch: 10	Training Loss 0.8208 	Training Prec@1 76.170 	Validation Loss 1.0824 	Validation Prec@1 71.186 	
2022-01-05 15:43:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:33 - INFO - TRAINING - Epoch: [10][0/4]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 1.0441 (1.0441)	Prec@1 70.312 (70.312)	
2022-01-05 15:43:33 - INFO - EVALUATING - Epoch: [10][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.5456 (0.5456)	Prec@1 83.051 (83.051)	
2022-01-05 15:43:33 - INFO - 
 Epoch: 11	Training Loss 0.7598 	Training Prec@1 73.191 	Validation Loss 0.5456 	Validation Prec@1 83.051 	
2022-01-05 15:43:33 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:33 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:33 - INFO - TRAINING - Epoch: [11][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4326 (0.4326)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:34 - INFO - EVALUATING - Epoch: [11][0/1]	Time 0.148 (0.148)	Data 0.146 (0.146)	Loss 0.7128 (0.7128)	Prec@1 76.271 (76.271)	
2022-01-05 15:43:34 - INFO - 
 Epoch: 12	Training Loss 0.7013 	Training Prec@1 72.766 	Validation Loss 0.7128 	Validation Prec@1 76.271 	
2022-01-05 15:43:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:34 - INFO - TRAINING - Epoch: [12][0/4]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.7641 (0.7641)	Prec@1 84.375 (84.375)	
2022-01-05 15:43:34 - INFO - EVALUATING - Epoch: [12][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 1.2518 (1.2518)	Prec@1 66.102 (66.102)	
2022-01-05 15:43:34 - INFO - 
 Epoch: 13	Training Loss 0.6273 	Training Prec@1 78.298 	Validation Loss 1.2518 	Validation Prec@1 66.102 	
2022-01-05 15:43:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:34 - INFO - TRAINING - Epoch: [13][0/4]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.5620 (0.5620)	Prec@1 82.812 (82.812)	
2022-01-05 15:43:34 - INFO - EVALUATING - Epoch: [13][0/1]	Time 0.149 (0.149)	Data 0.147 (0.147)	Loss 0.6709 (0.6709)	Prec@1 69.492 (69.492)	
2022-01-05 15:43:34 - INFO - 
 Epoch: 14	Training Loss 0.5472 	Training Prec@1 84.255 	Validation Loss 0.6709 	Validation Prec@1 69.492 	
2022-01-05 15:43:34 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:34 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:34 - INFO - TRAINING - Epoch: [14][0/4]	Time 0.161 (0.161)	Data 0.155 (0.155)	Loss 0.3768 (0.3768)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:35 - INFO - EVALUATING - Epoch: [14][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.2339 (1.2339)	Prec@1 79.661 (79.661)	
2022-01-05 15:43:35 - INFO - 
 Epoch: 15	Training Loss 0.4879 	Training Prec@1 83.404 	Validation Loss 1.2339 	Validation Prec@1 79.661 	
2022-01-05 15:43:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:35 - INFO - TRAINING - Epoch: [15][0/4]	Time 0.154 (0.154)	Data 0.149 (0.149)	Loss 0.2771 (0.2771)	Prec@1 92.188 (92.188)	
2022-01-05 15:43:35 - INFO - EVALUATING - Epoch: [15][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.9951 (0.9951)	Prec@1 69.492 (69.492)	
2022-01-05 15:43:35 - INFO - 
 Epoch: 16	Training Loss 0.4310 	Training Prec@1 87.234 	Validation Loss 0.9951 	Validation Prec@1 69.492 	
2022-01-05 15:43:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:35 - INFO - TRAINING - Epoch: [16][0/4]	Time 0.155 (0.155)	Data 0.150 (0.150)	Loss 0.6409 (0.6409)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:35 - INFO - EVALUATING - Epoch: [16][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.0193 (1.0193)	Prec@1 77.966 (77.966)	
2022-01-05 15:43:35 - INFO - 
 Epoch: 17	Training Loss 0.7660 	Training Prec@1 77.447 	Validation Loss 1.0193 	Validation Prec@1 77.966 	
2022-01-05 15:43:35 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:35 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:35 - INFO - TRAINING - Epoch: [17][0/4]	Time 0.152 (0.152)	Data 0.145 (0.145)	Loss 0.6986 (0.6986)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:36 - INFO - EVALUATING - Epoch: [17][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.9666 (0.9666)	Prec@1 64.407 (64.407)	
2022-01-05 15:43:36 - INFO - 
 Epoch: 18	Training Loss 0.5736 	Training Prec@1 85.106 	Validation Loss 0.9666 	Validation Prec@1 64.407 	
2022-01-05 15:43:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:36 - INFO - TRAINING - Epoch: [18][0/4]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.3772 (0.3772)	Prec@1 82.812 (82.812)	
2022-01-05 15:43:36 - INFO - EVALUATING - Epoch: [18][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.7832 (0.7832)	Prec@1 67.797 (67.797)	
2022-01-05 15:43:36 - INFO - 
 Epoch: 19	Training Loss 0.5160 	Training Prec@1 84.255 	Validation Loss 0.7832 	Validation Prec@1 67.797 	
2022-01-05 15:43:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:36 - INFO - TRAINING - Epoch: [19][0/4]	Time 0.155 (0.155)	Data 0.149 (0.149)	Loss 0.7200 (0.7200)	Prec@1 64.062 (64.062)	
2022-01-05 15:43:36 - INFO - EVALUATING - Epoch: [19][0/1]	Time 0.170 (0.170)	Data 0.168 (0.168)	Loss 0.9546 (0.9546)	Prec@1 71.186 (71.186)	
2022-01-05 15:43:36 - INFO - 
 Epoch: 20	Training Loss 0.5320 	Training Prec@1 80.851 	Validation Loss 0.9546 	Validation Prec@1 71.186 	
2022-01-05 15:43:36 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:36 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:36 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:37 - INFO - TRAINING - Epoch: [20][0/4]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.3620 (0.3620)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:37 - INFO - EVALUATING - Epoch: [20][0/1]	Time 0.148 (0.148)	Data 0.146 (0.146)	Loss 1.4151 (1.4151)	Prec@1 69.492 (69.492)	
2022-01-05 15:43:37 - INFO - 
 Epoch: 21	Training Loss 0.5077 	Training Prec@1 88.085 	Validation Loss 1.4151 	Validation Prec@1 69.492 	
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:37 - INFO - TRAINING - Epoch: [21][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2778 (0.2778)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:37 - INFO - EVALUATING - Epoch: [21][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.1615 (1.1615)	Prec@1 71.186 (71.186)	
2022-01-05 15:43:37 - INFO - 
 Epoch: 22	Training Loss 0.4366 	Training Prec@1 90.638 	Validation Loss 1.1615 	Validation Prec@1 71.186 	
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:37 - INFO - TRAINING - Epoch: [22][0/4]	Time 0.132 (0.132)	Data 0.127 (0.127)	Loss 0.6860 (0.6860)	Prec@1 84.375 (84.375)	
2022-01-05 15:43:37 - INFO - EVALUATING - Epoch: [22][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.0714 (1.0714)	Prec@1 69.492 (69.492)	
2022-01-05 15:43:37 - INFO - 
 Epoch: 23	Training Loss 0.4048 	Training Prec@1 90.638 	Validation Loss 1.0714 	Validation Prec@1 69.492 	
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:37 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:38 - INFO - TRAINING - Epoch: [23][0/4]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.3563 (0.3563)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:38 - INFO - EVALUATING - Epoch: [23][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.9907 (0.9907)	Prec@1 71.186 (71.186)	
2022-01-05 15:43:38 - INFO - 
 Epoch: 24	Training Loss 0.3053 	Training Prec@1 91.915 	Validation Loss 0.9907 	Validation Prec@1 71.186 	
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:38 - INFO - TRAINING - Epoch: [24][0/4]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.3953 (0.3953)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:38 - INFO - EVALUATING - Epoch: [24][0/1]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.5551 (0.5551)	Prec@1 72.881 (72.881)	
2022-01-05 15:43:38 - INFO - 
 Epoch: 25	Training Loss 0.3199 	Training Prec@1 91.064 	Validation Loss 0.5551 	Validation Prec@1 72.881 	
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:38 - INFO - TRAINING - Epoch: [25][0/4]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.4423 (0.4423)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:38 - INFO - EVALUATING - Epoch: [25][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.0289 (1.0289)	Prec@1 69.492 (69.492)	
2022-01-05 15:43:38 - INFO - 
 Epoch: 26	Training Loss 0.4622 	Training Prec@1 86.809 	Validation Loss 1.0289 	Validation Prec@1 69.492 	
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:38 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:39 - INFO - TRAINING - Epoch: [26][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.2814 (0.2814)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:39 - INFO - EVALUATING - Epoch: [26][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.0097 (1.0097)	Prec@1 69.492 (69.492)	
2022-01-05 15:43:39 - INFO - 
 Epoch: 27	Training Loss 0.2862 	Training Prec@1 91.064 	Validation Loss 1.0097 	Validation Prec@1 69.492 	
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:39 - INFO - TRAINING - Epoch: [27][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3693 (0.3693)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:39 - INFO - EVALUATING - Epoch: [27][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.8510 (0.8510)	Prec@1 72.881 (72.881)	
2022-01-05 15:43:39 - INFO - 
 Epoch: 28	Training Loss 0.4279 	Training Prec@1 86.383 	Validation Loss 0.8510 	Validation Prec@1 72.881 	
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:39 - INFO - TRAINING - Epoch: [28][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.1677 (0.1677)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:39 - INFO - EVALUATING - Epoch: [28][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.8026 (0.8026)	Prec@1 74.576 (74.576)	
2022-01-05 15:43:39 - INFO - 
 Epoch: 29	Training Loss 0.2544 	Training Prec@1 92.766 	Validation Loss 0.8026 	Validation Prec@1 74.576 	
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:39 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:40 - INFO - TRAINING - Epoch: [29][0/4]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.4223 (0.4223)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:40 - INFO - EVALUATING - Epoch: [29][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.6739 (0.6739)	Prec@1 72.881 (72.881)	
2022-01-05 15:43:40 - INFO - 
 Epoch: 30	Training Loss 0.2792 	Training Prec@1 91.489 	Validation Loss 0.6739 	Validation Prec@1 72.881 	
2022-01-05 15:43:40 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:40 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:40 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:40 - INFO - TRAINING - Epoch: [30][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2696 (0.2696)	Prec@1 92.188 (92.188)	
2022-01-05 15:43:40 - INFO - EVALUATING - Epoch: [30][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.9060 (0.9060)	Prec@1 72.881 (72.881)	
2022-01-05 15:43:40 - INFO - 
 Epoch: 31	Training Loss 0.3960 	Training Prec@1 88.511 	Validation Loss 0.9060 	Validation Prec@1 72.881 	
2022-01-05 15:43:40 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:40 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:40 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:40 - INFO - TRAINING - Epoch: [31][0/4]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.1156 (0.1156)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:41 - INFO - EVALUATING - Epoch: [31][0/1]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.9058 (0.9058)	Prec@1 72.881 (72.881)	
2022-01-05 15:43:41 - INFO - 
 Epoch: 32	Training Loss 0.3410 	Training Prec@1 89.787 	Validation Loss 0.9058 	Validation Prec@1 72.881 	
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:41 - INFO - TRAINING - Epoch: [32][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.2685 (0.2685)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:41 - INFO - EVALUATING - Epoch: [32][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.9072 (0.9072)	Prec@1 72.881 (72.881)	
2022-01-05 15:43:41 - INFO - 
 Epoch: 33	Training Loss 0.3462 	Training Prec@1 88.085 	Validation Loss 0.9072 	Validation Prec@1 72.881 	
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:41 - INFO - TRAINING - Epoch: [33][0/4]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.3169 (0.3169)	Prec@1 92.188 (92.188)	
2022-01-05 15:43:41 - INFO - EVALUATING - Epoch: [33][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.6925 (0.6925)	Prec@1 71.186 (71.186)	
2022-01-05 15:43:41 - INFO - 
 Epoch: 34	Training Loss 0.3083 	Training Prec@1 90.638 	Validation Loss 0.6925 	Validation Prec@1 71.186 	
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:41 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:41 - INFO - TRAINING - Epoch: [34][0/4]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.2575 (0.2575)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:42 - INFO - EVALUATING - Epoch: [34][0/1]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.9598 (0.9598)	Prec@1 71.186 (71.186)	
2022-01-05 15:43:42 - INFO - 
 Epoch: 35	Training Loss 0.3414 	Training Prec@1 88.511 	Validation Loss 0.9598 	Validation Prec@1 71.186 	
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:42 - INFO - TRAINING - Epoch: [35][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3183 (0.3183)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:42 - INFO - EVALUATING - Epoch: [35][0/1]	Time 0.150 (0.150)	Data 0.148 (0.148)	Loss 0.7306 (0.7306)	Prec@1 72.881 (72.881)	
2022-01-05 15:43:42 - INFO - 
 Epoch: 36	Training Loss 0.2988 	Training Prec@1 90.213 	Validation Loss 0.7306 	Validation Prec@1 72.881 	
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:42 - INFO - TRAINING - Epoch: [36][0/4]	Time 0.160 (0.160)	Data 0.155 (0.155)	Loss 0.3115 (0.3115)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:42 - INFO - EVALUATING - Epoch: [36][0/1]	Time 0.150 (0.150)	Data 0.147 (0.147)	Loss 0.6124 (0.6124)	Prec@1 69.492 (69.492)	
2022-01-05 15:43:42 - INFO - 
 Epoch: 37	Training Loss 0.3644 	Training Prec@1 88.511 	Validation Loss 0.6124 	Validation Prec@1 69.492 	
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:42 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:43 - INFO - TRAINING - Epoch: [37][0/4]	Time 0.155 (0.155)	Data 0.148 (0.148)	Loss 0.3404 (0.3404)	Prec@1 92.188 (92.188)	
2022-01-05 15:43:43 - INFO - EVALUATING - Epoch: [37][0/1]	Time 0.149 (0.149)	Data 0.147 (0.147)	Loss 0.6161 (0.6161)	Prec@1 67.797 (67.797)	
2022-01-05 15:43:43 - INFO - 
 Epoch: 38	Training Loss 0.3802 	Training Prec@1 87.234 	Validation Loss 0.6161 	Validation Prec@1 67.797 	
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:43 - INFO - TRAINING - Epoch: [38][0/4]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.2805 (0.2805)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:43 - INFO - EVALUATING - Epoch: [38][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 0.8092 (0.8092)	Prec@1 74.576 (74.576)	
2022-01-05 15:43:43 - INFO - 
 Epoch: 39	Training Loss 0.3346 	Training Prec@1 89.362 	Validation Loss 0.8092 	Validation Prec@1 74.576 	
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:43 - INFO - TRAINING - Epoch: [39][0/4]	Time 0.153 (0.153)	Data 0.148 (0.148)	Loss 0.1924 (0.1924)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:43 - INFO - EVALUATING - Epoch: [39][0/1]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 1.1821 (1.1821)	Prec@1 69.492 (69.492)	
2022-01-05 15:43:43 - INFO - 
 Epoch: 40	Training Loss 0.2936 	Training Prec@1 89.787 	Validation Loss 1.1821 	Validation Prec@1 69.492 	
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:43 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:44 - INFO - TRAINING - Epoch: [40][0/4]	Time 0.154 (0.154)	Data 0.149 (0.149)	Loss 0.2269 (0.2269)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:44 - INFO - EVALUATING - Epoch: [40][0/1]	Time 0.150 (0.150)	Data 0.147 (0.147)	Loss 0.5880 (0.5880)	Prec@1 71.186 (71.186)	
2022-01-05 15:43:44 - INFO - 
 Epoch: 41	Training Loss 0.3306 	Training Prec@1 89.362 	Validation Loss 0.5880 	Validation Prec@1 71.186 	
2022-01-05 15:43:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:44 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:44 - INFO - TRAINING - Epoch: [41][0/4]	Time 0.154 (0.154)	Data 0.149 (0.149)	Loss 0.3643 (0.3643)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:44 - INFO - EVALUATING - Epoch: [41][0/1]	Time 0.157 (0.157)	Data 0.154 (0.154)	Loss 0.8529 (0.8529)	Prec@1 76.271 (76.271)	
2022-01-05 15:43:44 - INFO - 
 Epoch: 42	Training Loss 0.3020 	Training Prec@1 91.064 	Validation Loss 0.8529 	Validation Prec@1 76.271 	
2022-01-05 15:43:44 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:44 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:44 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:44 - INFO - TRAINING - Epoch: [42][0/4]	Time 0.154 (0.154)	Data 0.149 (0.149)	Loss 0.3458 (0.3458)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:45 - INFO - EVALUATING - Epoch: [42][0/1]	Time 0.150 (0.150)	Data 0.147 (0.147)	Loss 0.6786 (0.6786)	Prec@1 76.271 (76.271)	
2022-01-05 15:43:45 - INFO - 
 Epoch: 43	Training Loss 0.2884 	Training Prec@1 92.340 	Validation Loss 0.6786 	Validation Prec@1 76.271 	
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:45 - INFO - TRAINING - Epoch: [43][0/4]	Time 0.153 (0.153)	Data 0.148 (0.148)	Loss 0.2398 (0.2398)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:45 - INFO - EVALUATING - Epoch: [43][0/1]	Time 0.148 (0.148)	Data 0.146 (0.146)	Loss 0.6948 (0.6948)	Prec@1 76.271 (76.271)	
2022-01-05 15:43:45 - INFO - 
 Epoch: 44	Training Loss 0.2786 	Training Prec@1 93.191 	Validation Loss 0.6948 	Validation Prec@1 76.271 	
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:45 - INFO - TRAINING - Epoch: [44][0/4]	Time 0.155 (0.155)	Data 0.148 (0.148)	Loss 0.3548 (0.3548)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:45 - INFO - EVALUATING - Epoch: [44][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 0.7197 (0.7197)	Prec@1 76.271 (76.271)	
2022-01-05 15:43:45 - INFO - 
 Epoch: 45	Training Loss 0.2862 	Training Prec@1 91.915 	Validation Loss 0.7197 	Validation Prec@1 76.271 	
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:45 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:45 - INFO - TRAINING - Epoch: [45][0/4]	Time 0.152 (0.152)	Data 0.145 (0.145)	Loss 0.0885 (0.0885)	Prec@1 98.438 (98.438)	
2022-01-05 15:43:46 - INFO - EVALUATING - Epoch: [45][0/1]	Time 0.148 (0.148)	Data 0.146 (0.146)	Loss 0.6030 (0.6030)	Prec@1 74.576 (74.576)	
2022-01-05 15:43:46 - INFO - 
 Epoch: 46	Training Loss 0.2895 	Training Prec@1 92.766 	Validation Loss 0.6030 	Validation Prec@1 74.576 	
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:46 - INFO - TRAINING - Epoch: [46][0/4]	Time 0.154 (0.154)	Data 0.147 (0.147)	Loss 0.2777 (0.2777)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:46 - INFO - EVALUATING - Epoch: [46][0/1]	Time 0.149 (0.149)	Data 0.146 (0.146)	Loss 0.7747 (0.7747)	Prec@1 74.576 (74.576)	
2022-01-05 15:43:46 - INFO - 
 Epoch: 47	Training Loss 0.3031 	Training Prec@1 91.915 	Validation Loss 0.7747 	Validation Prec@1 74.576 	
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:46 - INFO - TRAINING - Epoch: [47][0/4]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.3616 (0.3616)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:46 - INFO - EVALUATING - Epoch: [47][0/1]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.6437 (0.6437)	Prec@1 76.271 (76.271)	
2022-01-05 15:43:46 - INFO - 
 Epoch: 48	Training Loss 0.3046 	Training Prec@1 92.340 	Validation Loss 0.6437 	Validation Prec@1 76.271 	
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:46 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:47 - INFO - TRAINING - Epoch: [48][0/4]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.1777 (0.1777)	Prec@1 95.312 (95.312)	
2022-01-05 15:43:47 - INFO - EVALUATING - Epoch: [48][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.6713 (0.6713)	Prec@1 74.576 (74.576)	
2022-01-05 15:43:47 - INFO - 
 Epoch: 49	Training Loss 0.2554 	Training Prec@1 94.043 	Validation Loss 0.6713 	Validation Prec@1 74.576 	
2022-01-05 15:43:47 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:47 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:47 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:47 - INFO - TRAINING - Epoch: [49][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.2466 (0.2466)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:47 - INFO - EVALUATING - Epoch: [49][0/1]	Time 0.151 (0.151)	Data 0.149 (0.149)	Loss 0.6277 (0.6277)	Prec@1 76.271 (76.271)	
2022-01-05 15:43:47 - INFO - 
 Epoch: 50	Training Loss 0.3271 	Training Prec@1 91.064 	Validation Loss 0.6277 	Validation Prec@1 76.271 	
