2022-01-05 15:43:08 - INFO - saving to ./results/small/quantise/q6/penn-ml/heart-statlog/heart-statlog_test1/
2022-01-05 15:43:08 - DEBUG - run arguments: Namespace(config='./configs/config_small.json', data='../../paper_bench/complete/quantise/q6/penn-ml/heart-statlog/heart-statlog_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/small/quantise/q6/penn-ml/heart-statlog/heart-statlog_test1/', test='../../paper_bench/cv/test/quantise/q6/penn-ml/heart-statlog/heart-statlog_test1_data.csv', train='../../paper_bench/cv/train/quantise/q6/penn-ml/heart-statlog/heart-statlog_train1_data.csv')
2022-01-05 15:43:08 - INFO - creating model mlp_binary
2022-01-05 15:43:08 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [10, 5, 5, 2]}
2022-01-05 15:43:08 - INFO - number of parameters: 677
2022-01-05 15:43:08 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:08 - INFO - TRAINING - Epoch: [0][0/4]	Time 0.155 (0.155)	Data 0.147 (0.147)	Loss 1.0305 (1.0305)	Prec@1 54.688 (54.688)	
2022-01-05 15:43:09 - INFO - EVALUATING - Epoch: [0][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.7517 (0.7517)	Prec@1 68.519 (68.519)	
2022-01-05 15:43:09 - INFO - 
 Epoch: 1	Training Loss 0.6636 	Training Prec@1 73.148 	Validation Loss 0.7517 	Validation Prec@1 68.519 	
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:09 - INFO - TRAINING - Epoch: [1][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5460 (0.5460)	Prec@1 78.125 (78.125)	
2022-01-05 15:43:09 - INFO - EVALUATING - Epoch: [1][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.4980 (0.4980)	Prec@1 81.481 (81.481)	
2022-01-05 15:43:09 - INFO - 
 Epoch: 2	Training Loss 0.4829 	Training Prec@1 81.944 	Validation Loss 0.4980 	Validation Prec@1 81.481 	
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:09 - INFO - TRAINING - Epoch: [2][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3406 (0.3406)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:09 - INFO - EVALUATING - Epoch: [2][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.6930 (0.6930)	Prec@1 72.222 (72.222)	
2022-01-05 15:43:09 - INFO - 
 Epoch: 3	Training Loss 0.4451 	Training Prec@1 84.259 	Validation Loss 0.6930 	Validation Prec@1 72.222 	
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:09 - INFO - TRAINING - Epoch: [3][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4560 (0.4560)	Prec@1 84.375 (84.375)	
2022-01-05 15:43:10 - INFO - EVALUATING - Epoch: [3][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.5747 (0.5747)	Prec@1 77.778 (77.778)	
2022-01-05 15:43:10 - INFO - 
 Epoch: 4	Training Loss 0.3796 	Training Prec@1 87.500 	Validation Loss 0.5747 	Validation Prec@1 77.778 	
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:10 - INFO - TRAINING - Epoch: [4][0/4]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.5195 (0.5195)	Prec@1 79.688 (79.688)	
2022-01-05 15:43:10 - INFO - EVALUATING - Epoch: [4][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.8516 (0.8516)	Prec@1 70.370 (70.370)	
2022-01-05 15:43:10 - INFO - 
 Epoch: 5	Training Loss 0.4022 	Training Prec@1 85.185 	Validation Loss 0.8516 	Validation Prec@1 70.370 	
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:10 - INFO - TRAINING - Epoch: [5][0/4]	Time 0.149 (0.149)	Data 0.143 (0.143)	Loss 0.2575 (0.2575)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:10 - INFO - EVALUATING - Epoch: [5][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.6906 (0.6906)	Prec@1 53.704 (53.704)	
2022-01-05 15:43:10 - INFO - 
 Epoch: 6	Training Loss 0.3992 	Training Prec@1 87.500 	Validation Loss 0.6906 	Validation Prec@1 53.704 	
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:10 - INFO - TRAINING - Epoch: [6][0/4]	Time 0.148 (0.148)	Data 0.143 (0.143)	Loss 0.6975 (0.6975)	Prec@1 50.000 (50.000)	
2022-01-05 15:43:11 - INFO - EVALUATING - Epoch: [6][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.1394 (1.1394)	Prec@1 62.963 (62.963)	
2022-01-05 15:43:11 - INFO - 
 Epoch: 7	Training Loss 0.4565 	Training Prec@1 77.778 	Validation Loss 1.1394 	Validation Prec@1 62.963 	
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:11 - INFO - TRAINING - Epoch: [7][0/4]	Time 0.149 (0.149)	Data 0.143 (0.143)	Loss 0.3631 (0.3631)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:11 - INFO - EVALUATING - Epoch: [7][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 1.0225 (1.0225)	Prec@1 75.926 (75.926)	
2022-01-05 15:43:11 - INFO - 
 Epoch: 8	Training Loss 0.5065 	Training Prec@1 75.463 	Validation Loss 1.0225 	Validation Prec@1 75.926 	
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:11 - INFO - TRAINING - Epoch: [8][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4085 (0.4085)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:11 - INFO - EVALUATING - Epoch: [8][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.1095 (1.1095)	Prec@1 75.926 (75.926)	
2022-01-05 15:43:11 - INFO - 
 Epoch: 9	Training Loss 0.5602 	Training Prec@1 74.074 	Validation Loss 1.1095 	Validation Prec@1 75.926 	
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:11 - INFO - TRAINING - Epoch: [9][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5092 (0.5092)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:12 - INFO - EVALUATING - Epoch: [9][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8783 (0.8783)	Prec@1 62.963 (62.963)	
2022-01-05 15:43:12 - INFO - 
 Epoch: 10	Training Loss 0.4840 	Training Prec@1 84.259 	Validation Loss 0.8783 	Validation Prec@1 62.963 	
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:12 - INFO - TRAINING - Epoch: [10][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3905 (0.3905)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:12 - INFO - EVALUATING - Epoch: [10][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 1.3074 (1.3074)	Prec@1 75.926 (75.926)	
2022-01-05 15:43:12 - INFO - 
 Epoch: 11	Training Loss 0.4917 	Training Prec@1 85.648 	Validation Loss 1.3074 	Validation Prec@1 75.926 	
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:12 - INFO - TRAINING - Epoch: [11][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.3945 (0.3945)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:12 - INFO - EVALUATING - Epoch: [11][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 1.0551 (1.0551)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:12 - INFO - 
 Epoch: 12	Training Loss 0.4750 	Training Prec@1 85.185 	Validation Loss 1.0551 	Validation Prec@1 74.074 	
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:12 - INFO - TRAINING - Epoch: [12][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4499 (0.4499)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:13 - INFO - EVALUATING - Epoch: [12][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.2149 (1.2149)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:13 - INFO - 
 Epoch: 13	Training Loss 0.6436 	Training Prec@1 73.148 	Validation Loss 1.2149 	Validation Prec@1 74.074 	
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:13 - INFO - TRAINING - Epoch: [13][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.6044 (0.6044)	Prec@1 82.812 (82.812)	
2022-01-05 15:43:13 - INFO - EVALUATING - Epoch: [13][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.0086 (1.0086)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:13 - INFO - 
 Epoch: 14	Training Loss 0.5745 	Training Prec@1 73.611 	Validation Loss 1.0086 	Validation Prec@1 74.074 	
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:13 - INFO - TRAINING - Epoch: [14][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2881 (0.2881)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:13 - INFO - EVALUATING - Epoch: [14][0/1]	Time 0.144 (0.144)	Data 0.141 (0.141)	Loss 1.0827 (1.0827)	Prec@1 75.926 (75.926)	
2022-01-05 15:43:13 - INFO - 
 Epoch: 15	Training Loss 0.3996 	Training Prec@1 88.889 	Validation Loss 1.0827 	Validation Prec@1 75.926 	
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:13 - INFO - TRAINING - Epoch: [15][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2689 (0.2689)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:14 - INFO - EVALUATING - Epoch: [15][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.2890 (1.2890)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:14 - INFO - 
 Epoch: 16	Training Loss 0.3977 	Training Prec@1 85.185 	Validation Loss 1.2890 	Validation Prec@1 74.074 	
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:14 - INFO - TRAINING - Epoch: [16][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.5000 (0.5000)	Prec@1 78.125 (78.125)	
2022-01-05 15:43:14 - INFO - EVALUATING - Epoch: [16][0/1]	Time 0.143 (0.143)	Data 0.141 (0.141)	Loss 1.1631 (1.1631)	Prec@1 75.926 (75.926)	
2022-01-05 15:43:14 - INFO - 
 Epoch: 17	Training Loss 0.4874 	Training Prec@1 79.167 	Validation Loss 1.1631 	Validation Prec@1 75.926 	
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:14 - INFO - TRAINING - Epoch: [17][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.6306 (0.6306)	Prec@1 81.250 (81.250)	
2022-01-05 15:43:14 - INFO - EVALUATING - Epoch: [17][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.6907 (0.6907)	Prec@1 53.704 (53.704)	
2022-01-05 15:43:14 - INFO - 
 Epoch: 18	Training Loss 0.5285 	Training Prec@1 78.241 	Validation Loss 0.6907 	Validation Prec@1 53.704 	
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:14 - INFO - TRAINING - Epoch: [18][0/4]	Time 0.147 (0.147)	Data 0.142 (0.142)	Loss 0.6733 (0.6733)	Prec@1 62.500 (62.500)	
2022-01-05 15:43:15 - INFO - EVALUATING - Epoch: [18][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.5320 (1.5320)	Prec@1 66.667 (66.667)	
2022-01-05 15:43:15 - INFO - 
 Epoch: 19	Training Loss 0.5972 	Training Prec@1 81.019 	Validation Loss 1.5320 	Validation Prec@1 66.667 	
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:15 - INFO - TRAINING - Epoch: [19][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4251 (0.4251)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:15 - INFO - EVALUATING - Epoch: [19][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.9561 (0.9561)	Prec@1 75.926 (75.926)	
2022-01-05 15:43:15 - INFO - 
 Epoch: 20	Training Loss 0.6249 	Training Prec@1 76.389 	Validation Loss 0.9561 	Validation Prec@1 75.926 	
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:15 - INFO - TRAINING - Epoch: [20][0/4]	Time 0.156 (0.156)	Data 0.151 (0.151)	Loss 0.4025 (0.4025)	Prec@1 84.375 (84.375)	
2022-01-05 15:43:15 - INFO - EVALUATING - Epoch: [20][0/1]	Time 0.152 (0.152)	Data 0.149 (0.149)	Loss 1.0839 (1.0839)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:15 - INFO - 
 Epoch: 21	Training Loss 0.4338 	Training Prec@1 83.796 	Validation Loss 1.0839 	Validation Prec@1 74.074 	
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:15 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:16 - INFO - TRAINING - Epoch: [21][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.7993 (0.7993)	Prec@1 75.000 (75.000)	
2022-01-05 15:43:16 - INFO - EVALUATING - Epoch: [21][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.9315 (0.9315)	Prec@1 75.926 (75.926)	
2022-01-05 15:43:16 - INFO - 
 Epoch: 22	Training Loss 0.5314 	Training Prec@1 78.241 	Validation Loss 0.9315 	Validation Prec@1 75.926 	
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:16 - INFO - TRAINING - Epoch: [22][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.1977 (0.1977)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:16 - INFO - EVALUATING - Epoch: [22][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.8660 (0.8660)	Prec@1 70.370 (70.370)	
2022-01-05 15:43:16 - INFO - 
 Epoch: 23	Training Loss 0.3707 	Training Prec@1 83.796 	Validation Loss 0.8660 	Validation Prec@1 70.370 	
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:16 - INFO - TRAINING - Epoch: [23][0/4]	Time 0.153 (0.153)	Data 0.148 (0.148)	Loss 0.3556 (0.3556)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:16 - INFO - EVALUATING - Epoch: [23][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.7688 (0.7688)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:16 - INFO - 
 Epoch: 24	Training Loss 0.3739 	Training Prec@1 86.111 	Validation Loss 0.7688 	Validation Prec@1 74.074 	
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:16 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:17 - INFO - TRAINING - Epoch: [24][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.3171 (0.3171)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:17 - INFO - EVALUATING - Epoch: [24][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.3211 (1.3211)	Prec@1 68.519 (68.519)	
2022-01-05 15:43:17 - INFO - 
 Epoch: 25	Training Loss 0.3487 	Training Prec@1 87.963 	Validation Loss 1.3211 	Validation Prec@1 68.519 	
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:17 - INFO - TRAINING - Epoch: [25][0/4]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.3233 (0.3233)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:17 - INFO - EVALUATING - Epoch: [25][0/1]	Time 0.144 (0.144)	Data 0.142 (0.142)	Loss 0.8756 (0.8756)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:17 - INFO - 
 Epoch: 26	Training Loss 0.3504 	Training Prec@1 86.574 	Validation Loss 0.8756 	Validation Prec@1 74.074 	
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:17 - INFO - TRAINING - Epoch: [26][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.4416 (0.4416)	Prec@1 87.500 (87.500)	
2022-01-05 15:43:17 - INFO - EVALUATING - Epoch: [26][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.7384 (0.7384)	Prec@1 75.926 (75.926)	
2022-01-05 15:43:17 - INFO - 
 Epoch: 27	Training Loss 0.3578 	Training Prec@1 87.500 	Validation Loss 0.7384 	Validation Prec@1 75.926 	
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:17 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:18 - INFO - TRAINING - Epoch: [27][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2776 (0.2776)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:18 - INFO - EVALUATING - Epoch: [27][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.5658 (0.5658)	Prec@1 77.778 (77.778)	
2022-01-05 15:43:18 - INFO - 
 Epoch: 28	Training Loss 0.3412 	Training Prec@1 90.741 	Validation Loss 0.5658 	Validation Prec@1 77.778 	
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:18 - INFO - TRAINING - Epoch: [28][0/4]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 0.2950 (0.2950)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:18 - INFO - EVALUATING - Epoch: [28][0/1]	Time 0.143 (0.143)	Data 0.140 (0.140)	Loss 1.1022 (1.1022)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:18 - INFO - 
 Epoch: 29	Training Loss 0.3038 	Training Prec@1 90.741 	Validation Loss 1.1022 	Validation Prec@1 74.074 	
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:18 - INFO - TRAINING - Epoch: [29][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.4726 (0.4726)	Prec@1 84.375 (84.375)	
2022-01-05 15:43:18 - INFO - EVALUATING - Epoch: [29][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.1865 (1.1865)	Prec@1 77.778 (77.778)	
2022-01-05 15:43:18 - INFO - 
 Epoch: 30	Training Loss 0.3193 	Training Prec@1 91.204 	Validation Loss 1.1865 	Validation Prec@1 77.778 	
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:18 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:19 - INFO - TRAINING - Epoch: [30][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.2267 (0.2267)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:19 - INFO - EVALUATING - Epoch: [30][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.5657 (0.5657)	Prec@1 77.778 (77.778)	
2022-01-05 15:43:19 - INFO - 
 Epoch: 31	Training Loss 0.2851 	Training Prec@1 89.352 	Validation Loss 0.5657 	Validation Prec@1 77.778 	
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:19 - INFO - TRAINING - Epoch: [31][0/4]	Time 0.149 (0.149)	Data 0.144 (0.144)	Loss 0.2218 (0.2218)	Prec@1 95.312 (95.312)	
2022-01-05 15:43:19 - INFO - EVALUATING - Epoch: [31][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.2082 (1.2082)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:19 - INFO - 
 Epoch: 32	Training Loss 0.3014 	Training Prec@1 90.278 	Validation Loss 1.2082 	Validation Prec@1 74.074 	
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:19 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:19 - INFO - TRAINING - Epoch: [32][0/4]	Time 0.155 (0.155)	Data 0.150 (0.150)	Loss 0.2913 (0.2913)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:20 - INFO - EVALUATING - Epoch: [32][0/1]	Time 0.147 (0.147)	Data 0.145 (0.145)	Loss 0.5318 (0.5318)	Prec@1 79.630 (79.630)	
2022-01-05 15:43:20 - INFO - 
 Epoch: 33	Training Loss 0.3507 	Training Prec@1 86.574 	Validation Loss 0.5318 	Validation Prec@1 79.630 	
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:20 - INFO - TRAINING - Epoch: [33][0/4]	Time 0.149 (0.149)	Data 0.143 (0.143)	Loss 0.2994 (0.2994)	Prec@1 92.188 (92.188)	
2022-01-05 15:43:20 - INFO - EVALUATING - Epoch: [33][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 1.1700 (1.1700)	Prec@1 72.222 (72.222)	
2022-01-05 15:43:20 - INFO - 
 Epoch: 34	Training Loss 0.2721 	Training Prec@1 91.204 	Validation Loss 1.1700 	Validation Prec@1 72.222 	
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:20 - INFO - TRAINING - Epoch: [34][0/4]	Time 0.150 (0.150)	Data 0.144 (0.144)	Loss 0.2193 (0.2193)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:20 - INFO - EVALUATING - Epoch: [34][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.9843 (0.9843)	Prec@1 77.778 (77.778)	
2022-01-05 15:43:20 - INFO - 
 Epoch: 35	Training Loss 0.3621 	Training Prec@1 88.426 	Validation Loss 0.9843 	Validation Prec@1 77.778 	
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:20 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:20 - INFO - TRAINING - Epoch: [35][0/4]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.1913 (0.1913)	Prec@1 92.188 (92.188)	
2022-01-05 15:43:21 - INFO - EVALUATING - Epoch: [35][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 1.2506 (1.2506)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:21 - INFO - 
 Epoch: 36	Training Loss 0.2875 	Training Prec@1 89.352 	Validation Loss 1.2506 	Validation Prec@1 74.074 	
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:21 - INFO - TRAINING - Epoch: [36][0/4]	Time 0.155 (0.155)	Data 0.149 (0.149)	Loss 0.2733 (0.2733)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:21 - INFO - EVALUATING - Epoch: [36][0/1]	Time 0.153 (0.153)	Data 0.150 (0.150)	Loss 1.4975 (1.4975)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:21 - INFO - 
 Epoch: 37	Training Loss 0.5063 	Training Prec@1 77.778 	Validation Loss 1.4975 	Validation Prec@1 74.074 	
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:21 - INFO - TRAINING - Epoch: [37][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.2804 (0.2804)	Prec@1 92.188 (92.188)	
2022-01-05 15:43:21 - INFO - EVALUATING - Epoch: [37][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8526 (0.8526)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:21 - INFO - 
 Epoch: 38	Training Loss 0.2617 	Training Prec@1 90.741 	Validation Loss 0.8526 	Validation Prec@1 74.074 	
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:21 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:22 - INFO - TRAINING - Epoch: [38][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1541 (0.1541)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:22 - INFO - EVALUATING - Epoch: [38][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8526 (0.8526)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:22 - INFO - 
 Epoch: 39	Training Loss 0.2668 	Training Prec@1 87.963 	Validation Loss 0.8526 	Validation Prec@1 74.074 	
2022-01-05 15:43:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:22 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:22 - INFO - TRAINING - Epoch: [39][0/4]	Time 0.154 (0.154)	Data 0.149 (0.149)	Loss 0.2799 (0.2799)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:22 - INFO - EVALUATING - Epoch: [39][0/1]	Time 0.154 (0.154)	Data 0.151 (0.151)	Loss 1.0626 (1.0626)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:22 - INFO - 
 Epoch: 40	Training Loss 0.3278 	Training Prec@1 88.426 	Validation Loss 1.0626 	Validation Prec@1 74.074 	
2022-01-05 15:43:22 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:22 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:22 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:22 - INFO - TRAINING - Epoch: [40][0/4]	Time 0.177 (0.177)	Data 0.170 (0.170)	Loss 0.3960 (0.3960)	Prec@1 92.188 (92.188)	
2022-01-05 15:43:22 - INFO - EVALUATING - Epoch: [40][0/1]	Time 0.146 (0.146)	Data 0.144 (0.144)	Loss 1.2688 (1.2688)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:22 - INFO - 
 Epoch: 41	Training Loss 0.3257 	Training Prec@1 91.667 	Validation Loss 1.2688 	Validation Prec@1 74.074 	
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:23 - INFO - TRAINING - Epoch: [41][0/4]	Time 0.151 (0.151)	Data 0.146 (0.146)	Loss 0.6589 (0.6589)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:23 - INFO - EVALUATING - Epoch: [41][0/1]	Time 0.145 (0.145)	Data 0.142 (0.142)	Loss 0.5711 (0.5711)	Prec@1 83.333 (83.333)	
2022-01-05 15:43:23 - INFO - 
 Epoch: 42	Training Loss 0.3504 	Training Prec@1 89.815 	Validation Loss 0.5711 	Validation Prec@1 83.333 	
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:23 - INFO - TRAINING - Epoch: [42][0/4]	Time 0.156 (0.156)	Data 0.151 (0.151)	Loss 0.6644 (0.6644)	Prec@1 51.562 (51.562)	
2022-01-05 15:43:23 - INFO - EVALUATING - Epoch: [42][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.0982 (1.0982)	Prec@1 72.222 (72.222)	
2022-01-05 15:43:23 - INFO - 
 Epoch: 43	Training Loss 0.6198 	Training Prec@1 74.537 	Validation Loss 1.0982 	Validation Prec@1 72.222 	
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:23 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:23 - INFO - TRAINING - Epoch: [43][0/4]	Time 0.151 (0.151)	Data 0.145 (0.145)	Loss 0.3696 (0.3696)	Prec@1 89.062 (89.062)	
2022-01-05 15:43:24 - INFO - EVALUATING - Epoch: [43][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.8089 (0.8089)	Prec@1 75.926 (75.926)	
2022-01-05 15:43:24 - INFO - 
 Epoch: 44	Training Loss 0.3116 	Training Prec@1 89.352 	Validation Loss 0.8089 	Validation Prec@1 75.926 	
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:24 - INFO - TRAINING - Epoch: [44][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1950 (0.1950)	Prec@1 92.188 (92.188)	
2022-01-05 15:43:24 - INFO - EVALUATING - Epoch: [44][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.5539 (0.5539)	Prec@1 74.074 (74.074)	
2022-01-05 15:43:24 - INFO - 
 Epoch: 45	Training Loss 0.2345 	Training Prec@1 90.278 	Validation Loss 0.5539 	Validation Prec@1 74.074 	
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:24 - INFO - TRAINING - Epoch: [45][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.2763 (0.2763)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:24 - INFO - EVALUATING - Epoch: [45][0/1]	Time 0.147 (0.147)	Data 0.144 (0.144)	Loss 1.3916 (1.3916)	Prec@1 68.519 (68.519)	
2022-01-05 15:43:24 - INFO - 
 Epoch: 46	Training Loss 0.2153 	Training Prec@1 92.593 	Validation Loss 1.3916 	Validation Prec@1 68.519 	
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:24 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:25 - INFO - TRAINING - Epoch: [46][0/4]	Time 0.186 (0.186)	Data 0.181 (0.181)	Loss 0.2033 (0.2033)	Prec@1 96.875 (96.875)	
2022-01-05 15:43:25 - INFO - EVALUATING - Epoch: [46][0/1]	Time 0.148 (0.148)	Data 0.145 (0.145)	Loss 0.7729 (0.7729)	Prec@1 81.481 (81.481)	
2022-01-05 15:43:25 - INFO - 
 Epoch: 47	Training Loss 0.3512 	Training Prec@1 89.352 	Validation Loss 0.7729 	Validation Prec@1 81.481 	
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:25 - INFO - TRAINING - Epoch: [47][0/4]	Time 0.152 (0.152)	Data 0.147 (0.147)	Loss 0.2545 (0.2545)	Prec@1 85.938 (85.938)	
2022-01-05 15:43:25 - INFO - EVALUATING - Epoch: [47][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.9110 (0.9110)	Prec@1 66.667 (66.667)	
2022-01-05 15:43:25 - INFO - 
 Epoch: 48	Training Loss 0.3316 	Training Prec@1 87.963 	Validation Loss 0.9110 	Validation Prec@1 66.667 	
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:25 - INFO - TRAINING - Epoch: [48][0/4]	Time 0.154 (0.154)	Data 0.147 (0.147)	Loss 0.2696 (0.2696)	Prec@1 90.625 (90.625)	
2022-01-05 15:43:25 - INFO - EVALUATING - Epoch: [48][0/1]	Time 0.146 (0.146)	Data 0.143 (0.143)	Loss 0.7940 (0.7940)	Prec@1 70.370 (70.370)	
2022-01-05 15:43:25 - INFO - 
 Epoch: 49	Training Loss 0.3179 	Training Prec@1 89.352 	Validation Loss 0.7940 	Validation Prec@1 70.370 	
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-05 15:43:25 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-05 15:43:26 - INFO - TRAINING - Epoch: [49][0/4]	Time 0.150 (0.150)	Data 0.145 (0.145)	Loss 0.1538 (0.1538)	Prec@1 93.750 (93.750)	
2022-01-05 15:43:26 - INFO - EVALUATING - Epoch: [49][0/1]	Time 0.145 (0.145)	Data 0.143 (0.143)	Loss 0.8677 (0.8677)	Prec@1 62.963 (62.963)	
2022-01-05 15:43:26 - INFO - 
 Epoch: 50	Training Loss 0.2978 	Training Prec@1 90.741 	Validation Loss 0.8677 	Validation Prec@1 62.963 	
